Document,Text Content,Code,Full Length,len,tloc,cloc,tpos1,tpos2,clen,tlen,ppau,npau,aa,begauth,has_code,first_turn,last_turn
1 37_tensorflow.doc,Node.js (JavaScript) Wrapper API,Expected Behaviour,32,32,0.5,0.002293577982,0,1,1,0.05555555556,0,0.0004647668033,NONE,TRUE,FALSE,TRUE,FALSE
1 37_tensorflow.doc,Because JavaScript is Awesome,Motivation,29,29,1,0.004587155963,0,1,1,0.05555555556,0,0.0004647668033,NONE,TRUE,FALSE,TRUE,FALSE
1 37_tensorflow.doc,+1!,Social Conversation,3,3,1,0.006880733945,2.58E-05,0.9999741703,1,0.01388888889,0.0004647668033,0.0009160332375,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.009174311927,7.67E-05,0.9999232613,1,0.01388888889,0.0009160332375,0.00104373345,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.01146788991,0.0001347447366,0.9998652553,1,0.01388888889,0.00104373345,0.001373053927,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.01376146789,0.0002110529379,0.9997889471,1,0.01388888889,0.001373053927,0.0002084811089,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Just what I was searching for.,Social Conversation,30,30,0.1428571429,0.01605504587,0.0002226393863,0.9997773606,0.1935483871,0.08333333333,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,0.2857142857,0.01834862385,0.0002226393863,0.9997773606,0.03225806452,0.01388888889,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,As quoted from the offical website http://www.tensorflow.org/,Motivation,61,61,0.4285714286,0.02064220183,0.0002226393863,0.9997773606,0.2258064516,0.09722222222,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"weâre hoping to entice you to contribute SWIG interfaces to your favorite language -- be it Go, Java, Lua, Javascript, or R.",Contribution and Commitment,124,124,0.5714285714,0.02293577982,0.0002226393863,0.9997773606,0.7096774194,0.3055555556,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I am new to this whole SWIG thing but searched around and found this. http://www.swig.org/Doc3.0/Javascript.html,Solution Discussion,112,112,0.7142857143,0.0252293578,0.0002226393863,0.9997773606,0.4838709677,0.2083333333,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Not really sure how this works.,Solution Discussion,31,31,0.8571428571,0.02752293578,0.0002226393863,0.9997773606,0.1935483871,0.08333333333,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Do we need to write swig interface file specifically for Javascript or is it auto-generated when running some commands or is somebody already working on this (this would be awesome) ?,Solution Discussion,183,183,1,0.02981651376,0.0002226393863,0.9997773606,1,0.4305555556,0.0002084811089,0.0003691576323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 :+1:,Social Conversation,7,7,1,0.03211009174,0.0002431555178,0.9997568445,1,0.02777777778,0.0003691576323,0.0004247083312,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.03440366972,0.0002667589089,0.9997332411,1,0.01388888889,0.0004247083312,0.001126727522,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.03669724771,0.0003293773894,0.9996706226,1,0.01388888889,0.001126727522,0.0001801524656,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.03899082569,0.0003393894584,0.9996606105,1,0.01388888889,0.0001801524656,0.000502169465,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.04128440367,0.0003672977931,0.9996327022,1,0.01388888889,0.000502169465,0.0004087734693,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.04357798165,0.0003900155958,0.9996099844,1,0.01388888889,0.0004087734693,0.0002144566821,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.04587155963,0.0004019341398,0.9995980659,1,0.01388888889,0.0002144566821,0.004187991532,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1!,Social Conversation,3,3,0.3333333333,0.04816513761,0.0006346839938,0.999365316,0.04347826087,0.01388888889,0.004187991532,0.0001418645338,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Just starting out on one, but new to writing a nodejs addon.",Contribution and Commitment,60,60,0.6666666667,0.0504587156,0.0006346839938,0.999365316,0.5217391304,0.1666666667,0.004187991532,0.0001418645338,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Checking out the swig interface files to see if they're going to be helpful, or if I should just use the c++ API.",Solution Discussion,113,113,1,0.05275229358,0.0006346839938,0.999365316,1,0.3194444444,0.004187991532,0.0001418645338,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.05504587156,0.0006425681906,0.9993574318,1,0.01388888889,0.0001418645338,0.0001602338884,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.05733944954,0.0006514732741,0.9993485267,1,0.01388888889,0.0001602338884,0.002999516421,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.05963302752,0.0008181729925,0.999181827,1,0.01388888889,0.002999516421,0.0001887838491,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.0619266055,0.0008286647552,0.9991713352,1,0.01388888889,0.0001887838491,0.006994519071,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"This is something the core TensorFlow team is unlikely to tackle in the near future, so if you want to contribute it, please go ahead!",Contribution and Commitment,134,134,0.5,0.06422018349,0.001217388868,0.9987826111,0.6756756757,0.3472222222,0.006994519071,0.004261247633,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I would recommend circulating a proposed implementation on the discuss mailing list early on, so that a consensus about where such API might live (in repo / off repo / in 'contrib' directory) can be reached ahead of time.",Solution Discussion,221,221,1,0.06651376147,0.001217388868,0.9987826111,1,0.5138888889,0.006994519071,0.004261247633,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Anyone up to write a NodeJS library?,Contribution and Commitment,36,36,0.1666666667,0.06880733945,0.001454209969,0.99854579,0.28,0.09722222222,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,0.3333333333,0.07110091743,0.001454209969,0.99854579,0.04,0.01388888889,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I think it would be better with a official NodeJS API however a community one will be as (if not more) interesting in my opinion.,Expected Behaviour,129,129,0.5,0.07339449541,0.001454209969,0.99854579,1,0.3472222222,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I know there are multiple ways of approaching this however I strongly recommend node-gyp for performance.,Solution Discussion,105,105,0.6666666667,0.07568807339,0.001454209969,0.99854579,0.68,0.2361111111,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I will gladly contribute in any way I can, however, this is something I will not be able to do alone.",Contribution and Commitment,101,101,0.8333333333,0.07798165138,0.001454209969,0.99854579,0.84,0.2916666667,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Would be best if a few other people is interested as well, specially someone with C++ knowledge.",Contribution and Commitment,96,96,1,0.08027522936,0.001454209969,0.99854579,0.68,0.2361111111,0.004261247633,0.002175772592,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.08256880734,0.001575129686,0.9984248703,1,0.01388888889,0.002175772592,1.04E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@Foorack I am willing to contribute it if some people are interested as well.,Contribution and Commitment,77,77,1,0.08486238532,0.001575707779,0.9984242922,1,0.1944444444,1.04E-05,9.27E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.0871559633,0.001580861411,0.9984191386,1,0.01388888889,9.27E-05,0.0006821006132,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,We hope more developers to discuss and contribute.,Contribution and Commitment,50,50,0.5,0.08944954128,0.001618769515,0.9983812305,1,0.1111111111,0.0006821006132,7.33E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thanks @Foorack !,Social Conversation,17,17,1,0.09174311927,0.001618769515,0.9983812305,0.25,0.02777777778,0.0006821006132,7.33E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I am willing to contribute.,Contribution and Commitment,27,27,0.5,0.09403669725,0.001622840762,0.9983771592,1,0.06944444444,7.33E-05,0.001375709738,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thanks for the initiative guys!,Social Conversation,31,31,1,0.09633027523,0.001622840762,0.9983771592,1,0.06944444444,7.33E-05,0.001375709738,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@miguelalche Glad to see you're interested!,Social Conversation,43,43,0.5,0.09862385321,0.001699296561,0.9983007034,1,0.08333333333,0.001375709738,0.3330465796,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,^^,Social Conversation,2,2,1,0.1009174312,0.001699296561,0.9983007034,0.1666666667,0.01388888889,0.001375709738,0.3330465796,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1032110092,0.02020853713,0.9797914629,1,0.01388888889,0.3330465796,0.05306596701,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Hooray for node!,Social Conversation,16,16,0.5,0.1055045872,0.02315770643,0.9768422936,1,0.04166666667,0.05306596701,0.0276474279,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Let's do this.,Social Conversation,14,14,1,0.1077981651,0.02315770643,0.9768422936,1,0.04166666667,0.05306596701,0.0276474279,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1100917431,0.02469422692,0.9753057731,1,0.01388888889,0.0276474279,0.03100791321,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1123853211,0.02641750817,0.9735824918,1,0.01388888889,0.03100791321,0.001023814872,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Here's a writeup on how to load and execute TensorFlow graphs using the C API: https://medium.com/jim-fleming/loading-tensorflow-graphs-via-host-languages-be10fd81876f (source code included),Solution Discussion,190,190,1,0.1146788991,0.02647440723,0.9735255928,1,0.2638888889,0.001023814872,0.01847204594,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The proposal will be released in the next week.,Solution Discussion,47,47,1,0.1169724771,0.02750100099,0.972498999,1,0.125,0.01847204594,0.010635635,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.119266055,0.02809208206,0.9719079179,1,0.01388888889,0.010635635,0.01651736955,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I have published my starting point -- https://github.com/nikhilk/node-tensorflow that will be published to npm later.,Task Progress,117,117,0.25,0.121559633,0.02901004364,0.9709899564,0.8823529412,0.2083333333,0.01651736955,0.001724506158,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@jimfleming - like your approach (we're both using ffi ... I did it to get started quickly).,Solution Discussion,92,92,0.5,0.123853211,0.02901004364,0.9709899564,0.8823529412,0.2083333333,0.01651736955,0.001724506158,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Are you going to take on building higher level framework-style APIs to replicate the python experience?,Task Progress,103,103,0.75,0.126146789,0.02901004364,0.9709899564,1,0.2361111111,0.01651736955,0.001724506158,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thats my next step.,Task Progress,19,19,1,0.128440367,0.02901004364,0.9709899564,0.2941176471,0.06944444444,0.01651736955,0.001724506158,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@nikhilk Thanks.,Social Conversation,16,16,0.5,0.130733945,0.02910588399,0.970894116,0.125,0.02777777778,0.001724506158,0.1562320249,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I'm only interested in loading graphs created in python and I think I like the minimalism.,Solution Discussion,90,90,1,0.1330275229,0.02910588399,0.970894116,1,0.2222222222,0.001724506158,0.1562320249,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1353211009,0.03778856176,0.9622114382,1,0.01388888889,0.1562320249,0.006959329585,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The proposal is released here with current progress.,Task Progress,52,52,0.5,0.1376146789,0.0381753302,0.9618246698,1,0.1111111111,0.006959329585,0.01060885558,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,https://github.com/node-tensorflow/node-tensorflow/tree/1.0.0,Task Progress,61,61,1,0.1399082569,0.0381753302,0.9618246698,0.125,0.01388888889,0.006959329585,0.01060885558,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1422018349,0.03876492298,0.961235077,1,0.01388888889,0.01060885558,0.06837007389,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1444954128,0.04256462615,0.9574353738,1,0.01388888889,0.06837007389,0.02889078976,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1467889908,0.04417024714,0.9558297529,1,0.01388888889,0.02889078976,0.001794442496,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1490825688,0.04426997423,0.9557300258,1,0.01388888889,0.001794442496,0.002504650435,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1513761468,0.04440917151,0.9555908285,1,0.01388888889,0.002504650435,0.02032203913,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1536697248,0.04553857963,0.9544614204,1,0.01388888889,0.02032203913,0.1015440217,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1559633028,0.05118194258,0.9488180574,1,0.01388888889,0.1015440217,0.1833290361,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1582568807,0.06137055114,0.9386294489,1,0.01388888889,0.1833290361,0.002434714096,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1605504587,0.06150586167,0.9384941383,1,0.01388888889,0.002434714096,0.003035591178,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1628440367,0.06167456626,0.9383254337,1,0.01388888889,0.003035591178,0.0133861692,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1651376147,0.06241850972,0.9375814903,1,0.01388888889,0.0133861692,0.02896227532,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1674311927,0.06402810356,0.9359718964,1,0.01388888889,0.02896227532,0.01406981904,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1697247706,0.06481004122,0.9351899588,1,0.01388888889,0.01406981904,0.02963463796,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1720183486,0.06645700197,0.933542998,1,0.01388888889,0.02963463796,0.05849599249,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1743119266,0.06970794783,0.9302920522,1,0.01388888889,0.05849599249,0.007222033488,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1766055046,0.07010931617,0.9298906838,1,0.01388888889,0.007222033488,0.1385345903,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I am very willing to contribute.,Contribution and Commitment,32,32,0.5,0.1788990826,0.07780844961,0.9221915504,0.6666666667,0.08333333333,0.1385345903,0.004404440072,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@Foorack please add me to what ever you can!,Social Conversation,44,44,1,0.1811926606,0.07780844961,0.9221915504,1,0.125,0.1385345903,0.004404440072,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@pushtheworldllc I'm glad you are interested.,Social Conversation,45,45,0.5,0.1834862385,0.07805322871,0.9219467713,1,0.08333333333,0.004404440072,0.009522850481,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:),Social Conversation,2,2,1,0.1857798165,0.07805322871,0.9219467713,0.1666666667,0.01388888889,0.004404440072,0.009522850481,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1880733945,0.07858246618,0.9214175338,1,0.01388888889,0.009522850481,0.0073712015,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1903669725,0.07899212462,0.9210078754,1,0.01388888889,0.0073712015,0.001621150873,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.1926605505,0.07908222094,0.9209177791,1,0.01388888889,0.001621150873,0.08136760952,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 :+1:,Social Conversation,7,7,1,0.1949541284,0.08360426906,0.9163957309,1,0.02777777778,0.08136760952,0.09653383558,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 :+1:,Social Conversation,7,7,1,0.1972477064,0.08896918825,0.9110308117,1,0.02777777778,0.09653383558,0.265083066,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I have a working prototype using SWIG here: https://github.com/node-tensorflow/node-tensorflow/pull/13,Task Progress,102,102,0.2,0.1995412844,0.1037013205,0.8962986795,0.2368421053,0.125,0.265083066,0.07059453633,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The next steps would be to define the areas that the bindings would initially cover (must be within the C++ API ) and start implementing the SWIG interface files for these.,Task Progress,172,172,0.4,0.2018348624,0.1037013205,0.8962986795,0.7894736842,0.4166666667,0.265083066,0.07059453633,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"If anyone has experience with SWIG, I'd love to collaborate, as it seems like a huge amount of the python SWIG interfaces are custom overrides etc. and I'm keen not to reproduce their work.",Contribution and Commitment,189,189,0.6,0.2041284404,0.1037013205,0.8962986795,0.9210526316,0.4861111111,0.265083066,0.07059453633,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Additionally, would be great to get some clarity from the tensorflow team on what API's would be good to initially cover as I'm sure their roadmap has many changes on the way, and I wouldn't want to conflict.",Expected Behaviour,208,208,0.8,0.2064220183,0.1037013205,0.8962986795,1,0.5277777778,0.265083066,0.07059453633,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,(cc @martinwicke ? ),Contribution and Commitment,20,20,1,0.2087155963,0.1037013205,0.8962986795,0.05263157895,0.02777777778,0.265083066,0.07059453633,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2110091743,0.1076246493,0.8923753507,1,0.01388888889,0.07059453633,0.0331659804,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 :+1:,Social Conversation,7,7,1,0.2133027523,0.1094678663,0.8905321337,1,0.02777777778,0.0331659804,0.1406758373,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2155963303,0.1172860007,0.8827139993,1,0.01388888889,0.1406758373,0.255129089,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2178899083,0.1314649353,0.8685350647,1,0.01388888889,0.255129089,0.149949263,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2201834862,0.1397984452,0.8602015548,1,0.01388888889,0.149949263,0.06698506881,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2224770642,0.143521176,0.856478824,1,0.01388888889,0.06698506881,0.07537765069,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2247706422,0.147710329,0.852289671,1,0.01388888889,0.07537765069,0.02199475699,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,please try use reactions button --> http://www.geekwire.com/2016/github-adds-reactions-keep-comments-track/ no more +1 comments xD,Social Conversation,130,130,1,0.2270642202,0.1489326993,0.8510673007,1,0.1666666667,0.02199475699,0.3160527134,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2293577982,0.1664974967,0.8335025033,1,0.01388888889,0.3160527134,0.005033424479,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.2316513761,0.166777232,0.833222768,1,0.01388888889,0.005033424479,0.2582538711,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2339449541,0.181129828,0.818870172,1,0.01388888889,0.2582538711,0.06623967139,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2362385321,0.184811133,0.815188867,1,0.01388888889,0.06623967139,0.01420703591,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2385321101,0.1856006965,0.8143993035,1,0.01388888889,0.01420703591,0.003082953128,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@peterbraden sorry for the prolonged silence.,Social Conversation,45,45,0.25,0.2408256881,0.1857720333,0.8142279667,0.2857142857,0.08333333333,0.003082953128,0.02229862595,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"We are building out the C++ API, and it will grow over time.",Solution Discussion,60,60,0.5,0.2431192661,0.1857720333,0.8142279667,0.619047619,0.1805555556,0.003082953128,0.02229862595,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I expect the most useful bits to be the parts that are needed to run an existing graph.,Solution Discussion,87,87,0.75,0.245412844,0.1857720333,0.8142279667,0.8571428571,0.25,0.003082953128,0.02229862595,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"The C++ graph building API is being redone right now, so it's not particularly useful to spend much time on it.",Solution Discussion,111,111,1,0.247706422,0.1857720333,0.8142279667,1,0.2916666667,0.003082953128,0.02229862595,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@martinwicke thanks for the encouragement.,Social Conversation,42,42,0.3333333333,0.25,0.1870112913,0.8129887087,0.2173913043,0.06944444444,0.02229862595,0.708526811,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I made an initial stab at it here: https://github.com/tensorflow/tensorflow/pull/2206 - this is just a proof of concept that gets the version string into nodejs.,Task Progress,161,161,0.6666666667,0.252293578,0.1870112913,0.8129887087,1,0.3194444444,0.02229862595,0.708526811,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I'll start work on adding the swig interfaces for the graph running stuff.,Task Progress,74,74,1,0.254587156,0.1870112913,0.8129887087,0.5652173913,0.1805555556,0.02229862595,0.708526811,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+10000,Social Conversation,6,6,1,0.2568807339,0.2263880451,0.7736119549,1,0.01388888889,0.708526811,0.0226086918,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2591743119,0.2276445352,0.7723554648,1,0.01388888889,0.0226086918,0.2970470709,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2614678899,0.2441530839,0.7558469161,1,0.01388888889,0.2970470709,0.1151068023,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,# +1,Social Conversation,4,4,1,0.2637614679,0.2505502056,0.7494497944,1,0.01388888889,0.1151068023,0.3442040813,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2660550459,0.2696795303,0.7303204697,1,0.01388888889,0.3442040813,0.1521422983,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2683486239,0.2781349193,0.7218650807,1,0.01388888889,0.1521422983,0.03349862064,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2706422018,0.279996623,0.720003377,1,0.01388888889,0.03349862064,0.1434033545,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,This would be interesting for pure front-end graph exportation for direct usage on web clients.,Motivation,95,95,0.5,0.2729357798,0.2879663406,0.7120336594,0.7619047619,0.2222222222,0.1434033545,0.06129056889,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Even if the desired inputs/outputs asked from the graph would be hard-coded in the exported JS ""sess.run"" equivalent function.",Expected Behaviour,126,126,1,0.2752293578,0.2879663406,0.7120336594,1,0.2916666667,0.1434033545,0.06129056889,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2775229358,0.2913725965,0.7086274035,1,0.01388888889,0.06129056889,0.16554905,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.2798165138,0.3005730729,0.6994269271,1,0.01388888889,0.16554905,0.122190955,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2821100917,0.3073639001,0.6926360999,1,0.01388888889,0.122190955,0.2341900166,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2844036697,0.3203791347,0.6796208653,1,0.01388888889,0.2341900166,0.1377274453,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2866972477,0.3280334106,0.6719665894,1,0.01388888889,0.1377274453,0.2645419447,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2889908257,0.3427354697,0.6572645303,1,0.01388888889,0.2645419447,0.005883505094,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.2912844037,0.3430624486,0.6569375514,1,0.01388888889,0.005883505094,0.02043978005,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Found this while looking into wether or not bindings existed already.,Social Conversation,69,69,0.1666666667,0.2935779817,0.3441984002,0.6558015998,0.3055555556,0.1527777778,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Going to learn some tensor flow via the current python API before researching more, but I have built nodejs bindings for C++ libs before and can tell you from experience that swig is the wrong way.",Solution Discussion,197,197,0.3333333333,0.2958715596,0.3441984002,0.6558015998,1,0.5,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,If you simply use the swig bindings then you will have synchronous blocking code in an async environment.,Solution Discussion,105,105,0.5,0.2981651376,0.3441984002,0.6558015998,0.5,0.25,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"The swig bindings do not run things on IO threads, they execute on the main event loop from what I understand/experienced.",Solution Discussion,122,122,0.6666666667,0.3004587156,0.3441984002,0.6558015998,0.6111111111,0.3055555556,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Once I have some basic tensor flow experience under my belt I'll likely be interested in building out proper bindings.,Contribution and Commitment,118,118,0.8333333333,0.3027522936,0.3441984002,0.6558015998,0.5555555556,0.2777777778,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"So if anyone is serious about that and/or wants more details on working with v8 modules, let me know.",Contribution and Commitment,101,101,1,0.3050458716,0.3441984002,0.6558015998,0.5277777778,0.2638888889,0.02043978005,0.1292799766,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Is there any link related to node-gyp binding for tensor flow API ??,Solution Discussion,68,68,1,0.3073394495,0.3513832036,0.6486167964,1,0.1805555556,0.1292799766,0.003344771761,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@dmcmorris I am seriously interested in lending a hand!,Contribution and Commitment,55,55,0.3333333333,0.3096330275,0.3515690911,0.6484309089,0.4736842105,0.125,0.003344771761,0.1714133005,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,What resources do you recommend for working with v8 modules?,Solution Discussion,60,60,0.6666666667,0.3119266055,0.3515690911,0.6484309089,0.5263157895,0.1388888889,0.003344771761,0.1714133005,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,We can assemble a team here and start diving into materials asap as this project is way overdue :),Contribution and Commitment,98,98,1,0.3142201835,0.3515690911,0.6484309089,1,0.2638888889,0.003344771761,0.1714133005,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3165137615,0.3610954763,0.6389045237,1,0.01388888889,0.1714133005,0.1014656753,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3188073394,0.3667344851,0.6332655149,1,0.01388888889,0.1014656753,0.06070739721,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3211009174,0.370108331,0.629891669,1,0.01388888889,0.06070739721,0.1560058384,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1s,Social Conversation,3,3,1,0.3233944954,0.3787784383,0.6212215617,1,0.01388888889,0.1560058384,0.08062287604,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Is there any update ??,Task Progress,22,22,0.5,0.3256880734,0.3832590974,0.6167409026,1,0.05555555556,0.08062287604,0.1116482733,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"
REFERENCE",Social Conversation,6,10,1,0.3279816514,0.3832590974,0.6167409026,0.5,0.02777777778,0.08062287604,0.1116482733,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Happy Anniversary TensorFlow !,Social Conversation,30,30,0.2,0.3302752294,0.3894640095,0.6105359905,0.2727272727,0.04166666667,0.1116482733,0.1289154667,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,https://research.googleblog.com/2016/11/celebrating-tensorflows-first-year.html,Social Conversation,79,79,0.4,0.3325688073,0.3894640095,0.6105359905,0.09090909091,0.01388888889,0.1116482733,0.1289154667,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I notice TensorFlow is now accessible from Go, Rust and Haskell.",Motivation,64,64,0.6,0.3348623853,0.3894640095,0.6105359905,1,0.1527777778,0.1116482733,0.1289154667,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Why ignore JavaScript ?,Motivation,23,23,0.8,0.3371559633,0.3894640095,0.6105359905,0.2727272727,0.04166666667,0.1116482733,0.1289154667,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Really waiting for a machine library in JavaScript.,Expected Behaviour,51,51,1,0.3394495413,0.3894640095,0.6105359905,0.7272727273,0.1111111111,0.1116482733,0.1289154667,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3417431193,0.3966285551,0.6033714449,1,0.01388888889,0.1289154667,0.123263681,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3440366972,0.4034789996,0.5965210004,1,0.01388888889,0.123263681,0.2128875408,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð¯ ð,Social Conversation,4,4,1,0.3463302752,0.4153103378,0.5846896622,1,0.02777777778,0.2128875408,0.1129128817,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3486238532,0.4215855312,0.5784144688,1,0.01388888889,0.1129128817,0.1150477105,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1.0000000000000000000000001,Social Conversation,28,28,1,0.3509174312,0.4279793688,0.5720206312,1,0.01388888889,0.1150477105,0.001093308575,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3532110092,0.42804013,0.57195987,1,0.01388888889,0.001093308575,0.02148838249,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3555045872,0.4292343583,0.5707656417,1,0.01388888889,0.02148838249,0.06064343644,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3577981651,0.4326046495,0.5673953505,1,0.01388888889,0.06064343644,0.03907670755,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.3600917431,0.4347763582,0.5652236418,1,0.01388888889,0.03907670755,0.003115708122,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I am looking forward to see a official Node.js API.,Social Conversation,51,51,0.1666666667,0.3623853211,0.4349495154,0.5650504846,0.4761904762,0.1388888889,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,But I think there are some problems.,Solution Discussion,36,36,0.3333333333,0.3646788991,0.4349495154,0.5650504846,0.3333333333,0.09722222222,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"1.         JavaScript have only 1 thread ,trainning  can block the whole process unless using callbacks or  other tricks.",Solution Discussion,121,121,0.5,0.3669724771,0.4349495154,0.5650504846,1,0.2916666667,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"2.         lack of other science labs, like numpy",Solution Discussion,49,49,0.6666666667,0.369266055,0.4349495154,0.5650504846,0.4285714286,0.125,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,3.         JavaScript only support 53bit precision.,Solution Discussion,51,51,0.8333333333,0.371559633,0.4349495154,0.5650504846,0.3333333333,0.09722222222,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"anyway, JavaScript is awesome!",Motivation,30,30,1,0.373853211,0.4349495154,0.5650504846,0.1904761905,0.05555555556,0.003115708122,0.2584362368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Is anybody working on this?,Task Progress,27,27,1,0.376146789,0.4493122465,0.5506877535,1,0.06944444444,0.2584362368,0.2040658243,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Looks very difficult.,Social Conversation,21,21,1,0.378440367,0.4606533131,0.5393466869,1,0.04166666667,0.2040658243,0.1785457004,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.380733945,0.4705760852,0.5294239148,1,0.01388888889,0.1785457004,0.02051170825,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,very need it!,Social Conversation,13,13,1,0.3830275229,0.4717160343,0.5282839657,1,0.04166666667,0.02051170825,0.0635462371,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@stackOverMind.,Social Conversation,15,15,0.125,0.3853211009,0.4752476502,0.5247523498,0.03333333333,0.01388888889,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Did a little search on those bullet points.,Social Conversation,43,43,0.25,0.3876146789,0.4752476502,0.5247523498,0.2666666667,0.1111111111,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I've not tried any of these and they might not be efficient to use / run but it looks like there are things that exist to potentially solve those issues.,Solution Discussion,153,153,0.375,0.3899082569,0.4752476502,0.5247523498,1,0.4166666667,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         [taking advantage of multi processor environments in node js] URL,Solution Discussion,171,76,0.5,0.3922018349,0.4752476502,0.5247523498,0.3666666667,0.1527777778,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         [node-lapack] URL,Solution Discussion,67,28,0.625,0.3944954128,0.4752476502,0.5247523498,0.1333333333,0.05555555556,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         [Long.js] URL,Solution Discussion,55,24,0.75,0.3967889908,0.4752476502,0.5247523498,0.1,0.04166666667,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         [mljs] URL,Solution Discussion,41,21,0.875,0.3990825688,0.4752476502,0.5247523498,0.1,0.04166666667,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         [WebMonkeys - node GPU processing] URL,Solution Discussion,86,49,1,0.4013761468,0.4752476502,0.5247523498,0.2,0.08333333333,0.0635462371,0.3197097642,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4036697248,0.4930156902,0.5069843098,1,0.01388888889,0.3197097642,0.006507399198,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4059633028,0.4933773423,0.5066226577,1,0.01388888889,0.006507399198,0.01390095377,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 pweeettyyy pwease!!!,Social Conversation,23,23,1,0.4082568807,0.4941498952,0.5058501048,1,0.04166666667,0.01390095377,0.02346784644,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4105504587,0.4954541332,0.5045458668,1,0.01388888889,0.02346784644,0.1182638968,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4128440367,0.5020267121,0.4979732879,1,0.01388888889,0.1182638968,0.1156266772,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Looking forward to it.,Social Conversation,22,22,0.5,0.4151376147,0.5084527261,0.4915472739,1,0.05555555556,0.1156266772,0.004802368983,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.4174311927,0.5084527261,0.4915472739,0.25,0.01388888889,0.1156266772,0.004802368983,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4197247706,0.5087196203,0.4912803797,1,0.01388888889,0.004802368983,0.01110659869,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Looking forward to it.,Social Conversation,22,22,0.5,0.4220183486,0.5093368755,0.4906631245,1,0.05555555556,0.01110659869,0.063150964,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.4243119266,0.5093368755,0.4906631245,0.25,0.01388888889,0.01110659869,0.063150964,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.4266055046,0.5128465238,0.4871534762,1,0.01388888889,0.063150964,0.003100215895,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4288990826,0.51301882,0.48698118,1,0.01388888889,0.003100215895,0.0001876772615,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1.,Social Conversation,3,3,0.5,0.4311926606,0.5130292502,0.4869707498,0.07142857143,0.01388888889,0.0001876772615,0.009961501816,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I have some experience in Node, and will take a  look at this.",Contribution and Commitment,62,62,1,0.4334862385,0.5130292502,0.4869707498,1,0.1944444444,0.0001876772615,0.009961501816,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4357798165,0.513582866,0.486417134,1,0.01388888889,0.009961501816,0.1876779255,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"+1 Can't wait, Python is great, Node and JS is great too",Social Conversation,56,56,1,0.4380733945,0.5240131664,0.4759868336,1,0.1666666667,0.1876779255,0.2086234161,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4403669725,0.5356075236,0.4643924764,1,0.01388888889,0.2086234161,0.0186825189,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 just for the sake of it,Social Conversation,26,26,1,0.4426605505,0.5366458145,0.4633541855,1,0.09722222222,0.0186825189,0.01977759802,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1!,Social Conversation,3,3,1,0.4449541284,0.537744965,0.462255035,1,0.01388888889,0.01977759802,0.1444971057,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4472477064,0.5457754684,0.4542245316,1,0.01388888889,0.1444971057,0.02000046477,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,![image] URL,Social Conversation,111,13,1,0.4495412844,0.5468870048,0.4531129952,1,0.02777777778,0.02000046477,0.005053785692,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 ð,Social Conversation,4,4,1,0.4518348624,0.5471678717,0.4528321283,1,0.02777777778,0.005053785692,0.07567554408,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4541284404,0.5513735802,0.4486264198,1,0.01388888889,0.07567554408,0.01337665255,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 would be cool af,Social Conversation,19,19,1,0.4564220183,0.5521169948,0.4478830052,1,0.06944444444,0.01337665255,0.0276259601,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 <3,Social Conversation,5,5,1,0.4587155963,0.5536523222,0.4463476778,1,0.02777777778,0.0276259601,0.01532070569,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.4610091743,0.5545037786,0.4454962214,1,0.01388888889,0.01532070569,0.02505292255,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.4633027523,0.555896108,0.444103892,1,0.01388888889,0.02505292255,0.05261868429,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+100,Social Conversation,4,4,1,0.4655963303,0.5588204194,0.4411795806,1,0.01388888889,0.05261868429,0.07356638806,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4678899083,0.5629089105,0.4370910895,1,0.01388888889,0.07356638806,0.04294821502,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4701834862,0.5652957803,0.4347042197,1,0.01388888889,0.04294821502,0.07703399105,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.4724770642,0.5695769853,0.4304230147,1,0.01388888889,0.07703399105,0.01001196221,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+2,Social Conversation,2,2,1,0.4747706422,0.5701334054,0.4298665946,1,0.01388888889,0.01001196221,0.06122240309,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 ;),Social Conversation,5,5,1,0.4770642202,0.573535873,0.426464127,1,0.02777777778,0.06122240309,0.05162917363,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,mark,Social Conversation,4,4,1,0.4793577982,0.5764051917,0.4235948083,1,0.01388888889,0.05162917363,0.1112315324,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4816513761,0.5825869432,0.4174130568,1,0.01388888889,0.1112315324,0.1275751677,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4839449541,0.5896770009,0.4103229991,1,0.01388888889,0.1275751677,0.01978932785,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4862385321,0.5907768033,0.4092231967,1,0.01388888889,0.01978932785,0.0008416705489,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4885321101,0.5908235796,0.4091764204,1,0.01388888889,0.0008416705489,0.01788489054,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4908256881,0.5918175419,0.4081824581,1,0.01388888889,0.01788489054,0.05582181283,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.4931192661,0.5949198688,0.4050801312,1,0.01388888889,0.05582181283,0.001516025049,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.495412844,0.5950041227,0.4049958773,1,0.01388888889,0.001516025049,0.005853627228,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.497706422,0.5953294412,0.4046705588,1,0.01388888889,0.005853627228,0.009641476675,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5,0.5958652714,0.4041347286,1,0.01388888889,0.009641476675,0.01115728041,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.502293578,0.5964853431,0.4035146569,1,0.01388888889,0.01115728041,0.1324784575,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.504587156,0.6038479038,0.3961520962,1,0.01388888889,0.1324784575,0.02541389144,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5068807339,0.6052602943,0.3947397057,1,0.01388888889,0.02541389144,0.01426214397,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5091743119,0.6060529205,0.3939470795,1,0.01388888889,0.01426214397,0.00617188183,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5114678899,0.6063959261,0.3936040739,1,0.01388888889,0.00617188183,0.07848406348,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ðPlease !,Social Conversation,9,9,1,0.5137614679,0.6107577197,0.3892422803,1,0.01388888889,0.07848406348,0.00674332368,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5160550459,0.6111324834,0.3888675166,1,0.01388888889,0.00674332368,0.002226454305,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5183486239,0.6112562198,0.3887437802,1,0.01388888889,0.002226454305,0.000183250911,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"The OP's date was from 2015, its now 2017 and it's not really been picked up by anyone on the project.",Task Progress,102,102,0.5,0.5206422018,0.6112664041,0.3887335959,0.8076923077,0.2916666667,0.000183250911,0.003347427571,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Does anyone know if there has been any healthy discussion regarding tensorflow and node anywhere else as these +1's don't seem to be doing much :(,Social Conversation,146,146,1,0.5229357798,0.6112664041,0.3887335959,1,0.3611111111,0.000183250911,0.003347427571,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5252293578,0.6114524392,0.3885475608,1,0.01388888889,0.003347427571,0.01192259641,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,# +1,Social Conversation,4,4,1,0.5275229358,0.6121150438,0.3878849562,1,0.01388888889,0.01192259641,0.03009940477,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,1,0.5298165138,0.6137878342,0.3862121658,1,0.01388888889,0.03009940477,0.1177654897,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5321100917,0.6203327138,0.3796672862,1,0.01388888889,0.1177654897,0.04744051815,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5344036697,0.6229692458,0.3770307542,1,0.01388888889,0.04744051815,0.1465312351,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.5366972477,0.6311127971,0.3688872029,1,0.01388888889,0.1465312351,0.02364180201,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,it's been 2 years and still no luck?,Task Progress,36,36,1,0.5389908257,0.6324267028,0.3675732972,1,0.1111111111,0.02364180201,9.56E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Good.,Social Conversation,5,5,0.5,0.5412844037,0.6324320163,0.3675679837,0.5,0.01388888889,9.56E-05,0.001398505443,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Fuck Javascript.,Social Conversation,16,16,1,0.5435779817,0.6324320163,0.3675679837,1,0.02777777778,9.56E-05,0.001398505443,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1.0/0.0,Social Conversation,8,8,1,0.5458715596,0.632509739,0.367490261,1,0.01388888889,0.001398505443,0.01279613668,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Use synaptic https://github.com/cazala/synaptic,Workarounds,47,47,1,0.5481651376,0.6332208911,0.3667791089,1,0.04166666667,0.01279613668,0.001457597222,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,This is still in progress.,Task Progress,26,26,0.5,0.5504587156,0.6333018978,0.3666981022,1,0.06944444444,0.001457597222,0.003508325412,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,https://github.com/tngan/tensornode,Task Progress,35,35,1,0.5527522936,0.6333018978,0.3666981022,0.2,0.01388888889,0.001457597222,0.003508325412,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,this could be useful [keras-js] URL,Solution Discussion,73,36,1,0.5550458716,0.6334968749,0.3665031251,1,0.09722222222,0.003508325412,0.0006531080173,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Other useful [source] URL .,Solution Discussion,66,27,0.25,0.5573394495,0.6335331717,0.3664668283,0.1212121212,0.05555555556,0.0006531080173,0.08742750468,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Unfortunately my day job is not coding and it requires proficiency in C++, which I personally don't have.",Social Conversation,105,105,0.5,0.5596330275,0.6335331717,0.3664668283,0.5454545455,0.25,0.0006531080173,0.08742750468,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"By the way CODE does only inference, no training, so no backpropagation.",Motivation,78,72,0.75,0.5619266055,0.6335331717,0.3664668283,0.3636363636,0.1666666667,0.0006531080173,0.08742750468,NONE,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,"Google developers implemented a small portion of Tensorflow in Javascript in their [playground] URL , the neural network implementation is [here] URL  and does include [back propagation](https://github.com/tensorflow/playground/blob/master/src/nn.ts#L282).",Motivation,352,256,1,0.5642201835,0.6335331717,0.3664668283,1,0.4583333333,0.0006531080173,0.08742750468,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"There is I started work on native nodejs Tensorflow implementation, would be great if anybody joinshttps://github.com/nodejs-tensorflow/nodejs-tensorflow",Contribution and Commitment,153,153,1,0.5665137615,0.6383920017,0.3616079983,1,0.2222222222,0.08742750468,0.1059320843,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5688073394,0.6442792336,0.3557207664,1,0.01388888889,0.1059320843,0.0269339002,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5711009174,0.6457760994,0.3542239006,1,0.01388888889,0.0269339002,0.05654463587,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,**+1**,Social Conversation,6,6,1,0.5733944954,0.6489185975,0.3510814025,1,0.01388888889,0.05654463587,0.01776869884,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5756880734,0.6499061024,0.3500938976,1,0.01388888889,0.01776869884,0.01305197974,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I'm so happy to hear you're giving this a shot @JIoJIaJIu.,Social Conversation,58,58,0.1111111111,0.5779816514,0.6506314731,0.3493685269,0.3142857143,0.1527777778,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The potential for impact in solving this issue is huge.,Motivation,55,55,0.2222222222,0.5802752294,0.6506314731,0.3493685269,0.2857142857,0.1388888889,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,It's our most upvoted issue.,Motivation,28,28,0.3333333333,0.5825688073,0.6506314731,0.3493685269,0.1428571429,0.06944444444,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"At cursory glance, so far you seem to be doing the right thing.",Task Progress,63,63,0.4444444444,0.5848623853,0.6506314731,0.3493685269,0.3714285714,0.1805555556,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"You created this in a separate project and are using the TensorFlow C API, as @martinwicke recommended earlier.",Task Progress,111,111,0.5555555556,0.5871559633,0.6506314731,0.3493685269,0.5142857143,0.25,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"A good way to attract contributors to your project would be by sharing a design doc with the [TensorFlow mailing list](https://groups.google.com/a/tensorflow.org/forum/#!forum/discuss), as Vincent [recommended](https://github.com/tensorflow/tensorflow/issues/37#issuecomment-155605035) a few years back.",Contribution and Commitment,303,303,0.6666666667,0.5894495413,0.6506314731,0.3493685269,1,0.4861111111,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,That way we can build consensus around your vision and help it be the best vision possible.,Social Conversation,91,91,0.7777777778,0.5917431193,0.6506314731,0.3493685269,0.4857142857,0.2361111111,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The TensorFlow team wants the NodeJS community to benefit from TensorFlow.,Motivation,74,74,0.8888888889,0.5940366972,0.6506314731,0.3493685269,0.3142857143,0.1527777778,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,So we're absolutely interested in helping the individual devoted to making that happen be successful.,Social Conversation,101,101,1,0.5963302752,0.6506314731,0.3493685269,0.4285714286,0.2083333333,0.01305197974,0.05958996502,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.5986238532,0.6539432171,0.3460567829,1,0.01388888889,0.05958996502,0.04791701478,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Hi all, I created the Node.js bridging library for Tensorflow at: https://github.com/yorkie/tensorflow-nodejs without SWIG, it has supported ""predefined graph running"" and very simple ""graph construction"", I'm also planing to support more client features in the future :)",Task Progress,271,271,0.5,0.6009174312,0.6566062306,0.3433937694,1,0.5138888889,0.04791701478,0.0005984425886,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"At the same time, I would very happy to make this be merged by Tensorflow official group, that would be a zero-cost PR to me :)",Action on Issue,127,127,1,0.6032110092,0.6566062306,0.3433937694,0.7297297297,0.375,0.04791701478,0.0005984425886,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@yorkie It looks interesting, I will try it out!",Social Conversation,48,48,0.5,0.6055045872,0.6566394894,0.3433605106,1,0.125,0.0005984425886,0.0005714418505,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,However we cannot merge GPL code into TensorFlow.,Action on Issue,49,49,1,0.6077981651,0.6566394894,0.3433605106,1,0.125,0.0005984425886,0.0005714418505,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@yorkie it looks awesome, would you like to join [to the project] URL  and join forces?",Contribution and Commitment,121,87,1,0.6100917431,0.6566712476,0.3433287524,1,0.2361111111,0.0005714418505,0.0009029755035,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@ry sure I can change the license surely :),Action on Issue,43,43,0.5,0.6123853211,0.6567214309,0.3432785691,0.28125,0.125,0.0009029755035,0.000624336739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@JIoJIaJIu I dunno what's the best place to move this repo for now, if this repo is not suitable for moving tensorflow org, I think nodejs-tensorflow is the good place :)",Action on Issue,170,170,1,0.6146788991,0.6567214309,0.3432785691,1,0.4444444444,0.0009029755035,0.000624336739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@ry Updated the license to MIT and @JIoJIaJIu joined the group, thanks for the invitation :)",Action on Issue,92,92,1,0.6169724771,0.6567561288,0.3432438712,1,0.2222222222,0.000624336739,0.2551138181,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.619266055,0.6709342147,0.3290657853,1,0.01388888889,0.2551138181,0.28998505,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.621559633,0.6870502879,0.3129497121,1,0.01388888889,0.28998505,0.04966188215,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.623853211,0.6898102734,0.3101897266,1,0.01388888889,0.04966188215,0.00144254763,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.626146789,0.6898904437,0.3101095563,1,0.01388888889,0.00144254763,0.01609443176,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.628440367,0.6907849003,0.3092150997,1,0.01388888889,0.01609443176,0.02124426926,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,JavaScript APIs for TensorFlow were [announced] URL  earlier this month.,Potential New Issues and Requests,150,72,0.25,0.630733945,0.6919655619,0.3080344381,1,0.1527777778,0.02124426926,0.001938741522,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,See details on the [deeplearn.js] URL  homepage.,Potential New Issues and Requests,85,48,0.5,0.6330275229,0.6919655619,0.3080344381,0.7272727273,0.1111111111,0.02124426926,0.001938741522,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I'll close this (broad) bug now.,Action on Issue,32,32,0.75,0.6353211009,0.6919655619,0.3080344381,0.5454545455,0.08333333333,0.02124426926,0.001938741522,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Feel free to open other more specific FRs.,Potential New Issues and Requests,42,42,1,0.6376146789,0.6919655619,0.3080344381,0.7272727273,0.1111111111,0.02124426926,0.001938741522,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Fair enough.,Social Conversation,12,12,0.5,0.6399082569,0.6920733085,0.3079266915,0.2,0.02777777778,0.001938741522,0.0871107993,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I see now that the bug title references Node.js directly.,Social Conversation,57,57,1,0.6422018349,0.6920733085,0.3079266915,1,0.1388888889,0.001938741522,0.0871107993,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@vincentvanhoucke it's not even about node.js in the title.,Social Conversation,59,59,0.125,0.6444954128,0.6969145374,0.3030854626,0.25,0.125,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Talking about ""deeplearn.js"" and ""Tensorflow API for Javascript"" is like talking about apples & pears.",Social Conversation,102,102,0.25,0.6467889908,0.6969145374,0.3030854626,0.3888888889,0.1944444444,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"First of all - deeplearn.js is a library that only mirrors to some extent ""the style of TensorFlow API"" and operates purely in the browser and the other would be a direct API to whole Tensorflow goodness.",Potential New Issues and Requests,204,204,0.375,0.6490825688,0.6969145374,0.3030854626,1,0.5,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Also, its not even remotely close to being called an alternative to Tensorflow...",Potential New Issues and Requests,81,81,0.5,0.6513761468,0.6969145374,0.3030854626,0.3611111111,0.1805555556,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"maybe for hobbyists but not for commercial use, where one would need clusters of machines to aim the computing process.",Potential New Issues and Requests,119,119,0.625,0.6536697248,0.6969145374,0.3030854626,0.5555555556,0.2777777778,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I think of it as a demo what you can achieve with JavaScript and neural networks...,Potential New Issues and Requests,83,83,0.75,0.6559633028,0.6969145374,0.3030854626,0.4444444444,0.2222222222,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,a taste of things to come...,Social Conversation,28,28,0.875,0.6582568807,0.6969145374,0.3030854626,0.1666666667,0.08333333333,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,;-),Social Conversation,3,3,1,0.6605504587,0.6969145374,0.3030854626,0.02777777778,0.01388888889,0.0871107993,0.1143443634,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.6628440367,0.7032692861,0.2967307139,1,0.01388888889,0.1143443634,0.03291102261,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+999,Social Conversation,4,4,1,0.6651376147,0.7050983337,0.2949016663,1,0.01388888889,0.03291102261,5.13E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Jesus christ, stop sending people useless notifications, there's a reason GitHub introduced ð and ð reactions.",Social Conversation,110,110,0.5,0.6674311927,0.7051011873,0.2948988127,1,0.2222222222,5.13E-05,0.000336181321,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 and +999 just annoys people and adds no value whatsoever.,Social Conversation,60,60,1,0.6697247706,0.7051011873,0.2948988127,0.6875,0.1527777778,5.13E-05,0.000336181321,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1000,Social Conversation,5,5,1,0.6720183486,0.7051198707,0.2948801293,1,0.01388888889,0.000336181321,6.20E-06,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,:+1:,Social Conversation,4,4,1,0.6743119266,0.7051202151,0.2948797849,1,0.01388888889,6.20E-06,8.43E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.6766055046,0.7051249014,0.2948750986,1,0.01388888889,8.43E-05,0.0008082516026,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.6788990826,0.7051698204,0.2948301796,1,0.01388888889,0.0008082516026,6.46E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,#                  ATTENTION,Social Conversation,28,28,0.3333333333,0.6811926606,0.7051734119,0.2948265881,0.1333333333,0.02777777778,6.46E-05,2.81E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð Guys please before commenting +1 or +whatever - Please take a look at @k1sul1 's comment,Social Conversation,90,90,0.6666666667,0.6834862385,0.7051734119,0.2948265881,1,0.2083333333,6.46E-05,2.81E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"
REFERENCE",Social Conversation,173,10,1,0.6857798165,0.7051734119,0.2948265881,0.1333333333,0.02777777778,6.46E-05,2.81E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@shahen94 we all saw that but still...,Social Conversation,38,38,0.5,0.6880733945,0.705174974,0.294825026,1,0.09722222222,2.81E-05,0.0003645099643,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,we are js dev.,Social Conversation,14,14,1,0.6903669725,0.705174974,0.294825026,0.5714285714,0.05555555556,2.81E-05,0.0003645099643,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.6926605505,0.7051952318,0.2948047682,1,0.01388888889,0.0003645099643,0.0001865706739,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@BruceHem not really sure how being a js dev correlates with blindly pushing unnecessary spam to the feed...,Social Conversation,108,108,0.1666666667,0.6949541284,0.7052056006,0.2947943994,0.4864864865,0.25,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,ð,Social Conversation,1,1,0.3333333333,0.6972477064,0.7052056006,0.2947943994,0.02702702703,0.01388888889,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"You all are aware that ""+1"" just makes this topic unreadable?",Social Conversation,61,61,0.5,0.6995412844,0.7052056006,0.2947943994,0.2972972973,0.1527777778,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I understand that we all have the desire to support this case but can only deduct that on github's closest thing to ""vote"" functionality is implemented with ""reactions"" not with a count of comments in the thread...",Social Conversation,214,214,0.6666666667,0.7018348624,0.7052056006,0.2947943994,1,0.5138888889,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,or am I missing something?,Social Conversation,26,26,0.8333333333,0.7041284404,0.7052056006,0.2947943994,0.1351351351,0.06944444444,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,;-P,Social Conversation,3,3,1,0.7064220183,0.7052056006,0.2947943994,0.02702702703,0.01388888889,0.0001865706739,0.002671966484,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Lol :P this thread died years ago.,Social Conversation,34,34,0.3333333333,0.7087155963,0.7053540966,0.2946459034,1,0.09722222222,0.002671966484,3.43E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,.,Social Conversation,1,1,0.6666666667,0.7110091743,0.7053540966,0.2946459034,0,0,0.002671966484,3.43E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1 Googolplex!,Social Conversation,14,14,1,0.7133027523,0.7053540966,0.2946459034,0.2857142857,0.02777777778,0.002671966484,3.43E-05,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.7155963303,0.705356003,0.294643997,1,0.01388888889,3.43E-05,0.001234509156,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Agreed with @thefill absolutely ""+1"" just makes this topic unreadable, and actually we had community implementations then if anyone wants to use TensorFlow with Node.js or JavaScript, just have a try with the above one or two, I think this might be a good start than comment votes here.",Social Conversation,286,286,0.3333333333,0.7178899083,0.7054246115,0.2945753885,0.6805555556,0.6805555556,0.001234509156,0.0009450258333,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I was also asking for the help from @ry to make my personal repository to be supported officially, there are few things we have to do like building some example models especially RNN cases, but unfortunately I'm got to work on other fields and have no time for these few months, if someone is interested in making this be happened, email to me, I'd love to guide you how to start.",Potential New Issues and Requests,380,380,0.6666666667,0.7201834862,0.7054246115,0.2945753885,1,1,0.001234509156,0.0009450258333,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Let's the do something useful for community in best wishes :),Social Conversation,61,61,1,0.7224770642,0.7054246115,0.2945753885,0.1527777778,0.1527777778,0.001234509156,0.0009450258333,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"In regards to the current projects that have been started, and specifically the challenges of working with the C API, I have a suggestion on implementation that has worked well for me.",Solution Discussion,184,184,0.09090909091,0.7247706422,0.7054771319,0.2945228681,0.8205128205,0.4444444444,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Since python is still the most robust, developer-friendly, and full featured wrapper around the Tensorflow API, rather than trying to ""re-create"" the python API for js, why not create bindings directly TO the python API?",Solution Discussion,220,220,0.1818181818,0.7270642202,0.7054771319,0.2945228681,0.9487179487,0.5138888889,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"This would still require first creating a node C++ add-on, but rather than binding to the C API directly, you can employ ""embedded"" python to run python methods directly from C++.",Solution Discussion,179,179,0.2727272727,0.7293577982,0.7054771319,0.2945228681,0.8205128205,0.4444444444,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,This is unlike other JS => Python solutions out there that suggest simply spawning a python script...,Solution Discussion,101,101,0.3636363636,0.7316513761,0.7054771319,0.2945228681,0.4102564103,0.2222222222,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,a solution not viable for any reasonable size learning problems because of the extensive data transfer cost (time) between the processes.,Solution Discussion,137,137,0.4545454545,0.7339449541,0.7054771319,0.2945228681,0.5384615385,0.2916666667,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"With embedded python however, memory accessed by your python script / numpy arrays directly point to your js Float32Array buffers.",Solution Discussion,130,130,0.5454545455,0.7362385321,0.7054771319,0.2945228681,0.4871794872,0.2638888889,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,This solution is working very well for me (though admittedly getting the initial js => C++ => python flow working was kind of a pain).,Solution Discussion,134,134,0.6363636364,0.7385321101,0.7054771319,0.2945228681,0.5897435897,0.3194444444,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Since I have specific needs, I have not gone through the task of binding to each individual python TensorFlow method, and instead just pass my data and hyper parameters to a few methods that build most of the graph.",Solution Discussion,215,215,0.7272727273,0.7408256881,0.7054771319,0.2945228681,1,0.5416666667,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The full individual binding wouldnt be too bad from my current starting point.,Solution Discussion,78,78,0.8181818182,0.7431192661,0.7054771319,0.2945228681,0.358974359,0.1944444444,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I welcome any thoughts or suggestions on the approach outlined above.,Social Conversation,69,69,0.9090909091,0.745412844,0.7054771319,0.2945228681,0.2820512821,0.1527777778,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thanks.,Social Conversation,7,7,1,0.747706422,0.7054771319,0.2945228681,0.02564102564,0.01388888889,0.0009450258333,0.0002671302531,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@djimoh5 Awesome thoughts on JavaScript to Python full-featured APIs!,Social Conversation,69,69,0.25,0.75,0.7054919778,0.2945080222,0.1923076923,0.1388888889,0.0002671302531,0.0550485294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"The other hand, we also could put an implementation of a RPC server for TensorFlow Python APIs with introspection feature, so that JavaScript and other language clients could access the real-time Python.",Solution Discussion,203,203,0.5,0.752293578,0.7054919778,0.2945080222,0.6346153846,0.4583333333,0.0002671302531,0.0550485294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"(I will do this when I'm available, aha)",Contribution and Commitment,40,40,0.75,0.754587156,0.7054919778,0.2945080222,0.1538461538,0.1111111111,0.0002671302531,0.0550485294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"But here is something about why re-creating some Python features for JavaScript, because they are written in JavaScript, they are more friend to JavaScript developers, and it's easy for that developers to modify the source code to check if something different is possible, not just the get feeds from upstream :)",Solution Discussion,312,312,1,0.7568807339,0.7054919778,0.2945080222,1,0.7222222222,0.0002671302531,0.0550485294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.7591743119,0.708551329,0.291448671,1,0.01388888889,0.0550485294,0.8203682945,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I'm also interested in nodejs tensorflow API   to be able to use it in a node-red flows that would chain tensorflows graphs and may be other kinds of data analysis nodes.,Motivation,170,170,0.25,0.7614678899,0.7541437327,0.2458562673,1,0.4583333333,0.8203682945,0.005981548758,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I still don't know much about tensorflow.,Social Conversation,41,41,0.5,0.7637614679,0.7541437327,0.2458562673,0.2121212121,0.09722222222,0.8203682945,0.005981548758,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,It may not be the right place to ask but I'd like to know why others developers look for a nodejs api/add-on for tensorflow ?,Motivation,125,125,0.75,0.7660550459,0.7541437327,0.2458562673,0.8181818182,0.375,0.8203682945,0.005981548758,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,What would be your use cases ?,Motivation,30,30,1,0.7683486239,0.7541437327,0.2458562673,0.1818181818,0.08333333333,0.8203682945,0.005981548758,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@khelkun answer is rather simple: providing mature JavaScript package that allows easy interaction with Tensorflow opens myriad new possibilities.,Motivation,146,146,0.3333333333,0.7706422018,0.7544761605,0.2455238395,0.5757575758,0.2638888889,0.005981548758,0.1170572737,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"JavaScript operates on every mobile platform, all major desktop Operating systems & in all the browsers so possibilities are endless.",Motivation,133,133,0.6666666667,0.7729357798,0.7544761605,0.2455238395,0.5757575758,0.2638888889,0.005981548758,0.1170572737,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Biggest benefits would come for sure from server-side applications that operate on node.js that could directly interact with Tensorflow, but also node-webkit (desktop applications) could potentially spawn dozens of interesting projects.",Motivation,236,236,1,0.7752293578,0.7544761605,0.2455238395,1,0.4583333333,0.005981548758,0.1170572737,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Are the community organizers /admin of this thread not able to simply delete the posts of the those people that intensionally trolling with all the ""+1'sâ maybe even ban them?",Social Conversation,175,175,0.5,0.7775229358,0.7609816807,0.2390183193,1,0.4166666667,0.1170572737,0.4412746119,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Lol,Social Conversation,3,3,1,0.7798165138,0.7609816807,0.2390183193,0.03333333333,0.01388888889,0.1170572737,0.4412746119,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Has anyone working on this integration considered using WebAssembly (wasm)?,Solution Discussion,75,75,0.1111111111,0.7821100917,0.7855057516,0.2144942484,0.2380952381,0.1388888889,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"It is potentially the most elegant solution to this problem, side-stepping all of the JS talking to Python talking to C++, you know.",Solution Discussion,132,132,0.2222222222,0.7844036697,0.7855057516,0.2144942484,0.5714285714,0.3333333333,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I really don't know much about the internals of TensorFlow, but I believe the C++ parts of TensorFlow could be compiled to wasm (check the MVP features supported, but Unreal Engine 4 was compiled to wasm's predecessor and ran successfully in FireFox).",Solution Discussion,251,251,0.3333333333,0.7866972477,0.7855057516,0.2144942484,1,0.5833333333,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Once the C/C++ API is compiled to wasm, you just need to ensure the necessary API is exposed.",Solution Discussion,93,93,0.4444444444,0.7889908257,0.7855057516,0.2144942484,0.4523809524,0.2638888889,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"wasm will run in Node.js, all major browsers, and even outside of any of those, since it is meant to be an extremely portable bytecode.",Solution Discussion,135,135,0.5555555556,0.7912844037,0.7855057516,0.2144942484,0.5952380952,0.3472222222,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,This seems like the best path forward to me.,Social Conversation,44,44,0.6666666667,0.7935779817,0.7855057516,0.2144942484,0.2142857143,0.125,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Related resources/discussion:,Solution Discussion,29,29,0.7777777778,0.7958715596,0.7855057516,0.2144942484,0.07142857143,0.04166666667,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         https://groups.google.com/forum/#!topic/v8-reviews/DjiUKahI6ak,Solution Discussion,72,72,0.8888888889,0.7981651376,0.7855057516,0.2144942484,0.04761904762,0.02777777778,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         https://github.com/tomasreimers/tensorflow-emscripten,Solution Discussion,63,63,1,0.8004587156,0.7855057516,0.2144942484,0.04761904762,0.02777777778,0.4412746119,0.2066977323,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1...,Social Conversation,5,5,0.3333333333,0.8027522936,0.7969930879,0.2030069121,0.08333333333,0.01388888889,0.2066977323,0.2701229087,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,we no longer live in the medieval portion of the information age.,Social Conversation,65,65,0.6666666667,0.8050458716,0.7969930879,0.2030069121,1,0.1666666667,0.2066977323,0.2701229087,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Please support node.js.,Social Conversation,23,23,1,0.8073394495,0.7969930879,0.2030069121,0.25,0.04166666667,0.2066977323,0.2701229087,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Why would anyone need another Javascript library?,Motivation,49,49,0.3333333333,0.8096330275,0.812005312,0.187994688,0.7,0.09722222222,0.2701229087,0.0002104729666,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Why would anybody use a JS library to train NNs?,Motivation,48,48,0.6666666667,0.8119266055,0.812005312,0.187994688,1,0.1388888889,0.2701229087,0.0002104729666,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Javascropt is a bad desigbed language.,Social Conversation,38,38,1,0.8142201835,0.812005312,0.187994688,0.6,0.08333333333,0.2701229087,0.0002104729666,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@AyalaSaenzJorge lol (since you're trolling why dont I have at it) ...,Social Conversation,70,70,0.125,0.8165137615,0.8120170092,0.1879829908,0.8,0.1666666667,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"How about we LOVE ""badly"" designed languages?",Social Conversation,45,45,0.25,0.8188073394,0.8120170092,0.1879829908,0.4666666667,0.09722222222,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Javascript happens to be to most prevalent language currently in existance..,Motivation,76,76,0.375,0.8211009174,0.8120170092,0.1879829908,0.8,0.1666666667,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,more code (on earth) is written in javascript than ANY other high level language..,Motivation,82,82,0.5,0.8233944954,0.8120170092,0.1879829908,1,0.2083333333,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,And that's a FACT and it's never going away sorry lol,Social Conversation,53,53,0.625,0.8256880734,0.8120170092,0.1879829908,0.7333333333,0.1527777778,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,For those of you more serious than this troll Checkout the https://deeplearnjs.org ...,Solution Discussion,86,86,0.75,0.8279816514,0.8120170092,0.1879829908,0.8,0.1666666667,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,It is influenced by tensorflow and backed by Google ...,Solution Discussion,55,55,0.875,0.8302752294,0.8120170092,0.1879829908,0.6,0.125,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Maybe rather than starting from scratch we may consider porting that to Node.js instead,Solution Discussion,87,87,1,0.8325688073,0.8120170092,0.1879829908,0.9333333333,0.1944444444,0.0002104729666,0.0001068963647,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@somombo yes, it looks really interesting.",Social Conversation,42,42,0.1666666667,0.8348623853,0.81202295,0.18797705,1,0.08333333333,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"RE: tensorflow + deeplearnjs, see esp:",Solution Discussion,38,38,0.3333333333,0.8371559633,0.81202295,0.18797705,0.8333333333,0.06944444444,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         https://deeplearnjs.org/demos/mnist/mnist.html,Solution Discussion,56,56,0.5,0.8394495413,0.81202295,0.18797705,0.3333333333,0.02777777778,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         https://github.com/PAIR-code/deeplearnjs/issues/238,Potential New Issues and Requests,61,61,0.6666666667,0.8417431193,0.81202295,0.18797705,0.3333333333,0.02777777778,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,*         https://github.com/PAIR-code/deeplearnjs/issues/407,Potential New Issues and Requests,61,61,0.8333333333,0.8440366972,0.81202295,0.18797705,0.3333333333,0.02777777778,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,etc,Social Conversation,3,3,1,0.8463302752,0.81202295,0.18797705,0.1666666667,0.01388888889,0.0001068963647,0.0006469111266,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@AyalaSaenzJorge this is a place for informative comments, not an opinionated-firestarters.",Social Conversation,91,91,0.5,0.8486238532,0.8120589024,0.1879410976,0.6666666667,0.1666666667,0.0006469111266,0.001164130183,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@somombo please see my comment from 26 Aug where I explain why deeplearnjs is irrelevant to this debate.,Solution Discussion,104,104,1,0.8509174312,0.8120589024,0.1879410976,1,0.25,0.0006469111266,0.001164130183,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Ok sorry for the comment.,Social Conversation,25,25,1,0.8532110092,0.8121235996,0.1878764004,1,0.06944444444,0.001164130183,0.1167888155,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.8555045872,0.8186142,0.1813858,1,0.01388888889,0.1167888155,0.0004092161044,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@cpple Remember not to add +1s, they cause noise and have been replaced by reactions.",Social Conversation,85,85,0.5,0.8577981651,0.8186369424,0.1813630576,1,0.2083333333,0.0004092161044,0.2335327035,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Try giving the first comment a thumbs up,Social Conversation,40,40,1,0.8600917431,0.8186369424,0.1813630576,0.5333333333,0.1111111111,0.0004092161044,0.2335327035,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"Just want to share an update -- revamped https://github.com/nikhilk/node-tensorflow with plan to have that support using TensorFlow graphs (and later, saved models) for prediction/inference in node.js.",Task Progress,201,201,0.5,0.8623853211,0.8316156465,0.1683843535,1,0.375,0.2335327035,0.08097676277,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thought I'd share since a number of folks have expressed interest on this issue.,Social Conversation,80,80,1,0.8646788991,0.8316156465,0.1683843535,0.5555555556,0.2083333333,0.2335327035,0.08097676277,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I've created a fork of headless-gl that works with deeplearnjs (which in turn works with tensorflow) - this allows models to be run natively on the GPU from node.js (note that it's only been tested on OSX so far).,Potential New Issues and Requests,213,213,0.25,0.8669724771,0.8361159731,0.1638840269,1,0.5555555556,0.08097676277,0.003132528254,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"You can find the install directions and a basic sample at https://github.com/dfoody/headless-glAnd, of course https://deeplearnjs.org for more details.",Potential New Issues and Requests,151,151,0.5,0.869266055,0.8361159731,0.1638840269,0.45,0.25,0.08097676277,0.003132528254,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,General directions to install on OSX:CODE,Potential New Issues and Requests,142,41,0.75,0.871559633,0.8361159731,0.1638840269,0.175,0.09722222222,0.08097676277,0.003132528254,NONE,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,And a quick sample to show how it's used together with deeplearnjs:CODE,Potential New Issues and Requests,475,71,1,0.873853211,0.8361159731,0.1638840269,0.325,0.1805555556,0.08097676277,0.003132528254,NONE,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,"@dfoody thank you for sharing this with the community but the statement ""which in turn works with tensorflow"" is incorrect.",Social Conversation,123,123,0.25,0.876146789,0.836290065,0.163709935,1,0.2777777778,0.003132528254,1,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Also please see my comment from 26 Aug where I explain why deeplearnjs is irrelevant to this debate.,Social Conversation,100,100,0.5,0.878440367,0.836290065,0.163709935,0.9,0.25,0.003132528254,1,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@nikhilk amazing, keep on going!",Social Conversation,32,32,0.75,0.880733945,0.836290065,0.163709935,0.25,0.06944444444,0.003132528254,1,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I will keep an eye on your project for sure ;-D,Social Conversation,47,47,1,0.8830275229,0.836290065,0.163709935,0.55,0.1527777778,0.003132528254,1,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,+1,Social Conversation,2,2,1,0.8853211009,0.8918655962,0.1081344038,1,0.01388888889,1,0.07162521205,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,[propelml.org] URL  - Looks interesting.,Workarounds,56,40,0.5,0.8876146789,0.8958462054,0.1041537946,0.2777777778,0.06944444444,0.07162521205,0.0976605631,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I've not used it but its GPU enabled and runs in both the browser and on node,Workarounds,77,77,1,0.8899082569,0.8958462054,0.1041537946,1,0.25,0.07162521205,0.0976605631,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@7ammer propelml.org looks rather promising.,Social Conversation,44,44,0.5,0.8922018349,0.901273743,0.09872625696,0.7142857143,0.06944444444,0.0976605631,0.3331738372,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Thanks for sharing this with us ;-),Social Conversation,35,35,1,0.8944954128,0.901273743,0.09872625696,1,0.09722222222,0.0976605631,0.3331738372,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Because NodeJS it's fast!,Motivation,25,25,0.5,0.8967889908,0.919790056,0.08020994398,1,0.05555555556,0.3331738372,0.01198832771,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,;D,Social Conversation,2,2,1,0.8990825688,0.919790056,0.08020994398,0.25,0.01388888889,0.3331738372,0.01198832771,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"If an ambitious member of the community wants the glory of solving this problem, and having it merged into the TensorFlow contrib codebase, here are some tips on how I would do it.",Contribution and Commitment,180,180,0.05882352941,0.9013761468,0.9204563137,0.0795436863,1,0.4583333333,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Please note I'm not going to do this.,Contribution and Commitment,37,37,0.1176470588,0.9036697248,0.9204563137,0.0795436863,0.2424242424,0.1111111111,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,You can add Node to [workspace.bzl] URL  just like TensorBoard did in [js.bzl](https://github.com/tensorflow/tensorboard/blob/99a7437/third_party/js.bzl#L25).,Solution Discussion,232,158,0.1764705882,0.9059633028,0.9204563137,0.0795436863,0.5757575758,0.2638888889,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Please note TensorFlow can not depend on [rules_nodejs] URL . CODE,Solution Discussion,1700,66,0.2352941176,0.9082568807,0.9204563137,0.0795436863,0.303030303,0.1388888889,0.01198832771,0.1095689952,MEMBER,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,"Now let's say you want you have a Node program, e.g. [tsc.js](https://github.com/tensorflow/tensorboard/blob/99a7437/third_party/js.bzl#L73), which you want to turn into something you can CODE.",Solution Discussion,235,193,0.2941176471,0.9105504587,0.9204563137,0.0795436863,0.8181818182,0.375,0.01198832771,0.1095689952,MEMBER,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,One quick way you could do this in Bazel is by defining a macro in CODE: CODE,Solution Discussion,730,77,0.3529411765,0.9128440367,0.9204563137,0.0795436863,0.5151515152,0.2361111111,0.01198832771,0.1095689952,MEMBER,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,Now for the fun part.,Social Conversation,21,21,0.4117647059,0.9151376147,0.9204563137,0.0795436863,0.1515151515,0.06944444444,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"I would write a single .js file (even if it had to be 30,000 lines long like [tex.web] URL  with zero dependencies other than the Node standard library.",Solution Discussion,211,152,0.4705882353,0.9174311927,0.9204563137,0.0795436863,0.8787878788,0.4027777778,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The inputs for this program would be [ops.pbtxt] URL  and all the other pbtxt files in [api_def/base_api] URL .,Solution Discussion,272,111,0.5294117647,0.9197247706,0.9204563137,0.0795436863,0.6060606061,0.2777777778,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,The output to this program would be exactly one gigantic C++ file that talks to [TensorFlow C API] URL  and [Node C++ Addon API] URL  based on [this example] URL .,Solution Discussion,342,163,0.5882352941,0.9220183486,0.9204563137,0.0795436863,0.9696969697,0.4444444444,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,CODE,Solution Discussion,640,4,0.6470588235,0.9243119266,0.9204563137,0.0795436863,0.0303030303,0.01388888889,0.01198832771,0.1095689952,MEMBER,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,Then you CODE and bam you've got your NodeJS project all bundled and ready for distribution to places like NPM.,Solution Discussion,157,111,0.7058823529,0.9266055046,0.9204563137,0.0795436863,0.6363636364,0.2916666667,0.01198832771,0.1095689952,MEMBER,FALSE,TRUE,FALSE,FALSE
1 37_tensorflow.doc,Then I would encourage our friends in the community to veneer the library.,Contribution and Commitment,74,74,0.7647058824,0.9288990826,0.9204563137,0.0795436863,0.3939393939,0.1805555556,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"There's a diversity of visions out there on friendly modern high-level idiomatic JS and ML APIs, each catering to different use cases.",Motivation,134,134,0.8235294118,0.9311926606,0.9204563137,0.0795436863,0.696969697,0.3194444444,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,However they could all share this binding in common.,Motivation,52,52,0.8823529412,0.9334862385,0.9204563137,0.0795436863,0.2727272727,0.125,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Please note there are examples of where we already generate language bindings.,Motivation,78,78,0.9411764706,0.9357798165,0.9204563137,0.0795436863,0.3636363636,0.1666666667,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,See [tensorflow/go/genop/main.go] URL  and [tensorflow/go/op/generate.go] URL  for inspiration.,Motivation,250,95,1,0.9380733945,0.9204563137,0.0795436863,0.4848484848,0.2222222222,0.01198832771,0.1095689952,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Looks like the TensorFlow team is making this a top priority now: https://js.tensorflow.org/faq/,Social Conversation,96,96,1,0.9403669725,0.9265456688,0.0734543312,1,0.1805555556,0.1095689952,0.519959189,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,As update to this issue - we have open-sourced the Node.js binding for TFJS: https://github.com/tensorflow/tfjs-node,Task Progress,116,116,0.5,0.9426605505,0.9554426769,0.04455732307,1,0.2083333333,0.519959189,0.0005732123907,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,We are working hard at getting a proper NPM build and will release it soon!,Task Progress,75,75,1,0.9449541284,0.9554426769,0.04455732307,1,0.2083333333,0.519959189,0.0005732123907,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I will close this issue.,Action on Issue,24,24,0.5,0.9472477064,0.9554745335,0.04452546649,0.4545454545,0.06944444444,0.0005732123907,0.2254964429,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Please track tensorflow/tfjs and tensorflow/tfjs-node for further updates.,Action on Issue,74,74,1,0.9495412844,0.9554745335,0.04452546649,1,0.1527777778,0.0005732123907,0.2254964429,MEMBER,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Related and possibly of interest: I managed to get TF running in the browser via Webassembly.,Potential New Issues and Requests,93,93,0.5,0.9518348624,0.9680066181,0.0319933819,1,0.2222222222,0.2254964429,0.0002863848778,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,See https://humantoanimal.com for a demo; I will be providing more details in the future.,Potential New Issues and Requests,89,89,1,0.9541284404,0.9680066181,0.0319933819,0.875,0.1944444444,0.2254964429,0.0002863848778,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,"@nuchi, so did you compile the necessary TensorFlow code from the C API to WebAssembly?",Potential New Issues and Requests,87,87,0.5,0.9564220183,0.9680225341,0.03197746591,1,0.2083333333,0.0002863848778,0.000479816395,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Or are you using TensorFlow.js?,Potential New Issues and Requests,31,31,1,0.9587155963,0.9680225341,0.03197746591,0.3333333333,0.06944444444,0.0002863848778,0.000479816395,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@lastmjs I explain in more detail in the link I provided.,Potential New Issues and Requests,57,57,0.3333333333,0.9610091743,0.9680492001,0.03195079986,1,0.1527777778,0.000479816395,0.007495803266,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Short version: I added Webassembly as an XLA compilation target.,Potential New Issues and Requests,64,64,0.6666666667,0.9633027523,0.9680492001,0.03195079986,0.9090909091,0.1388888889,0.000479816395,0.007495803266,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,I did not use Tensorflow.js in any way.,Potential New Issues and Requests,39,39,1,0.9655963303,0.9680492001,0.03195079986,0.7272727273,0.1111111111,0.000479816395,0.007495803266,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,@nuchi Great work!,Social Conversation,18,18,0.5,0.9678899083,0.9684657834,0.03153421661,0.1764705882,0.04166666667,0.007495803266,0.5674118797,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,and I know another WebAssemble research on TensorFlow at here:https://medium.com/@tomasreimers/compiling-tensorflow-for-the-browser-f3387b8e1e1c,Potential New Issues and Requests,144,144,1,0.9701834862,0.9684657834,0.03153421661,1,0.2361111111,0.007495803266,0.5674118797,NONE,FALSE,FALSE,FALSE,FALSE
1 37_tensorflow.doc,Glad to see that there's official progress on this.,Social Conversation,51,51,1,0.9724770642,1,0,9,0.125,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"I'd love to have fast, parallel GPU compute power at my fingertips with the ease and composability of JS.",Motivation,105,105,2,0.9747706422,1,0,20,0.2777777778,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"I started working on a [NodeJS binding for TensorFlow] URL  a while ago, but a haven't had much free time to devote to it lately.",Social Conversation,168,129,3,0.9770642202,1,0,26,0.3611111111,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,The concept is similar to @jart's suggested approach.,Solution Discussion,53,53,4,0.9793577982,1,0,8,0.1111111111,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,I had three goals in mind for the project:,Solution Discussion,42,42,5,0.9816513761,1,0,9,0.125,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,#### 1. Don't require building or installing tensorflow,Solution Discussion,55,55,6,0.9839449541,1,0,7,0.09722222222,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"Instead, it should [download and use] URL  the pre-built, multi-platform python binaries and download any needed source files on the fly.",Solution Discussion,207,137,7,0.9862385321,1,0,24,0.3333333333,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,#### 2. Don't require a complete C++ or JS reproduction or abstraction of the API,Solution Discussion,81,81,8,0.9885321101,1,0,14,0.1944444444,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"Instead, it should provide a complete 1-to-1 interface with the C API, [providing convenient JS abstractions] URL  as much as possible.",Solution Discussion,190,135,9,0.9908256881,1,0,23,0.3194444444,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,#### 3. Don't maintain the C API [bindings] URL  [by] URL  [hand] URL,Solution Discussion,283,70,10,0.9931192661,1,0,14,0.1944444444,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"Instead, it should [use a swig script] URL  to map the core data structures between Tensorflow/stdc++/V8/node and the rest will follow.",Solution Discussion,203,135,11,0.995412844,1,0,24,0.3333333333,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"I got pretty far along with this, but last I remember a was having issues with TF_Session related segfaults.",Solution Discussion,108,108,12,0.997706422,1,0,19,0.2638888889,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
1 37_tensorflow.doc,"Right now it's just collecting dust, so if someone wants to jump in and help with this I'd gladly accept PRs.",Contribution and Commitment,109,109,13,1,1,0,22,0.3055555556,0.5674118797,0,NONE,FALSE,FALSE,FALSE,TRUE
2 1122_tensorflow.doc,Easy to use batch norm layer.,Expected Behaviour,29,29,0.3333333333,0.002320185615,0,1,0.3529411765,0.02230483271,0,0.0003451477926,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
2 1122_tensorflow.doc,Many non-experts are using the following code http://stackoverflow.com/questions/33949786/how-could-i-use-batch-normalization-in-tensorflow?answertab=votes#tab-top.,Motivation,164,164,0.6666666667,0.00464037123,0,1,0.5294117647,0.03345724907,0,0.0003451477926,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
2 1122_tensorflow.doc,It would be nice to have an official batch norm layer given its importance in training DNNs.,Motivation,92,92,1,0.006960556845,0,1,1,0.06319702602,0,0.0003451477926,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
2 1122_tensorflow.doc,I'm working on some parts of that.,Contribution and Commitment,34,34,1,0.009280742459,5.86E-05,0.9999413618,1,0.02602230483,0.0003451477926,1,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I think some thing wrong with this layer.,Solution Discussion,41,41,0.1666666667,0.01160092807,0.1699515439,0.8300484561,0.2857142857,0.02973977695,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,in training every thing is OK and loss decrease very good.,Solution Discussion,58,58,0.3333333333,0.01392111369,0.1699515439,0.8300484561,0.3928571429,0.04089219331,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,but in testing I get zero accuracy.,Solution Discussion,35,35,0.5,0.0162412993,0.1699515439,0.8300484561,0.25,0.02602230483,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"By the way in testing when I use is_training=False, I get zero acc.",Solution Discussion,67,67,0.6666666667,0.01856148492,0.1699515439,0.8300484561,0.5,0.05204460967,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I know batch normalization behave different in train and test phase, as describe in [How does batch normalization behave differently at training time and test time? - Quora] URL .",Solution Discussion,276,179,0.8333333333,0.02088167053,0.1699515439,0.8300484561,1,0.1040892193,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I think this implementation is unclear,Solution Discussion,38,38,1,0.02320185615,0.1699515439,0.8300484561,0.2142857143,0.02230483271,1,0.0209784789,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Same here, I have experienced some unexpected behavior with is_training=False.",Solution Discussion,78,78,0.3333333333,0.02552204176,0.1735156386,0.8264843614,0.7857142857,0.04089219331,0.0209784789,4.39E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,What is the correct way to change this flag?,Usage,44,44,0.6666666667,0.02784222738,0.1735156386,0.8264843614,0.6428571429,0.03345724907,0.0209784789,4.39E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I am currently using a CODE because it does not take CODE by itself.,Usage,86,68,1,0.03016241299,0.1735156386,0.8264843614,1,0.05204460967,0.0209784789,4.39E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@pawni You have to use a Python boolean for CODE.,Usage,58,49,0.5,0.03248259861,0.1735230886,0.8264769114,1,0.03717472119,4.39E-05,2.40E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,It cannot be a CODE.,Usage,25,20,1,0.03480278422,0.1735230886,0.8264769114,0.6,0.02230483271,4.39E-05,2.40E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@ppwwyyxx well I am doing CODE or is one just supposed to do a CODE and change that outside of the graph when needed?,Usage,242,117,1,0.03712296984,0.173527174,0.826472826,1,0.08921933086,2.40E-05,9.82E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Oh I thought you were doing CODE, which is incorrect.",Usage,99,53,0.25,0.03944315545,0.1735438522,0.8264561478,0.4,0.03717472119,9.82E-05,4.66E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Your current way might have problems as well.,Usage,45,45,0.5,0.04176334107,0.1735438522,0.8264561478,0.32,0.02973977695,9.82E-05,4.66E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"You'll need to double check that the two CODE op you created share the same scope, otherwise they won't share the underlying mean/variance statistics.",Usage,158,150,0.75,0.04408352668,0.1735438522,0.8264561478,1,0.09293680297,9.82E-05,4.66E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"To do this the CODE argument might help, but I'm not sure because I use my own version of bn layer.",Usage,102,99,1,0.0464037123,0.1735438522,0.8264561478,0.84,0.0780669145,9.82E-05,4.66E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I am using the same scope and CODE.,Usage,43,35,0.3333333333,0.04872389791,0.1735517668,0.8264482332,0.2962962963,0.02973977695,4.66E-05,0.001063922786,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,It seems to work sometimes but I am not too sure.,Usage,49,49,0.6666666667,0.05104408353,0.1735517668,0.8264482332,0.4074074074,0.04089219331,4.66E-05,0.001063922786,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It would be great if the layer could be added to the documentation with a short explanation how to best handle the change from training to test.,Usage,144,144,1,0.05336426914,0.1735517668,0.8264482332,1,0.1003717472,4.66E-05,0.001063922786,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada FYI,Social Conversation,11,11,1,0.05568445476,0.1737325197,0.8262674803,1,0.007434944238,0.001063922786,0.0008864451503,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Currently batch_norm requires a python boolean, but we are working in adding the option of passing a Tensor.",Task Progress,108,108,1,0.05800464037,0.1738831205,0.8261168795,1,0.06691449814,0.0008864451503,1.08E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@pawni If you don't want to worry about about updating moving_mean and moving_variance set updates_collections=None to make sure they are updated in place, otherwise you need to make sure the update_ops added to tf.GraphKeys.UPDATE_OPS are run during training.",Usage,260,260,1,0.06032482599,0.1738849469,0.8261150531,1,0.1524163569,1.08E-05,0.0001281573361,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I think tensorflow need 2 hyper methods that change the model state, something like torch.",Potential New Issues and Requests,90,90,0.3333333333,0.0626450116,0.1739067199,0.8260932801,1,0.05576208178,0.0001281573361,0.1683889321,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,[change model state](https://github.com/torch/nn/blob/master/doc/module.md#training).,Potential New Issues and Requests,85,85,0.6666666667,0.06496519722,0.1739067199,0.8260932801,0.6,0.03345724907,0.0001281573361,0.1683889321,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I think it is very straightforward.,Social Conversation,35,35,1,0.06728538283,0.1739067199,0.8260932801,0.4,0.02230483271,0.0001281573361,0.1683889321,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"is there a small script with a very simple NN that shows what is the proper way of using this ""official"" BN layer?",Usage,114,114,0.5,0.06960556845,0.2025148049,0.7974851951,1,0.08550185874,0.1683889321,4.98E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I'd really appreciate it.,Social Conversation,25,25,1,0.07192575406,0.2025148049,0.7974851951,0.2173913043,0.01858736059,0.1683889321,4.98E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,is that not the official way to use BN?,Usage,39,39,0.5,0.07424593968,0.2025232642,0.7974767358,0.2571428571,0.03345724907,4.98E-05,0.001425762152,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I am confused on how to use it and the SO seems to be outdated and then there is a layer in a different link from the API, just how exactly does one do this?",Usage,157,157,1,0.07656612529,0.2025232642,0.7974767358,1,0.1301115242,4.98E-05,0.001425762152,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"sorry for the spamming, but what is wrong with just using something like this: CODE",Usage,1498,83,0.3333333333,0.0788863109,0.202765491,0.797234509,0.5172413793,0.05576208178,0.001425762152,0.0002365111103,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,then its simple to tell tensorflow which one to use with a feed dictionary as in: CODE,Usage,208,86,0.6666666667,0.08120649652,0.202765491,0.797234509,0.5862068966,0.06319702602,0.001425762152,0.0002365111103,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"since its unclear if the implementation will change, I wanted to give a suggestion (note its easy to extend to convolutions and stuff I just didn't paste that code).",Social Conversation,165,165,1,0.08352668213,0.202765491,0.797234509,1,0.1078066914,0.001425762152,0.0002365111103,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@pawni @ppwwyyxx did you guys decide if you had to use reuse to true to solve the scoping issue?,Usage,96,96,1,0.08584686775,0.2028056726,0.7971943274,1,0.07063197026,0.0002365111103,0.0001607860618,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@brando90 currently I am doing something like: CODE,Usage,340,51,0.3333333333,0.08816705336,0.202832989,0.797167011,0.6153846154,0.02973977695,0.0001607860618,0.006956991284,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"However, I think that #3265 would basically want to implement it like this.",Potential New Issues and Requests,75,75,0.6666666667,0.09048723898,0.202832989,0.797167011,1,0.04832713755,0.0001607860618,0.006956991284,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,A reference could be the dropout implementation here: https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L433-L435,Potential New Issues and Requests,166,166,1,0.09280742459,0.202832989,0.797167011,0.6923076923,0.03345724907,0.0001607860618,0.006956991284,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,When the updates_collections=None then the updates happens in-place and it is easier to use a tf.cond() to allow is_training being a Tensor a bit more complicated is when the updates are delayed and the the update_ops are run later.,Usage,232,232,0.5,0.09512761021,0.2040149325,0.7959850675,1,0.1524163569,0.006956991284,0.009270141613,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I will try to get the first part in soon.,Contribution and Commitment,41,41,1,0.09744779582,0.2040149325,0.7959850675,0.243902439,0.03717472119,0.006956991284,0.009270141613,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@brando90 @pawni he's code works good, but have to change like below CODE",Usage,421,73,0.5,0.09976798144,0.2055898638,0.7944101362,1,0.04832713755,0.009270141613,0.06419664069,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"And when run in training or test time, CODE",Usage,210,43,1,0.1020881671,0.2055898638,0.7944101362,0.6923076923,0.03345724907,0.009270141613,0.06419664069,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@nmhkahn @pawni thanks for the code snippets.,Social Conversation,45,45,0.04347826087,0.1044083527,0.2164964176,0.7835035824,0.1944444444,0.02602230483,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,They were very useful in adding batch normalization to my convolution network.,Social Conversation,78,78,0.08695652174,0.1067285383,0.2164964176,0.7835035824,0.3333333333,0.04460966543,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Training seems to work very well.,Usage,33,33,0.1304347826,0.1090487239,0.2164964176,0.7835035824,0.1666666667,0.02230483271,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Testing is not.,Usage,15,15,0.1739130435,0.1113689095,0.2164964176,0.7835035824,0.08333333333,0.01115241636,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In some versions of the code training accuracies are much higher than testing accuracies, which probably mean I am not sharing batch normalization parameters.",Usage,158,158,0.2173913043,0.1136890951,0.2164964176,0.7835035824,0.6666666667,0.08921933086,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In other versions of the code I get ""ValueError: Variable conv1/beta already exists, disallowed. Did you mean to set reuse=True in VarScope?"" which seem to indicate that I am trying to relearn the parameter...",Usage,209,209,0.2608695652,0.1160092807,0.2164964176,0.7835035824,1,0.1338289963,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,when I was trying to reuse.,Usage,27,27,0.3043478261,0.1183294664,0.2164964176,0.7835035824,0.1666666667,0.02230483271,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Can someone provide an example of how to call the ""def BatchNorm"" function during training and testing so that variable sharing happen correctly.",Usage,145,145,0.347826087,0.120649652,0.2164964176,0.7835035824,0.6388888889,0.08550185874,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks for any help.,Social Conversation,20,20,0.3913043478,0.1229698376,0.2164964176,0.7835035824,0.1111111111,0.01486988848,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"UPDATE July 25, 2016:",Social Conversation,21,21,0.4347826087,0.1252900232,0.2164964176,0.7835035824,0.1111111111,0.01486988848,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@nmhkahn @pawni thanks for your comments.,Social Conversation,41,41,0.4782608696,0.1276102088,0.2164964176,0.7835035824,0.1666666667,0.02230483271,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,After taking a closer look at the code in contrib I realized what my problem was.,Usage,81,81,0.5217391304,0.1299303944,0.2164964176,0.7835035824,0.4444444444,0.0594795539,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"During training and testing we are either updating or reusing four variables (beta, gamma, moving_mean and moving_variance).",Usage,124,124,0.5652173913,0.13225058,0.2164964176,0.7835035824,0.4722222222,0.06319702602,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,To make those unique I had to set a scope per layer.,Usage,52,52,0.6086956522,0.1345707657,0.2164964176,0.7835035824,0.3333333333,0.04460966543,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I did it like this:,Usage,19,19,0.652173913,0.1368909513,0.2164964176,0.7835035824,0.1388888889,0.01858736059,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"conv1 = tf.nn.relu(batch_norm_layer(conv2d_stride2_valid(data, W_conv1) + b_conv1, train_phase, scope=""conv1""))",Usage,111,111,0.6956521739,0.1392111369,0.2164964176,0.7835035824,0.1666666667,0.02230483271,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"where batch_norm_layer is similar to the examples from @nmhkahn @pawni, conv2d_stride2_valid is just a def to define a convolutional layer, and W_conv1 and b_conv1 are variables holding the weights and biases.",Usage,209,209,0.7391304348,0.1415313225,0.2164964176,0.7835035824,0.8611111111,0.1152416357,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I could probably remove the bias term because we are using batch normalization.,Usage,79,79,0.7826086957,0.1438515081,0.2164964176,0.7835035824,0.3611111111,0.04832713755,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The net is working well now.,Usage,28,28,0.8260869565,0.1461716937,0.2164964176,0.7835035824,0.1666666667,0.02230483271,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I noticed after plotting accuracies in training and test mode that the testing accuracies start climbing after the training accuracies.,Usage,135,135,0.8695652174,0.1484918794,0.2164964176,0.7835035824,0.5555555556,0.07434944238,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,In retrospect it make sense since we are collecting dataset statistics for testing.,Usage,83,83,0.9130434783,0.150812065,0.2164964176,0.7835035824,0.3611111111,0.04832713755,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,But it appeared as if I was doing something wrong during my initial tests.,Usage,74,74,0.9565217391,0.1531322506,0.2164964176,0.7835035824,0.3888888889,0.05204460967,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks for your comments and making batch normalization available to the community.,Social Conversation,83,83,1,0.1554524362,0.2164964176,0.7835035824,0.3333333333,0.04460966543,0.06419664069,0.007155781325,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@nmhkahn how is it different from pawni's suggestion?,Usage,53,53,1,0.1577726218,0.2177121341,0.7822878659,1,0.02973977695,0.007155781325,0.0001289117575,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@brando90 I had a small error in my version which was fixed by nmhkahn (changing CODE to CODE),Usage,111,94,0.25,0.1600928074,0.2177340353,0.7822659647,0.9473684211,0.06691449814,0.0001289117575,0.0001817212558,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@diegoAtAlpine I found the same problems - not sure why this is the case though.,Usage,80,80,0.5,0.162412993,0.2177340353,0.7822659647,0.7368421053,0.05204460967,0.0001289117575,0.0001817212558,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"However, the ValueError should be resolved by the code snippet.",Usage,63,63,0.75,0.1647331787,0.2177340353,0.7822659647,0.5263157895,0.03717472119,0.0001289117575,0.0001817212558,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Not sure what you want to see how to call it as nmhkahn's examples seems to do the job?,Usage,87,87,1,0.1670533643,0.2177340353,0.7822659647,1,0.07063197026,0.0001289117575,0.0001817212558,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@nmhkahn @pawni @ when you do: CODE doesn't that mean that your using CODE as a placeholder?,Usage,164,92,0.3333333333,0.1693735499,0.2177649084,0.7822350916,0.6666666667,0.0594795539,0.0001817212558,2.72E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,People have commented that they want CODE to be a placer holder but thats what I had for my version of it: CODE,Usage,519,111,0.6666666667,0.1716937355,0.2177649084,0.7822350916,1,0.08921933086,0.0001817212558,2.72E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,is that not correct?,Usage,20,20,1,0.1740139211,0.2177649084,0.7822350916,0.1666666667,0.01486988848,0.0001817212558,2.72E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I have already extended tf.contrib.layers.batch_norm to allow passing a Tensor or a Placeholder for is_training.,Task Progress,112,112,0.5,0.1763341067,0.2177695226,0.7822304774,1,0.05576208178,2.72E-05,0.0002905465434,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Now available inhttps://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed,Task Progress,142,142,1,0.1786542923,0.2177695226,0.7822304774,0.2,0.01115241636,2.72E-05,0.0002905465434,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,is it just me or does adding this BN layer noticeably slows down training of a single epoch?,Solution Discussion,92,92,1,0.180974478,0.2178188844,0.7821811156,1,0.06691449814,0.0002905465434,3.25E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@brando90 It slows down training for me as well but I think that this is expected as it needs to calculate some statistics.,Solution Discussion,123,123,0.5,0.1832946636,0.2178244117,0.7821755883,1,0.08550185874,3.25E-05,0.0001191985819,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,And your version looks good to me.,Social Conversation,34,34,1,0.1856148492,0.2178244117,0.7821755883,0.3043478261,0.02602230483,3.25E-05,0.0001191985819,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"BatchNorm is currently very slow (because of all the statistics computed), but they are working on adding a cudnn batchnorm op as said [here](https://github.com/tensorflow/tensorflow/pull/1759#issuecomment-228856467).",Solution Discussion,217,217,1,0.1879350348,0.2178446627,0.7821553373,1,0.1003717472,0.0001191985819,0.02397966155,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@nmhkahn  quick question. When you wrote (for testing): CODE in theory, can bx and by be any data set?",Usage,166,102,0.3333333333,0.1902552204,0.2219186371,0.7780813629,1,0.0780669145,0.02397966155,0.002529669272,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,i.e. it can still be the **training** set even though we are not training?,Usage,74,74,0.6666666667,0.192575406,0.2219186371,0.7780813629,0.6666666667,0.05204460967,0.02397966155,0.002529669272,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,(i.e. just to track the train error),Usage,36,36,1,0.1948955916,0.2219186371,0.7780813629,0.3333333333,0.02602230483,0.02397966155,0.002529669272,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@brando90 you're right.,Social Conversation,23,23,1,0.1972157773,0.22234841,0.77765159,1,0.01115241636,0.002529669272,0.006369485616,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I am also confused regarding is_training and reuse flags.,Social Conversation,57,57,0.0625,0.1995359629,0.2234305404,0.7765694596,0.3461538462,0.03345724907,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I have created a program following the CIFAR example, where my code is structured as in CIFAR:-         Inference-         Loss-         Train",Usage,142,142,0.125,0.2018561485,0.2234305404,0.7765694596,0.8846153846,0.08550185874,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,And I am running it in a multi-gpu fashion (for training).,Usage,58,58,0.1875,0.2041763341,0.2234305404,0.7765694596,0.4615384615,0.04460966543,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,So I have one script for training (similar to cifar10_multigpu.py) and one for testing (similar to cifar10_eval.py).,Usage,116,116,0.25,0.2064965197,0.2234305404,0.7765694596,0.6538461538,0.06319702602,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,So CODE,Usage,343,7,0.3125,0.2088167053,0.2234305404,0.7765694596,0.07692307692,0.007434944238,0.006369485616,0.006685871092,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,The inference happens with the function MyModel.,Usage,48,48,0.375,0.211136891,0.2234305404,0.7765694596,0.2692307692,0.02602230483,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"(below is an example of the function, in reality i use more layers and neurons). CODE",Usage,1113,85,0.4375,0.2134570766,0.2234305404,0.7765694596,0.6153846154,0.0594795539,0.006369485616,0.006685871092,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I want to perform batch nomalization.,Usage,37,37,0.5,0.2157772622,0.2234305404,0.7765694596,0.2307692308,0.02230483271,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,So when I did: CODE,Usage,560,19,0.5625,0.2180974478,0.2234305404,0.7765694596,0.1923076923,0.01858736059,0.006369485616,0.006685871092,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I got the following error in the training phase:Variable bnormalization/beta does not exist, disallowed. Did you mean to set reuse=None in VarScope?",Usage,148,148,0.625,0.2204176334,0.2234305404,0.7765694596,0.9615384615,0.09293680297,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,From what I 've been reading in this thread in the training phase I should be using reuse=None.,Usage,95,95,0.6875,0.222737819,0.2234305404,0.7765694596,0.7307692308,0.07063197026,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Have I got this part correct?,Usage,29,29,0.75,0.2250580046,0.2234305404,0.7765694596,0.2307692308,0.02230483271,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"If this is true, then since I am using two GPUS, should I do reuse=None in the first GPU and reuse=True in the second?",Usage,118,118,0.8125,0.2273781903,0.2234305404,0.7765694596,1,0.09665427509,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Or since I am doing tf.get_variable_scope().reuse_variables() it takes care of itself?,Usage,86,86,0.875,0.2296983759,0.2234305404,0.7765694596,0.4230769231,0.04089219331,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Finally, in the testing phase, should I have is_training=False and reuse=True?",Usage,78,78,0.9375,0.2320185615,0.2234305404,0.7765694596,0.5,0.04832713755,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Any help is greatly appreciated.,Social Conversation,32,32,1,0.2343387471,0.2234305404,0.7765694596,0.1923076923,0.01858736059,0.006369485616,0.006685871092,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Now tf.contrib.layers.batch_norm accepts a Tensor, Variable or Placeholder as is_training https://github.com/tensorflow/tensorflow/commit/9da5fc8e6425cabd61fc36f0dcc1823a093d5c1d#diff-94bbcef0ec8a5cdef55f705e99c2b2ed",Task Progress,216,216,1,0.2366589327,0.2245664225,0.7754335775,1,0.04089219331,0.006685871092,0.003771541207,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Is it normal that Batch Normalization makes my experiments **worse**?,Usage,69,69,0.25,0.2389791183,0.2252071806,0.7747928194,0.2127659574,0.03717472119,0.003771541207,0.003197332215,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I tried it on a 2 layered NN network based on the MNIST beginner tutorial and I consistently get worse results when BN is present: with BN (one with scale and center trained and the other not) accuracy is 0.8423, 0.8221 and without BN accuracy is 0.9477.",Usage,254,254,0.5,0.2412993039,0.2252071806,0.7747928194,1,0.1747211896,0.003771541207,0.003197332215,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,My script is present here https://github.com/brando90/tensor_flow_experiments/blob/master/tf_tutorials/beginner_tutorial_MNIST_BN.py,Usage,132,132,0.75,0.2436194896,0.2252071806,0.7747928194,0.1276595745,0.02230483271,0.003771541207,0.003197332215,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,anyone has experienced these problems or is BN just like this and I need to do something else to make it work?,Usage,110,110,1,0.2459396752,0.2252071806,0.7747928194,0.4680851064,0.08178438662,0.003771541207,0.003197332215,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"But what it is important is that either you pass [updates_collections=None](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/layers/python/layers/layers.py#L142) so the moving_mean and moving_variance are updated in-place, otherwise you will need gather the update_ops and make sure they are run.",Usage,319,319,0.3333333333,0.2482598608,0.2257503846,0.7742496154,1,0.1635687732,0.003197332215,0.0005734545701,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I would like to encourage you to use [CODE] URL  or [CODE] URL  to build your model.,Usage,260,84,0.6666666667,0.2505800464,0.2257503846,0.7742496154,0.4318181818,0.07063197026,0.003197332215,0.0005734545701,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,605,4,1,0.252900232,0.2257503846,0.7742496154,0.02272727273,0.003717472119,0.003197332215,0.0005734545701,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada I changed my old one where I manually tell it to train or not (based on a tf.cond) and now it seems the accuracy is up to ~95's again.,Usage,142,142,0.09090909091,0.2552204176,0.2258478105,0.7741521895,1,0.1115241636,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Why was it that I needed to change updates_collections to be None?,Usage,66,66,0.1818181818,0.2575406032,0.2258478105,0.7741521895,0.4,0.04460966543,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Do you mind explaining me why that gave such a big accuracy difference?,Usage,71,71,0.2727272727,0.2598607889,0.2258478105,0.7741521895,0.4333333333,0.04832713755,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Its seems like a non-trivial change (should it None be its default value then if it matters so much?).,Usage,102,102,0.3636363636,0.2621809745,0.2258478105,0.7741521895,0.6666666667,0.07434944238,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks!,Social Conversation,7,7,0.4545454545,0.2645011601,0.2258478105,0.7741521895,0.03333333333,0.003717472119,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,:),Social Conversation,2,2,0.5454545455,0.2668213457,0.2258478105,0.7741521895,0.03333333333,0.003717472119,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Also, I noticed you said it was a placeholder and I didn't need to do it manually.",Usage,82,82,0.6363636364,0.2691415313,0.2258478105,0.7741521895,0.5666666667,0.06319702602,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"However, when I passed a placeholder for is_training it said CODEtf.TensorCODEboolCODEif t is not None:CODEif t:CODE and pointed to batch_norm code.",Usage,293,148,0.7272727273,0.2714617169,0.2258478105,0.7741521895,0.8,0.08921933086,0.0005734545701,0.0001523931237,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Maybe It could be nice to show how this placeholder thing should be used because it seems I don't understand how its suppose to be used.,Usage,136,136,0.8181818182,0.2737819026,0.2258478105,0.7741521895,0.8666666667,0.09665427509,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks!,Social Conversation,7,7,0.9090909091,0.2761020882,0.2258478105,0.7741521895,0.03333333333,0.003717472119,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,:),Social Conversation,2,2,1,0.2784222738,0.2258478105,0.7741521895,0.03333333333,0.003717472119,0.0005734545701,0.0001523931237,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@brando90The relevant part of the code is here [L227-256](https://github.com/tensorflow/tensorflow/blob/98d63de3bb2bab7c9a81f83c8ca864741399300c/tensorflow/contrib/layers/python/layers/layers.py#L227-L256).,Solution Discussion,206,206,0.25,0.2807424594,0.225873701,0.774126299,0.5882352941,0.07434944238,0.0001523931237,0.002542683041,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,As you will notice is there is a CODE statement that forces the updates.,Solution Discussion,99,72,0.5,0.283062645,0.225873701,0.774126299,0.4117647059,0.05204460967,0.0001523931237,0.002542683041,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I believe that for the code to be used ""right out of the box"" the default should be None.",Usage,89,89,0.75,0.2853828306,0.225873701,0.774126299,0.5588235294,0.07063197026,0.0001523931237,0.002542683041,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"As for my comment above [1122](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235433645), I figured out that   tf.get_variable_scope().reuse_variables() takes care of the issue, so  in the training phase the argument reuse of batch_norm should be None.",Usage,271,271,1,0.2877030162,0.225873701,0.774126299,1,0.126394052,0.0001523931237,0.002542683041,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Use of batch_norm with tf.placeholder CODE,Usage,315,42,1,0.2900232019,0.2263056848,0.7736943152,1,0.02230483271,0.002542683041,2.86E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"The problem before was that you were not updating the CODE and CODE after each step, when updates_collections is None it forces the updates as part of the computation.",Usage,189,167,0.3333333333,0.2923433875,0.2263105393,0.7736894607,0.8529411765,0.1078066914,2.86E-05,0.1007313833,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"However when a network has many batch_norm layers it is more efficient to collect all the update ops and run them together, so each layer don't need to wait for the update to finish.",Usage,182,182,0.6666666667,0.2946635731,0.2263105393,0.7736894607,1,0.126394052,2.86E-05,0.1007313833,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,145,4,1,0.2969837587,0.2263105393,0.7736894607,0.02941176471,0.003717472119,2.86E-05,0.1007313833,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I was trying to use batch norm with a 2 layered densely connected NN with the (flatten) MNIST  (and relu units) data set for the task of auto-encoding  and I keep getting a NaN error.,Usage,183,183,0.25,0.2993039443,0.2434240867,0.7565759133,1,0.1412639405,0.1007313833,0.1326150236,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Anyone know why might this be?,Usage,30,30,0.5,0.3016241299,0.2434240867,0.7565759133,0.1578947368,0.02230483271,0.1007313833,0.1326150236,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Is this ever possible with BN?,Solution Discussion,30,30,0.75,0.3039443155,0.2434240867,0.7565759133,0.1578947368,0.02230483271,0.1007313833,0.1326150236,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"seem fishy, but it couldn't be my learning set up, rate etc. (but I'd assume it shouldn't because BN should be sort of rubust to this)",Usage,134,134,1,0.3062645012,0.2434240867,0.7565759133,0.7105263158,0.1003717472,0.1007313833,0.1326150236,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada I am not understanding the right way of using CODE specially concerning the flag CODE.,Usage,119,94,0.1666666667,0.3085846868,0.2659544384,0.7340455616,0.5,0.0594795539,0.1326150236,0.1061453942,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"If I understood correctly if the flag is CODE the network is not efficient, so I should let CODE and then I should collect all the batch_norm updates and run them together.",Usage,215,172,0.3333333333,0.3109048724,0.2659544384,0.7340455616,1,0.1189591078,0.1326150236,0.1061453942,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,You collect the batch_norms updates by doing: CODE.,Usage,114,51,0.5,0.313225058,0.2659544384,0.7340455616,0.25,0.02973977695,0.1326150236,0.1061453942,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I have many different models that use different batch_norm layers, this wouldn't work right?: CODE",Usage,405,98,0.6666666667,0.3155452436,0.2659544384,0.7340455616,0.46875,0.05576208178,0.1326150236,0.1061453942,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Could you explain this part with a bit more details?,Usage,52,52,0.8333333333,0.3178654292,0.2659544384,0.7340455616,0.3125,0.03717472119,0.1326150236,0.1061453942,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you very much.,Social Conversation,20,20,1,0.3201856148,0.2659544384,0.7340455616,0.125,0.01486988848,0.1326150236,0.1061453942,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Just put it in seperate collection-keys: CODE CODE,Usage,489,50,1,0.3225058005,0.2839877878,0.7160122122,1,0.03345724907,0.1061453942,3.21E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Nevertheless, the documentation seams to be out-dated.",Usage,54,54,0.09090909091,0.3248259861,0.2839932351,0.7160067649,0.1355932203,0.02973977695,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It tells to do the following: CODE,Usage,205,34,0.1818181818,0.3271461717,0.2839932351,0.7160067649,0.1186440678,0.02602230483,3.21E-05,0.06565842647,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I replaced it with _tf.tuple()_,Usage,31,31,0.2727272727,0.3294663573,0.2839932351,0.7160067649,0.08474576271,0.01858736059,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"-         ~~I don't know how to access _control_flow_ops.with_dependencies()_. How can I access functions within control_flow_ops module? I have seen other examples just using tf.with_dependecies(), but I cannot do that with Tensorflow 0.10.~~ I found it here: _tf.python.control_flow_ops.with_dependencies()_",Usage,309,309,0.3636363636,0.3317865429,0.2839932351,0.7160067649,0.6440677966,0.1412639405,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,**EDIT:**,Social Conversation,9,9,0.4545454545,0.3341067285,0.2839932351,0.7160067649,0.03389830508,0.007434944238,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,**EDIT 2:**,Social Conversation,11,11,0.5454545455,0.3364269142,0.2839932351,0.7160067649,0.05084745763,0.01115241636,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"After doing some runs on my network, I have to say that ~~I can not see any performance difference between using  _updates_collections=None_ in contrast to manually fetching _tf.GraphKeys.UPDATE_OPS_ while graph construction~~. Even with heavy use of batch normalization (in total, my _tf.get_collection(tf.GraphKeys.UPDATE_OPS)_ returns 140 Update-Ops, all of them are BN-ops only)",Usage,382,382,0.6363636364,0.3387470998,0.2839932351,0.7160067649,1,0.219330855,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Edit: Hard to say, if my results are correct, but the whole network indeed seams to be 1.5x faster.",Solution Discussion,99,99,0.7272727273,0.3410672854,0.2839932351,0.7160067649,0.3220338983,0.07063197026,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"As far as I know, BN-statistics are calculated on CPU, not GPU so far.",Solution Discussion,70,70,0.8181818182,0.343387471,0.2839932351,0.7160067649,0.2542372881,0.05576208178,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Can anyone of you see any performance benefits as well?,Solution Discussion,55,55,0.9090909091,0.3457076566,0.2839932351,0.7160067649,0.1694915254,0.03717472119,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Please share your results :),Social Conversation,28,28,1,0.3480278422,0.2839932351,0.7160067649,0.08474576271,0.01858736059,3.21E-05,0.06565842647,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Coming back to the performance issue, does the current batch norm layer benfit at all from GPU usage?",Solution Discussion,101,101,0.5,0.3503480278,0.2951481359,0.7048518641,1,0.06691449814,0.06565842647,7.04E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Anyone has experienced benefits from GPUs with this batch norm implementation?,Solution Discussion,78,78,1,0.3526682135,0.2951481359,0.7048518641,0.6111111111,0.04089219331,0.06565842647,7.04E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,You can test for yourself:https://github.com/tensorflow/tensorflow/blob/4addf4b5806cd731949c6582a83f5824599cd1ef/tensorflow/python/ops/batch_norm_benchmark.py,Solution Discussion,158,158,1,0.3549883991,0.2951601039,0.7048398961,1,0.04832713755,7.04E-05,0.01930083431,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Sorry for the spam, but the documentation doesn't really explain how to use this BN with convolution (maybe should be provided somewhere?).",Usage,139,139,0.3333333333,0.3573085847,0.2984391787,0.7015608213,1,0.08178438662,0.01930083431,0.003725804409,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,In short how does it figure out that it should apply and learn the same parameters per feature (rather than per activation)?,Solution Discussion,124,124,0.6666666667,0.3596287703,0.2984391787,0.7015608213,1,0.08178438662,0.01930083431,0.003725804409,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,(Is there at least a code snippet to do this?),Usage,46,46,1,0.3619489559,0.2984391787,0.7015608213,0.4545454545,0.03717472119,0.01930083431,0.003725804409,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The slim batch_norm wrapper normalizes over the last dimension of your input tensor.,Solution Discussion,84,84,0.25,0.3642691415,0.2990721664,0.7009278336,0.5,0.04832713755,0.003725804409,0.360850414,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization.",Solution Discussion,139,139,0.5,0.3665893271,0.2990721664,0.7009278336,0.8846153846,0.08550185874,0.003725804409,0.360850414,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization.",Solution Discussion,163,163,0.75,0.3689095128,0.2990721664,0.7009278336,1,0.09665427509,0.003725804409,0.360850414,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada maybe forth being a bit more descriptive about this.,Contribution and Commitment,60,60,1,0.3712296984,0.2990721664,0.7009278336,0.3846153846,0.03717472119,0.003725804409,0.360850414,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@nmhkahn Regarding your code snippet, may I ask why is CODE set to be CODE when CODE?",Usage,104,85,0.25,0.373549884,0.3603780918,0.6396219082,1,0.06319702602,0.360850414,0.06400737522,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I thought in the original paper, CODE and CODE are ""learned along with the original model parameters"".",Solution Discussion,107,102,0.5,0.3758700696,0.3603780918,0.6396219082,1,0.06319702602,0.360850414,0.06400737522,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"To do that, shouldn't they be only initialized once and then reused in all training steps?",Usage,90,90,0.75,0.3781902552,0.3603780918,0.6396219082,0.9411764706,0.0594795539,0.360850414,0.06400737522,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,207,4,1,0.3805104408,0.3603780918,0.6396219082,0.05882352941,0.003717472119,0.360850414,0.06400737522,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I greatly appreciate the work that the TF team has put in here to make batch_norm available and effective.,Social Conversation,106,106,0.1111111111,0.3828306265,0.3712524908,0.6287475092,0.6129032258,0.07063197026,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"From my searching, this thread is the best resource for how to use it.",Social Conversation,70,70,0.2222222222,0.3851508121,0.3712524908,0.6287475092,0.4516129032,0.05204460967,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"There are many different problems and ideas flying around here, and it's difficult to figure out the consensus advice for the simplest standard case of how to use the batch_norm layer.",Social Conversation,184,184,0.3333333333,0.3874709977,0.3712524908,0.6287475092,1,0.1152416357,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,My best attempt to figure that out brought me to the following code: CODE,Usage,525,73,0.4444444444,0.3897911833,0.3712524908,0.6287475092,0.4516129032,0.05204460967,0.06400737522,0.0004404877976,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Then I set is_training_ph to True for training and False for testing.,Usage,69,69,0.5555555556,0.3921113689,0.3712524908,0.6287475092,0.3870967742,0.04460966543,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,This doesn't work for me.,Usage,25,25,0.6666666667,0.3944315545,0.3712524908,0.6287475092,0.1612903226,0.01858736059,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The model trains fine, but the test performance is terrible.",Usage,60,60,0.7777777778,0.3967517401,0.3712524908,0.6287475092,0.3225806452,0.03717472119,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In contrast, if I maintain is_training_ph=True for test time, it works great.",Usage,77,77,0.8888888889,0.3990719258,0.3712524908,0.6287475092,0.4193548387,0.04832713755,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Thus, I'm guessing I still have a scope issue so that it's not finding the proper existing variables.",Usage,101,101,1,0.4013921114,0.3712524908,0.6287475092,0.5806451613,0.06691449814,0.06400737522,0.0004404877976,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@davek44 I'm using the same code framework that you are using and I observed the same thing: when turns on CODE during training phase and turns off CODE for validation and/or testing phase, the model trains well like the paper described (model converges faster and I was able to use a larger learning rate), however the testing performance is terrible.",Usage,381,352,0.25,0.403712297,0.3713273265,0.6286726735,1,0.2230483271,0.0004404877976,0.001260543864,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"If I turns on CODE all the time, the model trains the same as without inserting batch norm layer.",Usage,111,97,0.5,0.4060324826,0.3713273265,0.6286726735,0.3166666667,0.07063197026,0.0004404877976,0.001260543864,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I haven't figured out what I did wrong, I'm planning to use TensorBoard to monitor the parameters.",Usage,98,98,0.75,0.4083526682,0.3713273265,0.6286726735,0.2833333333,0.06319702602,0.0004404877976,0.001260543864,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Would you please update if you diagnose the cause of this behavior?,Usage,67,67,1,0.4106728538,0.3713273265,0.6286726735,0.2,0.04460966543,0.0004404877976,0.001260543864,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial.",Usage,97,97,0.5,0.4129930394,0.371541484,0.628458516,1,0.04832713755,0.001260543864,0.002290423384,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,224,4,1,0.4153132251,0.371541484,0.628458516,0.07692307692,0.003717472119,0.001260543864,0.002290423384,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,I see the same poor test performance with that code.,Usage,52,52,1,0.4176334107,0.3719306107,0.6280693893,1,0.03717472119,0.002290423384,0.006696810203,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Without more details is impossible to know, my guesses are that you only train for a few iterations, so the moving_mean and moving_average haven't converge yet.",Usage,160,160,0.5,0.4199535963,0.3730683512,0.6269316488,1,0.09665427509,0.006696810203,0.035573704,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,You can change the batch_size during test to see how the performance degrades as you make your batch smaller.,Usage,109,109,1,0.4222737819,0.3730683512,0.6269316488,0.7307692308,0.07063197026,0.006696810203,0.035573704,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I had exactly the same problem either with tf.slim batchnorm or with tf.cond and input is_training as a placeholder.,Usage,116,116,0.3333333333,0.4245939675,0.3791120712,0.6208879288,0.6333333333,0.07063197026,0.035573704,0.002989300513,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In the former case, when investigating the trained model, I found out that the moving mean and moving variance consist of all zeros.",Usage,132,132,0.6666666667,0.4269141531,0.3791120712,0.6208879288,0.7666666667,0.08550185874,0.035573704,0.002989300513,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In the latter case, the moving mean and variance look more reasonable (with different values), but if I use is_training=False in test time, the performance is also really bad.",Usage,175,175,1,0.4292343387,0.3791120712,0.6208879288,1,0.1115241636,0.035573704,0.002989300513,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@nmduc @davek44  I wrote some code to track the moving mean and moving variance computed in CODE during training and testing.,Usage,151,125,0.1666666667,0.4315545244,0.3796199321,0.6203800679,0.55,0.08178438662,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I found out that the value of CODE matters a lot (they use exponential decay to compute moving average and moving variance), with a CODE setting closer to 1.0 (i.e. CODE), moving mean drops to a value closer to 0.",Usage,227,213,0.3333333333,0.43387471,0.3796199321,0.6203800679,1,0.1486988848,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I did 2 test runs with the exact same code but different CODE settings in the CODE, and my validation/test accuracies seemed more reasonable.",Usage,170,141,0.5,0.4361948956,0.3796199321,0.6203800679,0.625,0.09293680297,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"The test run results with CODE<img width=""784"" alt=""screen shot 2016-11-16 at 1 51 51 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361517/dd5dbbd8-ac05-11e6-85ac-5a9e2dec3a2b.png"">",Usage,204,197,0.6666666667,0.4385150812,0.3796199321,0.6203800679,0.6,0.08921933086,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"The test run results with CODE (CODE is the default setting in CODE)<img width=""784"" alt=""screen shot 2016-11-16 at 2 03 58 pm"" src=""https://cloud.githubusercontent.com/assets/6901075/20361605/31729f5e-ac06-11e6-9736-eb9ad2f15de1.png"">",Usage,279,235,0.8333333333,0.4408352668,0.3796199321,0.6203800679,0.75,0.1115241636,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,(also seems like larger decay value would require the model to train longer to see validation accuracy change ),Usage,111,111,1,0.4431554524,0.3796199321,0.6203800679,0.45,0.06691449814,0.002989300513,0.00370364328,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Yup that fixed it.,Usage,18,18,0.2,0.4454756381,0.3802491548,0.6197508452,0.2857142857,0.01486988848,0.00370364328,0.0009405748861,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks for sharing your analysis @zhongyuk!,Social Conversation,43,43,0.4,0.4477958237,0.3802491548,0.6197508452,0.4285714286,0.02230483271,0.00370364328,0.0009405748861,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I encourage the developers to consider making decay=0.9 the default.,Solution Discussion,68,68,0.6,0.4501160093,0.3802491548,0.6197508452,0.7142857143,0.03717472119,0.00370364328,0.0009405748861,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Even 0.99 doesn't work well for me.,Solution Discussion,35,35,0.8,0.4524361949,0.3802491548,0.6197508452,0.5,0.02602230483,0.00370364328,0.0009405748861,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"That's the default value in Torch's implementation, too; see the momentum parameter in https://github.com/torch/nn/blob/master/BatchNormalization.lua",Solution Discussion,149,149,1,0.4547563805,0.3802491548,0.6197508452,1,0.05204460967,0.00370364328,0.0009405748861,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@zhongyuk Thanks a lot for sharing .,Social Conversation,36,36,0.5,0.4570765661,0.3804089518,0.6195910482,1,0.02230483271,0.0009405748861,0.00284398009,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It works for me now.,Usage,20,20,1,0.4593967517,0.3804089518,0.6195910482,0.8333333333,0.01858736059,0.0009405748861,0.00284398009,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,This seems important.,Social Conversation,21,21,0.25,0.4617169374,0.3808921239,0.6191078761,0.1,0.01115241636,0.00284398009,0.001516387023,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada we should consider the right course of action here before 1.0.,Social Conversation,70,70,0.5,0.464037123,0.3808921239,0.6191078761,0.4,0.04460966543,0.00284398009,0.001516387023,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In the short term, can one of the interested parties send me a PR documenting the fact that CODE might have to be significantly lowered when experiencing poor eval performance?",Action on Issue,179,176,0.75,0.4663573086,0.3808921239,0.6191078761,1,0.1115241636,0.00284398009,0.001516387023,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I am pretty sure I've never had to tweak that parameter, but it might be a side effect of the distributed setting.",Solution Discussion,114,114,1,0.4686774942,0.3808921239,0.6191078761,0.7666666667,0.08550185874,0.00284398009,0.001516387023,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,We could change the default to 0.9 or document better its impact in smaller datasets or few updates.,Solution Discussion,100,100,0.5,0.4709976798,0.3811497473,0.6188502527,0.2857142857,0.06691449814,0.001516387023,0.03062535971,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@vincentvanhoucke in our distributed setting we usually do millions of updates so it is ok, however in other cases like the one here which does only a few hundreds of updates it makes a big difference:For example using decay=0.999 has a 0.36 bias after 1000 updates, but that bias goes down to 0.000045 after 10000 updates and to 0.0 after 50000 updates.",Solution Discussion,354,354,1,0.4733178654,0.3811497473,0.6188502527,1,0.2342007435,0.001516387023,0.03062535971,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Just wanted to note that I also have the problem of poor test performance, specifically using small batch sizes (anything smaller than 10 instead of the 200 I used for training diminishes test accuracy).",Usage,203,203,0.25,0.475638051,0.3863527786,0.6136472214,1,0.126394052,0.03062535971,0.0005793956387,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I've used a tf.placeholder to switch between testing/training mode.,Usage,67,67,0.5,0.4779582367,0.3863527786,0.6136472214,0.3235294118,0.04089219331,0.03062535971,0.0005793956387,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"It's great that this batch normalization layer works for better training convergence, but if you can't apply the model in production, there isn't much of a point in using it.",Motivation,174,174,0.75,0.4802784223,0.3863527786,0.6136472214,0.8823529412,0.1115241636,0.03062535971,0.0005793956387,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Can anyone confirm good test performance with small or single data samples using this batch norm layer?,Usage,103,103,1,0.4825986079,0.3863527786,0.6136472214,0.5,0.06319702602,0.03062535971,0.0005793956387,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I can confirm that test performance is good when using is_training=False with small batches and even with batch_size=1, since it is not using statistic from the batch, but the statistic learnt during training.",Usage,209,209,0.5,0.4849187935,0.3864512138,0.6135487862,1,0.126394052,0.0005793956387,0.001342021376,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Just need to make sure that the statistics have converged with default decay=0.999 that implies at least 50k updates.,Usage,117,117,1,0.4872389791,0.3864512138,0.6135487862,0.5588235294,0.07063197026,0.0005793956387,0.001342021376,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"To follow up with TF developer's confirmation, I track the convergence of the statistics with two different CODE settings (and training batch_size=1).",Solution Discussion,153,150,0.3333333333,0.4895591647,0.3866792137,0.6133207863,1,0.08178438662,0.001342021376,0.0004646292825,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"With CODE, the statistics converge (bias<0.001) after 550~600 steps of learning/updates.",Solution Discussion,96,88,0.6666666667,0.4918793503,0.3866792137,0.6133207863,0.5454545455,0.04460966543,0.001342021376,0.0004646292825,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"With CODE, the statistics converge (biase<0.001) within within 100 steps of learning/updates.",Solution Discussion,100,93,1,0.494199536,0.3866792137,0.6133207863,0.5909090909,0.04832713755,0.001342021376,0.0004646292825,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"@sguada thanks, does that also mean the output is actually independent of the batch size?",Solution Discussion,89,89,0.1111111111,0.4965197216,0.386758151,0.613241849,0.5769230769,0.05576208178,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,because I'm noticing very slight changes with big impact on my accuracy (maybe my definition of performance is just more easily affected by this slight change).,Usage,160,160,0.2222222222,0.4988399072,0.386758151,0.613241849,1,0.09665427509,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"To be precise, all values in my 128 dimensional output tensor increase such that the total vector length scales almost linearly with the batch size.",Usage,148,148,0.3333333333,0.5011600928,0.386758151,0.613241849,0.9615384615,0.09293680297,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Per value this isn't that much of a difference, but has a big impact when computing vector distances in latent spaces.",Usage,118,118,0.4444444444,0.5034802784,0.386758151,0.613241849,0.8076923077,0.0780669145,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@zhongyuk thanks, I've run about 5k updates with CODE, so it should've converged and testing performance using large batch sizes is fine.",Usage,144,137,0.5555555556,0.505800464,0.386758151,0.613241849,0.9230769231,0.08921933086,0.0004646292825,0.0004596312407,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"But even if it didn't, would it result in a difference between training a testing?",Usage,82,82,0.6666666667,0.5081206497,0.386758151,0.613241849,0.5769230769,0.05576208178,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I'd be seeing bad performance during training *and* testing if it hadn't converged, right?",Usage,90,90,0.7777777778,0.5104408353,0.386758151,0.613241849,0.5769230769,0.05576208178,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I will investigate some more and see if I can reproduce the issue on another task.,Social Conversation,82,82,0.8888888889,0.5127610209,0.386758151,0.613241849,0.6153846154,0.0594795539,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks for the quick feed back so far!,Social Conversation,38,38,1,0.5150812065,0.386758151,0.613241849,0.3076923077,0.02973977695,0.0004646292825,0.0004596312407,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@dominikandreas If your poor testing performance is caused by statistics not converging, you'd see reasonably good training performance but bad testing performance.",Usage,164,164,0.3333333333,0.5174013921,0.386836239,0.613163761,1,0.08550185874,0.0004596312407,0.01050154595,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Because during training, the batch normalization is done using the training batch statistics only.",Solution Discussion,98,98,0.6666666667,0.5197215777,0.386836239,0.613163761,0.6086956522,0.05204460967,0.0004596312407,0.01050154595,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"However, during testing time, it's using the moving average statistics of all the training batches to normalize the input tensor.",Solution Discussion,129,129,1,0.5220417633,0.386836239,0.613163761,0.8695652174,0.07434944238,0.0004596312407,0.01050154595,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I found and error in my code, batch normalization is working fine now :-)",Usage,73,73,0.5,0.524361949,0.3886203772,0.6113796228,1,0.05204460967,0.01050154595,0.06114849531,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,thanks for your support,Social Conversation,23,23,1,0.5266821346,0.3886203772,0.6113796228,0.2857142857,0.01486988848,0.01050154595,0.06114849531,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Hi @zhongyuk , how did you keep track of the moving mean and variance?",Usage,70,70,0.5,0.5290023202,0.3990090727,0.6009909273,1,0.04832713755,0.06114849531,0.001171333533,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks!,Social Conversation,7,7,1,0.5313225058,0.3990090727,0.6009909273,0.07692307692,0.003717472119,0.06114849531,0.001171333533,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@rogertrullo Generally I setup TensorBoard to track moving mean and variance.,Usage,77,77,0.5,0.5336426914,0.399208074,0.600791926,0.55,0.04089219331,0.001171333533,0.5172067019,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Other than that, I also tried fetching statistics through CODE within scope during training and reference to monitor the bias.",Usage,154,126,1,0.535962877,0.399208074,0.600791926,1,0.07434944238,0.001171333533,0.5172067019,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"hi,I have same problem as other described that I have good training results but validation/testing is bad after using batch_norm.",Usage,129,129,0.2,0.5382830626,0.4870778235,0.5129221765,1,0.08178438662,0.5172067019,0.02794046823,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I use the function like this:conv_normed1 = tf.contrib.layers.batch_norm(conv1 + block1_layer3_1_biases, updates_collections=None, scale=True, decay=batch_norm_decay, center=True, is_training=is_training )",Usage,205,205,0.4,0.5406032483,0.4870778235,0.5129221765,0.8636363636,0.07063197026,0.5172067019,0.02794046823,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,decay value is 0.9,Usage,18,18,0.6,0.5429234339,0.4870778235,0.5129221765,0.1818181818,0.01486988848,0.5172067019,0.02794046823,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,do I need to set the reuse flag?,Usage,32,32,0.8,0.5452436195,0.4870778235,0.5129221765,0.3636363636,0.02973977695,0.5172067019,0.02794046823,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I will glad for any help.,Social Conversation,25,25,1,0.5475638051,0.4870778235,0.5129221765,0.2727272727,0.02230483271,0.5172067019,0.02794046823,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I have been using batch_norm as described in this thread (with a tf.bool for training; and ops.GraphKeys.UPDATE_OPS) and everything works.,Usage,138,138,0.2,0.5498839907,0.4918247108,0.5081752892,0.5641025641,0.08178438662,0.02794046823,0.001087592757,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"When saving and restoring using:saver = tf.train.Saver()it works, but when saving using:saver = tf.train.Saver(tf.trainable_variables() + [global_step])so that I can save storage space (by not saving the gradients etc)on restore there is an error:""uninitialized value unpool4/convc/bn/moving_mean""",Usage,297,297,0.4,0.5522041763,0.4918247108,0.5081752892,1,0.1449814126,0.02794046823,0.001087592757,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Obviously this is because moving_mean (and I suppose moving_variance) hasn't been saved for any of the layers.,Usage,110,110,0.6,0.5545243619,0.4918247108,0.5081752892,0.4358974359,0.06319702602,0.02794046823,0.001087592757,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,As I have lots of them (nested in many layers) - what is the most efficient way of adding them to the list of values to be saved?,Usage,129,129,0.8,0.5568445476,0.4918247108,0.5081752892,0.6923076923,0.1003717472,0.02794046823,0.001087592757,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Also, given that these are trainable variables, why are they not addded to the trainable_variables collection?",Solution Discussion,110,110,1,0.5591647332,0.4918247108,0.5081752892,0.4102564103,0.0594795539,0.02794046823,0.001087592757,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@mshunshin moving mean and variance are not trainable variables: there are no gradients coming to them, they are just accumulating statistics across minibatches of examples.",Solution Discussion,173,173,0.5,0.5614849188,0.4920094851,0.5079905149,1,0.09293680297,0.001087592757,0.003029756361,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"To save/restore them, you can use tf.global_variables()",Usage,55,55,1,0.5638051044,0.4920094851,0.5079905149,0.32,0.02973977695,0.001087592757,0.003029756361,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,for me things started to work when I used this wrapper:CODE,Usage,314,59,0.5,0.56612529,0.4925242192,0.5074757808,0.75,0.04460966543,0.003029756361,0.001952065384,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,the whole using of scopes and reuse is not clear in this thread for my opinion.,Social Conversation,79,79,1,0.5684454756,0.4925242192,0.5074757808,1,0.0594795539,0.003029756361,0.001952065384,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Many thanks.,Social Conversation,12,12,0.3333333333,0.5707656613,0.4928558613,0.5071441387,0.0625,0.007434944238,0.001952065384,0.003585953541,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,With tf.global_variables() the save files are much larger as I think it includes the gradients; in the end I used: saver = tf.train.Saver([x for x in tf.global_variables() if 'Adam' not in x.name]),Usage,197,197,0.6666666667,0.5730858469,0.4928558613,0.5071441387,1,0.1189591078,0.001952065384,0.003585953541,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,and because the session manager init doesn't initialise them properly: sess.run(tf.variables_initializer([x for x in tf.global_variables() if 'Adam' in x.name])) (Using tf.train.AdamOptimizer),Usage,192,192,1,0.5754060325,0.4928558613,0.5071441387,0.6875,0.08178438662,0.001952065384,0.003585953541,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"You can also use tf.model_variables() which contains the variables of the model, i.e. moving_mean",Usage,97,97,1,0.5777262181,0.4934650893,0.5065349107,1,0.05204460967,0.003585953541,0.07644203172,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@sguada Sorry for trouble you, but is it possible to make an example on how to use slim.batch_norm when combined with slim.conv2d/slim.fully_connect in readme.md?",Usage,162,162,0.125,0.5800464037,0.5064520482,0.4935479518,0.8064516129,0.09293680297,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I'm using slim.batch_norm, but get good training performance and poor validation/test performance.",Usage,98,98,0.25,0.5823665893,0.5064520482,0.4935479518,0.4193548387,0.04832713755,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I think it must be due to improper use of CODE or CODE or some other parameters.,Usage,86,80,0.375,0.5846867749,0.5064520482,0.4935479518,0.5483870968,0.06319702602,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Though there are many issues on batch normalization, it's hard to find a complete code snippet on how to use it, esp. for how to pass different parameters in different phase.",Usage,174,174,0.5,0.5870069606,0.5064520482,0.4935479518,1,0.1152416357,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Say, in my [mnist_bn] URL  code, I controlled dependencies using CODE and set up CODE as a placeholder.",Usage,189,103,0.625,0.5893271462,0.5064520482,0.4935479518,0.6129032258,0.07063197026,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,But validation performance still is poor if I feed {is_training: False}.,Usage,72,72,0.75,0.5916473318,0.5064520482,0.4935479518,0.3548387097,0.04089219331,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I would greatly appreciate it if there's an official and complete (which means training, validating, testing are all included) batch normalization example.",Usage,155,155,0.875,0.5939675174,0.5064520482,0.4935479518,0.7096774194,0.08178438662,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you in advance!,Social Conversation,21,21,1,0.596287703,0.5064520482,0.4935479518,0.1290322581,0.01486988848,0.07644203172,0.0001059019047,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"hi,you need to set different scope for every time you use batch norm and give it the reuse input according to the training/test phase(TRUE when test FALSE when train) that works for me.",Usage,185,185,1,0.5986078886,0.5064700402,0.4935299598,1,0.1301115242,0.0001059019047,0.0009006848543,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@ishaybee Thanks for you help.,Social Conversation,30,30,0.1,0.6009280742,0.5066230602,0.4933769398,0.1282051282,0.01858736059,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I've found my problem= = **It's due to the cold start of moving_mean/moving_variance.**,Usage,87,87,0.2,0.6032482599,0.5066230602,0.4933769398,0.358974359,0.05204460967,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Since I haven't trained enough steps, the estimated moving mean/variance is not that stable.",Usage,92,92,0.3,0.6055684455,0.5066230602,0.4933769398,0.3846153846,0.05576208178,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The result turns out to be: the model performs pretty well on training mini-batches (you know at the beginning loss goes down quickly), but validation performance is erratic (because the estimated population mean/variance are not stable enough).",Usage,245,245,0.4,0.6078886311,0.5066230602,0.4933769398,1,0.1449814126,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"When I trained the model longer, validation accuracy becomes prettier, too.",Usage,75,75,0.5,0.6102088167,0.5066230602,0.4933769398,0.2820512821,0.04089219331,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"**Another important thing is, be sure to use CODE to create train op**.",Usage,98,71,0.6,0.6125290023,0.5066230602,0.4933769398,0.3333333333,0.04832713755,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Do not use tf native CODE.,Usage,77,26,0.7,0.6148491879,0.5066230602,0.4933769398,0.1538461538,0.02230483271,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,What's more:1.         [Here is a full example] URL  on how to use BN layer on MNIST dataset.,Usage,125,93,0.8,0.6171693735,0.5066230602,0.4933769398,0.4871794872,0.07063197026,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,2.         Use a smaller decay value will accelerate the warm-up phase.,Usage,71,71,0.9,0.6194895592,0.5066230602,0.4933769398,0.3333333333,0.04832713755,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The default decay is 0.999, for small datasets such like MNIST, you can choose 0.99 or 0.95, and it warms up in a short time.",Usage,125,125,1,0.6218097448,0.5066230602,0.4933769398,0.641025641,0.09293680297,0.0009006848543,0.008352765185,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@soloice , notice, how in about [comment](https://github.com/tensorflow/tensorflow/issues/1122#issuecomment-235928564) the following parameter is passed inside to the layer for calling batch_norm: >  batch_norm_params = {'is_training': is_training, 'decay': 0.9, 'updates_collections': None}",Usage,291,291,0.2,0.6241299304,0.5080421357,0.4919578643,0.6444444444,0.1078066914,0.008352765185,0.001307600899,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Without CODEset to None (so mean updates are done in place inside BatchNorm), I won't expect surrounding layer (e.g. conv2d) to somehow execute tf.GraphKeys.UPDATE_OPS needed for BatchNorm layer to update running mean and therefore be able to do run on test data later.",Usage,287,269,0.4,0.626450116,0.5080421357,0.4919578643,1,0.1672862454,0.008352765185,0.001307600899,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Or you may try to run UPDATE_OPS yourself explicitly as one [here](https://github.com/tensorflow/tensorflow/issues/7469#issuecomment-279646674)CODE,Usage,325,147,0.6,0.6287703016,0.5080421357,0.4919578643,0.3333333333,0.05576208178,0.008352765185,0.001307600899,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Update - I found that I quoted exactly your code and you do use UPDATE_OPS.,Social Conversation,75,75,0.8,0.6310904872,0.5080421357,0.4919578643,0.3111111111,0.05204460967,0.008352765185,0.001307600899,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"As for ""cold start"", as you see above in discussiion, decreasing BatchNorm running average decay (input param) from default 0.999 to something like 0.95 can speed-up start-up",Usage,174,174,1,0.6334106729,0.5080421357,0.4919578643,0.6444444444,0.1078066914,0.008352765185,0.001307600899,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@pavelbulanov It's very kind of you to help me with this!,Social Conversation,57,57,0.1666666667,0.6357308585,0.5082642878,0.4917357122,0.34375,0.04089219331,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I'll try a smaller value of CODE to see how this helps.,Social Conversation,58,55,0.3333333333,0.6380510441,0.5082642878,0.4917357122,0.375,0.04460966543,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Update: use a small decay (say, 0.9 or 0.95) does help a lot.",Usage,61,61,0.5,0.6403712297,0.5082642878,0.4917357122,0.40625,0.04832713755,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Validation loss goes down very quickly when I set CODE to 0.9.,Usage,65,62,0.6666666667,0.6426914153,0.5082642878,0.4917357122,0.375,0.04460966543,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"However, the drawback of small decay is that its effective range is small: The result is dominated by a few recent samples thus it's not a good estimation of population mean/variance.",Usage,183,183,0.8333333333,0.6450116009,0.5082642878,0.4917357122,1,0.1189591078,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,One needs to balance between quick start (small decay) and a longer effective range (large decay).,Usage,98,98,1,0.6473317865,0.5082642878,0.4917357122,0.5,0.0594795539,0.001307600899,0.3505953752,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Hi,I tried to implement a batch normalisation layer with the help of the suggestions in this issue, but I still have a >70% error in validation and testing...",Usage,158,158,0.25,0.6496519722,0.5678279549,0.4321720451,1,0.1078066914,0.3505953752,0.002790133262,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I do have a lower decay for non-training calls...,Usage,49,49,0.5,0.6519721578,0.5678279549,0.4321720451,0.3448275862,0.03717472119,0.3505953752,0.002790133262,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Here is my code:CODE,Usage,442,20,0.75,0.6542923434,0.5678279549,0.4321720451,0.1724137931,0.01858736059,0.3505953752,0.002790133262,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you in advance.,Social Conversation,21,21,1,0.656612529,0.5678279549,0.4321720451,0.1379310345,0.01486988848,0.3505953752,0.002790133262,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@Alexivia It seems that you are using two different batch normalization layers?,Usage,79,79,0.5,0.6589327146,0.5683019787,0.4316980213,0.9230769231,0.04460966543,0.002790133262,0.003363493529,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"You should use only one BN layer (of course, with different CODE parameter).",Usage,85,76,1,0.6612529002,0.5683019787,0.4316980213,1,0.04832713755,0.002790133262,0.003363493529,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you for your advice @soloice.,Social Conversation,35,35,0.3333333333,0.6635730858,0.5688734124,0.4311265876,0.5454545455,0.02230483271,0.003363493529,0.00232833306,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I tried now with just different CODE and CODE parameters:CODE,Usage,410,61,0.6666666667,0.6658932715,0.5688734124,0.4311265876,1,0.04089219331,0.003363493529,0.00232833306,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,still don't get good validation and testing results... >70%...,Usage,62,62,1,0.6682134571,0.5688734124,0.4311265876,0.8181818182,0.03345724907,0.003363493529,0.00232833306,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"hi,please see my wrapper above.you should use ""with tf.variable_scope(scope, reuse=reuse):"" I think.",Usage,100,100,1,0.6705336427,0.5692689797,0.4307310203,1,0.05576208178,0.00232833306,0.00716690904,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Hi @ishaybee,I followed your advice, now my code is:CODE",Usage,328,56,0.5,0.6728538283,0.5704865867,0.4295134133,0.6875,0.04089219331,0.00716690904,0.000102601311,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"and I feed CODE and CODE through the feed_dict, but now I get the error CODE",Usage,150,76,1,0.6751740139,0.5704865867,0.4295134133,1,0.0594795539,0.00716690904,0.000102601311,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,try to feed reuse as a python variable (input of the model) and as placeholder.,Usage,79,79,1,0.6774941995,0.5705040179,0.4294959821,1,0.05576208178,0.000102601311,0.0007694155299,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I tried that, and now it stopped complaining about the value...",Usage,63,63,0.3333333333,0.6798143852,0.5706347361,0.4293652639,0.34375,0.04089219331,0.0007694155299,4.82E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"but I think that the placeholder value is not being used, because I see no change if I force values to CODE function, and in TensorBoard it's not connected to the graph...",Usage,179,171,0.6666666667,0.6821345708,0.5706347361,0.4293652639,1,0.1189591078,0.0007694155299,4.82E-05,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,(see attached image)![screen shot 2017-04-03 at 19 54 54] URL,Usage,160,62,1,0.6844547564,0.5706347361,0.4293652639,0.375,0.04460966543,0.0007694155299,4.82E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,My code is like this now:**Batch Normalisation wrapper**CODE**Model definition**CODE**Training**CODE**Validation**CODE,Usage,924,118,1,0.686774942,0.5706429231,0.4293570769,1,0.03345724907,4.82E-05,0.001707349941,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Although is_traning can a placeholder reuse has to be a bool, and it cannot be a tensor nor a placeholder.",Solution Discussion,106,106,0.2,0.6890951276,0.5709329897,0.4290670103,1,0.0780669145,0.001707349941,0.003630653009,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I'm not sure what are you trying to do, in most cases using static values solve the problem.",Usage,92,92,0.4,0.6914153132,0.5709329897,0.4290670103,0.8571428571,0.06691449814,0.001707349941,0.003630653009,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,For example this pattern works well: CODE,Usage,561,41,0.6,0.6937354988,0.5709329897,0.4290670103,0.3333333333,0.02602230483,0.001707349941,0.003630653009,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Unless you need to change the behavior of the model dynamically, you don't need to use a placeholder for is_training.",Usage,117,117,0.8,0.6960556845,0.5709329897,0.4290670103,0.9523809524,0.07434944238,0.001707349941,0.003630653009,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The trick is to build the model twice, but sharing the variables the second time.",Usage,81,81,1,0.6983758701,0.5709329897,0.4290670103,0.7142857143,0.05576208178,0.001707349941,0.003630653009,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you @sguada !,Social Conversation,19,19,0.5,0.7006960557,0.5715498119,0.4284501881,0.3,0.01115241636,0.003630653009,0.005549335246,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"After applying your suggestions, I finally made it to work!",Social Conversation,59,59,1,0.7030162413,0.5715498119,0.4284501881,1,0.03717472119,0.003630653009,0.005549335246,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Being a newer tf user, I found that my test error was crazy and then had to spend a fair amount of time debugging my graph until I realized that batch normalization was the problem.",Usage,181,181,0.3333333333,0.7053364269,0.5724926046,0.4275073954,1,0.1301115242,0.005549335246,0.0005175330835,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Then I had to spend more time figuring out that by default the variables tracking the moments don't update unless you use a contrib function for optimization.,Usage,158,158,0.6666666667,0.7076566125,0.5724926046,0.4275073954,0.7714285714,0.1003717472,0.005549335246,0.0005175330835,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Additionally, it seems like it might make sense to have a parameter to add the control flow dependencies to the op that runs in the training case.",Solution Discussion,146,146,1,0.7099767981,0.5724926046,0.4275073954,0.7714285714,0.1003717472,0.005549335246,0.0005175330835,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@danrsc Exactly.,Social Conversation,16,16,0.3333333333,0.7122969838,0.5725805298,0.4274194702,0.1111111111,0.007434944238,0.0005175330835,0.003121984377,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The usage of BN layer is quite confusing.,Social Conversation,41,41,0.6666666667,0.7146171694,0.5725805298,0.4274194702,0.4444444444,0.02973977695,0.0005175330835,0.003121984377,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I suggested to add documents or a complete official tutorial on batch normalization, but unfortunately got no response = =",Social Conversation,122,122,1,0.716937355,0.5725805298,0.4274194702,1,0.06691449814,0.0005175330835,0.003121984377,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Completely agree.,Social Conversation,17,17,1,0.7192575406,0.5731109328,0.4268890672,1,0.007434944238,0.003121984377,0.009348884347,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Reopening for visibility of the documentation issues.,Action on Issue,53,53,1,0.7215777262,0.5746992419,0.4253007581,1,0.02602230483,0.009348884347,1.86E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada assigning to you for triaging.,Contribution and Commitment,38,38,0.5,0.7238979118,0.5747023981,0.4252976019,0.6,0.02230483271,1.86E-05,0.1329359356,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Might be worth getting a tech writer on the case.,Contribution and Commitment,49,49,1,0.7262180974,0.5747023981,0.4252976019,1,0.03717472119,1.86E-05,0.1329359356,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Just got confused by this problem last week and wasted 3 days of training...,Social Conversation,76,76,1,0.7285382831,0.5972872705,0.4027127295,1,0.05204460967,0.1329359356,0.09213475136,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@sguada  I have noticed that you said"" tf.contrib.layers.batch_norm can take tensor as is_training, so not need to do anything especial"".",Usage,137,137,0.5,0.7308584687,0.6129403111,0.3870596889,0.65625,0.0780669145,0.09213475136,0.0129668065,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Howerver, the comment in the code isIf CODE doesn't have a constant value, because it is a CODE,# a CODE or CODE then is_training_value will be None and# CODE will be true.",Usage,211,172,1,0.7331786543,0.6129403111,0.3870596889,1,0.1189591078,0.09213475136,0.0129668065,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"So if CODE is a CODE or a CODE, it means it can change, so the graph to compute the moments is needed, so the layer builds it.",Solution Discussion,150,126,0.3333333333,0.7354988399,0.6151432795,0.3848567205,1,0.1040892193,0.0129668065,0.003123210312,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Then in running time depending on the value being CODE or CODE would use the batch CODE or the CODE and CODE.,Solution Discussion,141,109,0.6666666667,0.7378190255,0.6151432795,0.3848567205,0.7857142857,0.08178438662,0.0129668065,0.003123210312,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,So during testing you would set the value to CODE and the CODE won't be used.,Usage,85,77,1,0.7401392111,0.6151432795,0.3848567205,0.5714285714,0.0594795539,0.0129668065,0.003123210312,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@sguada @brando90CODE,Usage,534,21,0.5,0.7424593968,0.6156738908,0.3843261092,0.09090909091,0.007434944238,0.003123210312,0.001266296327,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I build batchnorm like this, however, the moving mean and moving variable are updated during test, I can not find the reason.",Usage,125,125,1,0.7447795824,0.6156738908,0.3843261092,1,0.08178438662,0.003123210312,0.001266296327,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I tried creating two models like @sguada said, however, my model where is_training=False just crashes.",Usage,102,102,0.1666666667,0.747099768,0.6158890256,0.3841109744,0.5925925926,0.0594795539,0.001266296327,0.00264028631,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,757,4,0.3333333333,0.7494199536,0.6158890256,0.3841109744,0.03703703704,0.003717472119,0.001266296327,0.00264028631,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I feel like maybe there should be a concrete example of how to do a batch norm with a fully connected net, as well as with CNNs.",Usage,128,128,0.5,0.7517401392,0.6158890256,0.3841109744,1,0.1003717472,0.001266296327,0.00264028631,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Sucks that I've trained models for days expecting things to work before seeing that everyone trying to use this feature going crazy.,Social Conversation,132,132,0.6666666667,0.7540603248,0.6158890256,0.3841109744,0.8518518519,0.08550185874,0.001266296327,0.00264028631,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Interestingly enough, it takes a zillion years to get the model restored after training with batch_norm as well.",Solution Discussion,112,112,0.8333333333,0.7563805104,0.6158890256,0.3841109744,0.6666666667,0.06691449814,0.001266296327,0.00264028631,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Will most likely wait until TF 2.0 to try something like this again.,Social Conversation,68,68,1,0.7587006961,0.6158890256,0.3841109744,0.4814814815,0.04832713755,0.001266296327,0.00264028631,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@MisayaZ you don't need to create two batch_norm layers you can just pass train_phase (assuming it is a tf.bool) to batch_norm.,Usage,127,127,0.3333333333,0.7610208817,0.6163375915,0.3836624085,1,0.0780669145,0.00264028631,6.29E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Also you are passing UPDATE_OPS_COLLECTION variables_collections, which changes which collections are the variables added to.",Usage,125,125,0.6666666667,0.7633410673,0.6163375915,0.3836624085,0.7142857143,0.05576208178,0.00264028631,6.29E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The following should work: CODE,Usage,154,31,1,0.7656612529,0.6163375915,0.3836624085,0.2380952381,0.01858736059,0.00264028631,6.29E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"@OktayGardener not sure what model are you trying to create, it seems that the variables are not saved in your checkpoint.",Usage,122,122,0.3333333333,0.7679814385,0.6163482777,0.3836517223,1,0.0780669145,6.29E-05,0.005207393745,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,batch_norm also works with fully_connected layers.,Solution Discussion,50,50,0.6666666667,0.7703016241,0.6163482777,0.3836517223,0.2857142857,0.02230483271,6.29E-05,0.005207393745,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,897,4,1,0.7726218097,0.6163482777,0.3836517223,0.04761904762,0.003717472119,6.29E-05,0.005207393745,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"@sguada Thanks, I build a network with bathnorm which is implemented as you mentioned above",Usage,91,91,0.2,0.7749419954,0.617232977,0.382767023,0.05576208178,0.05576208178,0.005207393745,0.02595483109,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE,Usage,126,4,0.4,0.777262181,0.617232977,0.382767023,0.003717472119,0.003717472119,0.005207393745,0.02595483109,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"the speed is slow, I use tensorflow benchmark to get the computation time as below:I tensorflow/core/util/stat_summarizer.cc:392] ============================== Top by Computation Time ==============================I tensorflow/core/util/stat_summarizer.cc:392]               [node type]                [start]                [first]               [avg ms]                   [%]                [cdf%]                [mem KB]              [Name]I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                106.164                 51.354                 51.004               23.145%               23.145%                 692.224              conv8/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                 85.187                 19.115                 19.283                8.750%               31.896%                 692.224              conv7/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]         SquaredDifference                 11.967                 15.105                 14.331                6.503%               38.399%               11075.584              conv1/batch_norm/moments/sufficient_statistics/SquaredDifferenceI tensorflow/core/util/stat_summarizer.cc:392]                       Mul                 11.970                 14.162                 13.495                6.124%               44.523%               11075.584              conv1/batch_norm/batchnorm/mul_1I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                  3.948                  8.170                  7.986                3.624%               48.146%               11075.584              conv1/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                       Sub                 11.960                 10.176                  7.943                3.604%               51.751%               11075.584              conv1/batch_norm/moments/sufficient_statistics/SubI tensorflow/core/util/stat_summarizer.cc:392]         SquaredDifference                 45.570                  5.908                  7.177                3.257%               55.007%                5537.792              conv2/batch_norm/moments/sufficient_statistics/SquaredDifferenceI tensorflow/core/util/stat_summarizer.cc:392]                       Mul                 45.574                  7.755                  6.902                3.132%               58.140%                5537.792              conv2/batch_norm/batchnorm/mul_1I tensorflow/core/util/stat_summarizer.cc:392]                    Conv2D                 40.692                  5.408                  4.845                2.199%               60.338%                5537.792              conv2/Conv2DI tensorflow/core/util/stat_summarizer.cc:392]                       Sub                 45.563                  6.067                  4.784                2.171%               62.509%                5537.792              con",Solution Discussion,2967,2967,0.6,0.7795823666,0.617232977,0.382767023,1,1,0.005207393745,0.02595483109,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I don't understand why some op in moment are executed during test and it cost a lot of time, such as conv1/batch_norm/moments/sufficient_statistics/SquaredDifference.",Solution Discussion,166,166,0.8,0.7819025522,0.617232977,0.382767023,0.09665427509,0.09665427509,0.005207393745,0.02595483109,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The moment is not needed in test, why are some ops under moment executed?",Solution Discussion,73,73,1,0.7842227378,0.617232977,0.382767023,0.05204460967,0.05204460967,0.005207393745,0.02595483109,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Hi, Using the above CODE layer in CODE, I'm getting CODE as an output for validation graph while the train graph runs seamlessly.",Usage,150,129,0.25,0.7865429234,0.6216425187,0.3783574813,1,0.08550185874,0.02595483109,0.00735617451,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Is there anything that I might be missing ?,Usage,43,43,0.5,0.788863109,0.6216425187,0.3783574813,0.347826087,0.02973977695,0.02595483109,0.00735617451,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I'm using:CODE,Usage,314,14,0.75,0.7911832947,0.6216425187,0.3783574813,0.1304347826,0.01115241636,0.02595483109,0.00735617451,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks,Social Conversation,6,6,1,0.7935034803,0.6216425187,0.3783574813,0.04347826087,0.003717472119,0.02595483109,0.00735617451,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"As a follow up, I'm reusing 16 layers of batch_norm.",Usage,52,52,0.5,0.7958236659,0.6228922805,0.3771077195,1,0.03717472119,0.00735617451,0.000759796657,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"However, I found that reusing 4 layers works.",Usage,45,45,1,0.7981438515,0.6228922805,0.3771077195,0.8,0.02973977695,0.00735617451,0.000759796657,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I've just been noticing that if I kill the tensorflow process and restart it, my error gets worse for a few epochs (i.e. worse than it should be at the last checkpoint).",Usage,169,169,0.1666666667,0.8004640371,0.6230213646,0.3769786354,0.8048780488,0.1226765799,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I also observe that if I remove batch_norm, this problem goes away.",Usage,67,67,0.3333333333,0.8027842227,0.6230213646,0.3769786354,0.2926829268,0.04460966543,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"After looking at the code for a while, I think this may be because the values of the variables are not restored from the shadow variables as they would be if the ExponentialMovingAverages class were used to manage the moving averages.",Solution Discussion,234,234,0.5,0.8051044084,0.6230213646,0.3769786354,1,0.1524163569,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"This also means that if I use a separate process to evaluate, I'm getting whatever the last value of the variable was and not the moving average.",Solution Discussion,145,145,0.6666666667,0.807424594,0.6230213646,0.3769786354,0.6585365854,0.1003717472,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Am I interpreting this correctly and is this the intended behavior?,Solution Discussion,67,67,0.8333333333,0.8097447796,0.6230213646,0.3769786354,0.2682926829,0.04089219331,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It seems like you want the shadow variable values to be restored...,Solution Discussion,67,67,1,0.8120649652,0.6230213646,0.3769786354,0.2926829268,0.04460966543,0.000759796657,0.006667293465,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The output of the tensor : CODE present in CODE isCODE,Usage,1521,54,0.3333333333,0.8143851508,0.6241540904,0.3758459096,0.5,0.03717472119,0.006667293465,0.0656384343,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,How is this even possible ?,Solution Discussion,27,27,0.6666666667,0.8167053364,0.6241540904,0.3758459096,0.25,0.01858736059,0.006667293465,0.0656384343,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,P.S. The batch norm layer is used just after the last fully connected layer of the network and before softmax.,Usage,110,110,1,0.819025522,0.6241540904,0.3758459096,1,0.07434944238,0.006667293465,0.0656384343,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@raghavgoyal14 are you using it with fused=True?,Usage,48,48,0.5,0.8213457077,0.6353055948,0.3646944052,0.5714285714,0.02973977695,0.0656384343,0.0001746485551,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Had a similar problem and it went away when I used the fused version,Usage,68,68,1,0.8236658933,0.6353055948,0.3646944052,1,0.05204460967,0.0656384343,0.0001746485551,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@abred : Yes, I used CODE, same problem.",Usage,48,40,1,0.8259860789,0.6353352663,0.3646647337,1,0.02602230483,0.0001746485551,0.4124560443,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"@sguada  Hi, sguada, I have a problem.",Social Conversation,38,38,0.25,0.8283062645,0.7054086222,0.2945913778,0.1538461538,0.02973977695,0.4124560443,2.09E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The definition of contrib.layers.batch_norm in tensorflow:def batch_norm(inputs,decay=0.999,center=True,scale=False,epsilon=0.001,activation_fn=None,param_initializers=None,param_regularizers=None,updates_collections=ops.GraphKeys.UPDATE_OPS,is_training=True,reuse=None,variables_collections=None,outputs_collections=None,trainable=True,batch_weights=None,fused=False,data_format=DATA_FORMAT_NHWC,zero_debias_moving_mean=False,scope=None,renorm=False,renorm_clipping=None,renorm_decay=0.99):scale: If True, multiply by gamma.",Solution Discussion,525,525,0.5,0.8306264501,0.7054086222,0.2945913778,1,0.1933085502,0.4124560443,2.09E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"If False, gamma isnot used.",Solution Discussion,27,27,0.75,0.8329466357,0.7054086222,0.2945913778,0.09615384615,0.01858736059,0.4124560443,2.09E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you very much.,Social Conversation,20,20,1,0.8352668213,0.7054086222,0.2945913778,0.07692307692,0.01486988848,0.4124560443,2.09E-05,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"When scale=False, gamma is a constant 1.",Solution Discussion,40,40,1,0.837587007,0.7054121789,0.2945878211,1,0.02973977695,2.09E-05,0.001229235376,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@ppwwyyxx Thank you very much for your help.,Social Conversation,44,44,0.25,0.8399071926,0.7056210173,0.2943789827,0.4210526316,0.02973977695,0.001229235376,0.08381433199,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I use tf.contrib.layers.batch_norm(input, scale=False)  in Tensorflow, and now I am convering the batchnorm of Tensorflow to Caffe.",Usage,131,131,0.5,0.8422273782,0.7056210173,0.2943789827,1,0.07063197026,0.001229235376,0.08381433199,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,How to set the param of BatchNormLayer and ScaleLayer in Caffe?,Usage,63,63,0.75,0.8445475638,0.7056210173,0.2943789827,0.5789473684,0.04089219331,0.001229235376,0.08381433199,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you very much.,Social Conversation,20,20,1,0.8468677494,0.7056210173,0.2943789827,0.2105263158,0.01486988848,0.001229235376,0.08381433199,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@MisayaZ I was having the same behavior using Batchnorm with a placeholder for ""is_training"".",Usage,93,93,0.5,0.849187935,0.7198604777,0.2801395223,0.2745098039,0.05204460967,0.08381433199,0.006688794475,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I would have preferred to leave it as a placeholder because this way I can do periodic testing during training without redefining the graph, but I decided to use it as a constant and define different behaviors for train vs test, and now the moments are not calculated at test time.",Usage,281,281,1,0.8515081206,0.7198604777,0.2801395223,1,0.1895910781,0.08381433199,0.006688794475,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@tano297 Thank you.,Social Conversation,19,19,0.2,0.8538283063,0.7209968564,0.2790031436,0.1153846154,0.01115241636,0.006688794475,0.0005195134397,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I now also use 'is_training' as a constant.,Usage,43,43,0.4,0.8561484919,0.7209968564,0.2790031436,0.3076923077,0.02973977695,0.006688794475,0.0005195134397,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Leave it as a placeholder and do periodic testing will change the value of moving mean and moving variance.,Solution Discussion,107,107,0.6,0.8584686775,0.7209968564,0.2790031436,0.7307692308,0.07063197026,0.006688794475,0.0005195134397,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,And the inference time will be longer for it will calculate the mean and variance of the inputs and update the moving mean and moving variance.,Solution Discussion,143,143,0.8,0.8607888631,0.7209968564,0.2790031436,1,0.09665427509,0.006688794475,0.0005195134397,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,The right way to do testing is to define different behaviors for train and test as you mentioned.,Usage,97,97,1,0.8631090487,0.7209968564,0.2790031436,0.6923076923,0.06691449814,0.006688794475,0.0005195134397,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@tano297 @MisayaZbut doesn't the ""smart_cond"" inCODEmake sure that the updates are only calculated and applied if is_training evaluates to True?",Solution Discussion,346,144,1,0.8654292343,0.7210851181,0.2789148819,1,0.07434944238,0.0005195134397,0.001521290762,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"@abred Yes indeed, but you are referring to line 391, where it does the update of the moving average within _fused_batch_norm(): CODECODEis_trainingCODETensorCODEVariableCODEPlaceholderCODEneed_updates` will be true.is_training_value = utils.constant_value(is_training)need_updates = is_training_value is None or is_training_valueif need_updates:...outputs = utils.smart_cond(is_training, _force_updates, no_updates)...CODE",Solution Discussion,516,423,0.3333333333,0.86774942,0.7213435746,0.2786564254,1,0.1412639405,0.001521290762,0.000523191244,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I am talking about line 753 within batch_norm(): CODECODEis_trainingCODETensorCODEVariableCODEPlaceholderCODEneeds_moments` will be true.is_training_value = utils.constant_value(is_training)need_moments = is_training_value is None or is_training_valueif need_moments:...mean, variance = utils.smart_cond(is_training,_force_updates,moving_vars_fn)...CODE",Solution Discussion,446,353,0.6666666667,0.8700696056,0.7213435746,0.2786564254,0.6578947368,0.09293680297,0.001521290762,0.000523191244,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"The smart condition in that case (as far as I am concerned) decides wether or not to update the moving averages, but the moments still get calculated.",Solution Discussion,150,150,1,0.8723897912,0.7213435746,0.2786564254,0.7105263158,0.1003717472,0.001521290762,0.000523191244,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@tano297 you right about that, I was in the wrong place, but still:line 755-770 calculate the moments, but the moments are only used in _force_updates which is only executed if is_training evaluates to True, aren't they?",Solution Discussion,220,220,0.25,0.8747099768,0.7214324611,0.2785675389,1,0.1412639405,0.000523191244,0.02141472308,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,And thusCODEshould be equivalent to line 804:CODE,Solution Discussion,176,49,0.5,0.8770301624,0.7214324611,0.2785675389,0.2105263158,0.02973977695,0.000523191244,0.02141472308,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"if is_training evalutes to False and thus the ""moments""-part of the graph is never used and thus shouldn't be executed",Solution Discussion,118,118,0.75,0.879350348,0.7214324611,0.2785675389,0.5263157895,0.07434944238,0.000523191244,0.02141472308,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"but I haven't tested, so I might be wrong about that :)",Social Conversation,55,55,1,0.8816705336,0.7214324611,0.2785675389,0.3157894737,0.04460966543,0.000523191244,0.02141472308,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@tano297 @abred  you right.,Social Conversation,27,27,0.5,0.8839907193,0.7250706706,0.2749293294,0.08474576271,0.01858736059,0.02141472308,0.09060252148,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"The moving mean and moving variance are changed when I used batchnorm like this: def batch_norm_layer(self, x,train_phase, scope_bn):bn_train = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=True,reuse=None,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)bn_inference = batch_norm(x, decay=0.9, center=False, scale=True,updates_collections=None,is_training=False,reuse=True,variables_collections= [UPDATE_OPS_COLLECTION],trainable=True,scope=scope_bn)z = tf.cond(train_phase, lambda: bn_train, lambda: bn_inference)return z",Usage,592,592,1,0.8863109049,0.7250706706,0.2749293294,1,0.219330855,0.02141472308,0.09060252148,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I also met the problem that I could get good results when using is_training=True for both training and inference, but get bad results when setting is_training=False during inference (worse than the case using is_training=True).",Usage,227,227,0.2,0.8886310905,0.7404633962,0.2595366038,1,0.1375464684,0.09060252148,0.005762082082,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Am I right?,Social Conversation,11,11,0.4,0.8909512761,0.7404633962,0.2595366038,0.08108108108,0.01115241636,0.09060252148,0.005762082082,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"BTW, do I need to retrain the model using decay=0.9 from scratch?",Usage,65,65,0.6,0.8932714617,0.7404633962,0.2595366038,0.3243243243,0.04460966543,0.09060252148,0.005762082082,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Or resuming training from the checkpoint (i.e., trained when decay=0.999) is also ok?",Usage,85,85,0.8,0.8955916473,0.7404633962,0.2595366038,0.3513513514,0.04832713755,0.09060252148,0.005762082082,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks!,Social Conversation,7,7,1,0.8979118329,0.7404633962,0.2595366038,0.02702702703,0.003717472119,0.09060252148,0.005762082082,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,@nmduc @davek44,Social Conversation,15,15,0.3333333333,0.9002320186,0.7414423331,0.2585576669,0.3333333333,0.007434944238,0.005762082082,0.04396079536,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Have you guys solved this problem?,Task Progress,34,34,0.6666666667,0.9025522042,0.7414423331,0.2585576669,1,0.02230483271,0.005762082082,0.04396079536,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Thanks!,Social Conversation,7,7,1,0.9048723898,0.7414423331,0.2585576669,0.1666666667,0.003717472119,0.005762082082,0.04396079536,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,I was confused after all these comments on how to properly use Batch Norm: So here is what I have.,Social Conversation,98,98,0.1,0.9071925754,0.7489109604,0.2510890396,1,0.07434944238,0.04396079536,0.2980535079,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Please correct me if I'm wrong.,Social Conversation,31,31,0.2,0.909512761,0.7489109604,0.2510890396,0.3,0.02230483271,0.04396079536,0.2980535079,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,CODE where phase_train_py is a python boolean variable and is_training is a placeholder taking a boolean variable.,Usage,238,114,0.3,0.9118329466,0.7489109604,0.2510890396,0.85,0.06319702602,0.04396079536,0.2980535079,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"I guess using tf.cond is wrong, otherwise would did the function came with a boolean parameters.",Usage,96,96,0.4,0.9141531323,0.7489109604,0.2510890396,0.8,0.0594795539,0.04396079536,0.2980535079,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"In other words, if CODE is true, then we should a CODE function for training and another one for testing.",Usage,118,105,0.5,0.9164733179,0.7489109604,0.2510890396,1,0.07434944238,0.04396079536,0.2980535079,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"So, developers allow us to change these boolean variables in order to change the behavior of the function.",Usage,106,106,0.6,0.9187935035,0.7489109604,0.2510890396,0.9,0.06691449814,0.04396079536,0.2980535079,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,So What I am doing is: setting CODE to False while training while CODE to True.,Usage,100,79,0.7,0.9211136891,0.7489109604,0.2510890396,0.8,0.0594795539,0.04396079536,0.2980535079,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,And the opposite while Testing.,Usage,31,31,0.8,0.9234338747,0.7489109604,0.2510890396,0.25,0.01858736059,0.04396079536,0.2980535079,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Since we can only change tensors or placeholders with CODE, I changed CODE intentionally before running the graph.",Usage,132,114,0.9,0.9257540603,0.7489109604,0.2510890396,0.9,0.06691449814,0.04396079536,0.2980535079,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Ex: CODE,Usage,180,8,1,0.9280742459,0.7489109604,0.2510890396,0.1,0.007434944238,0.04396079536,0.2980535079,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,AYBE YOU NEED READ THIS,Social Conversation,23,23,0.05882352941,0.9303944316,0.7995481369,0.2004518631,0.1666666667,0.01858736059,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It seems there are still problems with TF v1.3.,Solution Discussion,47,47,0.1176470588,0.9327146172,0.7995481369,0.2004518631,0.3,0.03345724907,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"I'm sure I note the following details, but still failed to use the official CODE, with CODE during evaluation(but when I keep CODE unchanged during evaluation, it is ok):",Usage,225,170,0.1764705882,0.9350348028,0.7995481369,0.2004518631,1,0.1115241636,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"1.         CODE,  exponential moving average is actually alpha filter in signal processing, the time to converge is approximately 1/(1-decay) steps of train.",Solution Discussion,161,157,0.2352941176,0.9373549884,0.7995481369,0.2004518631,0.8333333333,0.09293680297,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"For decay=0.999, you need 1/0.001=1000 steps to converge.",Solution Discussion,57,57,0.2941176471,0.939675174,0.7995481369,0.2004518631,0.2666666667,0.02973977695,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,So set the appropriate decay for your training step numbers.,Usage,60,60,0.3529411765,0.9419953596,0.7995481369,0.2004518631,0.3333333333,0.03717472119,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,2.         using placeholder to switch between train and test evaluation,Usage,72,72,0.4117647059,0.9443155452,0.7995481369,0.2004518631,0.3666666667,0.04089219331,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,3.         useCODE if you don't want to add control dependencies of update op to train_op,Usage,112,89,0.4705882353,0.9466357309,0.7995481369,0.2004518631,0.5333333333,0.0594795539,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,4.         set CODE to appropriate value.,Usage,44,41,0.5294117647,0.9489559165,0.7995481369,0.2004518631,0.2333333333,0.02602230483,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"It seems the only way to use the official batch_norm is to build two graphs, one for train and one for evaluation, with CODE and CODE, respectively.",Usage,177,148,0.5882352941,0.9512761021,0.7995481369,0.2004518631,0.9,0.1003717472,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"In this way, you don't need to switch dynamically between train and evaluation.",Usage,79,79,0.6470588235,0.9535962877,0.7995481369,0.2004518631,0.4333333333,0.04832713755,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,But this is a stupid way since you need to build more than one graph.,Usage,69,69,0.7058823529,0.9559164733,0.7995481369,0.2004518631,0.5,0.05576208178,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Finally, I write a moving average by myself, and I find it worked!",Usage,66,66,0.7647058824,0.9582366589,0.7995481369,0.2004518631,0.4333333333,0.04832713755,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,It's as follows(based on code on the web and modified by myself) CODE,Usage,2562,69,0.8235294118,0.9605568445,0.7995481369,0.2004518631,0.4333333333,0.04832713755,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Just use the CODE function during building a graph, the is_training parameter is a CODE.",Usage,110,88,0.8823529412,0.9628770302,0.7995481369,0.2004518631,0.5,0.05576208178,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,"Then you are free to switch the placeholder to True during train and False during evaluation, with CODE.",Usage,111,104,0.9411764706,0.9651972158,0.7995481369,0.2004518631,0.6,0.06691449814,0.2980535079,0.6717022095,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Hope it helps the community.,Social Conversation,28,28,1,0.9675174014,0.7995481369,0.2004518631,0.1666666667,0.01858736059,0.2980535079,0.6717022095,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"When you use slim.batch_norm,be sure to use ""slim.learning.create_train_op"" instead of ""tf.train.GradientDecentOptimizer(lr).minimize(loss)"" or other optimizer.",Usage,160,160,0.5,0.969837587,0.913665577,0.08633442295,1,0.0594795539,0.6717022095,0.02297194316,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Try it to see if it works!,Social Conversation,26,26,1,0.9721577726,0.913665577,0.08633442295,0.4375,0.02602230483,0.6717022095,0.02297194316,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@vincentvanhoucke You wrote in another post in this thread: > The slim batch_norm wrapper normalizes over the last dimension of your input tensor. So if it's a 2D input tensor coming from a fully connected layer, it normalizes over batch, and thus performs per-activation normalization. If it's a 4D tensor coming from a convolution, it will normalize over the three first dimensions (batch, width, depth), and thus perform per-feature normalization. @sguada maybe forth being a bit more descriptive about this.",Solution Discussion,511,511,0.5,0.9744779582,0.9175683472,0.08243165278,1,0.3011152416,0.02297194316,0.01027352208,NONE,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Do you mean with ""slim batch_norm wrapper"" the function CODE?",Solution Discussion,87,61,1,0.9767981439,0.9175683472,0.08243165278,0.1234567901,0.03717472119,0.02297194316,0.01027352208,NONE,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,@ZahlGraf I'll happily consider a PR that clarifies the documentation.,Action on Issue,70,70,0.5,0.9791183295,0.9193137457,0.08068625426,0.2857142857,0.03717472119,0.01027352208,0.1284918277,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"We've been at this for so long that I no longer have a good sense of what's obvious or not, and would welcome clarifying documentation for someone with a fresh perspective on the topic.",Social Conversation,185,185,1,0.9814385151,0.9193137457,0.08068625426,1,0.1301115242,0.01027352208,0.1284918277,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"@vincentvanhouckeI created a PR with a more detailed description, mainly based on your statement in this thread:https://github.com/tensorflow/tensorflow/pull/15653",Action on Issue,163,163,1,0.9837587007,0.9411435957,0.05885640429,1,0.0780669145,0.1284918277,0.1249965933,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue,77,77,0.3333333333,0.9860788863,0.9623796302,0.03762036985,1,0.04089219331,0.1249965933,0.2080360402,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Otherwise, remove the CODE label.",Action on Issue,52,33,0.6666666667,0.9883990719,0.9623796302,0.03762036985,0.4545454545,0.01858736059,0.1249965933,0.2080360402,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you.,Social Conversation,10,10,1,0.9907192575,0.9623796302,0.03762036985,0.1818181818,0.007434944238,0.1249965933,0.2080360402,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Please remove the assignee, as this issue is inviting external contributions.",Action on Issue,77,77,0.3333333333,0.9930394432,0.9977234775,0.002276522477,1,0.04089219331,0.2080360402,0.01339975008,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,"Otherwise, remove the CODE label.",Action on Issue,52,33,0.6666666667,0.9953596288,0.9977234775,0.002276522477,0.4545454545,0.01858736059,0.2080360402,0.01339975008,MEMBER,FALSE,TRUE,FALSE,FALSE
2 1122_tensorflow.doc,Thank you.,Social Conversation,10,10,1,0.9976798144,0.9977234775,0.002276522477,0.1818181818,0.007434944238,0.2080360402,0.01339975008,MEMBER,FALSE,FALSE,FALSE,FALSE
2 1122_tensorflow.doc,Closing this bug since the original request to add a batch norm layer has been addressed.,Action on Issue,89,89,1,1,1,0,16,0.0594795539,0.01339975008,0,MEMBER,FALSE,FALSE,FALSE,TRUE
3 197_spaCy.doc,"Feature Request: Vector ""File"" interface",Expected Behaviour,40,40,0.2,0.007352941176,0,1,0.1428571429,0.1315789474,0,0.003237761122,NONE,TRUE,FALSE,TRUE,FALSE
3 197_spaCy.doc,"Just read in an old spaCy tutorial the following ""Future versions of spaCy will allow you to provide a file-like object, instead of a location of a [vector bin] file.""",Task Progress,167,167,0.4,0.01470588235,0,1,0.8857142857,0.8157894737,0,0.003237761122,NONE,TRUE,FALSE,TRUE,FALSE
3 197_spaCy.doc,Is this in place yet?,Task Progress,21,21,0.6,0.02205882353,0,1,0.1428571429,0.1315789474,0,0.003237761122,NONE,TRUE,FALSE,TRUE,FALSE
3 197_spaCy.doc,"Would love to replace standard vector file and in-memory loading with my own Redis (or any other ""shared-memory-system"") interface to allow a distributed cluster of spacy nodes to share the same ""file"".",Expected Behaviour,202,202,0.8,0.02941176471,0,1,1,0.9210526316,0,0.003237761122,NONE,TRUE,FALSE,TRUE,FALSE
3 197_spaCy.doc,"Would love to contribute, any pointers on where to start looking?",Contribution and Commitment,65,65,1,0.03676470588,0,1,0.3142857143,0.2894736842,0,0.003237761122,NONE,TRUE,FALSE,TRUE,FALSE
3 197_spaCy.doc,"Yep, this should work: https://github.com/honnibal/spaCy/blob/master/spacy/vocab.pyx#L320",Solution Discussion,89,89,0.5,0.04411764706,0.002517369573,0.9974826304,0.3571428571,0.1315789474,0.003237761122,0.0005265343115,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Thanks for mentioning this â I'll keep this open until we update the docs.,Action on Issue,74,74,1,0.05147058824,0.002517369573,0.9974826304,1,0.3684210526,0.003237761122,0.0005265343115,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"That's almost what I'm looking for but exactly like expected so can be closed once updated in docs, thx.",Action on Issue,104,104,0.25,0.05882352941,0.002926751675,0.9970732483,0.5277777778,0.5,0.0005265343115,0.0006606771075,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"So pre-cook a ""database"" with vector lookups and each spaCy instance just calls class functions like find() and nearest() which can either be implemented as a ""hashmap"" (like it's currently) or a shared memory source.",Expected Behaviour,217,217,0.5,0.06617647059,0.002926751675,0.9970732483,1,0.9473684211,0.0005265343115,0.0006606771075,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,This makes spaCy much more useable for including in our docker environment where we literally have 100s of these containers running in parallel and memory is wasted for each instance.,Motivation,183,183,0.75,0.07352941176,0.002926751675,0.9970732483,0.8333333333,0.7894736842,0.0005265343115,0.0006606771075,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I'll hopefully have some spare time soon and will write a little pull request now that I know where to look :-),Social Conversation,111,111,1,0.08088235294,0.002926751675,0.9970732483,0.6111111111,0.5789473684,0.0005265343115,0.0006606771075,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,This makes sense.,Social Conversation,17,17,0.25,0.08823529412,0.003440430228,0.9965595698,0.1071428571,0.07894736842,0.0006606771075,0.0004625994361,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I'd like to change the current set up, because I want to support vectors keyed by different information, e.g. vectors keyed by lemma and part-of-speech.",Motivation,152,152,0.5,0.09558823529,0.003440430228,0.9965595698,1,0.7368421053,0.0006606771075,0.0004625994361,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,This lets you see different vectors for CODE and CODE.,Motivation,68,54,0.75,0.1029411765,0.003440430228,0.9965595698,0.3571428571,0.2631578947,0.0006606771075,0.0004625994361,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"Digital Reasoning wrote a paper showing this got them good results, and early examination of the vectors is looking good to me too.",Motivation,131,131,1,0.1102941176,0.003440430228,0.9965595698,0.8214285714,0.6052631579,0.0006606771075,0.0004625994361,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,That's actually a really good idea!,Social Conversation,35,35,0.2,0.1176470588,0.003800102762,0.9961998972,0.1578947368,0.1578947368,0.0004625994361,7.22E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Could you link the papers here and I'll have a look at that as well.,Motivation,68,68,0.4,0.125,0.003800102762,0.9961998972,0.3947368421,0.3947368421,0.0004625994361,7.22E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,(thinking I might actually do this as part of my master thesis :P ),Social Conversation,67,67,0.6,0.1323529412,0.003800102762,0.9961998972,0.3421052632,0.3421052632,0.0004625994361,7.22E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"In a way this information is already contained in word vectors because two verbs will be seen in more similar contexts than adjectives but guess that by reducing ambiguity and ""false positives"" it could make quite a difference.",Motivation,227,227,0.8,0.1397058824,0.003800102762,0.9961998972,1,1,0.0004625994361,7.22E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Do you have some form of basic class design for it yet which I should stick to or shall I just come up with something?,Solution Discussion,118,118,1,0.1470588235,0.003800102762,0.9961998972,0.6578947368,0.6578947368,0.0004625994361,7.22E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Here's the paper I mentioned, titled ""sense2vec"": http://arxiv.org/pdf/1511.06388.pdf , by @iamtrask",Motivation,100,100,0.05555555556,0.1544117647,0.003856276396,0.9961437236,0.3333333333,0.2631578947,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Not so!,Social Conversation,7,7,0.1111111111,0.1617647059,0.003856276396,0.9961437236,0.06666666667,0.05263157895,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"The most similar words to CODE might be things like CODE, while the most similar words to CODE might be CODE or CODE.",Motivation,154,117,0.1666666667,0.1691176471,0.003856276396,0.9961437236,0.7666666667,0.6052631579,7.22E-05,1.24E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"In normal Word2Vec these two share a key, so there's no way to look at the two different ""senses"" separately.",Motivation,109,109,0.2222222222,0.1764705882,0.003856276396,0.9961437236,0.6666666667,0.5263157895,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I've been playing with an extension of this idea, where noun chunks and named entities are also merged.",Potential New Issues and Requests,103,103,0.2777777778,0.1838235294,0.003856276396,0.9961437236,0.6333333333,0.5,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I've trained a model on one month of Reddit comments.,Potential New Issues and Requests,53,53,0.3333333333,0.1911764706,0.003856276396,0.9961437236,0.3666666667,0.2894736842,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"The results at the moment are quite messy, and many of the phrases need to be pruned from the vocab.",Potential New Issues and Requests,100,100,0.3888888889,0.1985294118,0.003856276396,0.9961437236,0.6666666667,0.5263157895,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,But there are also some interesting results in there too.,Potential New Issues and Requests,57,57,0.4444444444,0.2058823529,0.003856276396,0.9961437236,0.3333333333,0.2631578947,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Example: CODE,Potential New Issues and Requests,600,13,0.5,0.2132352941,0.003856276396,0.9961437236,0.06666666667,0.05263157895,7.22E-05,1.24E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,The vectors for the verb and noun senses are quite different: CODE,Potential New Issues and Requests,133,66,0.5555555556,0.2205882353,0.003856276396,0.9961437236,0.4,0.3157894737,7.22E-05,1.24E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"The nearest neighbour of CODE turns out to be a misspelling, that the POS tagger seems to often tag correctly: CODE",Potential New Issues and Requests,189,115,0.6111111111,0.2279411765,0.003856276396,0.9961437236,0.7,0.5526315789,7.22E-05,1.24E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"I'll be writing more about these vectors, and of course releasing the code. I'd like to sharpen up one or two things and run it on more data first.",Potential New Issues and Requests,147,147,0.6666666667,0.2352941176,0.003856276396,0.9961437236,1,0.7894736842,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I can give you some code to get you started on the POS tagged vectors, though.",Solution Discussion,78,78,0.7222222222,0.2426470588,0.003856276396,0.9961437236,0.5333333333,0.4210526316,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"As much as I dislike dumping state to disk, it's the most practical way to do this.",Solution Discussion,83,83,0.7777777778,0.25,0.003856276396,0.9961437236,0.5666666667,0.4473684211,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"It'd be nice to have the multi-threading sorted out for spaCy, but for now multi-processing is okay, especially for the tagger, which is fast and low-memory.",Solution Discussion,157,157,0.8333333333,0.2573529412,0.003856276396,0.9961437236,1,0.7894736842,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Example:https://github.com/honnibal/spaCy/blob/master/examples/pos_tag.py,Solution Discussion,73,73,0.8888888889,0.2647058824,0.003856276396,0.9961437236,0.2666666667,0.2105263158,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Here's how to train Word2Vec on the output using Gensim.,Solution Discussion,56,56,0.9444444444,0.2720588235,0.003856276396,0.9961437236,0.3333333333,0.2631578947,7.22E-05,1.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,(@piskvorky): CODE,Solution Discussion,1141,18,1,0.2794117647,0.003856276396,0.9961437236,0.1,0.07894736842,7.22E-05,1.24E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,That chunking experiment is fantastic.,Social Conversation,38,38,0.5,0.2867647059,0.003865952984,0.996134047,1,0.1315789474,1.24E-05,4.67E-06,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Love the take -> personal_stance.,Social Conversation,33,33,1,0.2941176471,0.003865952984,0.996134047,0.8,0.1052631579,1.24E-05,4.67E-06,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I thought the answer was ""no"", but then I started writing out some ""suggestions"", and I guess I have a clearer idea than I thought :).",Social Conversation,134,134,0.07692307692,0.3014705882,0.003869581704,0.9961304183,0.7647058824,0.6842105263,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Most of these things are demanded by consistency with the rest of the library.,Solution Discussion,78,78,0.1538461538,0.3088235294,0.003869581704,0.9961304183,0.4117647059,0.3684210526,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,You can see examples of pretty much all of this in the CODE and CODE classes: Python API:,Solution Discussion,102,89,0.2307692308,0.3161764706,0.003869581704,0.9961304183,0.5294117647,0.4736842105,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"-         Use the CODE, CODE and CODE special methods.",Solution Discussion,78,54,0.3076923077,0.3235294118,0.003869581704,0.9961304183,0.2647058824,0.2368421053,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,You don't necessarily have to subclass dict.,Solution Discussion,44,44,0.3846153846,0.3308823529,0.003869581704,0.9961304183,0.2058823529,0.1842105263,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,-         All vectors in the same CODE must be the same length.,Solution Discussion,72,63,0.4615384615,0.3382352941,0.003869581704,0.9961304183,0.3529411765,0.3157894737,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"-         The table should allow the user to pass in a key function, which should take a CODE object as an argument, and return a 64-bit unsigned integer (used to key the table)",Solution Discussion,193,177,0.5384615385,0.3455882353,0.003869581704,0.9961304183,1,0.8947368421,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"-         The hash will be non-reversible, and it won't be possible to iterate over the keys and get back a useful representation of the integer key.",Solution Discussion,149,149,0.6153846154,0.3529411765,0.003869581704,0.9961304183,0.7941176471,0.7105263158,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,This is okay.,Solution Discussion,13,13,0.6923076923,0.3602941176,0.003869581704,0.9961304183,0.08823529412,0.07894736842,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Otherwise we'll have to store the key strings, which could occupy a lot of memory.",Solution Discussion,82,82,0.7692307692,0.3676470588,0.003869581704,0.9961304183,0.4411764706,0.3947368421,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Implementation details:-         The data should be stored in a PreshMap instance.,Solution Discussion,82,82,0.8461538462,0.375,0.003869581704,0.9961304183,0.3529411765,0.3157894737,4.67E-06,6.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"-         The table should be keyed by a CODE (64 bit unisnged integer), with values being CODE, i.e. raw C arrays of floats.",Solution Discussion,136,125,0.9230769231,0.3823529412,0.003869581704,0.9961304183,0.6764705882,0.6052631579,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,-         Allocate the memory using CODE,Solution Discussion,48,40,1,0.3897058824,0.003869581704,0.9961304183,0.1764705882,0.1578947368,4.67E-06,6.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,A few bonus queries on the chunked model. 1)         The vector space seems like it'll give a good way to show compositionality:,Potential New Issues and Requests,128,128,0.07142857143,0.3970588235,0.003916559978,0.99608344,1,0.6052631579,6.04E-05,4.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"""fair game"" is not a type of game: CODE",Potential New Issues and Requests,189,39,0.1428571429,0.4044117647,0.003916559978,0.99608344,0.3913043478,0.2368421053,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"A ""class action"" is only very weakly a type of action: CODE",Potential New Issues and Requests,136,59,0.2142857143,0.4117647059,0.003916559978,0.99608344,0.5217391304,0.3157894737,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,But a class action _lawsuit_ is definitely a type of lawsuit: CODE,Potential New Issues and Requests,152,66,0.2857142857,0.4191176471,0.003916559978,0.99608344,0.5217391304,0.3157894737,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,2)         Similarity between entities can be kind of fun. Here's what Reddit thinks of Donald Trump: CODE,Potential New Issues and Requests,622,106,0.3571428571,0.4264705882,0.003916559978,0.99608344,0.7826086957,0.4736842105,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,Discussion of Bill Cosby makes some obvious (and some less obvious) comparisons: CODE,Potential New Issues and Requests,569,85,0.4285714286,0.4338235294,0.003916559978,0.99608344,0.5652173913,0.3421052632,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,Some queries produce more confusing results: CODE,Potential New Issues and Requests,559,49,0.5,0.4411764706,0.003916559978,0.99608344,0.3043478261,0.1842105263,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,I can't say the connection between Carrot Top and Kate Mara is obvious to me.,Social Conversation,77,77,0.5714285714,0.4485294118,0.003916559978,0.99608344,0.652173913,0.3947368421,6.04E-05,4.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I suppose this is true of most things about Carrot Top, so...Fair play.",Social Conversation,71,71,0.6428571429,0.4558823529,0.003916559978,0.99608344,0.6086956522,0.3684210526,6.04E-05,4.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"3)         Reddit talks about food a lot, and those regions of the vector space seem very well defined: CODE",Potential New Issues and Requests,564,108,0.7142857143,0.4632352941,0.003916559978,0.99608344,0.8695652174,0.5263157895,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,Some of Reddit's ideas about food are kind of...interesting.,Social Conversation,60,60,0.7857142857,0.4705882353,0.003916559978,0.99608344,0.4347826087,0.2631578947,6.04E-05,4.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,It seems to think CODE and CODE are very similar: CODE,Potential New Issues and Requests,135,54,0.8571428571,0.4779411765,0.003916559978,0.99608344,0.4782608696,0.2894736842,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,Reddit also thinks hot dogs are practically salad: CODE,Potential New Issues and Requests,200,55,0.9285714286,0.4852941176,0.003916559978,0.99608344,0.3913043478,0.2368421053,6.04E-05,4.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,Just keep telling yourself that Reddit.,Social Conversation,39,39,1,0.4926470588,0.003916559978,0.99608344,0.2608695652,0.1578947368,6.04E-05,4.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Haha that Donald Trump one is quite something.,Social Conversation,46,46,1,0.5,0.003947982877,0.9960520171,1,0.2105263158,4.04E-05,2.76E-05,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Love the link between bacon and broccoli, wonder what adding sentiment into the mix would change about that :P",Potential New Issues and Requests,110,110,0.125,0.5073529412,0.00396941704,0.996030583,0.5277777778,0.5,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Isn't this what we want to abstract away behind an interface so we can implement different ways of holding the vectors in memory, i.e. local vs central?",Solution Discussion,152,152,0.25,0.5147058824,0.00396941704,0.996030583,0.75,0.7105263158,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,**Although to be honest...I'm starting to doubt my own idea in terms of if the speed tradeoff is even worth it.**,Solution Discussion,113,113,0.375,0.5220588235,0.00396941704,0.996030583,0.6111111111,0.5789473684,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"agreed, didn't really mean the information was usable or retrievable, rather that the scoring of vectors **not** using POS tagging is influenced by these ""use cases"" and that making this information explicit seems a natural extension.",Motivation,234,234,0.5,0.5294117647,0.00396941704,0.996030583,1,0.9473684211,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Bit hard to explain my brainfart...but just meant that your idea made sense :),Social Conversation,78,78,0.625,0.5367647059,0.00396941704,0.996030583,0.4166666667,0.3947368421,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I'll read the paper and dig through some more code to get into it.,Social Conversation,66,66,0.75,0.5441176471,0.00396941704,0.996030583,0.3888888889,0.3684210526,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,But really love the work you're doing.,Social Conversation,38,38,0.875,0.5514705882,0.00396941704,0.996030583,0.1944444444,0.1842105263,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Is there anything I can help out with straight away or you just want me to wait until you push your initial ideas?,Contribution and Commitment,114,114,1,0.5588235294,0.00396941704,0.996030583,0.6388888889,0.6052631579,2.76E-05,7.25E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Hmm, maybe you're right. I was immediately thinking of how the C-level API would look.",Solution Discussion,86,86,0.2,0.5661764706,0.004025785766,0.9959742142,0.64,0.4210526316,7.25E-05,2.75E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,We might end up with use-cases where the vectors data is many gigabytes.,Motivation,72,72,0.4,0.5735294118,0.004025785766,0.9959742142,0.56,0.3684210526,7.25E-05,2.75E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Like, think trigram vectors, or vectors for subject/verb/object triples.",Motivation,72,72,0.6,0.5808823529,0.004025785766,0.9959742142,0.44,0.2894736842,7.25E-05,2.75E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"If this occurs, the architecture you had in mind would make a lot of sense to me.",Motivation,81,81,0.8,0.5882352941,0.004025785766,0.9959742142,0.68,0.4473684211,7.25E-05,2.75E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"A worker takes a few documents off the task queue, aggregates the vocabulary, and asks the vectors service for all vectors active on the batch.",Motivation,143,143,1,0.5955882353,0.004025785766,0.9959742142,1,0.6578947368,7.25E-05,2.75E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Yeah for large vector models it would be a necessity, question is though where supporting that is on your timeline & plans for spaCy.",Task Progress,133,133,0.2,0.6029411765,0.004047128885,0.9959528711,0.6764705882,0.6052631579,2.75E-05,4.08E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"For me it would be brilliant, because I have 100+ [Celery] URL  workers and the 100M for each instance to load the vector model makes it hard to scale across docker containers.",Motivation,197,176,0.4,0.6102941176,0.004047128885,0.9959528711,1,0.8947368421,2.75E-05,4.08E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"And in the future when we want to load more advanced, and possible context dependant models, and on the fly language switching it would be even more necessary.",Motivation,159,159,0.6,0.6176470588,0.004047128885,0.9959528711,0.8235294118,0.7368421053,2.75E-05,4.08E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"When you push your preliminary sense2vec setup I can have a look and how I would change it to acc my use case, so we have something more concrete to design around.",Task Progress,163,163,0.8,0.625,0.004047128885,0.9959528711,0.9411764706,0.8421052632,2.75E-05,4.08E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Then you can see if there's other places in the spaCy code that would need to change in accordance and we can orchestrate something from there :),Task Progress,145,145,1,0.6323529412,0.004047128885,0.9959528711,0.7941176471,0.7105263158,2.75E-05,4.08E-05,NONE,TRUE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I think there's a design problem here that should be fixed, so we may as well fix it sooner rather than later.",Solution Discussion,110,110,0.1111111111,0.6397058824,0.00407883792,0.9959211621,1,0.5789473684,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Send me an email, matt@spacy.io .",Solution Discussion,33,33,0.2222222222,0.6470588235,0.00407883792,0.9959211621,0.2272727273,0.1315789474,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,For now the following work-around could help:,Workarounds,45,45,0.3333333333,0.6544117647,0.00407883792,0.9959211621,0.3636363636,0.2105263158,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"1.         Remove the CODE file from your data directory, to avoid loading the vectors",Workarounds,91,86,0.4444444444,0.6617647059,0.00407883792,0.9959211621,0.6818181818,0.3947368421,4.08E-05,0.0001509211005,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"2.         Make your own similarity server, that does the central look-up for you",Workarounds,81,81,0.5555555556,0.6691176471,0.00407883792,0.9959211621,0.6818181818,0.3947368421,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,3.         Avoid the CODE methods on the spaCy objects.,Workarounds,66,55,0.6666666667,0.6764705882,0.00407883792,0.9959211621,0.4545454545,0.2631578947,4.08E-05,0.0001509211005,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"You might want to look into an approximate nearest neighbours library, to avoid the n**2 queries problem .",Workarounds,106,106,0.7777777778,0.6838235294,0.00407883792,0.9959211621,0.7727272727,0.4473684211,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Gensim recommends the CODE library.,Workarounds,38,35,0.8888888889,0.6911764706,0.00407883792,0.9959211621,0.2272727273,0.1315789474,4.08E-05,0.0001509211005,MEMBER,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,It seems good to me.,Social Conversation,20,20,1,0.6985294118,0.00407883792,0.9959211621,0.2272727273,0.1315789474,4.08E-05,0.0001509211005,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Hi guys, would appreciate your input on issue https://github.com/piskvorky/gensim/issues/527.",Potential New Issues and Requests,93,93,0.1666666667,0.7058823529,0.004196179556,0.9958038204,0.3214285714,0.2368421053,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"We're in the process of abstracting away particular vector stores (in-memory matrix, sharded on-disk store, approximate kNN index...) from gensim, behind a common API.",Potential New Issues and Requests,167,167,0.3333333333,0.7132352941,0.004196179556,0.9958038204,0.9285714286,0.6842105263,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,What operations that API should support is an open question; knowing the use cases required by spaCy or other tools would be extremely useful!,Potential New Issues and Requests,142,142,0.5,0.7205882353,0.004196179556,0.9958038204,0.8571428571,0.6315789474,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"How do you use such stores in spaCy, what metrics do you employ, what API signatures?",Potential New Issues and Requests,85,85,0.6666666667,0.7279411765,0.004196179556,0.9958038204,0.5714285714,0.4210526316,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"We'd like to end up with something that is flexible enough to cover all standard use cases (CODE, CODE, CODE etc) but still concise and clearly scoped.",Potential New Issues and Requests,241,151,0.8333333333,0.7352941176,0.004196179556,0.9958038204,1,0.7368421053,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
3 197_spaCy.doc,"This will be used throughout gensim (doc2vec, word2vec, docsim...).",Potential New Issues and Requests,67,67,1,0.7426470588,0.004196179556,0.9958038204,0.3214285714,0.2368421053,0.0001509211005,0.0002779711734,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Great!,Social Conversation,6,6,0.3333333333,0.75,0.004412303027,0.995587697,0.1428571429,0.02631578947,0.0002779711734,1.59E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Definitely want to get together on this.,Potential New Issues and Requests,40,40,0.6666666667,0.7573529412,0.004412303027,0.995587697,1,0.1842105263,0.0002779711734,1.59E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Will review.,Potential New Issues and Requests,12,12,1,0.7647058824,0.004412303027,0.995587697,0.2857142857,0.05263157895,0.0002779711734,1.59E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Just to get enlightened: it seems great idea but does that mean that SpaCy and gensim will work together?,Potential New Issues and Requests,105,105,0.5,0.7720588235,0.004424658886,0.9955753411,1,0.5,1.59E-05,0.0004120470569,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Do we have a rough plan for the change of APIs?,Potential New Issues and Requests,47,47,1,0.7794117647,0.004424658886,0.9955753411,0.5789473684,0.2894736842,1.59E-05,0.0004120470569,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I want spaCy and Gensim to interoperate sanely.,Potential New Issues and Requests,47,47,0.1428571429,0.7867647059,0.004745026783,0.9952549732,0.3333333333,0.2105263158,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"But it's more important that both libraries stay internally consistent, and they have fairly different API norms.",Potential New Issues and Requests,113,113,0.2857142857,0.7941176471,0.004745026783,0.9952549732,0.7083333333,0.4473684211,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I'd also rather spaCy didn't depend directly on Gensim, because that drags in scipy, so in total it's a fairly heavy-weight dependency.",Potential New Issues and Requests,135,135,0.4285714286,0.8014705882,0.004745026783,0.9952549732,1,0.6315789474,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I'm guessing Gensim would hesitate to depend on spaCy.,Potential New Issues and Requests,54,54,0.5714285714,0.8088235294,0.004745026783,0.9952549732,0.375,0.2368421053,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Among other things, we support a narrower range of platforms.",Potential New Issues and Requests,61,61,0.7142857143,0.8161764706,0.004745026783,0.9952549732,0.4166666667,0.2631578947,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"So, I'd say it's more of a design thing.",Potential New Issues and Requests,40,40,0.8571428571,0.8235294118,0.004745026783,0.9952549732,0.4166666667,0.2631578947,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,We'd like to figure out what sort of work-flows are required.,Potential New Issues and Requests,61,61,1,0.8308823529,0.004745026783,0.9952549732,0.5416666667,0.3421052632,0.0004120470569,0.0006334939121,MEMBER,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Yes.,Social Conversation,4,4,0.5,0.8382352941,0.005237570315,0.9947624297,0.04761904762,0.02631578947,0.0006334939121,0.003893704171,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I hope to discuss what kinds of behaviour people expect from such ""vector stores"", so we can design a sane API.",Potential New Issues and Requests,111,111,1,0.8455882353,0.005237570315,0.9947624297,1,0.5526315789,0.0006334939121,0.003893704171,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,We've been using an external server for word2vec for over a year now.,Potential New Issues and Requests,69,69,0.2,0.8529411765,0.008264937696,0.9917350623,0.7777777778,0.3684210526,0.003893704171,0.01990868788,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,It would be great to be able to plug it in spaCy.,Potential New Issues and Requests,49,49,0.4,0.8602941176,0.008264937696,0.9917350623,0.6666666667,0.3157894737,0.003893704171,0.01990868788,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Currently we are accessing the vector space through the https://github.com/3Top/word2vec-api/ project.,Potential New Issues and Requests,102,102,0.6,0.8676470588,0.008264937696,0.9917350623,0.6111111111,0.2894736842,0.003893704171,0.01990868788,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,A HTTP query will return a base 64 encoding of the vector.,Potential New Issues and Requests,58,58,0.8,0.875,0.008264937696,0.9917350623,0.6666666667,0.3157894737,0.003893704171,0.01990868788,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"If there is any interest, I would be glad to improve the service to enable communication with spaCy.",Potential New Issues and Requests,100,100,1,0.8823529412,0.008264937696,0.9917350623,1,0.4736842105,0.003893704171,0.01990868788,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Re: fusion of SpaCy and gensim APIs, I personally find the current gensim API tree not as straightforward/simple as scikit-learn (don't mistake me, gensim is extremely uniquely useful, e.g LDA, wikicorpus, etc).",Potential New Issues and Requests,211,211,0.1428571429,0.8897058824,0.02374400586,0.9762559941,1,0.8947368421,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"I think it'd be great to introduce an API lineage of scikit-learn flavour, or that simple.",Potential New Issues and Requests,90,90,0.2857142857,0.8970588235,0.02374400586,0.9762559941,0.5294117647,0.4736842105,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"As for SpaCy, I hope there's a portable way to train/retrieve the word embeddings across domains (pharma, legal, finance, etc) and natural languages.",Potential New Issues and Requests,149,149,0.4285714286,0.9044117647,0.02374400586,0.9762559941,0.7058823529,0.6315789474,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Could we make the underlying workings of word embeddings compositional/consistent as well (what if we need to do text analysis over legal+finance texts, or multi-lingual texts)?",Potential New Issues and Requests,177,177,0.5714285714,0.9117647059,0.02374400586,0.9762559941,0.8235294118,0.7368421053,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Could SpaCy keep an eye on Apache Flink, Apache Spark, and TensorFlow's about-to-be-released distributed processing framework as well?",Potential New Issues and Requests,134,134,0.7142857143,0.9191176471,0.02374400586,0.9762559941,0.6176470588,0.5526315789,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Please don't give up working on SpaCy.,Social Conversation,38,38,0.8571428571,0.9264705882,0.02374400586,0.9762559941,0.2058823529,0.1842105263,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,A versatile/portable/production-ready/modern NLP framework is never ever done before!,Potential New Issues and Requests,85,85,1,0.9338235294,0.02374400586,0.9762559941,0.3823529412,0.3421052632,0.01990868788,0.001584253352,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,We're definitely not about to give up working on SpaCy!,Social Conversation,55,55,0.5,0.9411764706,0.02497576789,0.9750242321,1,0.2631578947,0.001584253352,0.2540453279,COLLABORATOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,We're barely getting started.,Social Conversation,29,29,1,0.9485294118,0.02497576789,0.9750242321,0.4,0.1052631579,0.001584253352,0.2540453279,COLLABORATOR,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,"Hi, I am new to spacy and NLP and ML.",Social Conversation,37,37,0.2,0.9558823529,0.2224968185,0.7775031815,0.7142857143,0.2631578947,0.2540453279,1,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I was going through the documentation of spacy.,Social Conversation,47,47,0.4,0.9632352941,0.2224968185,0.7775031815,0.5714285714,0.2105263158,0.2540453279,1,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I am trying to make a QnA system.,Potential New Issues and Requests,33,33,0.6,0.9705882353,0.2224968185,0.7775031815,0.5714285714,0.2105263158,0.2540453279,1,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,Was wondering if spacy gives a direct method to find similarity between 2 sentences?,Potential New Issues and Requests,84,84,0.8,0.9779411765,0.2224968185,0.7775031815,1,0.3684210526,0.2540453279,1,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,I could only find sentence tokenizations and word similarities.,Potential New Issues and Requests,63,63,1,0.9852941176,0.2224968185,0.7775031815,0.6428571429,0.2368421053,0.2540453279,1,NONE,FALSE,FALSE,FALSE,FALSE
3 197_spaCy.doc,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue,107,107,1,0.9926470588,1,0,18,0.4736842105,1,0,NONE,FALSE,FALSE,FALSE,TRUE
3 197_spaCy.doc,Please open a new issue for related bugs.,Action on Issue,41,41,2,1,1,0,8,0.2105263158,1,0,NONE,FALSE,FALSE,FALSE,TRUE
4 285_spaCy.doc,Streaming Data Memory Growth,Expected Behaviour,28,28,0.05882352941,0.004545454545,0,1,0.0701754386,0.06451612903,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,I have been using spacy for streaming data (twitter and news stories mostly) and I believe that the fundamental design of the vocab/StringStore in spacy is problematic for streaming processing.,Motivation,193,193,0.1176470588,0.009090909091,0,1,0.5438596491,0.5,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"When used for batch jobs the additional memory overhead of storing a new lexeme struct for each new word form encountered in parsing is negligible compared to the speed gains, and because most text conforms to the assumption that vocabulary size grows logarithmically as the total number of tokens grows linearly this is usually a safe bet.",Motivation,340,340,0.1764705882,0.01363636364,0,1,1,0.9193548387,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"But for streaming text, especially for social media where new terms are invented by the minute (hashtags and URLs in particular) this assumption no longer holds and the spacy vocabulary storage represents a dynamic element in what should be a completely static production deployment.",Motivation,283,283,0.2352941176,0.01818181818,0,1,0.7719298246,0.7096774194,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"In order to test this assumption, I took one million tweets and performed a rudimentary analysis using the resources module in python to get the maximum memory used by the program at regular intervals during processing.",Observed Bug Behaviour,219,219,0.2941176471,0.02272727273,0,1,0.6315789474,0.5806451613,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"I first performed some minor preprocessing to remove newlines from the data so that it could be read line by line so that it wouldn't all be kept in memory, then I ran spacy with all models set to false, only the tokenizer loaded.",Observed Bug Behaviour,230,230,0.3529411765,0.02727272727,0,1,0.7719298246,0.7096774194,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"I then did the same thing again after removing all URLs, hashtags, and twitter mentions from the data , and then filtering all empty strings (this resulted in a 1.4% data loss in terms of total tweets processed but that's fairly minor).",Observed Bug Behaviour,236,236,0.4117647059,0.03181818182,0,1,0.7192982456,0.6612903226,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,The final result was that spacy used an additional 278.6 MB after tokenizing the raw tweets and 60.99 MB of additional memory when tokenizing the pre-processed tweets.,Observed Bug Behaviour,167,167,0.4705882353,0.03636363636,0,1,0.4912280702,0.4516129032,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,This result confirms my hypothesis but also shows that the memory increase really isn't all that significant (especially at the relatively low volume that I am currently processing).,Investigation and Exploration,182,182,0.5294117647,0.04090909091,0,1,0.4912280702,0.4516129032,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,But it still points to a potential flaw in the design of the library.,Investigation and Exploration,69,69,0.5882352941,0.04545454545,0,1,0.2456140351,0.2258064516,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,My suggestion/request in the near term would be to have an option to make the vocabulary read only so that users who want to be able to leave spacy alone to do streaming data processing don't need to worry about changing memory requirements.,Expected Behaviour,241,241,0.6470588235,0.05,0,1,0.7719298246,0.7096774194,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"In the long term, I think that an optimal solution would be to add some functionality for a timeout on vocabulary entries that aren't loaded at initialization.",Expected Behaviour,159,159,0.7058823529,0.05454545455,0,1,0.4736842105,0.435483871,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,"E.g. if this lexeme hasn't been accessed for the last _n_ seconds, delete it from the StringStore.",Expected Behaviour,98,98,0.7647058824,0.05909090909,0,1,0.298245614,0.2741935484,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,And _n_ would be user configurable.,Expected Behaviour,35,35,0.8235294118,0.06363636364,0,1,0.1052631579,0.09677419355,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,My code and results are available here: https://github.com/ELind77/spacy_memory_growth,Investigation and Exploration,86,86,0.8823529412,0.06818181818,0,1,0.1403508772,0.1290322581,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,Thanks again for continuing to develop such a great library!,Social Conversation,60,60,0.9411764706,0.07272727273,0,1,0.1754385965,0.1612903226,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,-- Eric,Social Conversation,7,7,1,0.07727272727,0,1,0.0350877193,0.03225806452,0,0.0008157310994,NONE,TRUE,FALSE,TRUE,FALSE
4 285_spaCy.doc,I really need to fix this issue.,Contribution and Commitment,32,32,0.5,0.08181818182,0.0002129451177,0.9997870549,1,0.1129032258,0.0008157310994,0.02381581855,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Thanks.,Social Conversation,7,7,1,0.08636363636,0.0002129451177,0.9997870549,0.1428571429,0.01612903226,0.0008157310994,0.02381581855,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Could you test this by CODE ?,Solution Discussion,91,29,1,0.09090909091,0.006430021171,0.9935699788,1,0.09677419355,0.02381581855,0.02955774717,COLLABORATOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Sorry this has taken a while.,Social Conversation,29,29,0.5,0.09545454545,0.01414601723,0.9858539828,0.6,0.09677419355,0.02955774717,0.02003548886,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I'll test again today/tomorrow and get back to you.,Social Conversation,51,51,1,0.1,0.01414601723,0.9858539828,1,0.1612903226,0.02955774717,0.02003548886,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I performed the same tests again, both installing from the zip you posted above and installing directly from master (commit 9cd21ad5b5aa664642a2e17925cd7b39eacb9aa9) and got nearly identical results to my previous trials.",Solution Discussion,221,221,0.1,0.1045454545,0.01937624511,0.9806237549,0.7317073171,0.4838709677,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If you believe that this is the cause of some kind of memory leak, I think we should really take a look at my testing script and update it as it's very rudimentary and I'm far from an expert profiler.",Investigation and Exploration,200,200,0.2,0.1090909091,0.01937624511,0.9806237549,0.9756097561,0.6451612903,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, I don't think that this is a leak.",Investigation and Exploration,43,43,0.3,0.1136363636,0.01937624511,0.9806237549,0.2195121951,0.1451612903,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"As I said in my original post, I think that this is just part of how spacy works.",Investigation and Exploration,81,81,0.4,0.1181818182,0.01937624511,0.9806237549,0.4390243902,0.2903225806,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,When parsing things like social media where there are many tokens that occur only once (e.g. links) storing them in the StringStore causes memory bloat.,Investigation and Exploration,152,152,0.5,0.1227272727,0.01937624511,0.9806237549,0.6097560976,0.4032258065,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"In your comments on https://github.com/spacy-io/spaCy/issues/172 you proposed a batch-processing generator that uses, and then throws away a tokenizer object for each batch in order to help find OOV tokens.",Solution Discussion,206,206,0.6,0.1272727273,0.01937624511,0.9806237549,0.7317073171,0.4838709677,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I think that's a fine approach, and could even be done a bit more quickly by asynchronously loading the new English() instance and replacing the old one when the new is ready, but that still leads to quite the slow down.",Solution Discussion,220,220,0.7,0.1318181818,0.01937624511,0.9806237549,1,0.6612903226,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If your feeling is that spacy is really meant for batch processing and that I should use mini-batches if I want to approximate streaming, I can do that.",Usage,152,152,0.8,0.1363636364,0.01937624511,0.9806237549,0.7073170732,0.4677419355,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Spacy is still far superior to anything else out there in my opinion, but it would be nice if I could use it with the expectation of roughly constant space complexity.",Expected Behaviour,167,167,0.9,0.1409090909,0.01937624511,0.9806237549,0.756097561,0.5,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,-- Eric,Social Conversation,7,7,1,0.1454545455,0.01937624511,0.9806237549,0.0487804878,0.03225806452,0.02003548886,0.01526654747,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"To clarify a little bit, the current release version has three known places that could be growing in memory use.",Investigation and Exploration,112,112,0.1111111111,0.15,0.02336154952,0.9766384505,0.8695652174,0.3225806452,0.01526654747,0.6482365618,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,1.         The CODE,Investigation and Exploration,28,19,0.2222222222,0.1545454545,0.02336154952,0.9766384505,0.1739130435,0.06451612903,0.01526654747,0.6482365618,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,2.         A cache in the CODE,Investigation and Exploration,37,30,0.3333333333,0.1590909091,0.02336154952,0.9766384505,0.3043478261,0.1129032258,0.01526654747,0.6482365618,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"3.         The CODE, for tokens that are part of CODE, CODE and CODE patterns.",Investigation and Exploration,92,78,0.4444444444,0.1636363636,0.02336154952,0.9766384505,0.652173913,0.2419354839,0.01526654747,0.6482365618,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,The patch I asked you to try out addresses 3.,Solution Discussion,45,45,0.5555555556,0.1681818182,0.02336154952,0.9766384505,0.4347826087,0.1612903226,0.01526654747,0.6482365618,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,We can also easily address 2.,Solution Discussion,29,29,0.6666666667,0.1727272727,0.02336154952,0.9766384505,0.2608695652,0.09677419355,0.01526654747,0.6482365618,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Addressing 1 is hard, because we currently intern all the strings, which is a much easier policy to implement than something more subtle.",Solution Discussion,137,137,0.7777777778,0.1772727273,0.02336154952,0.9766384505,1,0.3709677419,0.01526654747,0.6482365618,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Can you report the lengths of the CODE class in your two benchmark cases?,Investigation and Exploration,82,73,0.8888888889,0.1818181818,0.02336154952,0.9766384505,0.6086956522,0.2258064516,0.01526654747,0.6482365618,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"There's currently no Python API for inspecting the size of the tokenizer's cache, so it's easiest to do this by elimination.",Investigation and Exploration,124,124,1,0.1863636364,0.02336154952,0.9766384505,0.9130434783,0.3387096774,0.01526654747,0.6482365618,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Hi @honnibal, why do you think addressing 1 is so hard?",Solution Discussion,55,55,0.25,0.1909090909,0.1925825232,0.8074174768,0.2682926829,0.1774193548,0.6482365618,5.17E-06,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"What about FIFO queue or similar, or something like @ELind77 suggested like: > functionality for a timeout on vocabulary entries that aren't loaded at initialization",Solution Discussion,165,165,0.5,0.1954545455,0.1925825232,0.8074174768,0.5853658537,0.3870967742,0.6482365618,5.17E-06,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Do you have any more information on this issue since it cropped up a few months ago?,Investigation and Exploration,84,84,0.75,0.2,0.1925825232,0.8074174768,0.4146341463,0.2741935484,0.6482365618,5.17E-06,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I notice the same type of memory issues on my systems that analyze streaming Twitter data - note I've not yet narrowed it down to spacy yet but my first cursory look found this ticket to be the most relevant possibility,Observed Bug Behaviour,219,219,1,0.2045454545,0.1925825232,0.8074174768,1,0.6612903226,0.6482365618,5.17E-06,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Also curious if this issue is already solved already, I will test updating my version (currently 0.100.6) to see if that helps at all",Task Progress,133,133,1,0.2090909091,0.192583873,0.807416127,1,0.3870967742,5.17E-06,0.03459730626,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Hi @honnibal, I have had similar issues in my streaming application.",Observed Bug Behaviour,68,68,0.1111111111,0.2136363636,0.2016154368,0.7983845632,0.44,0.1774193548,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Basically memory grows at a logarithmic-ish pace.,Observed Bug Behaviour,49,49,0.2222222222,0.2181818182,0.2016154368,0.7983845632,0.32,0.1290322581,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,We have to deal with it as though it were a memory leak and periodically re-initialize the code.,Observed Bug Behaviour,96,96,0.3333333333,0.2227272727,0.2016154368,0.7983845632,0.76,0.3064516129,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I ran the benchmark you requested above - collecting metrics on the length of the CODE as memory usage grows.,Investigation and Exploration,118,109,0.4444444444,0.2272727273,0.2016154368,0.7983845632,0.76,0.3064516129,0.03459730626,0.03432994834,NONE,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"Here are the results:<img width=""555"" alt=""screen shot 2016-08-16 at 2 24 25 pm"" src=""https://cloud.githubusercontent.com/assets/1669062/17711263/c23cb262-63be-11e6-9aaf-96e9763a00e0.png"">",Investigation and Exploration,188,188,0.5555555556,0.2318181818,0.2016154368,0.7983845632,0.8,0.3225806452,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Here is the code I used to create the metrics.,Investigation and Exploration,46,46,0.6666666667,0.2363636364,0.2016154368,0.7983845632,0.4,0.1612903226,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,It basically ran until I ran out of memory on a 4G box.,Observed Bug Behaviour,55,55,0.7777777778,0.2409090909,0.2016154368,0.7983845632,0.56,0.2258064516,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,https://github.com/natb1/spaCy/blob/memory-benchmark/spacy/tests/benchmark/test_memory.py,Investigation and Exploration,89,89,0.8888888889,0.2454545455,0.2016154368,0.7983845632,0.04,0.01612903226,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I'd be glad to help implement some strategies to address this problem if you could help me isolate the issue and/or suggest some approaches.,Contribution and Commitment,140,140,1,0.25,0.2016154368,0.7983845632,1,0.4032258065,0.03459730626,0.03432994834,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Same problem here.,Social Conversation,18,18,0.5,0.2545454545,0.2105772073,0.7894227927,0.5,0.04838709677,0.03432994834,0.008337610386,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Would also be glad to help.,Contribution and Commitment,27,27,1,0.2590909091,0.2105772073,0.7894227927,1,0.09677419355,0.03432994834,0.008337610386,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,pinging @henningpeters given recent announcement on spaCy homepage,Contribution and Commitment,66,66,1,0.2636363636,0.2127537253,0.7872462747,1,0.1290322581,0.008337610386,0.0002910756073,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,To clarify the current behaviour a little: CODE is currently interning _all_ strings seen.,Observed Bug Behaviour,99,90,0.02777777778,0.2681818182,0.2128297101,0.7871702899,0.35,0.2258064516,0.0002910756073,0.01198979712,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,I agree that this should be changed.,Social Conversation,36,36,0.05555555556,0.2727272727,0.2128297101,0.7871702899,0.175,0.1129032258,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I'll discuss the design decision here, so that we can consider the trade-offs.",Social Conversation,78,78,0.08333333333,0.2772727273,0.2128297101,0.7871702899,0.35,0.2258064516,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I'll start from the beginning:,Social Conversation,30,30,0.1111111111,0.2818181818,0.2128297101,0.7871702899,0.125,0.08064516129,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,why intern the strings?,Investigation and Exploration,23,23,0.1388888889,0.2863636364,0.2128297101,0.7871702899,0.1,0.06451612903,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Two main reasons: 1)         String-to-int mapping 2)         Save memory to represent lots of documents at once.,Observed Bug Behaviour,113,113,0.1666666667,0.2909090909,0.2128297101,0.7871702899,0.5,0.3225806452,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"We can't do without 1 entirely â it's too fundamental to how spaCy is working, and we definitely don't want to be making lots of string comparisons.",Investigation and Exploration,148,148,0.1944444444,0.2954545455,0.2128297101,0.7871702899,0.675,0.435483871,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Comparing by integer value is pretty important.,Investigation and Exploration,47,47,0.2222222222,0.3,0.2128297101,0.7871702899,0.175,0.1129032258,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Consideration 2 is very useful, but it's only really a saving if strings occur multiple times.",Investigation and Exploration,94,94,0.25,0.3045454545,0.2128297101,0.7871702899,0.4,0.2580645161,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Certainly, for strings that occur once, there's no advantage.",Investigation and Exploration,61,61,0.2777777778,0.3090909091,0.2128297101,0.7871702899,0.225,0.1451612903,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,And it's also bad to have unbounded memory use on the streaming process.,Investigation and Exploration,72,72,0.3055555556,0.3136363636,0.2128297101,0.7871702899,0.325,0.2096774194,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,So the solution we want to get to is one where a limited number of somewhat common strings are interned in the common vocab.,Solution Discussion,124,124,0.3333333333,0.3181818182,0.2128297101,0.7871702899,0.6,0.3870967742,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, we still need to map _all_ strings, even rare ones, to integers.",Solution Discussion,73,73,0.3611111111,0.3227272727,0.2128297101,0.7871702899,0.325,0.2096774194,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"We also want the string-to-int table to be consistent, even for rare strings.",Solution Discussion,77,77,0.3888888889,0.3272727273,0.2128297101,0.7871702899,0.375,0.2419354839,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Here's the bit of code where the memory growth is occuring:,Observed Bug Behaviour,59,59,0.4166666667,0.3318181818,0.2128297101,0.7871702899,0.275,0.1774193548,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,https://github.com/spacy-io/spaCy/blob/master/spacy/strings.pyx#L147,Observed Bug Behaviour,68,68,0.4444444444,0.3363636364,0.2128297101,0.7871702899,0.025,0.01612903226,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The purpose here is to resolve a string to an integer.,Investigation and Exploration,54,54,0.4722222222,0.3409090909,0.2128297101,0.7871702899,0.275,0.1774193548,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Now, this is an integer representation --- so why not just use the hash?",Investigation and Exploration,72,72,0.5,0.3454545455,0.2128297101,0.7871702899,0.35,0.2258064516,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The problem is we also want the inverse mapping.,Investigation and Exploration,48,48,0.5277777778,0.35,0.2128297101,0.7871702899,0.225,0.1451612903,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"We therefore store the string, causing the memory growth.",Investigation and Exploration,57,57,0.5555555556,0.3545454545,0.2128297101,0.7871702899,0.225,0.1451612903,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If we insist that all integers can always be mapped back to strings, there's no solution.",Solution Discussion,89,89,0.5833333333,0.3590909091,0.2128297101,0.7871702899,0.4,0.2580645161,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,We have to accept the memory growth.,Solution Discussion,36,36,0.6111111111,0.3636363636,0.2128297101,0.7871702899,0.175,0.1129032258,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"But if we can accept that these strings pass out of date, so that they're around for a while and then they're not, the situation should be manageable.",Solution Discussion,150,150,0.6388888889,0.3681818182,0.2128297101,0.7871702899,0.7,0.4516129032,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,A simple way to achieve this is to extend the CODE so that the mapping is split in two.,Solution Discussion,96,87,0.6666666667,0.3727272727,0.2128297101,0.7871702899,0.475,0.3064516129,0.0002910756073,0.01198979712,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"There's the main intern area, which holds a fixed number of strings, hopefully the common ones.",Solution Discussion,95,95,0.6944444444,0.3772727273,0.2128297101,0.7871702899,0.4,0.2580645161,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"But there's also a rolling buffer, in which strings are interned, and then later freed.",Solution Discussion,87,87,0.7222222222,0.3818181818,0.2128297101,0.7871702899,0.375,0.2419354839,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This could be a LRU cache, or even something simpler.",Solution Discussion,53,53,0.75,0.3863636364,0.2128297101,0.7871702899,0.25,0.1612903226,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Efficiency is not really a problem here: only a small percentage of the encountered tokens will be triggering this logic, so we don't have to make it blazing fast, and it's easy to make sure we operate on contiguous buffers.",Solution Discussion,224,224,0.7777777778,0.3909090909,0.2128297101,0.7871702899,1,0.6451612903,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,A slightly more tricky solution is to do some reference counting.,Solution Discussion,65,65,0.8055555556,0.3954545455,0.2128297101,0.7871702899,0.275,0.1774193548,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The idea here would be for the CODE object to register interest in all OOV strings it owns.,Solution Discussion,92,91,0.8333333333,0.4,0.2128297101,0.7871702899,0.45,0.2903225806,0.0002910756073,0.01198979712,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"When the ref count of an OOV string drops to 0, it's freed.",Solution Discussion,59,59,0.8611111111,0.4045454545,0.2128297101,0.7871702899,0.325,0.2096774194,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This way, if you keep a CODE object in memory, you know that the string lookup will always be well behaved â but if you're letting the CODE objects pass out of scope, your memory won't be growing.",Solution Discussion,198,196,0.8888888889,0.4090909091,0.2128297101,0.7871702899,0.95,0.6129032258,0.0002910756073,0.01198979712,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"I think for both solutions, we should use the hash of the string as the integer representation for OOV strings.",Solution Discussion,111,111,0.9166666667,0.4136363636,0.2128297101,0.7871702899,0.5,0.3225806452,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This means that at least the string-to-int mapping will stay consistent, even if strings are passing out of memory.",Solution Discussion,115,115,0.9444444444,0.4181818182,0.2128297101,0.7871702899,0.525,0.3387096774,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"The only way to have a problem here is if you hold onto the integer representation, release all of the documents, and later want to recover the string.",Solution Discussion,151,151,0.9722222222,0.4227272727,0.2128297101,0.7871702899,0.7,0.4516129032,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"In this situation, you'll be out of luck --- but we'll at least know to use an OOV symbol when you try to look up your string.",Solution Discussion,126,126,1,0.4272727273,0.2128297101,0.7871702899,0.675,0.435483871,0.0002910756073,0.01198979712,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Simply hashing oov tokens sounds good enough to me.,Solution Discussion,51,51,0.5,0.4318181818,0.2159596248,0.7840403752,0.2307692308,0.1451612903,0.01198979712,0.001341566856,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"As long as we know theindices of the fist and last characters of the token in the input text, sothat we can look it up if we need to, I don't find saving the token instring store particularly necessary.",Solution Discussion,202,202,1,0.4363636364,0.2159596248,0.7840403752,1,0.6290322581,0.01198979712,0.001341566856,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The input text is currently not saved/represented on the document at the moment.,Solution Discussion,80,80,0.5,0.4409090909,0.2163098383,0.7836901617,0.4242424242,0.2258064516,0.001341566856,2.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Instead, we guarantee that the CODE attribute faithfully retains the slice for each token, so that we just have to join the CODE attributes and check whether the token has a trailing space.",Solution Discussion,193,189,1,0.4454545455,0.2163098383,0.7836901617,1,0.5322580645,0.001341566856,2.04E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Yeah I understand.,Social Conversation,18,18,0.5,0.45,0.2163151642,0.7836848358,0.06818181818,0.04838709677,2.04E-05,0.0001196000951,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"The point I was making was that, since the caller of the CODE object has the full input text string anyways, it shouldn't be a big problem to deal with the slight inconvenience of having to look up the original substring of OOV tokens.",Solution Discussion,241,235,1,0.4545454545,0.2163151642,0.7836848358,1,0.7096774194,2.04E-05,0.0001196000951,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,I think we're in agreement here.,Social Conversation,32,32,0.05882352941,0.4590909091,0.2163463856,0.7836536144,0.2307692308,0.09677419355,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, I think it's important that we either assume the string is unavailable, or save it ourselves.",Solution Discussion,102,102,0.1176470588,0.4636363636,0.2163463856,0.7836536144,0.6538461538,0.2741935484,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Saving the string on the document isn't a huge waste of memory, and it only impacts the API in a few places (e.g., CODE, deserialisation, etc).",Solution Discussion,155,143,0.1764705882,0.4681818182,0.2163463856,0.7836536144,1,0.4193548387,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"So if we want the user to be slicing into the string ever, we should probably switch to saving it.",Solution Discussion,98,98,0.2352941176,0.4727272727,0.2163463856,0.7836536144,0.7692307692,0.3225806452,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Here's a design that achieves something like the reference counting:,Solution Discussion,68,68,0.2941176471,0.4772727273,0.2163463856,0.7836536144,0.3846153846,0.1612903226,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"-         Add a CODE member to CODE, which will be a sequence of CODE instances.",Solution Discussion,106,80,0.3529411765,0.4818181818,0.2163463856,0.7836536144,0.5769230769,0.2419354839,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"-         Already in CODE, we accept a CODE argument, that represents the allocation pool that will own the memory for the created CODE struct.",Solution Discussion,157,143,0.4117647059,0.4863636364,0.2163463856,0.7836536144,0.9230769231,0.3870967742,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,This allows CODE objects to own their OOV lexemes.,Solution Discussion,51,50,0.4705882353,0.4909090909,0.2163463856,0.7836536144,0.3461538462,0.1451612903,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,We need to extend this such that the document also owns the strings.,Solution Discussion,68,68,0.5294117647,0.4954545455,0.2163463856,0.7836536144,0.5,0.2096774194,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Relevant code in CODE: https://github.com/spacy-io/spaCy/blob/master/spacy/vocab.pyx#L149 (called by CODE, called by CODE)",Solution Discussion,158,122,0.5882352941,0.5,0.2163463856,0.7836536144,0.4230769231,0.1774193548,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,-         I suggest using CODE as a way of selecting the appropriate child oov store.,Solution Discussion,90,85,0.6470588235,0.5045454545,0.2163463856,0.7836536144,0.5769230769,0.2419354839,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"This will allow us to have a method CODE that can be called from the CODE, CODE etc instances.",Solution Discussion,128,94,0.7058823529,0.5090909091,0.2163463856,0.7836536144,0.7307692308,0.3064516129,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"-         We then define a CODE method, which is the Cython way of adding a destructor.",Solution Discussion,100,87,0.7647058824,0.5136363636,0.2163463856,0.7836536144,0.6153846154,0.2580645161,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"In CODE, we tell the CODE to drop the oov store associated with the CODE object.",Solution Discussion,103,80,0.8235294118,0.5181818182,0.2163463856,0.7836536144,0.6153846154,0.2580645161,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,-         The CODE remains a single source of truth for the string-to-integer mapping.,Solution Discussion,95,86,0.8823529412,0.5227272727,0.2163463856,0.7836536144,0.5769230769,0.2419354839,0.0001196000951,0.008439281707,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"When decoding an integer, we can search for it in all the OOV stores.",Solution Discussion,69,69,0.9411764706,0.5272727273,0.2163463856,0.7836536144,0.5384615385,0.2258064516,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This makes it easier to prevent integers from being ""stranded"".",Solution Discussion,63,63,1,0.5318181818,0.2163463856,0.7836536144,0.3846153846,0.1612903226,0.0001196000951,0.008439281707,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,This sounds great!,Social Conversation,18,18,0.25,0.5363636364,0.2185494447,0.7814505553,0.1111111111,0.04838709677,0.008439281707,0.0010422294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Although probably due to lack of context and familiarity to the code base, I personally would still prefer some simpler approach that can keep the CODE immutable.",Solution Discussion,171,162,0.5,0.5409090909,0.2185494447,0.7814505553,1,0.435483871,0.008439281707,0.0010422294,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"e.g. use hashing to map OOV tokens to ints, keep reference to the text string in the CODE object, and obtain CODE strings by indexing on it.",Solution Discussion,143,140,0.75,0.5454545455,0.2185494447,0.7814505553,1,0.435483871,0.008439281707,0.0010422294,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Maybe this immutability can help parallelizing other parts of the pipeline too.,Solution Discussion,79,79,1,0.55,0.2185494447,0.7814505553,0.4444444444,0.1935483871,0.008439281707,0.0010422294,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Well, I think you could say ""the trap is set"": the existing design is such that the strings have to be globally available.",Solution Discussion,122,122,0.1428571429,0.5545454545,0.2188215168,0.7811784832,0.46,0.3709677419,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Recall that we're allowing transport to/from numpy arrays.,Solution Discussion,58,58,0.2857142857,0.5590909091,0.2188215168,0.7811784832,0.18,0.1451612903,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This means we're expecting to be able to unpack an array of ints and understand some of them as strings, without ties to a particular CODE object.",Solution Discussion,147,146,0.4285714286,0.5636363636,0.2188215168,0.7811784832,0.54,0.435483871,0.0010422294,0.002309046196,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,This is the mechanism being used for deserialization.,Solution Discussion,53,53,0.5714285714,0.5681818182,0.2188215168,0.7811784832,0.16,0.1290322581,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,We could hack through this by writing down the OOV strings in the global store only when we pack into an array.,Workarounds,111,111,0.7142857143,0.5727272727,0.2188215168,0.7811784832,0.44,0.3548387097,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,But I hope we can all agree that this is just digging ourselves a deeper hole.,Social Conversation,78,78,0.8571428571,0.5772727273,0.2188215168,0.7811784832,0.32,0.2580645161,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I would be very unhappy if I tried to pack an array myself in the obvious way, and I found that the library's version of this was quietly writing to global state, and without this write my method failed, but only on OOV words, so not on my test data!",Workarounds,250,250,1,0.5818181818,0.2188215168,0.7811784832,1,0.8064516129,0.0010422294,0.002309046196,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Yeah this sounds terrifying.,Social Conversation,28,28,0.1666666667,0.5863636364,0.2194242891,0.7805757109,0.16,0.06451612903,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I might be totally wrong, but I expect the feature of converting to/from numpy to only be used internally?",Solution Discussion,106,106,0.3333333333,0.5909090909,0.2194242891,0.7805757109,0.8,0.3225806452,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"The array doesn't seem to work across different CODE instances if there're OOV tokens, which kind of defeats the purpose of serialization for normal users.",Solution Discussion,161,155,0.5,0.5954545455,0.2194242891,0.7805757109,1,0.4032258065,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,So maybe we don't need to worry about breaking user code that uses it?,Solution Discussion,70,70,0.6666666667,0.6,0.2194242891,0.7805757109,0.56,0.2258064516,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I guess what I was proposing entails always including the original text as part of (de)serialization.,Solution Discussion,101,101,0.8333333333,0.6045454545,0.2194242891,0.7805757109,0.64,0.2580645161,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This might be too much refactor work, in which case what you mentioned also sounds great :)",Social Conversation,91,91,1,0.6090909091,0.2194242891,0.7805757109,0.68,0.2741935484,0.002309046196,0.1481803025,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Implemented ð,Task Progress,13,13,0.5,0.6136363636,0.2581064871,0.7418935129,0.1666666667,0.03225806452,0.1481803025,0.002179048536,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Need to update other modules to reflect the change, and do testing.",Task Progress,67,67,1,0.6181818182,0.2581064871,0.7418935129,1,0.1935483871,0.1481803025,0.002179048536,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Hmm.,Social Conversation,4,4,0.25,0.6227272727,0.2586753238,0.7413246762,0.03703703704,0.01612903226,0.002179048536,0.1151253204,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I don't want to rush this, because it touches a lot of files, but I also don't want to block the v1.0.0 release, which is otherwise ready.",Task Progress,138,138,0.5,0.6272727273,0.2586753238,0.7413246762,1,0.435483871,0.002179048536,0.1151253204,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,So unfortunately I have to move this out of the milestone.,Task Progress,58,58,0.75,0.6318181818,0.2586753238,0.7413246762,0.4074074074,0.1774193548,0.002179048536,0.1151253204,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I'll probably get back to it week after next.,Task Progress,45,45,1,0.6363636364,0.2586753238,0.7413246762,0.3333333333,0.1451612903,0.002179048536,0.1151253204,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"New plan â let's at least get a good workaround in place, where the user will do some manual management of when the strings will be freed.",Workarounds,138,138,0.07142857143,0.6409090909,0.288728579,0.711271421,1,0.435483871,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"This should be enough to keep you all productive, while we try to plan out a prettier, 'automagical' solution/wrapper around this.",Social Conversation,130,130,0.1428571429,0.6454545455,0.288728579,0.711271421,0.8148148148,0.3548387097,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"The freeze/flush behaviour is off by default, so it shouldn't disrupt anyone.",Workarounds,77,77,0.2142857143,0.65,0.288728579,0.711271421,0.4814814815,0.2096774194,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"@tomtung â I think this is the sort of solution you were looking for, since this makes it a bit easier to control things manually.",Workarounds,130,130,0.2857142857,0.6545454545,0.288728579,0.711271421,0.9259259259,0.4032258065,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Summary:-         New CODE keyword argument to CODE,Workarounds,73,51,0.3571428571,0.6590909091,0.288728579,0.711271421,0.2962962963,0.1290322581,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"-         New CODE method on CODE, controlling whether to start handling new strings as OOV",Workarounds,115,91,0.4285714286,0.6636363636,0.288728579,0.711271421,0.5555555556,0.2419354839,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"-         New CODE method on CODE, indicating that the current batch of OOV strings should be flushed away, and the memory freed.",Workarounds,148,129,0.5,0.6681818182,0.288728579,0.711271421,0.8148148148,0.3548387097,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Example (untested): CODE,Workarounds,192,24,0.5714285714,0.6727272727,0.288728579,0.711271421,0.1481481481,0.06451612903,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"CODE should be super cheap, so don't stress about trying to call it as late as possible.",Workarounds,98,88,0.6428571429,0.6772727273,0.288728579,0.711271421,0.6296296296,0.2741935484,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Call it whenever convenient.,Workarounds,28,28,0.7142857143,0.6818181818,0.288728579,0.711271421,0.1481481481,0.06451612903,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The OOV strings are encoded using the hash of the byte string.,Workarounds,62,62,0.7857142857,0.6863636364,0.288728579,0.711271421,0.4444444444,0.1935483871,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,This means that you'll get consistent integer encodings between flushings.,Workarounds,74,74,0.8571428571,0.6909090909,0.288728579,0.711271421,0.3703703704,0.1612903226,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, if you're holding an integer ID for an OOV string, and you flush the OOVs and try to decode the integer, you'll get an CODE.",Workarounds,141,133,0.9285714286,0.6954545455,0.288728579,0.711271421,0.962962963,0.4193548387,0.1151253204,0.02221386295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"Hopefully, this is logical.",Workarounds,27,27,1,0.7,0.288728579,0.711271421,0.1481481481,0.06451612903,0.1151253204,0.02221386295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If one serializes a Doc with an OOV word, the above is bound to happen.",Workarounds,71,71,0.25,0.7045454545,0.2945274675,0.7054725325,0.5357142857,0.2419354839,0.02221386295,0.000146521357,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Since serialization is the only way to reuse parsing results in a data pipeline and most real-world docs would have OOV words, this problem is pretty critical.",Workarounds,159,159,0.5,0.7090909091,0.2945274675,0.7054725325,1,0.4516129032,0.02221386295,0.000146521357,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"When serializing a Doc (with CODE), would it make sense to include the relevant OOV entries?",Usage,98,92,0.75,0.7136363636,0.2945274675,0.7054725325,0.5714285714,0.2580645161,0.02221386295,0.000146521357,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"That way, we can deserialize a Doc with only the standard vocab.",Usage,64,64,1,0.7181818182,0.2945274675,0.7054725325,0.4285714286,0.1935483871,0.02221386295,0.000146521357,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I'd be happy to try to take a crack at it, but things like the use of CODE in CODE make it pretty involved...",Contribution and Commitment,123,109,0.25,0.7227272727,0.2945657166,0.7054342834,1,0.4032258065,0.000146521357,8.32E-06,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"(actually, given a doc, are we guaranteed to get the same packing result if the vocab grows?)",Solution Discussion,93,93,0.5,0.7272727273,0.2945657166,0.7054342834,0.68,0.2741935484,0.000146521357,8.32E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Perhaps offer a way for self-contained serialization that doesn't depend on any vocab altogether?,Solution Discussion,97,97,0.75,0.7318181818,0.2945657166,0.7054342834,0.6,0.2419354839,0.000146521357,8.32E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,(Or only depending on a small set of symbols that are future proof),Solution Discussion,67,67,1,0.7363636364,0.2945657166,0.7054342834,0.52,0.2096774194,0.000146521357,8.32E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The serialiser backs off to a character codec for OOV words.,Solution Discussion,60,60,1,0.7409090909,0.294567888,0.705432112,1,0.1774193548,8.32E-06,1.64E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Incidentally I have regrets about the serialiser.,Solution Discussion,49,49,0.25,0.7454545455,0.2945721721,0.7054278279,0.5833333333,0.1129032258,1.64E-05,0.1206599722,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I think I got carried away...,Social Conversation,29,29,0.5,0.75,0.2945721721,0.7054278279,0.5,0.09677419355,1.64E-05,0.1206599722,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I don't even remember how much bigger a CODE tuple would be.,Solution Discussion,77,60,0.75,0.7545454545,0.2945721721,0.7054278279,1,0.1935483871,1.64E-05,0.1206599722,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Does anyone want to run a benchmark?,Solution Discussion,36,36,1,0.7590909091,0.2945721721,0.7054278279,0.5833333333,0.1129032258,1.64E-05,0.1206599722,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I'm so glad that this has received so much thought and attention!,Social Conversation,65,65,0.1666666667,0.7636363636,0.3260702381,0.6739297619,0.1935483871,0.1935483871,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,@honnibal could we get an update on the current status of this and your thoughts on how best to proceed?,Task Progress,104,104,0.3333333333,0.7681818182,0.3260702381,0.6739297619,0.3225806452,0.3225806452,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Your suggestion of splitting the string store seems most in line with my thoughts on this.,Solution Discussion,90,90,0.5,0.7727272727,0.3260702381,0.6739297619,0.2580645161,0.2580645161,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If that is still the way you are thinking of going with this and you're thinking of using multiple string stores for OOV words, I'd also just like to put out there that it might be a good idea to use some kind of data structure for storing them other than an array, especially if there are a lot of them.",Solution Discussion,304,304,0.6666666667,0.7772727273,0.3260702381,0.6739297619,1,1,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"If the integer ids of the multiple StringStores are guaranteed to never overlap a BST might be a good candidate, if they can overlap though you might need to go with something a bit different, like a UnionFind.",Solution Discussion,210,210,0.8333333333,0.7818181818,0.3260702381,0.6739297619,0.6129032258,0.6129032258,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,-- Eric,Social Conversation,7,7,1,0.7863636364,0.3260702381,0.6739297619,0.03225806452,0.03225806452,0.1206599722,1,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,#589 issue still exists.,Potential New Issues and Requests,24,24,0.2,0.7909090909,0.5871184167,0.4128815833,0.3636363636,0.06451612903,1,0.09855593002,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,So the workaround doesn't really work.,Workarounds,38,38,0.4,0.7954545455,0.5871184167,0.4128815833,0.5454545455,0.09677419355,1,0.09855593002,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,This is one of the blocking issues for us now.,Motivation,46,46,0.6,0.8,0.5871184167,0.4128815833,0.9090909091,0.1612903226,1,0.09855593002,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Will a more stable fix be available in next 1.x releases?,Task Progress,57,57,0.8,0.8045454545,0.5871184167,0.4128815833,1,0.1774193548,1,0.09855593002,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Thanks a lot for the work!,Social Conversation,26,26,1,0.8090909091,0.5871184167,0.4128815833,0.5454545455,0.09677419355,1,0.09855593002,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Hey, I just took a look at the StringStore class in main and saw that some work has been done on this.",Task Progress,102,102,0.2,0.8136363636,0.6128462627,0.3871537373,1,0.3548387097,0.09855593002,0.1714850105,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I still need to play with is a bit to see how it works but this looks really great.,Social Conversation,83,83,0.4,0.8181818182,0.6128462627,0.3871537373,0.8636363636,0.3064516129,0.09855593002,0.1714850105,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,https://github.com/explosion/spaCy/commits/master/spacy/strings.pyx,Task Progress,67,67,0.6,0.8227272727,0.6128462627,0.3871537373,0.04545454545,0.01612903226,0.09855593002,0.1714850105,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Thank you so much @honnibal !,Social Conversation,29,29,0.8,0.8272727273,0.6128462627,0.3871537373,0.2272727273,0.08064516129,0.09855593002,0.1714850105,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,-- Eric,Social Conversation,7,7,1,0.8318181818,0.6128462627,0.3871537373,0.09090909091,0.03225806452,0.09855593002,0.1714850105,NONE,TRUE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"Hi @honnibal First of all, thank you for this great tool, we use it as part of NLP in our product.",Social Conversation,98,98,0.1111111111,0.8363636364,0.6576121123,0.3423878877,0.5675675676,0.3387096774,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, our case is very high-load system with streaming data (hundreds of thousands emails per day).",Motivation,102,102,0.2222222222,0.8409090909,0.6576121123,0.3423878877,0.4594594595,0.2741935484,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"And we are experiencing the same problem as was discussed here - growth of StringStore causes tremendous memory growth over time, so it really blocks usage of spaCy without fear of crashing the whole system because of OOM.",Observed Bug Behaviour,222,222,0.3333333333,0.8454545455,0.6576121123,0.3423878877,1,0.5967741935,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The only workaround we came up with is to reload nlp object each N processed content items and force garbage collector to free memory of deleted object.,Workarounds,152,152,0.4444444444,0.85,0.6576121123,0.3423878877,0.7297297297,0.435483871,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"However, it seem not always working way - sometimes it frees all the memory, and sometimes not.",Workarounds,95,95,0.5555555556,0.8545454545,0.6576121123,0.3423878877,0.4324324324,0.2580645161,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,So my questions are as follows:1)         Is it planned to deal with this issue somehow?,Task Progress,88,88,0.6666666667,0.8590909091,0.6576121123,0.3423878877,0.4324324324,0.2580645161,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"From what I see, in version 2.0 the problem still exists.",Task Progress,57,57,0.7777777778,0.8636363636,0.6576121123,0.3423878877,0.2972972973,0.1774193548,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"2)         If it is such a fundamental way how spaCy works, maybe, there are some more clever workarounds to prevent such memory leaks?",Workarounds,135,135,0.8888888889,0.8681818182,0.6576121123,0.3423878877,0.6486486486,0.3870967742,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Thanks in advance.,Social Conversation,18,18,1,0.8727272727,0.6576121123,0.3423878877,0.08108108108,0.04838709677,0.1714850105,0.0002468438052,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,@azar923 Did you try the CODE mitigation above?,Workarounds,61,47,0.3333333333,0.8772727273,0.6576765505,0.3423234495,0.275862069,0.1290322581,0.0002468438052,0.0002666834826,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"The situation around this is much improved in spaCy 2, because the string-to-integer mapping no longer depends on the CODE state --- it's just a hash value.",Task Progress,165,156,0.6666666667,0.8818181818,0.6576765505,0.3423234495,1,0.4677419355,0.0002468438052,0.0002666834826,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,This makes everything much easier.,Social Conversation,34,34,1,0.8863636364,0.6576765505,0.3423234495,0.1724137931,0.08064516129,0.0002468438052,0.0002666834826,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"@honnibal thank you for quick answer,",Social Conversation,37,37,0.3333333333,0.8909090909,0.6577461677,0.3422538323,0.2307692308,0.09677419355,0.0002666834826,0.0002101432121,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I use 1.6 now, did not try older versions yet because of some performance degradation in one-thread mode, which is critical for us now.",Observed Bug Behaviour,135,135,0.6666666667,0.8954545455,0.6577461677,0.3422538323,0.9615384615,0.4032258065,0.0002666834826,0.0002101432121,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"""we can restore the original string store every N documents without causing any problems"" - sorry, did not catch that, how is it restored every N documents?",Solution Discussion,156,156,1,0.9,0.6577461677,0.3422538323,1,0.4193548387,0.0002666834826,0.0002101432121,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The restoration idea would look like this: CODE,Solution Discussion,371,47,0.2,0.9045454545,0.6578010252,0.3421989748,0.25,0.1290322581,0.0002101432121,0.0002159883295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,This would ensure that strings stay available from only the last 1000 documents.,Solution Discussion,80,80,0.4,0.9090909091,0.6578010252,0.3421989748,0.40625,0.2096774194,0.0002101432121,0.0002159883295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"It works by keeping two copies of the CODE: the active one, and the backup.",Solution Discussion,84,75,0.6,0.9136363636,0.6578010252,0.3421989748,0.46875,0.2419354839,0.0002101432121,0.0002159883295,MEMBER,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,"The backup tracks the active store for 1000 documents, and then takes over.",Solution Discussion,75,75,0.8,0.9181818182,0.6578010252,0.3421989748,0.40625,0.2096774194,0.0002101432121,0.0002159883295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"We then start a new backup from the original strings data, which adds entries for the next 1000 documents, so that when it takes over, those recent documents' strings will be available.",Solution Discussion,185,185,1,0.9227272727,0.6578010252,0.3421989748,1,0.5161290323,0.0002101432121,0.0002159883295,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"@honnibal Great, thanks very much for these improvements.",Social Conversation,57,57,0.3333333333,0.9272727273,0.6578574086,0.3421425914,0.6153846154,0.1290322581,0.0002159883295,0.09426527661,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Will look forward to 2.0 release to try.,Social Conversation,40,40,0.6666666667,0.9318181818,0.6578574086,0.3421425914,0.6153846154,0.1290322581,0.0002159883295,0.09426527661,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,For now workaround with reloading / collecting nlp object works quite ok in production.,Workarounds,87,87,1,0.9363636364,0.6578574086,0.3421425914,1,0.2096774194,0.0002159883295,0.09426527661,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"@honnibal  I'm also facing the same issue, (spacy 1.5.0).",Observed Bug Behaviour,57,57,0.1666666667,0.9409090909,0.6824651873,0.3175348127,0.3225806452,0.1612903226,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,"I know this is hackish, however, would resetting the _map and setting size to 0, or resetting the StringStore itself after a certain critical size is reached could cause any problems?",Workarounds,183,183,0.3333333333,0.9454545455,0.6824651873,0.3175348127,1,0.5,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Currently using spacy to get the POS tags. (from sentence subtree etc),Motivation,70,70,0.5,0.95,0.6824651873,0.3175348127,0.3870967742,0.1935483871,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Is there a way to reset the StringStore without reloading the model again ?,Workarounds,75,75,0.6666666667,0.9545454545,0.6824651873,0.3175348127,0.4193548387,0.2096774194,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,The workaround of using set_frozen does not work.,Workarounds,49,49,0.8333333333,0.9590909091,0.6824651873,0.3175348127,0.2580645161,0.1290322581,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Ref: [v1.5.0_source] URL,Workarounds,86,25,1,0.9636363636,0.6824651873,0.3175348127,0.09677419355,0.04838709677,0.09426527661,0.02091540384,NONE,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,I am experimenting with this workaround with the 1.x version.,Workarounds,61,61,0.3333333333,0.9681818182,0.6879251154,0.3120748846,1,0.1612903226,0.02091540384,0.2056416849,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,So far it is working well.,Workarounds,26,26,0.6666666667,0.9727272727,0.6879251154,0.3120748846,0.6,0.09677419355,0.02091540384,0.2056416849,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,CODE,Workarounds,795,4,1,0.9772727273,0.6879251154,0.3120748846,0.1,0.01612903226,0.02091540384,0.2056416849,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
4 285_spaCy.doc,Fixed!,Task Progress,6,6,0.3333333333,0.9818181818,0.7416075027,0.2583924973,0.25,0.01612903226,0.2056416849,0.9898268541,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,(!!!!):tada: :tada: :tada:,Social Conversation,26,26,0.6666666667,0.9863636364,0.7416075027,0.2583924973,1,0.06451612903,0.2056416849,0.9898268541,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,Please see https://github.com/explosion/spaCy/pull/1424,Action on Issue,55,55,1,0.9909090909,0.7416075027,0.2583924973,0.75,0.04838709677,0.2056416849,0.9898268541,MEMBER,FALSE,FALSE,FALSE,FALSE
4 285_spaCy.doc,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue,107,107,1,0.9954545455,1,0,18,0.2903225806,0.9898268541,0,NONE,FALSE,FALSE,FALSE,TRUE
4 285_spaCy.doc,Please open a new issue for related bugs.,Action on Issue,41,41,2,1,1,0,8,0.1290322581,0.9898268541,0,NONE,FALSE,FALSE,FALSE,TRUE
5 429_spaCy.doc,pipe(): ValueError Error parsing doc,Observed Bug Behaviour,36,36,0.1111111111,0.01162790698,0,1,0.3,0.06060606061,0,0.008598273629,NONE,TRUE,FALSE,TRUE,FALSE
5 429_spaCy.doc,I found strange behaviour using the CODE method (only verified on german variant):,Observed Bug Behaviour,86,82,0.2222222222,0.02325581395,0,1,0.7,0.1414141414,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,"If you parse a document using CODE you can get a ValueError, while if i use CODE everything is fine.",Observed Bug Behaviour,111,100,0.3333333333,0.03488372093,0,1,1,0.202020202,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,"I boiled it down to single words, while german words work, english words like 'windows' don't work.",Investigation and Exploration,99,99,0.4444444444,0.04651162791,0,1,0.85,0.1717171717,0,0.008598273629,NONE,TRUE,FALSE,TRUE,FALSE
5 429_spaCy.doc,Steps to reproduce: CODE,Bug Reproduction,197,24,0.5555555556,0.05813953488,0,1,0.2,0.0404040404,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,Trace CODE,Observed Bug Behaviour,579,10,0.6666666667,0.06976744186,0,1,0.1,0.0202020202,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,If you use CODE it works fine.,Observed Bug Behaviour,42,30,0.7777777778,0.08139534884,0,1,0.35,0.07070707071,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,"Also if you execute CODE before the same CODE call, CODE does not raise an exception (a dictionary is built?)",Observed Bug Behaviour,129,109,0.8888888889,0.09302325581,0,1,1,0.202020202,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,Maybe this is related to this region [syntax/parser.pyx](https://github.com/spacy-io/spaCy/blob/1822bb4ff1e6ceee76fe5e43de4345fab168e65b/spacy/syntax/parser.pyx#L179-L183) CODE,Investigation and Exploration,335,176,1,0.1046511628,0,1,0.9,0.1818181818,0,0.008598273629,NONE,TRUE,TRUE,TRUE,FALSE
5 429_spaCy.doc,Same issue here with the german model and CODE on Amazon Linux (also on Ubuntu Server 14.04 LTS) using python 3.5.,Bug Reproduction,122,114,0.3333333333,0.1162790698,0.004005078259,0.9959949217,0.9130434783,0.2121212121,0.008598273629,0.1559472602,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"However, blang's minimal example works on my Macbook (OSX 10.11.3) where I don't have OpenMP support in place (obviously only in single-thread).",Bug Reproduction,144,144,0.6666666667,0.1279069767,0.004005078259,0.9959949217,1,0.2323232323,0.008598273629,0.1559472602,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Setting CODE on Linux doesn't solve the issue for me.,Investigation and Exploration,62,53,1,0.1395348837,0.004005078259,0.9959949217,0.4347826087,0.101010101,0.008598273629,0.1559472602,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,I just tried this again and it seems to work now (reinstalled spaCy and the german model).,Bug Reproduction,90,90,0.25,0.1511627907,0.07664535565,0.9233546443,1,0.1717171717,0.1559472602,0.02247209918,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,@blang can you confirm?,Investigation and Exploration,23,23,0.5,0.1627906977,0.07664535565,0.9233546443,0.2352941176,0.0404040404,0.1559472602,0.02247209918,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,@syllog1sm Out of curiosity: Has there been an update to the German model which fixed this?,Task Progress,91,91,0.75,0.1744186047,0.07664535565,0.9233546443,0.9411764706,0.1616161616,0.1559472602,0.02247209918,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Or was it a code change?,Task Progress,24,24,1,0.1860465116,0.07664535565,0.9233546443,0.3529411765,0.06060606061,0.1559472602,0.02247209918,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Same problem here, working on Windows 10 with German text.",Bug Reproduction,58,58,0.2,0.1976744186,0.08711286573,0.9128871343,0.3333333333,0.101010101,0.02247209918,0.04915356896,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Thought it was German that made it break.,Investigation and Exploration,41,41,0.4,0.2093023256,0.08711286573,0.9128871343,0.2666666667,0.08080808081,0.02247209918,0.04915356896,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I also reinstalled spaCy and the German model yesterday, but this din't fix the problem in my case.",Investigation and Exploration,99,99,0.6,0.2209302326,0.08711286573,0.9128871343,0.6,0.1818181818,0.02247209918,0.04915356896,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I then tried to break it down to a specific sentence, but even after having removed this and succesively the follwoing sentences from my texts, the problem remained the same.",Investigation and Exploration,174,174,0.8,0.2325581395,0.08711286573,0.9128871343,1,0.303030303,0.02247209918,0.04915356896,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"As above, if I use nlp(text) everything is fine.",Investigation and Exploration,48,48,1,0.2441860465,0.08711286573,0.9128871343,0.3,0.09090909091,0.02247209918,0.04915356896,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Steps to reproduce: CODE,Bug Reproduction,142,24,0.25,0.2558139535,0.1100086119,0.8899913881,0.2857142857,0.0404040404,0.04915356896,0.07593267665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,raises: CODE,Observed Bug Behaviour,856,12,0.5,0.2674418605,0.1100086119,0.8899913881,0.1428571429,0.0202020202,0.04915356896,0.07593267665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"Curious thing, If you add a comma like this: CODE the error goes away.",Investigation and Exploration,130,70,0.75,0.2790697674,0.1100086119,0.8899913881,1,0.1414141414,0.04915356896,0.07593267665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,Directly doing: CODE is ok in both cases.,Investigation and Exploration,111,41,1,0.2906976744,0.1100086119,0.8899913881,0.5714285714,0.08080808081,0.04915356896,0.07593267665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"I think the CODE method isn't actually to blame here â rather, it reports on an error condition thrown by the CODE method, while the CODE method fails silently in the same situation.",Investigation and Exploration,197,182,0.1428571429,0.3023255814,0.1453780739,0.8546219261,0.7857142857,0.3333333333,0.07593267665,0.03116866066,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,The issue is arising because the entity recogniser's push-down automaton finds itself in a state with no continuations.,Investigation and Exploration,119,119,0.2857142857,0.3139534884,0.1453780739,0.8546219261,0.4523809524,0.1919191919,0.07593267665,0.03116866066,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I haven't stepped through the automaton yet (if you want to do that, use the methodCODE) to see exactly where the problem is, but I'm pretty sure the error will come from an interaction with entities pre-set by the CODE class.",Investigation and Exploration,257,226,0.4285714286,0.3255813953,0.1453780739,0.8546219261,1,0.4242424242,0.07593267665,0.03116866066,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"In order to preserve these entities, we restrict the actions of the entity recogniser, so that it can't over-write the previous ones.",Investigation and Exploration,133,133,0.5714285714,0.3372093023,0.1453780739,0.8546219261,0.5476190476,0.2323232323,0.07593267665,0.03116866066,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"There's apparently a bug in the logic to introduce this constraint, that's leaving the automaton with no available actions.",Investigation and Exploration,123,123,0.7142857143,0.3488372093,0.1453780739,0.8546219261,0.4523809524,0.1919191919,0.07593267665,0.03116866066,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"This results in an invalid predicted action, leading the parser to return a status code (it can't raise an error, as it's in a CODE function).",Investigation and Exploration,145,142,0.8571428571,0.3604651163,0.1453780739,0.8546219261,0.619047619,0.2626262626,0.07593267665,0.03116866066,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,This is the status code the CODE method was ignoring.,Investigation and Exploration,59,53,1,0.3720930233,0.1453780739,0.8546219261,0.2380952381,0.101010101,0.07593267665,0.03116866066,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,This might have something to do with state between the documents (don't know what if any is kept).,Investigation and Exploration,98,98,0.1428571429,0.3837209302,0.1598964447,0.8401035553,0.8181818182,0.1818181818,0.03116866066,0.03531242178,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"At first errors were still being produced, but after a few shuffles of the corpus to errors to my surprise went away.",Investigation and Exploration,117,117,0.2857142857,0.3953488372,0.1598964447,0.8401035553,1,0.2222222222,0.03116866066,0.03531242178,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,I'll try to produce a more reliable report of the behaviour.,Social Conversation,60,60,0.4285714286,0.4069767442,0.1598964447,0.8401035553,0.5,0.1111111111,0.03116866066,0.03531242178,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,**update** so the error going away didn't have anything to do with CODE.,Investigation and Exploration,84,72,0.5714285714,0.4186046512,0.1598964447,0.8401035553,0.5909090909,0.1313131313,0.03116866066,0.03531242178,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"However if you take the document that produces the error, pass it through CODE and then call CODE again, it works.",Investigation and Exploration,130,114,0.7142857143,0.4302325581,0.1598964447,0.8401035553,0.9545454545,0.2121212121,0.03116866066,0.03531242178,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"An example document where CODE causes the error, removing that one token everything is fine.",Investigation and Exploration,94,92,0.8571428571,0.4418604651,0.1598964447,0.8401035553,0.6818181818,0.1515151515,0.03116866066,0.03531242178,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,CODE,Investigation and Exploration,310,4,1,0.4534883721,0.1598964447,0.8401035553,0.04545454545,0.0101010101,0.03116866066,0.03531242178,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"I think I have this taken care of, but I'm not 100% sure.",Social Conversation,57,57,0.5,0.4651162791,0.1763449807,0.8236550193,1,0.1313131313,0.03531242178,0.02657364924,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Please reopen if it reoccurs.,Action on Issue,29,29,1,0.476744186,0.1763449807,0.8236550193,0.3846153846,0.05050505051,0.03531242178,0.02657364924,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,The text it tried to parse isn't relevant: CODE but I did update global CODE in a loop while parsing the doc in the same loop.,Observed Bug Behaviour,153,126,0.3333333333,0.488372093,0.1887229939,0.8112770061,1,0.2626262626,0.02657364924,1.15E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,I'll get back to this if I'll be able to reproduce it with specific steps.,Bug Reproduction,74,74,0.6666666667,0.5,0.1887229939,0.8112770061,0.5769230769,0.1515151515,0.02657364924,1.15E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,PS: Now I'm getting CODE and I have no idea if it's relevant or not..,Potential New Issues and Requests,89,69,1,0.511627907,0.1887229939,0.8112770061,0.6153846154,0.1616161616,0.02657364924,1.15E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,Do you have a minute to video chat about this?,Social Conversation,46,46,0.5,0.523255814,0.1887283593,0.8112716407,1,0.101010101,1.15E-05,4.73E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,If so click here: https://appear.in/spacy_issue429,Social Conversation,50,50,1,0.5348837209,0.1887283593,0.8112716407,0.5,0.05050505051,1.15E-05,4.73E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Sorry, my internet isn't good for video chatting, but I'm happy to text.",Social Conversation,72,72,1,0.5465116279,0.1887305627,0.8112694373,1,0.1313131313,4.73E-06,8.38E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,No worries.,Social Conversation,11,11,0.2,0.5581395349,0.1887344648,0.8112655352,0.1111111111,0.0202020202,8.38E-06,7.44E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,If you're getting a segfault the handiest thing to do would be to break out the pipeline manually.,Potential New Issues and Requests,98,98,0.4,0.5697674419,0.1887344648,0.8112655352,1,0.1818181818,8.38E-06,7.44E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Instead of: CODE,Potential New Issues and Requests,33,16,0.6,0.5813953488,0.1887344648,0.8112655352,0.1666666667,0.0303030303,8.38E-06,7.44E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,You can do: CODE,Potential New Issues and Requests,135,16,0.8,0.5930232558,0.1887344648,0.8112655352,0.2222222222,0.0404040404,8.38E-06,7.44E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,Then you can investigate what's going on.,Potential New Issues and Requests,41,41,1,0.6046511628,0.1887344648,0.8112655352,0.3888888889,0.07070707071,8.38E-06,7.44E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,The segfault is caused by matcher.,Potential New Issues and Requests,34,34,0.25,0.6162790698,0.1887379296,0.8112620704,0.2222222222,0.06060606061,7.44E-06,4.08E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"The number of matches I have is up to a million, python process eats about 4 GB of ram, and there's still enough for it to grow.",Potential New Issues and Requests,128,128,0.5,0.6279069767,0.1887379296,0.8112620704,1,0.2727272727,7.44E-06,4.08E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I could investigate this later, maybe in another issue.",Potential New Issues and Requests,55,55,0.75,0.6395348837,0.1887379296,0.8112620704,0.3333333333,0.09090909091,7.44E-06,4.08E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Trying to narrow the scope of ParserStateError right now.,Potential New Issues and Requests,57,57,1,0.6511627907,0.1887379296,0.8112620704,0.3333333333,0.09090909091,7.44E-06,4.08E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Hmm.,Social Conversation,4,4,0.5,0.6627906977,0.1887398302,0.8112601698,0.1111111111,0.0101010101,4.08E-06,4.26E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Is the match proliferation expected for your use-case?,Potential New Issues and Requests,54,54,1,0.6744186047,0.1887398302,0.8112601698,1,0.09090909091,4.08E-06,4.26E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,CODE -> CODE,Potential New Issues and Requests,1111,12,0.3333333333,0.6860465116,0.1887596939,0.8112403061,0.08333333333,0.0202020202,4.26E-05,1.86E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"It won't grow much after this, I'm just curious how much entities it can hold and how it will affect the memory and performance.",Potential New Issues and Requests,128,128,0.6666666667,0.6976744186,0.1887596939,0.8112403061,1,0.2424242424,4.26E-05,1.86E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Should I open another issue for that segfault? CODE,Potential New Issues and Requests,87,51,1,0.7093023256,0.1887596939,0.8112403061,0.375,0.09090909091,4.26E-05,1.86E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,I can easily make the matches list a numpy array if necessary.,Potential New Issues and Requests,62,62,0.3333333333,0.7209302326,0.1887683728,0.8112316272,0.75,0.1212121212,1.86E-05,0.0002408449665,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,A segfault via the Python API (as opposed to the Cython API) is always a bug.,Potential New Issues and Requests,77,77,0.6666666667,0.7325581395,0.1887683728,0.8112316272,1,0.1616161616,1.86E-05,0.0002408449665,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"So yes, please open an issue.",Potential New Issues and Requests,29,29,1,0.7441860465,0.1887683728,0.8112316272,0.375,0.06060606061,1.86E-05,0.0002408449665,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I'll do it tomorrow, once I know the steps to reproduce it.",Potential New Issues and Requests,59,59,0.5,0.7558139535,0.1888805584,0.8111194416,0.9230769231,0.1212121212,0.0002408449665,3.85E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,I guess now you have enough info for bug related to current issue.,Social Conversation,66,66,1,0.7674418605,0.1888805584,0.8111194416,1,0.1313131313,0.0002408449665,3.85E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Yes.,Social Conversation,4,4,0.5,0.7790697674,0.1888985047,0.8111014953,0.2,0.0101010101,3.85E-05,7.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Fix should be out soon.,Task Progress,23,23,1,0.7906976744,0.1888985047,0.8111014953,1,0.05050505051,3.85E-05,7.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,I think this should fix the segfault too â I think they were related.,Potential New Issues and Requests,69,69,0.3333333333,0.8023255814,0.1889319923,0.8110680077,1,0.1414141414,7.19E-05,0.20086138,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Closing for now.,Action on Issue,16,16,0.6666666667,0.8139534884,0.1889319923,0.8110680077,0.2142857143,0.0303030303,7.19E-05,0.20086138,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Again, if it reoccurs, don't hesitate to reopen :)",Action on Issue,50,50,1,0.8255813953,0.1889319923,0.8110680077,0.6428571429,0.09090909091,7.19E-05,0.20086138,MEMBER,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,UPDATE: I was able to get around this by converting multiple spaces to a single space.,Workarounds,86,86,0.5,0.8372093023,0.2824932792,0.7175067208,1,0.1616161616,0.20086138,0.06317627064,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,Not sure if this was an issue with my string or with spaCy's processing.,Investigation and Exploration,72,72,1,0.8488372093,0.2824932792,0.7175067208,0.875,0.1414141414,0.20086138,0.06317627064,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Hi, We are getting a parser state error.",Potential New Issues and Requests,40,40,0.3333333333,0.8604651163,0.3119208037,0.6880791963,0.08602150538,0.08080808081,0.06317627064,0.03932243631,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Here is the trace: Traceback (most recent call last):File ""tests/test_spacy_nlp.py"", line 231, in test_should_return_none_when_spacy_parsing_failsdoc = self.spacy_nlp.parse(query)File ""spacy_nlp.py"", line 49, in parsereturn SpacyDoc(self.__instance.parser(query))File ""lib/python3.5/site-packages/spacy/language.py"", line 328, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 146, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:6114)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:'splash On'",Potential New Issues and Requests,793,793,0.6666666667,0.8720930233,0.3119208037,0.6880791963,1,0.9393939394,0.06317627064,0.03932243631,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Here is our test:nlp = spacy.en.English()nlp.matcher.add('splash', 'my entity', {},[ [{LEMMA: 'splash'}, {LEMMA: 'on'}]])nlp('splash On')",Potential New Issues and Requests,137,137,1,0.8837209302,0.3119208037,0.6880791963,0.1505376344,0.1414141414,0.06317627064,0.03932243631,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I'm afraid I'm getting this, too, in version 1.5.0: CODE",Potential New Issues and Requests,731,56,0.3333333333,0.8953488372,0.3302372055,0.6697627945,0.5263157895,0.101010101,0.03932243631,0.2723202982,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"All was fine, until I added some matcher rules and an on_match callback: CODEwhere unit is 'BOPD', for example.",Potential New Issues and Requests,780,111,0.6666666667,0.9069767442,0.3302372055,0.6697627945,1,0.1919191919,0.03932243631,0.2723202982,NONE,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,The on_match callback is being called.,Potential New Issues and Requests,38,38,1,0.9186046512,0.3302372055,0.6697627945,0.3157894737,0.06060606061,0.03932243631,0.2723202982,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"Got this error in version 1.7.3: Traceback (most recent call last):File ""<stdin>"", line 1, in <module>File ""/home/ktyao/anaconda3/envs/python27/lib/python2.7/site-packages/spacy/language.py"", line 350, in __call__proc(doc)File ""spacy/syntax/parser.pyx"", line 207, in spacy.syntax.parser.Parser.__call__ (spacy/syntax/parser.cpp:7730)spacy.syntax.parser.ParserStateError: Error analysing doc -- no valid actions available. This should never happen, so please report the error on the issue tracker. Here's the thread to do so --- reopen it if it's closed:https://github.com/spacy-io/spaCy/issues/429Please include the text that the parser failed on, which is:u'Meet Linux.Mirai Trojan, a DDoS nightmare'",Potential New Issues and Requests,701,701,0.5,0.9302325581,0.4570840766,0.5429159234,1,1,0.2723202982,0.165555169,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I am using a customized tokenizer that merges the three tokens, 'Linux', '.' and 'Mirai', into one token.",Potential New Issues and Requests,105,105,1,0.9418604651,0.4570840766,0.5429159234,0.1717171717,0.1717171717,0.2723202982,0.165555169,NONE,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,"I'm also running in this issue on 1.8.2, nevertheless only after processing multiple documents in parallel:CODE",Potential New Issues and Requests,1797,111,0.3333333333,0.9534883721,0.5341997205,0.4658002795,0.85,0.1717171717,0.165555169,1,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,"Edit: I think it's just the parallelization, that's not done by CODE, but instead calling the parser from different threads.",Potential New Issues and Requests,129,124,0.6666666667,0.9651162791,0.5341997205,0.4658002795,1,0.202020202,0.165555169,1,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
5 429_spaCy.doc,So nevermind :),Social Conversation,15,15,1,0.976744186,0.5341997205,0.4658002795,0.15,0.0303030303,0.165555169,1,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
5 429_spaCy.doc,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue,107,107,1,0.988372093,1,0,18,0.1818181818,1,0,NONE,FALSE,FALSE,FALSE,TRUE
5 429_spaCy.doc,Please open a new issue for related bugs.,Action on Issue,41,41,2,1,1,0,8,0.08080808081,1,0,NONE,FALSE,FALSE,FALSE,TRUE
6 1585_scikit-learn.doc,Fitting additional estimators for ensemble methods,Expected Behaviour,50,50,0.1428571429,0.0036900369,0,1,0.1875,0.08955223881,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,I would like to propose an additional instance method to the ensemble estimators to fit additional sub-estimators.,Expected Behaviour,114,114,0.2857142857,0.007380073801,0,1,0.5625,0.2686567164,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,I kluged up an implementation for gradient boosting that appears to work through my limited testing.,Expected Behaviour,100,100,0.4285714286,0.0110701107,0,1,0.5,0.2388059701,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,I was thinking the signature would be something like CODE where CODE is updated as so.,Expected Behaviour,167,86,0.5714285714,0.0147601476,0,1,0.5,0.2388059701,0,0.02323680013,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
6 1585_scikit-learn.doc,I don't think fit_extend is a particularly great name so I'd welcome other suggestions.,Expected Behaviour,87,87,0.7142857143,0.0184501845,0,1,0.46875,0.223880597,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,Perhaps we would want to hash the features and labels when fit() is called so we can check that the same features and labels are provided to this function.,Solution Discussion,155,155,0.8571428571,0.0221402214,0,1,0.90625,0.4328358209,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,"If people think this would be a useful addition I would be willing to put together a PR, it seems like it should be straightforward to implement and add tests/docs for.",Contribution and Commitment,168,168,1,0.0258302583,0,1,1,0.4776119403,0,0.02323680013,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
6 1585_scikit-learn.doc,This is definitely a feature we want.,Social Conversation,37,37,0.1111111111,0.0295202952,0.02140516112,0.9785948389,0.4117647059,0.1044776119,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The question is: what would be the best way to implement it (in terms of API)?,Solution Discussion,78,78,0.2222222222,0.0332103321,0.02140516112,0.9785948389,0.9411764706,0.2388059701,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,There is something slightly similar in the adaboost pr: #522.,Motivation,61,61,0.3333333333,0.036900369,0.02140516112,0.9785948389,0.5882352941,0.1492537313,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"That implements predicting with a subset of the estimators, which is also very helpful.",Motivation,87,87,0.4444444444,0.0405904059,0.02140516112,0.9785948389,0.8235294118,0.2089552239,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"What do you think does the scenario / code look like, where a user wants CODE?",Motivation,86,78,0.5555555556,0.0442804428,0.02140516112,0.9785948389,0.8823529412,0.223880597,0.02323680013,2.21E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"It is probably most useful in an interactive setting, righ?",Motivation,59,59,0.6666666667,0.0479704797,0.02140516112,0.9785948389,0.5882352941,0.1492537313,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"There is  a slightly related function in SGD, CODE.",Solution Discussion,60,51,0.7777777778,0.05166051661,0.02140516112,0.9785948389,0.5882352941,0.1492537313,0.02323680013,2.21E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"That is actually for online learning, though, so it gets different data.",Solution Discussion,72,72,0.8888888889,0.05535055351,0.02140516112,0.9785948389,0.7058823529,0.1791044776,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I'd like to get this feature with adding as little API an names as possible ;),Solution Discussion,78,78,1,0.05904059041,0.02140516112,0.9785948389,1,0.2537313433,0.02323680013,2.21E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Btw, I wouldn't hash CODE and CODE .",Solution Discussion,34,36,0.5,0.06273062731,0.0214071977,0.9785928023,0.4666666667,0.1044776119,2.21E-06,0.003908717607,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't see a reason to force the user to provide the same input data.,Solution Discussion,70,70,1,0.06642066421,0.0214071977,0.9785928023,1,0.223880597,2.21E-06,0.003908717607,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I would like to train a small number of sub-estimators at a time (and wait a relatively short time).,Motivation,100,100,0.09090909091,0.07011070111,0.02500781094,0.9749921891,0.625,0.2985074627,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Then test it on my cross-validation set and if my cv score is still falling, I can continue training.",Motivation,101,101,0.1818181818,0.07380073801,0.02500781094,0.9749921891,0.625,0.2985074627,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,As opposed to training a large number of sub-estimators and waiting a long time (several hours for me).,Motivation,103,103,0.2727272727,0.07749077491,0.02500781094,0.9749921891,0.59375,0.2835820896,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,That was my motivation.,Social Conversation,23,23,0.3636363636,0.08118081181,0.02500781094,0.9749921891,0.125,0.05970149254,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I can understand being hesitant about adding another instance method.,Solution Discussion,69,69,0.4545454545,0.08487084871,0.02500781094,0.9749921891,0.3125,0.1492537313,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I thought it might be worthwhile to add another optional parameter to fit() but I saw this quote on the contributing page. > fit parameters should be restricted to directly data dependent variables,Solution Discussion,197,197,0.5454545455,0.08856088561,0.02500781094,0.9749921891,1,0.4776119403,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So I wasn't sure that would be a good idea.,Social Conversation,43,43,0.6363636364,0.09225092251,0.02500781094,0.9749921891,0.3125,0.1492537313,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Would CODE be acceptable?,Solution Discussion,85,25,0.7272727273,0.09594095941,0.02500781094,0.9749921891,0.125,0.05970149254,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Then if CODE, we'll then train that many more estimators.",Solution Discussion,87,57,0.8181818182,0.09963099631,0.02500781094,0.9749921891,0.3125,0.1492537313,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"I agree that adding in n_estimators parameter to the prediction method is nice, but I think you'll agree that it solves a different problem.",Solution Discussion,140,140,0.9090909091,0.1033210332,0.02500781094,0.9749921891,0.75,0.3582089552,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,For my problem performing grid search over n_estimators isn't really an option because it takes so long.,Solution Discussion,104,104,1,0.1070110701,0.02500781094,0.9749921891,0.53125,0.2537313433,0.003908717607,0.000199397869,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Until we agree on a proper interface to do that, you could use the following hack: CODE",Workarounds,403,87,1,0.110701107,0.02519149129,0.9748085087,1,0.2537313433,0.000199397869,2.53E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Note that this only work for RandomForest and ExtraTrees.,Workarounds,57,57,0.5,0.1143911439,0.02519381881,0.9748061812,0.9,0.1343283582,2.53E-06,0.004244661957,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The same trick cannot be used with Gradient Boosting.,Workarounds,53,53,1,0.1180811808,0.02519381881,0.9748061812,1,0.1492537313,2.53E-06,0.004244661957,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,See #1626.,Solution Discussion,10,10,0.5,0.1217712177,0.02910389561,0.9708961044,0.2222222222,0.02985074627,0.004244661957,0.00784593065,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Would early stopping be an acceptable solution to you?,Solution Discussion,54,54,1,0.1254612546,0.02910389561,0.9708961044,1,0.1343283582,0.004244661957,0.00784593065,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,@amueller I share the same opinion as @glouppe here https://github.com/scikit-learn/scikit-learn/issues/1626#issuecomment-12785168.,Social Conversation,131,131,0.5,0.1291512915,0.03633137137,0.9636686286,0.8333333333,0.1492537313,0.00784593065,0.0001465830515,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I like early stopping but it doesn't resolve this in my opinion.,Solution Discussion,64,64,1,0.1328413284,0.03633137137,0.9636686286,1,0.1791044776,0.00784593065,0.0001465830515,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Ok.,Social Conversation,3,3,0.5,0.1365313653,0.03646640003,0.9635336,0.0625,0.01492537313,0.0001465830515,0.0001586199169,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Then we should look for a solution that allows for early stopping and adding additional estimators.,Solution Discussion,99,99,1,0.1402214022,0.03646640003,0.9635336,1,0.2388059701,0.0001465830515,0.0001586199169,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Thinking about it a bit more, I think the CODE method would be the right interface.",Solution Discussion,92,83,0.2,0.1439114391,0.03661251674,0.9633874833,0.8421052632,0.2388059701,0.0001586199169,0.0007677976021,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,In SGD you can call CODE either with the same data or new data and it keeps on learning.,Solution Discussion,97,88,0.4,0.147601476,0.03661251674,0.9633874833,1,0.2835820896,0.0001586199169,0.0007677976021,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"The difference is that in SGD, if you manually iterate over batches, you get the original algorithm out.",Solution Discussion,104,104,0.6,0.1512915129,0.03661251674,0.9633874833,0.9473684211,0.2686567164,0.0001586199169,0.0007677976021,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"For ensembles, that would not be true.",Solution Discussion,38,38,0.8,0.1549815498,0.03661251674,0.9633874833,0.3684210526,0.1044776119,0.0001586199169,0.0007677976021,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,You would need to use the whole data on each call to CODE.,Solution Discussion,67,58,1,0.1586715867,0.03661251674,0.9633874833,0.6842105263,0.1940298507,0.0001586199169,0.0007677976021,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I like this suggestion.,Social Conversation,23,23,0.5,0.1623616236,0.03731979275,0.9626802072,0.8,0.05970149254,0.0007677976021,0.001972326369,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,What do other people think?,Social Conversation,27,27,1,0.1660516605,0.03731979275,0.9626802072,1,0.07462686567,0.0007677976021,0.001972326369,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Just to clarify, what would exactly happen in CODE in case of ensembles?",Solution Discussion,81,72,0.3333333333,0.1697416974,0.03913665065,0.9608633494,0.9285714286,0.1940298507,0.001972326369,0.0001423719033,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Would that add CODE more estimators, whereCODE is the parameter value from the constructor?",Solution Discussion,111,91,0.6666666667,0.1734317343,0.03913665065,0.9608633494,1,0.2089552239,0.001972326369,0.0001423719033,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,(or could we change that value?),Solution Discussion,32,32,1,0.1771217712,0.03913665065,0.9608633494,0.4285714286,0.08955223881,0.001972326369,0.0001423719033,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Good question.,Social Conversation,14,14,0.25,0.1808118081,0.03926780009,0.9607321999,0.1666666667,0.02985074627,0.0001423719033,0.0001259133323,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I also thought about that ;),Social Conversation,28,28,0.5,0.184501845,0.03926780009,0.9607321999,0.5,0.08955223881,0.0001423719033,0.0001259133323,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"actually, you would want to change that, right?",Solution Discussion,47,47,0.75,0.1881918819,0.03926780009,0.9607321999,0.6666666667,0.1194029851,0.0001423719033,0.0001259133323,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,you could change that afterwards by CODE but that feels awkward :-/,Solution Discussion,75,67,1,0.1918819188,0.03926780009,0.9607321999,1,0.1791044776,0.0001423719033,0.0001259133323,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,sorry for joining the discussion so late.,Social Conversation,41,41,0.1428571429,0.1955719557,0.03938378832,0.9606162117,0.1272727273,0.1044776119,0.0001259133323,6.16E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I agree that we need such a functionality, however, I'm not sure if CODE is the best solution to the problem that @jwkvam describes.",Solution Discussion,141,132,0.2857142857,0.1992619926,0.03938378832,0.9606162117,0.4363636364,0.3582089552,0.0001259133323,6.16E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,In order to do early stopping the user has to write some some code that basically repeatedly calls CODE and then checks the CV error.,Solution Discussion,142,133,0.4285714286,0.2029520295,0.03938378832,0.9606162117,0.4545454545,0.3731343284,0.0001259133323,6.16E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I'd rather propose the CODE fit parameter that we discussed in the past: CODE where CODE will be called after each iteration and is passed the complete state of the estimator.,Solution Discussion,225,175,0.5714285714,0.2066420664,0.03938378832,0.9606162117,0.5818181818,0.4776119403,0.0001259133323,6.16E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,The callable could also return a value whether or not the training should proceed.,Solution Discussion,82,82,0.7142857143,0.2103321033,0.03938378832,0.9606162117,0.2545454545,0.2089552239,0.0001259133323,6.16E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Using such an api one could implement not only early stopping but also custom reporting (e.g. interactive plotting the training vs. testing score) and snapshoting (all X iterations dump the estimator object and copy it to some location; this is great if you are running on EC2 spot instances or some other unreliable hardware ;-),Solution Discussion,329,329,0.8571428571,0.2140221402,0.03938378832,0.9606162117,1,0.8208955224,0.0001259133323,6.16E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Personally, I'd prefer CODE (or CODE) over CODE - warm start is quite implicit - you have to:: CODECODECODE`# if you forget warm_start=True you nuke your previous estimators - quite implicitest.fit(X, y, n_estimators=2000, warm_start=True) # alternatively - more explicitest.fit_more(X, y, n_estimators=1000)CODE",Solution Discussion,435,312,1,0.2177121771,0.03938378832,0.9606162117,0.7090909091,0.5820895522,0.0001259133323,6.16E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"To me, fit_more corresponds really to the partial_fit that we have inother estimators.",Solution Discussion,86,86,1,0.221402214,0.03944048936,0.9605595106,1,0.1940298507,6.16E-05,1.57E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,@pprett I think there should be an easy way to do easy things.,Motivation,62,62,0.25,0.2250922509,0.03945490707,0.9605450929,0.619047619,0.1940298507,1.57E-05,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"a monitor api is very flexible but actually you want to do early stopping **every time** you use an estimator, right?",Motivation,117,117,0.5,0.2287822878,0.03945490707,0.9605450929,1,0.3134328358,1.57E-05,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So there should be no need to write a callback to do that.,Solution Discussion,58,58,0.75,0.2324723247,0.03945490707,0.9605450929,0.619047619,0.1940298507,1.57E-05,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Also, it must be compatible with GridSearchCV.",Solution Discussion,46,46,1,0.2361623616,0.03945490707,0.9605450929,0.3333333333,0.1044776119,1.57E-05,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't think so.,Social Conversation,17,17,0.1428571429,0.2398523985,0.0394658335,0.9605341665,0.09756097561,0.05970149254,1.19E-05,6.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In CODE, ""partial"" stands for partial access to the data: you expect that the data does not fit in memory at once so you fit with one chunk at a time and update the model incrementally while scanning through the data.",Solution Discussion,226,217,0.2857142857,0.2435424354,0.0394658335,0.9605341665,1,0.6119402985,1.19E-05,6.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,In this case we want to change the number of sub estimators but might want to reuse exactly the same data at each call.,Solution Discussion,119,119,0.4285714286,0.2472324723,0.0394658335,0.9605341665,0.5853658537,0.3582089552,1.19E-05,6.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,For a similar reason ElasticNet has a CODE constructor param instead of a CODE method and SGDClassifier both has a CODE param and a CODE method: they serve different purposes.,Solution Discussion,209,175,0.5714285714,0.2509225092,0.0394658335,0.9605341665,0.7317073171,0.447761194,1.19E-05,6.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"I agree that the monitor API would be very useful in general (for dealing with snapshoting, early stopping and such) but would not solve the issue of growing the number of sub-estimators in an interactive manner.",Solution Discussion,212,212,0.7142857143,0.2546125461,0.0394658335,0.9605341665,0.9024390244,0.552238806,1.19E-05,6.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,We could also have: CODE,Solution Discussion,83,24,0.8571428571,0.258302583,0.0394658335,0.9605341665,0.1219512195,0.07462686567,1.19E-05,6.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Or even to grow by 110% (10% more estimators): CODE,Solution Discussion,110,51,1,0.2619926199,0.0394658335,0.9605341665,0.2682926829,0.1641791045,1.19E-05,6.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,hum I didn't look to much into the warm start api that we have currently.,Social Conversation,73,73,0.25,0.2656826568,0.03947204023,0.9605279598,1,0.223880597,6.74E-06,6.39E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"There is no central documentation for that, right?",Potential New Issues and Requests,50,50,0.5,0.2693726937,0.03947204023,0.9605279598,0.5333333333,0.1194029851,6.74E-06,6.39E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,We should really think about the organization of the docs.,Potential New Issues and Requests,58,58,0.75,0.2730627306,0.03947204023,0.9605279598,0.6666666667,0.1492537313,6.74E-06,6.39E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,We got quite some comments on that in the survey :-/,Social Conversation,52,52,1,0.2767527675,0.03947204023,0.9605279598,0.7333333333,0.1641791045,6.74E-06,6.39E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,@ogrisel I'd have to have a look at the SGD implementation to see the details but what is the difference in what actually happens between warm-starts and partial_fit?,Solution Discussion,166,166,0.2,0.2804428044,0.03947792369,0.9605220763,1,0.447761194,6.39E-06,3.58E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I think we agree on the point of same /changing data.,Solution Discussion,53,53,0.4,0.2841328413,0.03947792369,0.9605220763,0.3666666667,0.1641791045,6.39E-06,3.58E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Does CODE do several epochs and CODE does not?,Solution Discussion,63,46,0.6,0.2878228782,0.03947792369,0.9605220763,0.3,0.1343283582,6.39E-06,3.58E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"That would make sense to me, and then we should probably keep them separate.",Solution Discussion,76,76,0.8,0.2915129151,0.03947792369,0.9605220763,0.4666666667,0.2089552239,6.39E-06,3.58E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If we already have the warm-start api, we should definitely ""just"" implement that for the ensemble estimators.",Solution Discussion,110,110,1,0.295202952,0.03947792369,0.9605220763,0.6,0.2686567164,6.39E-06,3.58E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,CODE just prevents fit to forget about the previous state (assuming that the inner state of the model will likely make it converge faster to the solution of the new call with the new hyperparameter).,Solution Discussion,207,199,1,0.2988929889,0.03951089693,0.9604891031,1,0.5223880597,3.58E-05,4.95E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I think the main difference is the _semantics_: the main idea behindCODE is to converge more quickly - but no matter what valueCODE has you get the same solution!,Solution Discussion,178,162,0.2,0.3025830258,0.03951545499,0.960484545,1,0.4179104478,4.95E-06,1.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Partial fit on the other hand, changes the underlying model.",Solution Discussion,60,60,0.4,0.3062730627,0.03951545499,0.960484545,0.3571428571,0.1492537313,4.95E-06,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Consider thefollowing example: CODE can reuse the fitted weights from clf it might converge more quickly# under the hood,Solution Discussion,403,120,0.6,0.3099630996,0.03951545499,0.960484545,0.6785714286,0.2835820896,4.95E-06,1.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"CODE resets the ""training"" state modethe estimator (adaptive learning rate for sgd) CODE",Solution Discussion,329,88,0.8,0.3136531365,0.03951545499,0.960484545,0.4642857143,0.1940298507,4.95E-06,1.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Disclaimer: This example might be pedantic because the differences in termsof the learned weights is minimal - but conceptually they are IMHO totallydifferent things...,Social Conversation,168,168,1,0.3173431734,0.03951545499,0.960484545,0.8214285714,0.3432835821,4.95E-06,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The CODE API was initially introduced to allow faster computation of a series of identical linear models when using a path of regularizers CODE.,Solution Discussion,155,144,0.5,0.3210332103,0.03952644607,0.9604735539,0.4363636364,0.3582089552,1.19E-05,2.07E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,This is somewhat similar to iteratively growing the number of sub-estimators in a boosted ensemble model so we could decide to reuse CODE to adress that use case as well but if this API reveals cumbersome for boosted models it might be better to rethink it now that we have an additional use case.,Solution Discussion,305,297,1,0.3247232472,0.03952644607,0.9604735539,1,0.8208955224,1.19E-05,2.07E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I agree with @pprett's analysis.,Social Conversation,32,32,1,0.3284132841,0.03952835335,0.9604716466,1,0.07462686567,2.07E-06,3.23E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't know what to make of @pprett  analysis.,Social Conversation,47,47,0.1111111111,0.332103321,0.03955809392,0.9604419061,0.3846153846,0.1492537313,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In the case of linear models, the estimator will converge to the same result, even when the warm start gets different data than the original fit.",Solution Discussion,145,145,0.2222222222,0.3357933579,0.03955809392,0.9604419061,1,0.3880597015,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If we ""warm started"" ensembles / trees, that would not be the case.",Solution Discussion,67,67,0.3333333333,0.3394833948,0.03955809392,0.9604419061,0.4615384615,0.1791044776,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,We could try to assure that the data provided when warm starting is the same as the original.,Solution Discussion,93,93,0.4444444444,0.3431734317,0.03955809392,0.9604419061,0.6923076923,0.2686567164,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"At the moment, ""warm start"" refers to an optimization procedure, which there is none in tree based methods.",Solution Discussion,107,107,0.5555555556,0.3468634686,0.03955809392,0.9604419061,0.6923076923,0.2686567164,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,While CODE retains all of the state of the estimator and just keeps on fitting.,Solution Discussion,88,79,0.6666666667,0.3505535055,0.03955809392,0.9604419061,0.5769230769,0.223880597,3.23E-05,5.93E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"On the other hand, subsequent calls to partial fit on batches lead to the same model as training on the whole data.",Solution Discussion,115,115,0.7777777778,0.3542435424,0.03955809392,0.9604419061,0.8461538462,0.328358209,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Again, this is different from the tree/ensemble case.",Solution Discussion,53,53,0.8888888889,0.3579335793,0.03955809392,0.9604419061,0.3461538462,0.1343283582,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I feel this goes back to my argument that this is more of a path algorithms than anything else ;),Social Conversation,97,97,1,0.3616236162,0.03955809392,0.9604419061,0.7692307692,0.2985074627,3.23E-05,5.93E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"So I see two possible solutions: make sure warm-start is always called with the same data, then adding estimators would be warm starting.",Solution Discussion,137,137,0.3333333333,0.3653136531,0.03956355713,0.9604364429,1,0.3582089552,5.93E-06,6.34E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If not, we need a third way to refit a given model.",Solution Discussion,51,51,0.6666666667,0.36900369,0.03956355713,0.9604364429,0.5,0.1791044776,5.93E-06,6.34E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Where are the docs for that currently, btw ;)",Solution Discussion,45,45,1,0.3726937269,0.03956355713,0.9604364429,0.375,0.1343283582,5.93E-06,6.34E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Why so?,Social Conversation,7,7,0.5,0.3763837638,0.03962200382,0.9603779962,0.1333333333,0.02985074627,6.34E-05,7.05E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Let the user decide how and what for he / she want to use CODE for.,Solution Discussion,75,67,1,0.3800738007,0.03962200382,0.9603779962,1,0.223880597,6.34E-05,7.05E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,http://scikit-learn.org/dev/modules/generated/sklearn.linear_model.ElasticNet.html,Solution Discussion,82,82,0.3333333333,0.3837638376,0.03962850149,0.9603714985,0.03125,0.01492537313,7.05E-06,8.08E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,CODE,Solution Discussion,161,4,0.6666666667,0.3874538745,0.03962850149,0.9603714985,0.03125,0.01492537313,7.05E-06,8.08E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"I agree that giving motivation would be helpful, for instance in this case: ""This is useful to efficiently compute a regularization path of ElasticNet models as done by the :func:CODE function"".",Solution Discussion,201,194,1,0.3911439114,0.03962850149,0.9603714985,1,0.4776119403,7.05E-06,8.08E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I thought the argument was about semantics.,Solution Discussion,43,43,0.2,0.3948339483,0.03970291757,0.9602970824,0.28,0.1044776119,8.08E-05,0.0001056296349,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I think a semantic is defined by giving the user some guarantee of what will happen.,Solution Discussion,84,84,0.4,0.3985239852,0.03970291757,0.9602970824,0.64,0.2388059701,8.08E-05,0.0001056296349,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,That way the user doesn't need to know all the details of the algorithm.,Solution Discussion,72,72,0.6,0.4022140221,0.03970291757,0.9602970824,0.56,0.2089552239,8.08E-05,0.0001056296349,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I thought the guarantee of CODE was ""warm_start doesn't change the result"", while the guarantee of CODE was ""iterating over batches doesn't change the result"".",Solution Discussion,176,159,0.8,0.405904059,0.03970291757,0.9602970824,1,0.3731343284,8.08E-05,0.0001056296349,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"If there is no guarantee, then I don't see how there can be common semantics.",Solution Discussion,77,77,1,0.4095940959,0.03970291757,0.9602970824,0.6,0.223880597,8.08E-05,0.0001056296349,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,We provide guarantee to the user that if he provides the same data again with warm_start=true he will get the same results (just faster).,Solution Discussion,137,137,0.5,0.4132841328,0.03980022095,0.960199779,0.3731343284,0.3731343284,0.0001056296349,3.44E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,But we should not prevent the user to use different data if he makes an informed guess that warm starting on the new data will help him solve his problem (e.g. solving on the new data faster if he makes the assumption that the new data is distributed reasonably similarly to the first data and hence starting the optimizer from the previous position should speeds things up).,Solution Discussion,375,375,1,0.4169741697,0.03980022095,0.960199779,1,1,0.0001056296349,3.44E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,For linear estimators that is ok.,Solution Discussion,33,33,0.5,0.4206642066,0.03980338897,0.960196611,0.3,0.08955223881,3.44E-06,2.38E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"But if you want to use CODE on ensembles, it will have a very different semantic all of a sudden.",Solution Discussion,105,97,1,0.4243542435,0.03980338897,0.960196611,1,0.2985074627,3.44E-06,2.38E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Indeed growing a boosted ensemble on changing data is weird and probably useless (unless if it's a way to inject some randomization for some meta-meta-ensemble estimator that does bagging on boosted models maybe?).,Solution Discussion,214,214,0.3333333333,0.4280442804,0.0398253388,0.9601746612,1,0.5223880597,2.38E-05,3.79E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't think we should try to enforce that the data does not change across calls though.,Solution Discussion,89,89,0.6666666667,0.4317343173,0.0398253388,0.9601746612,0.4857142857,0.2537313433,2.38E-05,3.79E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Let's just document the expected usage scenario for that option in the docstring instead.,Solution Discussion,89,89,1,0.4354243542,0.0398253388,0.9601746612,0.4,0.2089552239,2.38E-05,3.79E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,ok.,Social Conversation,3,3,0.25,0.4391143911,0.03982883009,0.9601711699,0.05,0.01492537313,3.79E-06,1.86E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"So basically the docstring should say ""use warm_start with the same data unless you know exactly what you are doing"".",Solution Discussion,117,117,0.5,0.442804428,0.03982883009,0.9601711699,1,0.2985074627,3.79E-06,1.86E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Fine with me.,Social Conversation,13,13,0.75,0.4464944649,0.03982883009,0.9601711699,0.15,0.0447761194,3.79E-06,1.86E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Anyone opposed to using CODE?,Solution Discussion,37,29,1,0.4501845018,0.03982883009,0.9601711699,0.25,0.07462686567,3.79E-06,1.86E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"I still have to have a look at how that is handled in SGD and ENet, though...",Social Conversation,77,77,1,0.4538745387,0.0398305434,0.9601694566,1,0.2537313433,1.86E-06,1.16E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"No, not useless: it's one specific sub-sampling strategy.",Solution Discussion,57,57,0.5,0.4575645756,0.03983161019,0.9601683898,0.6,0.1343283582,1.16E-06,0.002891760401,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The practicaldifference with an online method is that you want the batch to be big.,Solution Discussion,83,83,1,0.4612546125,0.03983161019,0.9601683898,1,0.223880597,1.16E-06,0.002891760401,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So CODE in SGDClassifier can not be used for model selection.,Solution Discussion,69,61,0.2,0.4649446494,0.04249542779,0.9575045722,0.7333333333,0.1641791045,0.002891760401,1.06E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"On the other hand, CODE could be used to find the bestCODE.",Solution Discussion,74,59,0.4,0.4686346863,0.04249542779,0.9575045722,0.8,0.1791044776,0.002891760401,1.06E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"The more I think about it, the more confusing it gets for me :-/",Social Conversation,64,64,0.6,0.4723247232,0.04249542779,0.9575045722,0.9333333333,0.2089552239,0.002891760401,1.06E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Btw, is there any reason that CODE is an init parameterand CODE is a function?",Solution Discussion,95,78,0.8,0.4760147601,0.04249542779,0.9575045722,1,0.223880597,0.002891760401,1.06E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Wouldn't it be easier if CODE also was an init parameter?,Solution Discussion,66,57,1,0.479704797,0.04249542779,0.9575045722,0.7333333333,0.1641791045,0.002891760401,1.06E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Because CODE is a specific strategy that might differ from thestrategy used in CODE.,Solution Discussion,94,84,0.25,0.4833948339,0.04250515813,0.9574948419,0.875,0.2089552239,1.06E-05,4.81E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I think it would be confusing.,Social Conversation,30,30,0.5,0.4870848708,0.04250515813,0.9574948419,0.375,0.08955223881,1.06E-05,4.81E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The goal of CODE is to be abuilding block usable in an out-of-core framework.,Solution Discussion,86,77,0.75,0.4907749077,0.04250515813,0.9574948419,1,0.2388059701,1.06E-05,4.81E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Using CODE for thispurpose could lead to fairly catastrophic results.,Solution Discussion,70,69,1,0.4944649446,0.04250515813,0.9574948419,0.625,0.1492537313,1.06E-05,4.81E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't understand your argument.,Social Conversation,33,33,0.5,0.4981549815,0.04250958689,0.9574904131,0.5555555556,0.07462686567,4.81E-06,3.75E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"What CODE does is basically ""forget model, call CODE"".",Solution Discussion,64,54,1,0.5018450185,0.04250958689,0.9574904131,1,0.1343283582,4.81E-06,3.75E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Hm maybe what you mean is that CODE might need to do less work than CODE because CODE needs to store the ""sufficient statistics"" of the previous data and fit doesn't need to do that?",Solution Discussion,201,182,1,0.5055350554,0.04251304585,0.9574869542,1,0.5223880597,3.75E-06,1.68E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,It can do more.,Social Conversation,15,15,0.3333333333,0.5092250923,0.04251459753,0.9574854025,0.3076923077,0.05970149254,1.68E-06,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Typically it shuffles the data before calling partialfit.,Solution Discussion,57,57,0.6666666667,0.5129151292,0.04251459753,0.9574854025,0.6153846154,0.1194029851,1.68E-06,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,It may also divide it into mini batches of a user-selectable size.,Solution Discussion,66,66,1,0.5166051661,0.04251459753,0.9574854025,1,0.1940298507,1.68E-06,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,It might be the case.,Social Conversation,21,21,0.5,0.520295203,0.04251640782,0.9574835922,0.2173913043,0.07462686567,1.97E-06,3.38E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,It might be also that fit needs to do additionalwork to turn a large batch dataset into a set of mini-batch ones.,Solution Discussion,113,113,1,0.5239852399,0.04251640782,0.9574835922,1,0.3432835821,1.97E-06,3.38E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,hm ok maybe this is not so important right now.,Social Conversation,47,47,0.25,0.5276752768,0.04254757077,0.9574524292,0.3333333333,0.1492537313,3.38E-05,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I'd like to minimize the number of mechanisms we have in sklearn, and we definitely need one (more?) for efficient model selection.",Potential New Issues and Requests,131,131,0.5,0.5313653137,0.04254757077,0.9574524292,0.7666666667,0.3432835821,3.38E-05,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In the coordinate decent algorithms, the CODE option was introduced exactly for this purpose.",Potential New Issues and Requests,101,93,0.75,0.5350553506,0.04254757077,0.9574524292,0.4666666667,0.2089552239,3.38E-05,1.97E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I am not sure it is general enough to really do that (what if there is more than one parameter?) and it doesn't fulfil this requirement any more in SGDClassifier.,Potential New Issues and Requests,162,162,1,0.5387453875,0.04254757077,0.9574524292,1,0.447761194,3.38E-05,1.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,(just removed a lot of the previous comment as I was repeating myself).,Social Conversation,71,71,1,0.5424354244,0.04254938106,0.9574506189,1,0.1940298507,1.97E-06,8.62E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't understand this last remark.,Social Conversation,36,36,0.3333333333,0.5461254613,0.04262877546,0.9573712245,0.2857142857,0.08955223881,8.62E-05,4.57E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,warm_start is perfectly valid for SGDClassifier (in addition to CODE): right now SGDClassifier does not have convergence check / early stopping.,Solution Discussion,153,144,0.6666666667,0.5498154982,0.04262877546,0.9573712245,1,0.3134328358,8.62E-05,4.57E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"But as soon as it has, warm_starting will make it possible to compute the regularization path faster, exactly as for ElasticNet.",Solution Discussion,128,128,1,0.5535055351,0.04262877546,0.9573712245,1,0.3134328358,8.62E-05,4.57E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"SGDClassifier does CODE epochs of updates, then stops.",Solution Discussion,58,54,0.1666666667,0.557195572,0.04267086483,0.9573291352,0.380952381,0.1194029851,4.57E-05,8.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Where it ends up after CODE steps depends heavily on where you started.,Solution Discussion,75,71,0.3333333333,0.5608856089,0.04267086483,0.9573291352,0.619047619,0.1940298507,4.57E-05,8.74E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Even if you do ""early stopping"", this would be early stopping on the validation set, not early stopping of the optimization.",Solution Discussion,124,124,0.5,0.5645756458,0.04267086483,0.9573291352,1,0.3134328358,4.57E-05,8.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,SGDClassfier does not have the goal to fully optimize the objective to the end.,Solution Discussion,79,79,0.6666666667,0.5682656827,0.04267086483,0.9573291352,0.6666666667,0.2089552239,4.57E-05,8.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So where you will end up will depend on the initialization.,Solution Discussion,59,59,0.8333333333,0.5719557196,0.04267086483,0.9573291352,0.5238095238,0.1641791045,4.57E-05,8.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In particular, for early stopping (on a validation set!) it could be better to do less iterations, leading to lower bias.",Solution Discussion,121,121,1,0.5756457565,0.04267086483,0.9573291352,1,0.3134328358,4.57E-05,8.74E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In particular, I don't think a ""regularization path for alpha"" makes sense in the SGD setting.",Solution Discussion,94,94,0.3333333333,0.5793357934,0.04267891418,0.9573210858,0.5517241379,0.2388059701,8.74E-06,0.0006227235454,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"The ""path"" is a sequence of optima.",Solution Discussion,35,35,0.6666666667,0.5830258303,0.04267891418,0.9573210858,0.2413793103,0.1044776119,8.74E-06,0.0006227235454,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"SGD will never find the optimum, so the places you'll end up will probably depend as much on the scaling of the learning rate as on the actual regularization.",Solution Discussion,158,158,1,0.5867158672,0.04267891418,0.9573210858,1,0.4328358209,8.74E-06,0.0006227235454,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"For linear models, the problem is convex.",Solution Discussion,41,41,0.3333333333,0.5904059041,0.04325255159,0.9567474484,0.2916666667,0.1044776119,0.0006227235454,0.0001494957624,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If n_iter is big enough, SGD with a good learning schedule will converge to the optimum (if you don't stop before convergence).",Solution Discussion,127,127,0.6666666667,0.594095941,0.04325255159,0.9567474484,0.9166666667,0.328358209,0.0006227235454,0.0001494957624,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The convergence speed when getting closer to the optimum is just not as good as coordinate descent  but this is a different issue.,Solution Discussion,130,130,1,0.5977859779,0.04325255159,0.9567474484,1,0.3582089552,0.0006227235454,0.0001494957624,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,so we agree: the models will be different unless n_iter is big enough and the schedule is just right - which are unlikely in practice.,Solution Discussion,134,134,0.5,0.6014760148,0.04339026336,0.9566097366,1,0.3582089552,0.0001494957624,0.002306761725,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,also a guarantee of the form âresults will be the same if the other settings are appropriately tunedâ doesn't really sound like a guarantee.,Solution Discussion,140,140,1,0.6051660517,0.04339026336,0.9566097366,1,0.3582089552,0.0001494957624,0.002306761725,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So what about CODE,Solution Discussion,161,18,0.5,0.6088560886,0.04551519476,0.9544848052,0.6666666667,0.05970149254,0.002306761725,3.86E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Is that an acceptable usage pattern?,Solution Discussion,36,36,1,0.6125461255,0.04551519476,0.9544848052,1,0.08955223881,0.002306761725,3.86E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Or do you want these as parameters to CODE?,Solution Discussion,44,43,0.5,0.6162361624,0.0455187507,0.9544812493,0.8181818182,0.1343283582,3.86E-06,0.02110248492,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"In SGD, CODE is an CODE parameter according to the docs.",Solution Discussion,70,56,1,0.6199261993,0.0455187507,0.9544812493,1,0.1641791045,3.86E-06,0.02110248492,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Let's revive the discussion.,Social Conversation,28,28,0.2,0.6236162362,0.06495783385,0.9350421661,0.2352941176,0.05970149254,0.02110248492,0.0001673580495,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,in #1044 @GaelVaroquaux said he still prefers CODE.,Solution Discussion,60,51,0.4,0.6273062731,0.06495783385,0.9350421661,0.4705882353,0.1194029851,0.02110248492,0.0001673580495,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Currently, I think CODE is more in the right direction, but I don't have a strong opinion.",Solution Discussion,98,90,0.6,0.63099631,0.06495783385,0.9350421661,1,0.2537313433,0.02110248492,0.0001673580495,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,@ogrisel @pprett @glouppe @larsmans what is your opinion on the usage pattern I posted above?,Contribution and Commitment,93,93,0.8,0.6346863469,0.06495783385,0.9350421661,0.8823529412,0.223880597,0.02110248492,0.0001673580495,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Or would you like to have another interface using CODE or CODE?,Solution Discussion,80,63,1,0.6383763838,0.06495783385,0.9350421661,0.7058823529,0.1791044776,0.02110248492,0.0001673580495,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,What I dislike about using the 'warm_start' is that currently thecontract with scikit-learn estimators is that you can call 'fit' and geta valid/useful answer regardless of the history of the object.,Solution Discussion,199,199,0.25,0.6420664207,0.06511199992,0.9348880001,1,0.4925373134,0.0001673580495,3.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"It may gofaster or slower, but it's somewhat fool proof.",Solution Discussion,56,56,0.5,0.6457564576,0.06511199992,0.9348880001,0.303030303,0.1492537313,0.0001673580495,3.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If you pass differentdata to an ensemble estimator, and use the 'warm_start' to fit moreestimators, you will get nonsens.",Solution Discussion,121,121,0.75,0.6494464945,0.06511199992,0.9348880001,0.5757575758,0.2835820896,0.0001673580495,3.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I am worried about having to write'defensive' code to avoid such problems.,Solution Discussion,74,74,1,0.6531365314,0.06511199992,0.9348880001,0.3636363636,0.1791044776,0.0001673580495,3.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,how would CODE work in our setting - is this correct:: CODE,Solution Discussion,198,59,0.3333333333,0.6568265683,0.06514439128,0.9348556087,0.4583333333,0.1641791045,3.52E-05,0.000347946123,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,so it would take arbitrary CODE or just CODE?,Solution Discussion,63,45,0.6666666667,0.6605166052,0.06514439128,0.9348556087,0.375,0.1343283582,3.52E-05,0.000347946123,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Personally, I'm in favor of a CODE since the use-case that our current CODE serves is quite different and CODE is more explicit.",Solution Discussion,149,128,1,0.6642066421,0.06514439128,0.9348556087,1,0.3582089552,3.52E-05,0.000347946123,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I am also not very happy with the name CODE in case of ensembles.,Solution Discussion,74,65,0.09090909091,0.667896679,0.06546491057,0.9345350894,0.5384615385,0.2089552239,0.000347946123,5.39E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"From my point of view, that name suggests that it will build some estimators out of the total number requested in the constructor, but not more.",Solution Discussion,144,144,0.1818181818,0.6715867159,0.06546491057,0.9345350894,1,0.3880597015,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,If we go for CODE then what would be the specification?,Solution Discussion,63,55,0.2727272727,0.6752767528,0.06546491057,0.9345350894,0.4230769231,0.1641791045,0.000347946123,5.39E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,You set CODE in the constructor and calling CODE append CODE more estimators?,Solution Discussion,98,77,0.3636363636,0.6789667897,0.06546491057,0.9345350894,0.5,0.1940298507,0.000347946123,5.39E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Just like @amueller did above?,Social Conversation,30,30,0.4545454545,0.6826568266,0.06546491057,0.9345350894,0.1923076923,0.07462686567,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Well I am not against that pattern, but that does not seem very intuitive to me nevertheless.",Solution Discussion,93,93,0.5454545455,0.6863468635,0.06546491057,0.9345350894,0.6538461538,0.2537313433,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"From a very practical point of view, I like CODE.",Solution Discussion,55,49,0.6363636364,0.6900369004,0.06546491057,0.9345350894,0.3846153846,0.1492537313,0.000347946123,5.39E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,It is explicit.,Solution Discussion,15,15,0.7272727273,0.6937269373,0.06546491057,0.9345350894,0.1153846154,0.0447761194,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,No explanation required.,Solution Discussion,24,24,0.8181818182,0.6974169742,0.06546491057,0.9345350894,0.1153846154,0.0447761194,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"However, it adds another function to our API...",Solution Discussion,47,47,0.9090909091,0.7011070111,0.06546491057,0.9345350894,0.3076923077,0.1194029851,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"(I have no strong opinion yet, these remarks simply reflect what I think at the moment)",Social Conversation,87,87,1,0.704797048,0.06546491057,0.9345350894,0.6153846154,0.2388059701,0.000347946123,5.39E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I am not completely against adding a function, but I wouldn't like it to be to specific to the ensembles.",Solution Discussion,105,105,0.1666666667,0.7084870849,0.06551459672,0.9344854033,1,0.2985074627,5.39E-05,6.63E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I really do see a connection to the path algorithms so I think sharing an interface would be nice.,Solution Discussion,98,98,0.3333333333,0.7121771218,0.06551459672,0.9344854033,0.95,0.2835820896,5.39E-05,6.63E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Consider the following hypothetical situation (maybe not so realistic):,Solution Discussion,71,71,0.5,0.7158671587,0.06551459672,0.9344854033,0.5,0.1492537313,5.39E-05,6.63E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Would you also do that via CODE?,Solution Discussion,38,32,0.6666666667,0.7195571956,0.06551459672,0.9344854033,0.35,0.1044776119,5.39E-05,6.63E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Or add a CODE function?,Solution Discussion,31,23,0.8333333333,0.7232472325,0.06551459672,0.9344854033,0.25,0.07462686567,5.39E-05,6.63E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,I guess there is a trade-off between generality and explicitness.,Solution Discussion,65,65,1,0.7269372694,0.06551459672,0.9344854033,0.55,0.1641791045,5.39E-05,6.63E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"@GaelVaroquaux The contract with CODE is imho that if you iterate over the data in batches, you will get the same result out.",Solution Discussion,134,125,0.3333333333,0.7306273063,0.06552070647,0.9344792935,1,0.3432835821,6.63E-06,0.009473328886,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,That will definitely not be the case if used here.,Solution Discussion,50,50,0.6666666667,0.7343173432,0.06552070647,0.9344792935,0.4347826087,0.1492537313,6.63E-06,0.009473328886,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,So by design we would break the contract ?!,Solution Discussion,43,43,1,0.7380073801,0.06552070647,0.9344792935,0.347826087,0.1194029851,6.63E-06,0.009473328886,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Thinking about it again, maybe there is room for a new method which we could use to implement #1626.",Solution Discussion,100,100,0.3333333333,0.741697417,0.07424730092,0.9257526991,0.76,0.2835820896,0.009473328886,1.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I wouldn't mind calling it CODE, but in the sense of CODE not in the sense of CODE.",Solution Discussion,171,83,0.6666666667,0.7453874539,0.07424730092,0.9257526991,0.72,0.2686567164,0.009473328886,1.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,So imho we should either do CODE ( + maybe defensive programming ) or add another method that we can generally use to fit along a parameter path.,Solution Discussion,153,145,1,0.7490774908,0.07424730092,0.9257526991,1,0.3731343284,0.009473328886,1.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Would CODE then be defensive or not? ;),Solution Discussion,45,39,1,0.7527675277,0.074258292,0.925741708,1,0.1194029851,1.19E-05,0.0001053839846,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,-         1 on defensive.,Solution Discussion,25,25,0.5,0.7564575646,0.0743553691,0.9256446309,0.2666666667,0.05970149254,0.0001053839846,3.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I'd rather document it well and let the user decides whatis good for oneself.,Solution Discussion,77,77,1,0.7601476015,0.0743553691,0.9256446309,1,0.223880597,0.0001053839846,3.97E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I would also be against defensive.,Solution Discussion,34,34,0.3333333333,0.7638376384,0.07435902202,0.925640978,0.2608695652,0.08955223881,3.97E-06,0.0008481954405,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I was just wondering if adding the function really solved an issue or if we just added another way to do warm starts.,Solution Discussion,117,117,0.6666666667,0.7675276753,0.07435902202,0.925640978,1,0.3432835821,3.97E-06,0.0008481954405,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Both have the same defensive / not-defensive problem, right?",Solution Discussion,60,60,1,0.7712177122,0.07435902202,0.925640978,0.3913043478,0.1343283582,3.97E-06,0.0008481954405,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,My apologies if I'm simply repeating what has already been said.,Social Conversation,64,64,0.1428571429,0.7749077491,0.07514035852,0.9248596415,0.3793103448,0.1641791045,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"But it seems like you could split estimators into two classes: those that freeze parameters once they are fit (ensembles, DTs), and those that don't (linear models).",Solution Discussion,165,165,0.2857142857,0.778597786,0.07514035852,0.9248596415,0.9310344828,0.4029850746,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,By that I mean with warm_start you won't refit the first n sub-estimators of an ensemble or the existing splits in a decision tree.,Solution Discussion,131,131,0.4285714286,0.7822878229,0.07514035852,0.9248596415,0.8620689655,0.3731343284,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The lack of being able to reach anywhere in the parameter space with warm_start for ensembles and DTs makes me think that an instance method would be more appropriate.,Solution Discussion,167,167,0.5714285714,0.7859778598,0.07514035852,0.9248596415,1,0.4328358209,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If an instance method is chosen, does it need to be more general as @amueller noted?",Solution Discussion,84,84,0.7142857143,0.7896678967,0.07514035852,0.9248596415,0.5517241379,0.2388059701,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"For what it's worth, I would also be against defensive.",Solution Discussion,55,55,0.8571428571,0.7933579336,0.07514035852,0.9248596415,0.3448275862,0.1492537313,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"As @GaelVaroquaux pointed out earlier it provides a sub-sampling strategy, for instance, if your training data doesn't fit in main memory.",Solution Discussion,138,138,1,0.7970479705,0.07514035852,0.9248596415,0.7586206897,0.328358209,0.0008481954405,0.003576949312,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"After some thoughts, I think we should see the bigger picture here.",Social Conversation,67,67,0.04545454545,0.8007380074,0.07843535507,0.9215646449,0.4,0.1791044776,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In a near future, I would like to implement generic meta-ensembles that could combine any kind of estimators together.",Task Progress,118,118,0.09090909091,0.8044280443,0.07843535507,0.9215646449,0.6666666667,0.2985074627,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"What I rather see is a ""combination"" mechanism that would take as input a list of (fitted) estimators and would produce a meta-estimator combining them all.",Solution Discussion,156,156,0.1363636364,0.8081180812,0.07843535507,0.9215646449,0.9,0.4029850746,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In practice, I think we can achieve that without adding any new function to our API.",Solution Discussion,84,84,0.1818181818,0.8118081181,0.07843535507,0.9215646449,0.5333333333,0.2388059701,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"For example, one could simply pass such a list of fitted estimators to the constructor of the meta-ensemble.",Solution Discussion,108,108,0.2272727273,0.815498155,0.07843535507,0.9215646449,0.6333333333,0.2835820896,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In terms of API, one could (roughly) implement such ensembles in the following way:",Solution Discussion,83,83,0.2727272727,0.8191881919,0.07843535507,0.9215646449,0.4666666667,0.2089552239,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,a)         Bagging:,Solution Discussion,19,19,0.3181818182,0.8228782288,0.07843535507,0.9215646449,0.1,0.0447761194,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators (optional).",Solution Discussion,117,96,0.3636363636,0.8265682657,0.07843535507,0.9215646449,0.4333333333,0.1940298507,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,-         fit: extend CODE with CODE new instances of CODE fitted over (bootstrap copies of) the training samples.,Solution Discussion,136,114,0.4090909091,0.8302583026,0.07843535507,0.9215646449,0.6,0.2686567164,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"If no base estimator is given, then it is equivalent to combining the estimators in CODE.",Solution Discussion,88,89,0.4545454545,0.8339483395,0.07843535507,0.9215646449,0.5333333333,0.2388059701,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,b) Stacking:,Solution Discussion,12,12,0.5,0.8376383764,0.07843535507,0.9215646449,0.06666666667,0.02985074627,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators (optional).",Solution Discussion,117,96,0.5454545455,0.8413284133,0.07843535507,0.9215646449,0.4333333333,0.1940298507,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"-         fit: extend CODE with CODE new instances of CODE fitted of bootstrap samples, then refit a model over the predictions of the estimators.",Solution Discussion,168,146,0.5909090909,0.8450184502,0.07843535507,0.9215646449,0.8,0.3582089552,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,c) Forest:,Solution Discussion,10,10,0.6363636364,0.8487084871,0.07843535507,0.9215646449,0.06666666667,0.02985074627,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"-         constructor: CODE (optional), CODE (>=0), a list CODE of fitted estimators or a forest (optional).",Solution Discussion,129,108,0.6818181818,0.852398524,0.07843535507,0.9215646449,0.5333333333,0.2388059701,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,-         fit: extend CODE with CODE new instances of CODE fitted over the training samples. Here we could also check whether the estimators in CODE are forests or decision trees.,Solution Discussion,200,179,0.7272727273,0.8560885609,0.07843535507,0.9215646449,1,0.447761194,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,Forests would be flattened in order to put all trees on the same level.,Solution Discussion,71,71,0.7727272727,0.8597785978,0.07843535507,0.9215646449,0.4666666667,0.2089552239,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Also, in such a framework, computation of an ensemble could easily be distributed over several machines: build your estimators; pickle them; then recombine them into one single meta-estimator.",Solution Discussion,192,192,0.8181818182,0.8634686347,0.07843535507,0.9215646449,0.9666666667,0.4328358209,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"One could even wrap that interface into a MapReduce cluster, without digging into our implementation at all!",Solution Discussion,108,108,0.8636363636,0.8671586716,0.07843535507,0.9215646449,0.5666666667,0.2537313433,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,What do you think?,Social Conversation,18,18,0.9090909091,0.8708487085,0.07843535507,0.9215646449,0.1333333333,0.05970149254,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I am aware this is only relevant to some kind of ensembles though.,Solution Discussion,66,66,0.9545454545,0.8745387454,0.07843535507,0.9215646449,0.4333333333,0.1940298507,0.003576949312,2.46E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"For instance, GBRT and AdaBoost are (in my opinion) more suited to either CODE or CODE.",Solution Discussion,106,87,1,0.8782287823,0.07843535507,0.9215646449,0.5333333333,0.2388059701,0.003576949312,2.46E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,"Just to be clear, to extend a forest, one would do something like: CODE",Solution Discussion,246,71,1,0.8819188192,0.07845801609,0.9215419839,1,0.2089552239,2.46E-05,0.0001366868532,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,What is the motivation of that interface?,Solution Discussion,41,41,0.1428571429,0.8856088561,0.07858392862,0.9214160714,0.3043478261,0.1044776119,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I am totally with you in supporting more ensemble methods.,Social Conversation,58,58,0.2857142857,0.889298893,0.07858392862,0.9214160714,0.4347826087,0.1492537313,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I just feel it is quite awkward to have a different interface for GBRT and random forest.,Solution Discussion,89,89,0.4285714286,0.8929889299,0.07858392862,0.9214160714,0.7391304348,0.2537313433,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I don't really see the motivation for that.,Social Conversation,43,43,0.5714285714,0.8966789668,0.07858392862,0.9214160714,0.347826087,0.1194029851,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"If the main motivation is to distribute embarassingly parallel jobs, then I think we should attack this by implementing a more powerful parallelization.",Solution Discussion,152,152,0.7142857143,0.9003690037,0.07858392862,0.9214160714,1,0.3432835821,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Doing it the way you described seems pretty manual and hacky.,Solution Discussion,61,61,0.8571428571,0.9040590406,0.07858392862,0.9214160714,0.4782608696,0.1641791045,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Basically I feel your proposal just solves a very special case and leaves most cases unsolved.,Solution Discussion,94,94,1,0.9077490775,0.07858392862,0.9214160714,0.6956521739,0.2388059701,0.0001366868532,1.47E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Well ok...,Social Conversation,10,10,0.5,0.9114391144,0.07859750583,0.9214024942,0.125,0.02985074627,1.47E-05,2.11E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I just feel that extending boosted-like ensembles and average-like ensembles are quite different things.,Solution Discussion,104,104,1,0.9151291513,0.07859750583,0.9214024942,1,0.2388059701,1.47E-05,2.11E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,What is the use-case for your interface except parallelization?,Motivation,63,63,0.5,0.9188191882,0.07859944544,0.9214005546,0.5882352941,0.1492537313,2.11E-06,8.88E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,Or better: in what use cases do you need a different interface for boosted ensembles and bagging?,Motivation,97,97,1,0.9225092251,0.07859944544,0.9214005546,1,0.2537313433,2.11E-06,8.88E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,The use case is when you want to combine several estimators together.,Motivation,69,69,0.3333333333,0.926199262,0.07860762409,0.9213923759,0.8,0.1791044776,8.88E-06,1.13E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"It is natural for average-like ensembles, but makes no sense in boosted ensembles.",Motivation,82,82,0.6666666667,0.9298892989,0.07860762409,0.9213923759,0.9333333333,0.2089552239,8.88E-06,1.13E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"In that perspective, I see ""extending an estimator"" as ""combining"" it with more base estimators.",Expected Behaviour,96,96,1,0.9335793358,0.07860762409,0.9213923759,1,0.223880597,8.88E-06,1.13E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"So the setting is that you have trained some bagging estimators and want to combine them together, right?",Motivation,105,105,0.3333333333,0.9372693727,0.07861806562,0.9213819344,1,0.2686567164,1.13E-05,1.65E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,In which setting do you want to do that except for parallelization?,Motivation,67,67,0.6666666667,0.9409594096,0.07861806562,0.9213819344,0.6666666667,0.1791044776,1.13E-05,1.65E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,It is not so clear to me but maybe I'm overlooking something obvious.,Social Conversation,69,69,1,0.9446494465,0.07861806562,0.9213819344,0.7222222222,0.1940298507,1.13E-05,1.65E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,In case of Stacking the estimators might be completely different (say to you want to merge forests with svms).,Motivation,110,110,0.5,0.9483394834,0.07863322684,0.9213667732,1,0.2835820896,1.65E-05,1.93E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"(Indirectly, this could also be used to implement subsampling strategies or for monitoring the fitting process.)",Motivation,112,112,1,0.9520295203,0.07863322684,0.9213667732,0.8421052632,0.2388059701,1.65E-05,1.93E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I'm not sure I get the stacking example.,Social Conversation,40,40,0.5,0.9557195572,0.07865103886,0.9213489611,0.2962962963,0.1194029851,1.93E-05,8.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"I would have imagined that if we had a stacking interface, you could specify one estimator as the base estimator and another as the one on top.",Motivation,143,143,1,0.9594095941,0.07865103886,0.9213489611,1,0.4029850746,1.93E-05,8.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"As I see it, the point of stacking is to combine the predictions of estimators of different nature.",Motivation,99,99,0.5,0.963099631,0.07872936647,0.9212706335,1,0.2686567164,8.50E-05,7.92E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"The more diverse they are, often the better.",Motivation,44,44,1,0.9667896679,0.07872936647,0.9212706335,0.4444444444,0.1194029851,8.50E-05,7.92E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"Ok, so the base estimators would be different.",Solution Discussion,46,46,0.5,0.9704797048,0.07880236017,0.9211976398,0.6153846154,0.1194029851,7.92E-05,1,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"But then we could also build this into the interface for stacking, right?",Solution Discussion,73,73,1,0.9741697417,0.07880236017,0.9211976398,1,0.1940298507,7.92E-05,1,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,@jwkvam We recently agreed in #2570 to implement this feature using the CODE parameter.,Task Progress,95,87,0.3333333333,0.9778597786,0.999977436,2.26E-05,1,0.2089552239,1,2.45E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
6 1585_scikit-learn.doc,It is now implemented in GBRT.,Task Progress,30,30,0.6666666667,0.9815498155,0.999977436,2.26E-05,0.4285714286,0.08955223881,1,2.45E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,I'll try to update the forests with the same mechanism before the release.,Task Progress,74,74,1,0.9852398524,0.999977436,2.26E-05,0.9285714286,0.1940298507,1,2.45E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
6 1585_scikit-learn.doc,"@glouppe You're right, I forgot I had written this for any ensemble.",Social Conversation,68,68,1,0.9889298893,1,0,12,0.1791044776,2.45E-05,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
6 1585_scikit-learn.doc,But really I just wanted it for GBRT :),Social Conversation,39,39,2,0.9926199262,1,0,9,0.1343283582,2.45E-05,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
6 1585_scikit-learn.doc,"so in my haste, I decided this issue was resolved.",Social Conversation,50,50,3,0.9963099631,1,0,10,0.1492537313,2.45E-05,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
6 1585_scikit-learn.doc,"If you like you can reopen it and close it when you are done, it doesn't matter to me.",Action on Issue,86,86,4,1,1,0,19,0.2835820896,2.45E-05,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
7 2889_scikit-learn.doc,GridSearchCV parallel execution with own scorer freezes,Observed Bug Behaviour,55,55,0.1428571429,0.003039513678,0,1,0.3043478261,0.07142857143,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,I have been searching hours on this problem and can consistently replicate it: CODE,Observed Bug Behaviour,285,83,0.2857142857,0.006079027356,0,1,0.6086956522,0.1428571429,0,5.80E-05,NONE,TRUE,TRUE,TRUE,FALSE
7 2889_scikit-learn.doc,"This snippet crashes because of scoring=metrics.make_scorer(metrics.scorer.f1_score, average=""macro"") where metrics refers to sklearn.metrics module.",Investigation and Exploration,149,149,0.4285714286,0.009118541033,0,1,0.6086956522,0.1428571429,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,"If I cancel out the scoring=... line, the parallel execution works.",Investigation and Exploration,67,67,0.5714285714,0.01215805471,0,1,0.4782608696,0.112244898,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,"If I want to use the f1 score as evaluation method, I have to cancel out the parallel execution by setting n_jobs = 1.",Investigation and Exploration,118,118,0.7142857143,0.01519756839,0,1,1,0.2346938776,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,Is there a way I can define another score method without losing the parallel execution possibility?,Expected Behaviour,99,99,0.8571428571,0.01823708207,0,1,0.6956521739,0.1632653061,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,Thanks,Social Conversation,6,6,1,0.02127659574,0,1,0.04347826087,0.01020408163,0,5.80E-05,NONE,TRUE,FALSE,TRUE,FALSE
7 2889_scikit-learn.doc,"This is surprising, so we'll have to work out what the problem is and make sure it works!",Social Conversation,89,89,0.1111111111,0.02431610942,2.18E-05,0.9999782351,1,0.1836734694,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you please provide a little more detail:,Investigation and Exploration,44,44,0.2222222222,0.0273556231,2.18E-05,0.9999782351,0.4444444444,0.08163265306,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"-         What do you mean by ""crashes""?",Investigation and Exploration,40,40,0.3333333333,0.03039513678,2.18E-05,0.9999782351,0.3888888889,0.07142857143,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,-         What version of scikit-learn is this?,Investigation and Exploration,47,47,0.4444444444,0.03343465046,2.18E-05,0.9999782351,0.4444444444,0.08163265306,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If it's 0.14, does it still happen in the current development version?",Investigation and Exploration,70,70,0.5555555556,0.03647416413,2.18E-05,0.9999782351,0.6666666667,0.1224489796,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,-         Multiprocessing has platform-specific issues.,Investigation and Exploration,55,55,0.6666666667,0.03951367781,2.18E-05,0.9999782351,0.3333333333,0.0612244898,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,What platform are you on? (e.g. CODE),Investigation and Exploration,71,37,0.7777777778,0.04255319149,2.18E-05,0.9999782351,0.3888888889,0.07142857143,5.80E-05,0.0007141221038,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,-         Have you tried it on different datasets?,Investigation and Exploration,50,50,0.8888888889,0.04559270517,2.18E-05,0.9999782351,0.4444444444,0.08163265306,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"FWIW, my machine has no problem fitting iris with this snippet on the development version of sklearn.",Bug Reproduction,101,101,1,0.04863221884,2.18E-05,0.9999782351,0.9444444444,0.1734693878,5.80E-05,0.0007141221038,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Thank you for your fast reply.,Social Conversation,30,30,0.09090909091,0.05167173252,0.0002898878784,0.9997101121,0.1666666667,0.0612244898,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,With crashing I actually mean freezing.,Observed Bug Behaviour,39,39,0.1818181818,0.0547112462,0.0002898878784,0.9997101121,0.1666666667,0.0612244898,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It doesn't continue anymore and there is also no more activity to be monitored in the python process of task manager of windows.,Observed Bug Behaviour,128,128,0.2727272727,0.05775075988,0.0002898878784,0.9997101121,0.6388888889,0.2346938776,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The processes are still there and consume a constant amount of RAM but require no processing time.,Observed Bug Behaviour,98,98,0.3636363636,0.06079027356,0.0002898878784,0.9997101121,0.4722222222,0.1734693878,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"This is scikit-learn version 0.14, last updated and run using Enthought Canopy.",Observed Bug Behaviour,79,79,0.4545454545,0.06382978723,0.0002898878784,0.9997101121,0.3611111111,0.1326530612,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I am on platform ""Windows-7-6.1.7601-SP1"".",Observed Bug Behaviour,42,42,0.5454545455,0.06686930091,0.0002898878784,0.9997101121,0.1944444444,0.07142857143,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I will go more into depth by providing a generic example of the problem.,Social Conversation,72,72,0.6363636364,0.06990881459,0.0002898878784,0.9997101121,0.3888888889,0.1428571429,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I think it has to do with the GridSearchCV being placed in a for loop.,Investigation and Exploration,70,70,0.7272727273,0.07294832827,0.0002898878784,0.9997101121,0.4166666667,0.1530612245,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"(To not waste too much of your time, you should probably start at the run_tune_process() method which is being called at the bottom of the code and calls the method containing GridSearchCV() in a for loop)",Investigation and Exploration,205,205,0.8181818182,0.07598784195,0.0002898878784,0.9997101121,1,0.3673469388,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,# Code: CODE,Investigation and Exploration,1588,12,0.9090909091,0.07902735562,0.0002898878784,0.9997101121,0.05555555556,0.02040816327,0.0007141221038,8.58E-05,NONE,TRUE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Once again, this code works on my computer only when I change n_jobs to 1 or when I don't define a scoring= argument.",Observed Bug Behaviour,117,117,1,0.0820668693,0.0002898878784,0.9997101121,0.6388888889,0.2346938776,0.0007141221038,8.58E-05,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Generally multiprocessing in Windows encounters a lot of problems.,Investigation and Exploration,66,66,0.2,0.08510638298,0.0003221026152,0.9996778974,0.4285714286,0.09183673469,8.58E-05,9.26E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,But Idon't know why this should be correlated with a custom metric.,Investigation and Exploration,67,67,0.4,0.08814589666,0.0003221026152,0.9996778974,0.5714285714,0.1224489796,8.58E-05,9.26E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,There'snothing about the average=macro option in 0.14 that suggests it should bemore likely to hang than the default average (weighted).,Investigation and Exploration,136,136,0.6,0.09118541033,0.0003221026152,0.9996778974,1,0.2142857143,8.58E-05,9.26E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"At the developmenthead, this completes in 11s on my macbook, and in 7s at version 0.14(that's something to look into!)",Investigation and Exploration,118,118,0.8,0.09422492401,0.0003221026152,0.9996778974,0.9523809524,0.2040816327,8.58E-05,9.26E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Are you able to try this out in the current development version, to see ifit's still an issue?",Investigation and Exploration,94,94,1,0.09726443769,0.0003221026152,0.9996778974,0.8571428571,0.1836734694,8.58E-05,9.26E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"(As a side point, @ogrisel, I note there seems to be a lot more joblibparallelisation overhead in master -- on OS X at least -- that wasn't therein 0.14...)",Potential New Issues and Requests,156,156,1,0.1003039514,0.0003255784354,0.9996744216,1,0.2959183673,9.26E-06,0.02437524994,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,This has nothing to do with custom scorers.,Investigation and Exploration,43,43,0.3333333333,0.103343465,0.009477465184,0.9905225348,0.2666666667,0.08163265306,0.02437524994,2.55E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,This is a [well-known feature](http://docs.python.org/2/library/multiprocessing.html#windows) of Python multiprocessing on Windows: you have to run everything that uses CODE in an CODE block or you'll get freezes/crashes.,Investigation and Exploration,251,221,0.6666666667,0.1063829787,0.009477465184,0.9905225348,1,0.306122449,0.02437524994,2.55E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Maybe we should document this somewhere prominently, e.g. in the README?",Solution Discussion,72,72,1,0.1094224924,0.009477465184,0.9905225348,0.3666666667,0.112244898,0.02437524994,2.55E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Well, the good news is that nowadays joblib gives a meaningful errormessage on such crash, rather than a fork bomb.",Solution Discussion,115,115,1,0.1124620061,0.009487034877,0.9905129651,1,0.2040816327,2.55E-05,4.65E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@GaelVaroquaux does current scikit-learn give that error message?,Solution Discussion,65,65,0.5,0.1155015198,0.009488780246,0.9905112198,1,0.09183673469,4.65E-06,2.07E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If so, the issue can be considered fixed, IMHO.",Action on Issue,47,47,1,0.1185410334,0.009488780246,0.9905112198,1,0.09183673469,4.65E-06,2.07E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It should do.,Solution Discussion,13,13,0.3333333333,0.1215805471,0.009489555966,0.990510444,0.1666666667,0.0306122449,2.07E-06,7.41E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The only way to be sure is to check.,Solution Discussion,36,36,0.6666666667,0.1246200608,0.009489555966,0.990510444,0.5,0.09183673469,2.07E-06,7.41E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I am on the move rightnow, and I cannot boot up a Windows VM to do that.",Contribution and Commitment,72,72,1,0.1276595745,0.009489555966,0.990510444,1,0.1836734694,2.07E-06,7.41E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I'm not going to install a C compiler on Windows just for this.,Contribution and Commitment,63,63,0.5,0.1306990881,0.009492338114,0.9905076619,1,0.1326530612,7.41E-06,4.99E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Sorry, but I really don't do Windows :)",Contribution and Commitment,39,39,1,0.1337386018,0.009492338114,0.9905076619,0.6153846154,0.08163265306,7.41E-06,4.99E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I have a Windows VM.,Contribution and Commitment,20,20,0.3333333333,0.1367781155,0.009494210283,0.9905057897,0.3846153846,0.05102040816,4.99E-06,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I can check.,Contribution and Commitment,12,12,0.6666666667,0.1398176292,0.009494210283,0.9905057897,0.2307692308,0.0306122449,4.99E-06,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It's just a question of finding alittle be of time to do it.,Social Conversation,60,60,1,0.1428571429,0.009494210283,0.9905057897,1,0.1326530612,4.99E-06,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@larsmans , you are completely right.",Social Conversation,37,37,0.25,0.1458966565,0.009500960535,0.9904990395,0.2777777778,0.05102040816,1.80E-05,0.006789037082,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The custom scorer object was a mistake of me, the problem lies indeed in the multiprocessing on windows.",Investigation and Exploration,104,104,0.5,0.1489361702,0.009500960535,0.9904990395,1,0.1836734694,1.80E-05,0.006789037082,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I tried this same code on a Linux and it runs well.,Bug Reproduction,51,51,0.75,0.1519756839,0.009500960535,0.9904990395,0.6666666667,0.1224489796,1.80E-05,0.006789037082,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I don't get any error messages because it doesn't crash, it just stops doing any meaningful.",Observed Bug Behaviour,92,92,1,0.1550151976,0.009500960535,0.9904990395,0.8888888889,0.1632653061,1.80E-05,0.006789037082,NONE,TRUE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@adverley Could you try the most recent version from GitHub on your Windows box?,Investigation and Exploration,80,80,1,0.1580547112,0.01204995998,0.98795004,1,0.1428571429,0.006789037082,0.5381059742,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Closing because of lack of feeback and it is probably a known issue that is fixed in newer joblib.,Action on Issue,98,98,1,0.1610942249,0.2140862446,0.7859137554,1,0.193877551,0.5381059742,0.1079292843,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Not sure if related, does seem to be.",Social Conversation,37,37,0.1666666667,0.1641337386,0.2546091762,0.7453908238,0.7272727273,0.08163265306,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"In windows, custom scorer still freezes.",Observed Bug Behaviour,40,40,0.3333333333,0.1671732523,0.2546091762,0.7453908238,0.5454545455,0.0612244898,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"When it freezes, it shows no error message.",Observed Bug Behaviour,43,43,0.5,0.170212766,0.2546091762,0.7453908238,0.7272727273,0.08163265306,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,There are 3 python processes spawned too (because I set n_jobs=3).,Observed Bug Behaviour,66,66,0.6666666667,0.1732522796,0.2546091762,0.7453908238,1,0.112244898,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"However, the CPU utilization remains 0 for all python processes.",Observed Bug Behaviour,64,64,0.8333333333,0.1762917933,0.2546091762,0.7453908238,0.9090909091,0.1020408163,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I am using IPython Notebook.,Observed Bug Behaviour,28,28,1,0.179331307,0.2546091762,0.7453908238,0.4545454545,0.05102040816,0.1079292843,0.008572782863,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you share the code of the scorer?,Observed Bug Behaviour,37,37,0.5,0.1823708207,0.2578278976,0.7421721024,1,0.08163265306,0.008572782863,8.34E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It seems a bit unlikely.,Social Conversation,24,24,1,0.1854103343,0.2578278976,0.7421721024,0.625,0.05102040816,0.008572782863,8.34E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Does your scorer use joblib / n_jobs anywhere?,Investigation and Exploration,46,46,0.5,0.188449848,0.2578282109,0.7421717891,0.4666666667,0.07142857143,8.34E-07,0.000173866989,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"It shouldn't, and that could maybe cause problems (though I think joblib should detect that).",Investigation and Exploration,93,93,1,0.1914893617,0.2578282109,0.7421717891,1,0.1530612245,8.34E-07,0.000173866989,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Sure - here's the full code - http://pastebin.com/yUE26SNs,Observed Bug Behaviour,58,58,0.2,0.1945288754,0.2578934907,0.7421065093,0.25,0.0612244898,0.000173866989,0.0009051930247,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The scorer function is ""score_model"", it doesn't use joblib.",Investigation and Exploration,60,60,0.4,0.1975683891,0.2578934907,0.7421065093,0.375,0.09183673469,0.000173866989,0.0009051930247,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"This runs from command prompt, but not from IPython Notebook.",Observed Bug Behaviour,61,61,0.6,0.2006079027,0.2578934907,0.7421065093,0.4166666667,0.1020408163,0.000173866989,0.0009051930247,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The error message is -CODE,Observed Bug Behaviour,108,26,0.8,0.2036474164,0.2578934907,0.7421065093,0.2083333333,0.05102040816,0.000173866989,0.0009051930247,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Then the IPython and all the spawned python instances become idle - silently - and don't respond to any python code anymore till I restart it.,Observed Bug Behaviour,142,142,1,0.2066869301,0.2578934907,0.7421065093,1,0.2448979592,0.000173866989,0.0009051930247,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Fix the attribute error, then it'll work.",Solution Discussion,41,41,0.3333333333,0.2097264438,0.2582333528,0.7417666472,0.875,0.07142857143,0.0009051930247,0.0005513005954,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Do you do pylab imports in IPython notebook?,Investigation and Exploration,44,44,0.6666666667,0.2127659574,0.2582333528,0.7417666472,1,0.08163265306,0.0009051930247,0.0005513005954,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Otherwise everything should be the same.,Investigation and Exploration,40,40,1,0.2158054711,0.2582333528,0.7417666472,0.75,0.0612244898,0.0009051930247,0.0005513005954,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Well I do not know what causes the AttributeError...,Social Conversation,52,52,0.1666666667,0.2188449848,0.2584403431,0.7415596569,0.4090909091,0.09183673469,0.0005513005954,0.001083708651,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Though it is most likely related to joblibs, since _it happens only when n_jobs is more than 1_, runs fine with CODE.",Investigation and Exploration,123,117,0.3333333333,0.2218844985,0.2584403431,0.7415596569,1,0.2244897959,0.0005513005954,0.001083708651,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"The error talks about attribute CODE missing from CODE, whether or not I have a CODE in the IPython Notebook or not.",Observed Bug Behaviour,154,116,0.5,0.2249240122,0.2584403431,0.7415596569,1,0.2244897959,0.0005513005954,0.001083708651,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,(I realized that the error line was pasted incorrectly above - I edited in the post above.),Social Conversation,91,91,0.6666666667,0.2279635258,0.2584403431,0.7415596569,0.7272727273,0.1632653061,0.0005513005954,0.001083708651,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I don't use pylab.,Observed Bug Behaviour,18,18,0.8333333333,0.2310030395,0.2584403431,0.7415596569,0.1818181818,0.04081632653,0.0005513005954,0.001083708651,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Here's the full extended error message - http://pastebin.com/23y5uHT2,Observed Bug Behaviour,69,69,1,0.2340425532,0.2584403431,0.7415596569,0.3181818182,0.07142857143,0.0005513005954,0.001083708651,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Hum, that is likely related to issues of multiprocessing on windows.",Investigation and Exploration,68,68,0.1666666667,0.2370820669,0.2588472304,0.7411527696,0.6111111111,0.112244898,0.001083708651,1,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Maybe @GaelVaroquaux or @ogrisel can help.,Contribution and Commitment,42,42,0.3333333333,0.2401215805,0.2588472304,0.7411527696,0.3333333333,0.0612244898,0.001083708651,1,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I don't know what the notebook makes of the CODE.,Social Conversation,69,49,0.5,0.2431610942,0.2588472304,0.7411527696,0.5555555556,0.1020408163,0.001083708651,1,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Try not defining the metric in the notebook, but in a separate file and import it.",Solution Discussion,82,82,0.6666666667,0.2462006079,0.2588472304,0.7411527696,0.8888888889,0.1632653061,0.001083708651,1,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I'd think that would fix it.,Solution Discussion,28,28,0.8333333333,0.2492401216,0.2588472304,0.7411527696,0.3888888889,0.07142857143,0.001083708651,1,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"This is not really related to GridSearchCV, but some interesting interaction between windows multiprocessing, IPython notebook and joblib.",Investigation and Exploration,138,138,1,0.2522796353,0.2588472304,0.7411527696,1,0.1836734694,0.001083708651,1,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,guys...thanks for the thread.,Social Conversation,29,29,0.1428571429,0.2553191489,0.6343054009,0.3656945991,0.2631578947,0.05102040816,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Anyway i should have checked this thread before, wasted 5 hours of my time on this.",Social Conversation,83,83,0.2857142857,0.2583586626,0.6343054009,0.3656945991,0.8421052632,0.1632653061,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Trying to run in parallel processing.,Observed Bug Behaviour,37,37,0.4285714286,0.2613981763,0.6343054009,0.3656945991,0.3157894737,0.0612244898,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Thanks a lot :),Social Conversation,15,15,0.5714285714,0.26443769,0.6343054009,0.3656945991,0.2105263158,0.04081632653,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,TO ADD A FEEDBACK: its still freezing.,Observed Bug Behaviour,38,38,0.7142857143,0.2674772036,0.6343054009,0.3656945991,0.3684210526,0.07142857143,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I faced the same issue when in presence of my own make_Score cost function..my system starts freezing.,Observed Bug Behaviour,102,102,0.8571428571,0.2705167173,0.6343054009,0.3656945991,1,0.193877551,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"When i did not use custom cost function, i did not face these freezes in parallel processing",Observed Bug Behaviour,92,92,1,0.273556231,0.6343054009,0.3656945991,0.8947368421,0.1734693878,1,0.005493875023,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The best way of turning these 5 hours into something useful for the project, would be to provide us with a stand-alone example reproducing the problem.",Bug Reproduction,151,151,1,0.2765957447,0.6363681212,0.3636318788,1,0.2755102041,0.005493875023,0.07308442859,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I was experiencing the same issue on Windows 10 working in Jupyter notebook trying to use a custom scorer within a nested cross-validation and n_jobs=-1.,Observed Bug Behaviour,153,153,0.3333333333,0.2796352584,0.663808267,0.336191733,1,0.2653061224,0.07308442859,0.3850825819,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I was getting the CODE message.,Observed Bug Behaviour,115,31,0.6666666667,0.282674772,0.663808267,0.336191733,0.2307692308,0.0612244898,0.07308442859,0.3850825819,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"As @amueller suggested, importing the custom scorer instead of defining it in the notebook works.",Solution Discussion,97,97,1,0.2857142857,0.663808267,0.336191733,0.5769230769,0.1530612245,0.07308442859,0.3850825819,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I have the exact same problem on OSX 10.10.5,Bug Reproduction,44,44,1,0.2887537994,0.8083906687,0.1916093313,1,0.09183673469,0.3850825819,0.004286302035,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Same here.OSX 10.12.5,Bug Reproduction,21,21,1,0.2917933131,0.8099999958,0.1900000042,1,0.04081632653,0.004286302035,0.002231981712,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Please give a reproducible code snippet.,Bug Reproduction,40,40,1,0.2948328267,0.8108380116,0.1891619884,1,0.0612244898,0.002231981712,0.003762853532,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Just run these lines in a python shell CODE,Bug Reproduction,590,43,0.3333333333,0.2978723404,0.8122508057,0.1877491943,0.375,0.09183673469,0.003762853532,0.0002075199459,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Note that removing the PCA step from the pipeline solves the issue.,Solution Discussion,67,67,0.6666666667,0.3009118541,0.8122508057,0.1877491943,0.5,0.1224489796,0.003762853532,0.0002075199459,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"More info: Darwin-16.6.0-x86_64-i386-64bit('Python', '2.7.13 (default, Apr  4 2017, 08:47:57) \n[GCC 4.2.1 Compatible Apple LLVM 8.1.0 (clang-802.0.38)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.2')",Bug Reproduction,218,218,1,0.3039513678,0.8122508057,0.1877491943,1,0.2448979592,0.003762853532,0.0002075199459,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"seeing as you don't use a custom scorer, should we assume that is aseparate issue?",Potential New Issues and Requests,82,82,1,0.3069908815,0.8123287208,0.1876712792,1,0.1530612245,0.0002075199459,1.26E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"When I first faced this issue I was using custom scorer, but while trying to simplify the example code as much as possible, I found that it is not necessarily have to contain custom scorer.",Observed Bug Behaviour,189,189,0.2,0.3100303951,0.8123334347,0.1876665653,1,0.3571428571,1.26E-05,3.93E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,At least on my machine.,Observed Bug Behaviour,23,23,0.4,0.3130699088,0.8123334347,0.1876665653,0.1428571429,0.05102040816,1.26E-05,3.93E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Importing the scorer also didn't help in my case.,Investigation and Exploration,49,49,0.6,0.3161094225,0.8123334347,0.1876665653,0.2571428571,0.09183673469,1.26E-05,3.93E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Anyway, the symptoms looks similar.",Investigation and Exploration,35,35,0.8,0.3191489362,0.8123334347,0.1876665653,0.1428571429,0.05102040816,1.26E-05,3.93E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The script hangs forever and the CPU utilization is low.,Observed Bug Behaviour,56,56,1,0.3221884498,0.8123334347,0.1876665653,0.2857142857,0.1020408163,1.26E-05,3.93E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@boazsh thanks a lot for the snippet, it is not deterministic though, can you edit it and use a CODE to make sure the random numbers are always the same on each run.",Bug Reproduction,184,165,0.3333333333,0.3252279635,0.8123482033,0.1876517967,1,0.3367346939,3.93E-05,5.52E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Also there is a work-around if you are using Python 3 suggested for example in https://github.com/scikit-learn/scikit-learn/issues/5115#issuecomment-187683383.,Workarounds,159,159,0.6666666667,0.3282674772,0.8123482033,0.1876517967,0.5151515152,0.1734693878,3.93E-05,5.52E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I don't have a way to test this on OSX at the moment but I may be able to try in the upcoming days.,Contribution and Commitment,99,99,1,0.3313069909,0.8123482033,0.1876517967,0.7272727273,0.2448979592,3.93E-05,5.52E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Some piece of information useful to have (just add what is missing to your earlier comment https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-320885103): CODE,Investigation and Exploration,416,177,0.5,0.3343465046,0.8123502768,0.1876497232,0.95,0.193877551,5.52E-06,7.19E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Also how did you install scikit-learn, with pip, with conda, with one of the OSX package managers (brew, etc ...) ?",Investigation and Exploration,115,115,1,0.3373860182,0.8123502768,0.1876497232,1,0.2040816327,5.52E-06,7.19E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Great thanks a lot!,Social Conversation,19,19,0.5,0.3404255319,0.8123772704,0.1876227296,0.4,0.04081632653,7.19E-05,2.17E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Have you answered this one, I can't find your answer ...",Social Conversation,56,56,1,0.3434650456,0.8123772704,0.1876227296,1,0.1020408163,7.19E-05,2.17E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Sorry, missed it - pip.",Investigation and Exploration,23,23,1,0.3465045593,0.8123780834,0.1876219166,1,0.04081632653,2.17E-06,2.64E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"FWIW, I have no problem running that snippet with: >>> import platform; print(platform.platform())Darwin-16.7.0-x86_64-i386-64bit>>> import sys; print(""Python"", sys.version)Python 2.7.12 |Continuum Analytics, Inc.| (default, Jul  2 2016, 17:43:17)[GCC 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)]>>> import numpy; print(""NumPy"", numpy.__version__)NumPy 1.13.1>>> import scipy; print(""SciPy"", scipy.__version__)SciPy 0.19.1>>> import sklearn; print(""Scikit-Learn"", sklearn.__version__)Scikit-Learn 0.18.2",Bug Reproduction,522,522,0.5,0.3495440729,0.8123880036,0.1876119964,1,0.5714285714,2.64E-05,2.68E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Could you put verbose=10 in cross_val_predict, too, so that we can perhapssee where it breaks for you?",Investigation and Exploration,102,102,1,0.3525835866,0.8123880036,0.1876119964,0.3035714286,0.1734693878,2.64E-05,2.68E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@jnothman I am guessing that your conda environment uses MKL and not Accelerate.,Investigation and Exploration,80,80,0.2,0.3556231003,0.8123980581,0.1876019419,0.4814814815,0.1326530612,2.68E-05,1.89E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,This freezing problem is specific to Accelerate and Python multiprocessing.,Investigation and Exploration,75,75,0.4,0.358662614,0.8123980581,0.1876019419,0.3703703704,0.1020408163,2.68E-05,1.89E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux for more details.,Investigation and Exploration,127,127,0.6,0.3617021277,0.8123980581,0.1876019419,0.1481481481,0.04081632653,2.68E-05,1.89E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,pip on the other hand will use wheels that are shipped with Accelerate (at the time of writing).,Investigation and Exploration,96,96,0.8,0.3647416413,0.8123980581,0.1876019419,0.6666666667,0.1836734694,2.68E-05,1.89E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,A work-around (other than the JOBLIB_START_METHOD) to avoid this particular bug is to use MKL (e.g. via conda) or OpenBLAS (e.g. via the conda-forge channel).,Workarounds,158,158,1,0.367781155,0.8123980581,0.1876019419,1,0.2755102041,2.68E-05,1.89E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Nothing is being printed... ![screen shot 2017-08-08 at 16 43 35] URL,Investigation and Exploration,166,70,1,0.3708206687,0.8123987667,0.1876012333,1,0.1428571429,1.89E-06,3.02E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@jnothman in case you want to reproduce the problem, IIRC you can create an environment with Accelerate on OSX  with something like:CODE",Bug Reproduction,200,136,1,0.3738601824,0.8123999005,0.1876000995,1,0.2448979592,3.02E-06,0.00176012514,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,FWIW I can not reproduce the problem on my OS X VM.,Bug Reproduction,51,51,0.5,0.376899696,0.8130607538,0.1869392462,1,0.1224489796,0.00176012514,2.15E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I tried to mimic as close as possible @boazsh's versions: CODE,Bug Reproduction,297,62,1,0.3799392097,0.8130607538,0.1869392462,0.9166666667,0.112244898,0.00176012514,2.15E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Hmm actually I can reproduce but your snippet was not a complete reproducer.,Bug Reproduction,76,76,0.2,0.3829787234,0.8130688094,0.1869311906,0.7222222222,0.1326530612,2.15E-05,0.004018329935,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Here is an updated snippet: CODE,Bug Reproduction,654,32,0.4,0.3860182371,0.8130688094,0.1869311906,0.3333333333,0.0612244898,2.15E-05,0.004018329935,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"In any case, this is a known problem with Accelerate and Python multiprocessing.",Investigation and Exploration,80,80,0.6,0.3890577508,0.8130688094,0.1869311906,0.7222222222,0.1326530612,2.15E-05,0.004018329935,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Workarounds exist and have been listed in earlier posts.,Workarounds,56,56,0.8,0.3920972644,0.8130688094,0.1869311906,0.5,0.09183673469,2.15E-05,0.004018329935,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The easiest one is probably to use conda and make sure that you use MKL and not Accelerate.,Workarounds,91,91,1,0.3951367781,0.8130688094,0.1869311906,1,0.1836734694,2.15E-05,0.004018329935,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Having a fix to multiprocessing be dependent on the scikit-learn version is symptomatic of the problems of vendoring....,Solution Discussion,120,120,1,0.3981762918,0.8145775242,0.1854224758,1,0.2040816327,0.004018329935,0.0004532620224,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I recently read the following, which I found interesting:https://lwn.net/Articles/730630/rss",Solution Discussion,92,92,1,0.4012158055,0.8147477051,0.1852522949,1,0.1224489796,0.0004532620224,0.08978722153,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I have a similar issue with RandomizedSearchCV; it hangs indefinitely.,Observed Bug Behaviour,70,70,0.09090909091,0.4042553191,0.8484590511,0.1515409489,0.2325581395,0.1020408163,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I am using a 3 year old macbook pro, 16GB ram and core i7 and my scikit-learn version is 0.19.",Observed Bug Behaviour,94,94,0.1818181818,0.4072948328,0.8484590511,0.1515409489,0.511627907,0.2244897959,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Puzzling part is that it was working last Friday!!!,Observed Bug Behaviour,51,51,0.2727272727,0.4103343465,0.8484590511,0.1515409489,0.2093023256,0.09183673469,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Monday morning, I go back and try to run and it just freezes.",Observed Bug Behaviour,61,61,0.3636363636,0.4133738602,0.8484590511,0.1515409489,0.3023255814,0.1326530612,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I know from previous runs that it take about 60 min to finish, but I waited a lot longer than that and nothing happens, it just hangs, no error msgs, nothing and my computer heats up and sucks power like there's no tomorrow.",Observed Bug Behaviour,224,224,0.4545454545,0.4164133739,0.8484590511,0.1515409489,1,0.4387755102,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Code below.,Observed Bug Behaviour,11,11,0.5454545455,0.4194528875,0.8484590511,0.1515409489,0.04651162791,0.02040816327,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,So it may have something to do with n_jobs=-1.,Investigation and Exploration,46,46,0.6363636364,0.4224924012,0.8484590511,0.1515409489,0.2093023256,0.09183673469,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Still, this code worked fine last Friday!",Observed Bug Behaviour,41,41,0.7272727273,0.4255319149,0.8484590511,0.1515409489,0.1627906977,0.07142857143,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,it just hates Mondays.,Social Conversation,22,22,0.8181818182,0.4285714286,0.8484590511,0.1515409489,0.09302325581,0.04081632653,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,My dataset size is less that 20k examples with dimensionality < 100..,Observed Bug Behaviour,69,69,0.9090909091,0.4316109422,0.8484590511,0.1515409489,0.2790697674,0.1224489796,0.08978722153,2.73E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Observed Bug Behaviour,582,4,1,0.4346504559,0.8484590511,0.1515409489,0.02325581395,0.01020408163,0.08978722153,2.73E-05,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,what is crf?,Investigation and Exploration,12,12,0.5,0.4376899696,0.8484692846,0.1515307154,0.3,0.0306122449,2.73E-05,1.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"just to eliminate the possibility, could you try usingreturn_train_score=False?",Investigation and Exploration,79,79,1,0.4407294833,0.8484692846,0.1515307154,1,0.1020408163,2.73E-05,1.52E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"It is very likely that this @KaisJM's problem is due to the well known limitation on Accelerate with multiprocessing, see our [faq](http://scikit-learn.org/stable/faq.html#why-do-i-sometime-get-a-crash-freeze-with-n-jobs-1-under-osx-or-linux).",Investigation and Exploration,243,243,0.3333333333,0.443768997,0.8484749906,0.1515250094,1,0.3979591837,1.52E-05,1.18E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,How did you install scikit-learn?,Investigation and Exploration,33,33,0.6666666667,0.4468085106,0.8484749906,0.1515250094,0.1538461538,0.0612244898,1.52E-05,1.18E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Also for future reference, can you paste the output of:CODE",Investigation and Exploration,298,59,1,0.4498480243,0.8484749906,0.1515250094,0.2820512821,0.112244898,1.52E-05,1.18E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,this was working last Friday!!,Investigation and Exploration,30,30,0.2,0.452887538,0.8484794361,0.1515205639,0.1851851852,0.05102040816,1.18E-05,2.74E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I done nothing since.,Investigation and Exploration,21,21,0.4,0.4559270517,0.8484794361,0.1515205639,0.1481481481,0.04081632653,1.18E-05,2.74E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I think scikit learn is part of anaconda, but I did upgrade with pip (pip install --upgrade sklearn), but thats before I got this problem..",Investigation and Exploration,139,139,0.6,0.4589665653,0.8484794361,0.1515205639,1,0.2755102041,1.18E-05,2.74E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I ran the code fine after upgrading to 0.19.,Investigation and Exploration,44,44,0.8,0.462006079,0.8484794361,0.1515205639,0.3333333333,0.09183673469,1.18E-05,2.74E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,here's the output of the above prints: CODE,Investigation and Exploration,292,43,1,0.4650455927,0.8484794361,0.1515205639,0.2962962963,0.08163265306,1.18E-05,2.74E-05,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,@jnothman : I am using RandomizedSearchCV from sklearn.grid_search which does not have the return_train_score parameter.,Investigation and Exploration,120,120,0.25,0.4680851064,0.8484897144,0.1515102856,0.7777777778,0.1428571429,2.74E-05,1.94E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I know sklearn.grid_search is depricated..,Investigation and Exploration,42,42,0.5,0.4711246201,0.8484897144,0.1515102856,0.3333333333,0.0612244898,2.74E-05,1.94E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I will try the one from sklearn.model_selection, but something tells me I will have the same exact issue).",Investigation and Exploration,106,106,0.75,0.4741641337,0.8484897144,0.1515102856,1,0.1836734694,2.74E-05,1.94E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Updated original comment with more info and code.,Social Conversation,49,49,1,0.4772036474,0.8484897144,0.1515102856,0.4444444444,0.08163265306,2.74E-05,1.94E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you post the output of CODE.,Investigation and Exploration,53,32,0.1,0.4802431611,0.8484970091,0.1515029909,0.21875,0.07142857143,1.94E-05,7.95E-07,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,I would wild guess that by updating scikit-learn with pip you updated numpy with pip too and you got the numpy wheels which uses Accelerate and has the limitation mentioned above.,Investigation and Exploration,179,179,0.2,0.4832826748,0.8484970091,0.1515029909,1,0.3265306122,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Small word of advice:,Social Conversation,21,21,0.3,0.4863221884,0.8484970091,0.1515029909,0.125,0.04081632653,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,*         post a fully stand-alone snippet (for your next issue).,Bug Reproduction,65,65,0.4,0.4893617021,0.8484970091,0.1515029909,0.34375,0.112244898,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,That means anyone can copy and paste it in a IPython session and easily try to reproduce.,Bug Reproduction,89,89,0.5,0.4924012158,0.8484970091,0.1515029909,0.53125,0.1734693878,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,This will give you the best chance of getting good feed-back.,Bug Reproduction,61,61,0.6,0.4954407295,0.8484970091,0.1515029909,0.375,0.1224489796,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"*         if you are using conda, stick to conda to manage packages that are available through conda.",Solution Discussion,101,101,0.7,0.4984802432,0.8484970091,0.1515029909,0.53125,0.1734693878,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Only use pip when you have to.,Solution Discussion,30,30,0.8,0.5015197568,0.8484970091,0.1515029909,0.21875,0.07142857143,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"*         If you insist you want to use CODE, I would strongly recommend you use CODE.",Solution Discussion,132,86,0.9,0.5045592705,0.8484970091,0.1515029909,0.5,0.1632653061,1.94E-05,7.95E-07,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Otherwise if a package dependends, say on numpy, and you happen not to have the latest numpy, numpy will be upgraded with pip, which you do not want.",Solution Discussion,149,149,1,0.5075987842,0.8484970091,0.1515029909,0.875,0.2857142857,1.94E-05,7.95E-07,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Oh yeah and BTW, sklearn.grid_search is deprecated you probably want to use sklearn.model_selection at one point not too far down the road.",Solution Discussion,139,139,1,0.5106382979,0.8484973075,0.1515026925,1,0.2244897959,7.95E-07,5.94E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Good advice, thank you.",Social Conversation,23,23,0.1666666667,0.5136778116,0.8484995377,0.1515004623,0.1818181818,0.04081632653,5.94E-06,2.00E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,So is the workaround to downgrade numpy?,Workarounds,40,40,0.3333333333,0.5167173252,0.8484995377,0.1515004623,0.3181818182,0.07142857143,5.94E-06,2.00E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,what limitation are you referring to?,Investigation and Exploration,37,37,0.5,0.5197568389,0.8484995377,0.1515004623,0.2727272727,0.0612244898,5.94E-06,2.00E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,the FAQ link above?,Investigation and Exploration,19,19,0.6666666667,0.5227963526,0.8484995377,0.1515004623,0.1818181818,0.04081632653,5.94E-06,2.00E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I did read it, but I do not understand this stuff (i'm just an algo guy :) ).",Social Conversation,77,77,0.8333333333,0.5258358663,0.8484995377,0.1515004623,0.7727272727,0.1734693878,5.94E-06,2.00E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,output of CODE numpy                     1.12.0                    <pip>numpy                     1.12.0                   py27_0numpy                     1.13.1                    <pip>numpydoc                  0.7.0                     <pip>,Investigation and Exploration,264,243,1,0.5288753799,0.8484995377,0.1515004623,1,0.2244897959,5.94E-06,2.00E-05,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Wow three numpy installed I saw two before but never three ...,Social Conversation,62,62,0.2,0.5319148936,0.8485070338,0.1514929662,0.4074074074,0.112244898,2.00E-05,7.30E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"anyway this seems indicative of the problem I was mentioning, i.e. that you have mixed pip and conda which is a bad idea for a given package.",Investigation and Exploration,141,141,0.4,0.5349544073,0.8485070338,0.1514929662,1,0.2755102041,2.00E-05,7.30E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Solution Discussion,117,4,0.6,0.537993921,0.8485070338,0.1514929662,0.03703703704,0.01020408163,2.00E-05,7.30E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Hopefully after that you will have a single numpy that uses MKL.,Solution Discussion,64,64,0.8,0.5410334347,0.8485070338,0.1514929662,0.4444444444,0.1224489796,2.00E-05,7.30E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If I were you I would double-check that you don't have the same problem for other core scientific packages, e.g. scipy, etc ...",Solution Discussion,127,127,1,0.5440729483,0.8485070338,0.1514929662,0.8518518519,0.2346938776,2.00E-05,7.30E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"the reason I resort to pip for some packages is that conda does not have some packages, which actually is very frustrating because I know mixing pip with conda is a bad idea.",Solution Discussion,174,174,0.5,0.547112462,0.8485344376,0.1514655624,1,0.3367346939,7.30E-05,0.0001585701904,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Next time that happens I'll use the --no-deps option.,Solution Discussion,53,53,1,0.5501519757,0.8485344376,0.1514655624,0.303030303,0.1020408163,7.30E-05,0.0001585701904,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,one thing I should've mentioned is that I installed Spyder within the python env I was working in.,Solution Discussion,98,98,0.25,0.5531914894,0.848593974,0.151406026,0.7916666667,0.193877551,0.0001585701904,6.42E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"However, I was able to run the code after installing Spyder, both in Spyder and in Jupyter.",Solution Discussion,91,91,0.5,0.556231003,0.848593974,0.151406026,0.7083333333,0.1734693878,0.0001585701904,6.42E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I did uninstall Spyder and the numpys above, re-installed bumpy with conda (which updated scikit to 0.19) and still get the same error.",Observed Bug Behaviour,135,135,0.75,0.5592705167,0.848593974,0.151406026,1,0.2448979592,0.0001585701904,6.42E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Something may have happened because of the Spyder install, but then why would it work for a day and then suddenly stop??",Investigation and Exploration,120,120,1,0.5623100304,0.848593974,0.151406026,0.9166666667,0.2244897959,0.0001585701904,6.42E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"ok, nothing is working!!",Observed Bug Behaviour,24,24,0.3333333333,0.5653495441,0.8486180736,0.1513819264,0.2857142857,0.04081632653,6.42E-05,0.0003438203814,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,should I just create a new environment (using conda) and re-install everything there?,Solution Discussion,85,85,0.6666666667,0.5683890578,0.8486180736,0.1513819264,1,0.1428571429,6.42E-05,0.0003438203814,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,will that solve it or make it worse?,Solution Discussion,36,36,1,0.5714285714,0.8486180736,0.1513819264,0.5714285714,0.08163265306,6.42E-05,0.0003438203814,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Sounds worth a try!,Solution Discussion,19,19,1,0.5744680851,0.8487471637,0.1512528363,1,0.04081632653,0.0003438203814,0.0002798718168,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"created a new env and installed everything with conda, still freezes indefinitely.",Observed Bug Behaviour,82,82,0.2,0.5775075988,0.8488522439,0.1511477561,0.8,0.1224489796,0.0002798718168,0.0005769674315,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,only one copy of each package etc.,Observed Bug Behaviour,34,34,0.4,0.5805471125,0.8488522439,0.1511477561,0.4666666667,0.07142857143,0.0002798718168,0.0005769674315,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"n_jobs=1 works,but takes forever of course (it worked in the previous env as well).",Observed Bug Behaviour,83,83,0.6,0.5835866261,0.8488522439,0.1511477561,1,0.1530612245,0.0002798718168,0.0005769674315,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,n_jobs=-1 is what freezes indefinitely.,Observed Bug Behaviour,39,39,0.8,0.5866261398,0.8488522439,0.1511477561,0.3333333333,0.05102040816,0.0002798718168,0.0005769674315,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Observed Bug Behaviour,321,4,1,0.5896656535,0.8488522439,0.1511477561,0.06666666667,0.01020408163,0.0002798718168,0.0005769674315,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Then I don't know.,Social Conversation,18,18,0.5,0.5927051672,0.849068871,0.150931129,0.1212121212,0.04081632653,0.0005769674315,0.0001106335994,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The only way we can investigate, is that you post a fully standalone snippet which we can just copy and paste in an IPython sesion and see if we can reproduce the problem.",Bug Reproduction,171,171,1,0.5957446809,0.849068871,0.150931129,1,0.3367346939,0.0005769674315,0.0001106335994,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,will try to create a minimal example that reproduces the problem.,Bug Reproduction,65,65,0.1428571429,0.5987841945,0.8491104093,0.1508895907,0.6470588235,0.112244898,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I need to do that to debug more efficiently.,Social Conversation,44,44,0.2857142857,0.6018237082,0.8491104093,0.1508895907,0.5294117647,0.09183673469,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I read the FAQ entry you refer to about ""Accelerate"".. its not much help for me.",Investigation and Exploration,80,80,0.4285714286,0.6048632219,0.8491104093,0.1508895907,1,0.1734693878,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,What I took from it is that fork() NOT followed by exec() call is bad.,Investigation and Exploration,70,70,0.5714285714,0.6079027356,0.8491104093,0.1508895907,0.8823529412,0.1530612245,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I've done some googling on this and nothing so far even hints at a workaround.,Social Conversation,78,78,0.7142857143,0.6109422492,0.8491104093,0.1508895907,0.9411764706,0.1632653061,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Can you point to some more information, more detail about what the problem is?",Investigation and Exploration,78,78,0.8571428571,0.6139817629,0.8491104093,0.1508895907,0.8235294118,0.1428571429,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"thanks,",Social Conversation,7,7,1,0.6170212766,0.8491104093,0.1508895907,0.05882352941,0.01020408163,0.0001106335994,3.83E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Try this snippet (taken from https://github.com/numpy/numpy/issues/4776):CODE,Investigation and Exploration,347,77,0.1666666667,0.6200607903,0.8491247825,0.1508752175,0.2142857143,0.0612244898,3.83E-05,3.51E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,*         If this freezes (i.e. it does not finish within one second) that means you are using Accelerate and the freeze is a known limitation with Python multiprocessing.,Investigation and Exploration,171,171,0.3333333333,0.623100304,0.8491247825,0.1508752175,1,0.2857142857,3.83E-05,3.51E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The work-around is to not use Accelerate.,Workarounds,41,41,0.5,0.6261398176,0.8491247825,0.1508752175,0.2857142857,0.08163265306,3.83E-05,3.51E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,On OSX you can do that with conda which uses MKL by default.,Workarounds,60,60,0.6666666667,0.6291793313,0.8491247825,0.1508752175,0.4642857143,0.1326530612,3.83E-05,3.51E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,You can also use OpenBLAS using conda-forge.,Workarounds,44,44,0.8333333333,0.632218845,0.8491247825,0.1508752175,0.2857142857,0.08163265306,3.83E-05,3.51E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"*         If it does not freeze then you are not using Accelerate, and we would need a stand-alone snippet to investigate.",Investigation and Exploration,122,122,1,0.6352583587,0.8491247825,0.1508752175,0.7857142857,0.2244897959,3.83E-05,3.51E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,will try to reproduce with minimal code. CODE,Bug Reproduction,120,45,1,0.6382978723,0.8491379548,0.1508620452,1,0.08163265306,3.51E-05,0.000108726466,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,@GaelVaroquaux scikit-learn is not an app but a library in a rich ecosystem.,Solution Discussion,76,76,0.25,0.641337386,0.8491787771,0.1508212229,1,0.1428571429,0.000108726466,0.001720552123,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If everybody did what we do, everything would come crashing down.",Solution Discussion,65,65,0.5,0.6443768997,0.8491787771,0.1508212229,0.7857142857,0.112244898,0.000108726466,0.001720552123,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,That's a pretty clear signal that we need to change.,Solution Discussion,52,52,0.75,0.6474164134,0.8491787771,0.1508212229,0.7142857143,0.1020408163,0.000108726466,0.001720552123,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,And there are many environments where the opposite is true from that comment.,Solution Discussion,77,77,1,0.6504559271,0.8491787771,0.1508212229,0.9285714286,0.1326530612,0.000108726466,0.001720552123,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I used a ubuntu virtual instance in google cloud compute engine (bumpy, spicy, scikit etc were not the most up to date).",Observed Bug Behaviour,120,120,0.1,0.6534954407,0.8498247724,0.1501752276,0.7857142857,0.2244897959,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The code ran fine.,Observed Bug Behaviour,18,18,0.2,0.6565349544,0.8498247724,0.1501752276,0.1428571429,0.04081632653,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Then I installed Gensim.,Observed Bug Behaviour,24,24,0.3,0.6595744681,0.8498247724,0.1501752276,0.1428571429,0.04081632653,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"This updated numpy and scipy to the latest versions and installed few other things it needs (boto, bz2file and smart_open).",Observed Bug Behaviour,123,123,0.4,0.6626139818,0.8498247724,0.1501752276,0.7142857143,0.2040816327,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,After that the code freezes.,Observed Bug Behaviour,28,28,0.5,0.6656534954,0.8498247724,0.1501752276,0.1785714286,0.05102040816,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I hope this gives a useful clue as to what causes this freeze.,Social Conversation,62,62,0.6,0.6686930091,0.8498247724,0.1501752276,0.4642857143,0.1326530612,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,**after installing Gensim**numpy (1.10.4) updated to numpy (1.13.3)scipy (0.16.1)   updated to scipy (0.19.1),Observed Bug Behaviour,109,109,0.7,0.6717325228,0.8498247724,0.1501752276,0.5,0.1428571429,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,**more info:**,Social Conversation,14,14,0.8,0.6747720365,0.8498247724,0.1501752276,0.1071428571,0.0306122449,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Doing some research I found that libblas, liblapack and liblapack_atlas were missing from my /usr/lib/, also I did not see the directory /usr/lib/atlas-base/.",Investigation and Exploration,158,158,0.9,0.6778115502,0.8498247724,0.1501752276,0.9642857143,0.2755102041,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I don't know if they were there and installing gensim removed them since it updated numpy etc, but this is likely since the code worked before installing gensim.",Investigation and Exploration,161,161,1,0.6808510638,0.8498247724,0.1501752276,1,0.2857142857,0.001720552123,0.0001657418063,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I think the problem is that numpy is using OpenBlas.,Investigation and Exploration,52,52,0.3333333333,0.6838905775,0.8498870015,0.1501129985,1,0.1020408163,0.0001657418063,0.0001597224167,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Will switch it to ATLAS and see what happens.,Investigation and Exploration,45,45,0.6666666667,0.6869300912,0.8498870015,0.1501129985,0.9,0.09183673469,0.0001657418063,0.0001597224167,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Investigation and Exploration,572,4,1,0.6899696049,0.8498870015,0.1501129985,0.1,0.01020408163,0.0001657418063,0.0001597224167,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Still the same problem.,Observed Bug Behaviour,23,23,0.5,0.6930091185,0.8499469706,0.1500530294,0.4444444444,0.04081632653,0.0001597224167,0.001154610306,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The following runs fine, unless I insert n_jobs=-1. CODE",Observed Bug Behaviour,400,56,1,0.6960486322,0.8499469706,0.1500530294,1,0.09183673469,0.0001597224167,0.001154610306,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,@paulaceccon are your Numpy and Scipy installations using ATLAS or OpenBLAS?,Investigation and Exploration,76,76,1,0.6990881459,0.8503804785,0.1496195215,1,0.112244898,0.001154610306,7.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It is a bit hard to follow what you have done @KaisJM.,Social Conversation,54,54,0.25,0.7021276596,0.850408121,0.149591879,0.3529411765,0.1224489796,7.36E-05,1.73E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,From a maintainer's point of view what we need is a fully stand-alone python snippet to see if we can reproduce.,Bug Reproduction,112,112,0.5,0.7051671733,0.850408121,0.149591879,0.6470588235,0.2244897959,7.36E-05,1.73E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If we can reproduce, only then can we investigate and try to understand what is happening.",Social Conversation,90,90,0.75,0.7082066869,0.850408121,0.149591879,0.4705882353,0.1632653061,7.36E-05,1.73E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"This requires a non negligible amount of time and effort, I completely agree, but without it, I am afraid that there is not much we can do to investigate the problem you are facing.",Social Conversation,181,181,1,0.7112462006,0.850408121,0.149591879,1,0.3469387755,7.36E-05,1.73E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@KaisJM by the way, this page is out-of-date, since nowadays wheels are available on Linux and contain their own OpenBLAS.",Investigation and Exploration,122,122,0.5,0.7142857143,0.8504146176,0.1495853824,1,0.2244897959,1.73E-05,2.27E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,If you install a released scikit-learn with pip you will be using OpenBLAS.,Investigation and Exploration,75,75,1,0.717325228,0.8504146176,0.1495853824,0.6363636364,0.1428571429,1.73E-05,2.27E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@lesteve are you saying that Openblas does not cause a freeze anymore?,Investigation and Exploration,70,70,1,0.7203647416,0.8504231356,0.1495768644,1,0.1224489796,2.27E-05,8.05E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@lesteve paula has posted a snippet that also has the same problem.,Investigation and Exploration,67,67,0.2,0.7234042553,0.8504261564,0.1495738436,0.5454545455,0.1224489796,8.05E-06,1.85E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I can see it's not complete code, but I hope it gives some clue.",Social Conversation,64,64,0.4,0.726443769,0.8504261564,0.1495738436,0.6363636364,0.1428571429,8.05E-06,1.85E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I can make here snippet ""complete"" and post for you.",Social Conversation,52,52,0.6,0.7294832827,0.8504261564,0.1495738436,0.4545454545,0.1020408163,8.05E-06,1.85E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"However, it is clear that the ""out-of-date"" -as you call it- instructions page may not be so out of date.",Investigation and Exploration,105,105,0.8,0.7325227964,0.8504261564,0.1495738436,1,0.2244897959,8.05E-06,1.85E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The highest likelihood is that OpenBLAS is causing the fees they are talking about in that page.,Investigation and Exploration,96,96,1,0.73556231,0.8504261564,0.1495738436,0.7727272727,0.1734693878,8.05E-06,1.85E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,These instructions are outdated believe me.,Investigation and Exploration,43,43,0.125,0.7386018237,0.8504331006,0.1495668994,0.2608695652,0.0612244898,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"If you read in details, it says ""but can freeze joblib/multiprocessing prior to OpenBLAS version 0.2.8-4"".",Investigation and Exploration,106,106,0.25,0.7416413374,0.8504331006,0.1495668994,0.7826086957,0.1836734694,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I checked a recent numpy wheel and it contains OpenBLAS 0.2.8.18.,Investigation and Exploration,65,65,0.375,0.7446808511,0.8504331006,0.1495668994,0.4782608696,0.112244898,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The freeze they are referring to is the one in https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-334155175, which you don't seem to have.",Investigation and Exploration,157,157,0.5,0.7477203647,0.8504331006,0.1495668994,0.7391304348,0.1734693878,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Not really no.,Social Conversation,14,14,0.625,0.7507598784,0.8504331006,0.1495668994,0.1304347826,0.0306122449,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"We have reports of users that seems to indicate that freezing can still happen, none of which we have managed to reproduce AFAIK.",Bug Reproduction,129,129,0.75,0.7537993921,0.8504331006,0.1495668994,1,0.2346938776,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"That seems to indicate, that this problem happens in some very specific combination of factors.",Investigation and Exploration,95,95,0.875,0.7568389058,0.8504331006,0.1495668994,0.652173913,0.1530612245,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,That would be great.,Social Conversation,20,20,1,0.7598784195,0.8504331006,0.1495668994,0.1739130435,0.04081632653,1.85E-05,4.50E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@lesteve @paulaceccon :I took Paula's excerpt code and made a complete run-able code snippet.,Investigation and Exploration,93,93,0.1428571429,0.7629179331,0.8504500024,0.1495499976,0.8823529412,0.1530612245,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Just paste it into a Jupyter cell and run it.,Investigation and Exploration,45,45,0.2857142857,0.7659574468,0.8504500024,0.1495499976,0.5882352941,0.1020408163,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Paula: I could not get this snippet to freeze.,Investigation and Exploration,46,46,0.4285714286,0.7689969605,0.8504500024,0.1495499976,0.5294117647,0.09183673469,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Notice that n_jobs=-1 and runs fine.,Investigation and Exploration,36,36,0.5714285714,0.7720364742,0.8504500024,0.1495499976,0.3529411765,0.0612244898,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Would be great if you can take a look and post a version of it that freezes.,Investigation and Exploration,76,76,0.7142857143,0.7750759878,0.8504500024,0.1495499976,1,0.1734693878,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Notice that you can switch between grid_search module and model_selection module, both ran fine for me.",Investigation and Exploration,103,103,0.8571428571,0.7781155015,0.8504500024,0.1495499976,0.9411764706,0.1632653061,4.50E-05,0.0001636161473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Investigation and Exploration,1108,4,1,0.7811550152,0.8504500024,0.1495499976,0.05882352941,0.01020408163,4.50E-05,0.0001636161473,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,@KaisJM I think it is more useful if you start from your freezing script and manage to simplify and post a fully stand-alone that freezes for you.,Bug Reproduction,146,146,1,0.7841945289,0.8505114334,0.1494885666,1,0.2857142857,0.0001636161473,7.81E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@lesteve Agreed.,Social Conversation,16,16,0.1666666667,0.7872340426,0.850540769,0.149459231,0.08333333333,0.02040816327,7.81E-05,0.005705487359,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I created a new python2 environment like the one I had before installing Gensim.,Investigation and Exploration,80,80,0.3333333333,0.7902735562,0.850540769,0.149459231,0.5833333333,0.1428571429,7.81E-05,0.005705487359,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Code ran fine, NO freeze with n_jobs=-1.",Investigation and Exploration,40,40,0.5,0.7933130699,0.850540769,0.149459231,0.2916666667,0.07142857143,7.81E-05,0.005705487359,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"What's more, Numpy is using OpenBLAS and has the same config as the environment that exhibits the freeze (the one where Gensim was installed).",Investigation and Exploration,142,142,0.6666666667,0.7963525836,0.850540769,0.149459231,1,0.2448979592,7.81E-05,0.005705487359,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,So it seems that openblas is not the cause of this freeze.,Investigation and Exploration,58,58,0.8333333333,0.7993920973,0.850540769,0.149459231,0.5,0.1224489796,7.81E-05,0.005705487359,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,CODE,Investigation and Exploration,549,4,1,0.8024316109,0.850540769,0.149459231,0.04166666667,0.01020408163,7.81E-05,0.005705487359,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,@KaisJM  I'm running the same snippet here (windows) and it freezes. CODE,Observed Bug Behaviour,1145,73,0.5,0.8054711246,0.8526829408,0.1473170592,0.8666666667,0.1326530612,0.005705487359,0.01083986775,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,I know that it's awkward but it didn't froze when running with a _custom_ metric.,Observed Bug Behaviour,81,81,1,0.8085106383,0.8526829408,0.1473170592,1,0.1530612245,0.005705487359,0.01083986775,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I have a similar problem.,Observed Bug Behaviour,25,25,0.5,0.811550152,0.8567528578,0.1432471422,0.2173913043,0.05102040816,0.01083986775,0.005718638633,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I have been running the same code and simply wanted to update the model with the new month data and it stopped running.,Observed Bug Behaviour,119,119,1,0.8145896657,0.8567528578,0.1432471422,1,0.2346938776,0.01083986775,0.005718638633,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Running GridSearchCV or RandomizedSearchCV in a loop and  n_jobs > 1 would hang silently in Jupiter & IntelliJ: CODE,Investigation and Exploration,294,116,0.3333333333,0.8176291793,0.8588999674,0.1411000326,0.1836734694,0.1836734694,0.005718638633,2.10E-05,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Followed @lesteve recommendation & checked environment & removed numpy installed with pip: Darwin-16.6.0-x86_64-i386-64bitPython 3.6.1 |Anaconda custom (x86_64)| (default, May 11 2017, 13:04:09)[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]NumPy 1.13.1SciPy 0.19.1Scikit-Learn 0.19.0  $conda list | grep numpygnumpy                   0.2                pipnumpy                     1.13.1            py36_0numpy                     1.13.3           pipnumpydoc              0.6.0             py36_0 $pip uninstall numpy $conda list | grep numpygnumpy                   0.2                      pipnumpy                     1.13.1                  py36_0numpydoc              0.6.0                  py36_0 $conda install numpy -f                                // most likely unnecessary $conda list | grep numpygnumpy                   0.2                       pipnumpy                     1.13.1                   py36_0numpydoc               0.6.0                   py36_0",Solution Discussion,983,983,0.6666666667,0.820668693,0.8588999674,0.1411000326,1,1,0.005718638633,2.10E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Fixed my problem.,Solution Discussion,17,17,1,0.8237082067,0.8588999674,0.1411000326,0.0306122449,0.0306122449,0.005718638633,2.10E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@paulaceccon your problem is related to > https://stackoverflow.com/questions/36533134/cant-get-attribute-abc-on-module-main-from-abc-h-py> If you declare the pool prior to declaring the function you are trying to use in parallel it will throw this error. Reverse the order and it will no longer throw this error.,Social Conversation,313,313,0.25,0.8267477204,0.8589078439,0.1410921561,1,0.4081632653,2.10E-05,0.1984119539,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The following will run your code:CODE,Solution Discussion,697,37,0.5,0.829787234,0.8589078439,0.1410921561,0.175,0.07142857143,2.10E-05,0.1984119539,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,with external.py CODEResults running on 8 cores,Solution Discussion,574,47,0.75,0.8328267477,0.8589078439,0.1410921561,0.175,0.07142857143,2.10E-05,0.1984119539,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Fitting 3 folds for each of 54 candidates, totalling 162 fits[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   30.5s finished{'class_weight': {0: 0.51891309, 1: 13.71835531}, 'criterion': 'gini', 'min_samples_leaf': 10, 'min_samples_split': 20, 'n_estimators': 400}",Solution Discussion,332,332,1,0.8358662614,0.8589078439,0.1410921561,1,0.4081632653,2.10E-05,0.1984119539,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Issue is still there guys.,Observed Bug Behaviour,26,26,0.3333333333,0.8389057751,0.9334032331,0.06659676688,0.2777777778,0.05102040816,0.1984119539,0.0001350091473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I am using a custom scorer and it keeps going on forever when I set n_jobs to anything.,Observed Bug Behaviour,87,87,0.6666666667,0.8419452888,0.9334032331,0.06659676688,1,0.1836734694,0.1984119539,0.0001350091473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,When I don't specify n_jobs at all it works fine but otherwise it freezes.,Observed Bug Behaviour,74,74,1,0.8449848024,0.9334032331,0.06659676688,0.7777777778,0.1428571429,0.1984119539,0.0001350091473,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction,64,64,0.5,0.8480243161,0.9334539234,0.06654607659,1,0.112244898,0.0001350091473,0.05592088416,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Please read https://stackoverflow.com/help/mcve for more details.,Solution Discussion,65,65,1,0.8510638298,0.9334539234,0.06654607659,0.5454545455,0.0612244898,0.0001350091473,0.05592088416,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Still facing this problem with the same sample  code.,Bug Reproduction,53,53,0.5,0.8541033435,0.9544498763,0.04555012373,0.4545454545,0.1020408163,0.05592088416,0.0005450428142,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Windows-10-10.0.15063-SP0Python 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]NumPy 1.14.1SciPy 1.0.0Scikit-Learn 0.19.1",Bug Reproduction,167,167,1,0.8571428571,0.9544498763,0.04555012373,1,0.2244897959,0.05592088416,0.0005450428142,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you provide a stand-alone snippet to reproduce the problem ?,Bug Reproduction,64,64,0.5,0.8601823708,0.954654517,0.04534548295,1,0.112244898,0.0005450428142,0.001193905199,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Please read https://stackoverflow.com/help/mcve for more details.,Solution Discussion,65,65,1,0.8632218845,0.954654517,0.04534548295,0.5454545455,0.0612244898,0.0005450428142,0.001193905199,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I suspect this is the same old multiprocessing in windows issue.,Investigation and Exploration,64,64,0.5,0.8662613982,0.9551027785,0.04489722149,1,0.112244898,0.001193905199,0.04128957575,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,see our FAQ,Solution Discussion,11,11,1,0.8693009119,0.9551027785,0.04489722149,0.2727272727,0.0306122449,0.001193905199,0.04128957575,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I tested the code in thomberg1's https://github.com/scikit-learn/scikit-learn/issues/2889#issuecomment-337985212.,Bug Reproduction,113,113,0.3333333333,0.8723404255,0.9706052871,0.02939471292,0.6363636364,0.07142857143,0.04128957575,0.0165742005,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,OS: Windows 10 x64 10.0.16299.309Python package: WinPython-64bit-3.6.1numpy (1.14.2)scikit-learn (0.19.1)scipy (1.0.0),Bug Reproduction,118,118,0.6666666667,0.8753799392,0.9706052871,0.02939471292,1,0.112244898,0.04128957575,0.0165742005,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,It worked fine in Jupyter Notebook and command-line.,Bug Reproduction,52,52,1,0.8784194529,0.9706052871,0.02939471292,0.8181818182,0.09183673469,0.04128957575,0.0165742005,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"HI, i m having the same issue, so i did not want to open new one which could lead to almost identical thread.",Observed Bug Behaviour,109,109,0.2,0.8814589666,0.9768282061,0.02317179392,1,0.2346938776,0.0165742005,0.01231978335,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,-         Macos-         Anaconda-         scikit-learn 0.19.1-         scipy 1.0.1-         numpy 1.14.2CODE,Observed Bug Behaviour,1814,109,0.4,0.8844984802,0.9768282061,0.02317179392,0.6086956522,0.1428571429,0.0165742005,0.01231978335,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Code is from a tutorial : https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/,Observed Bug Behaviour,112,112,0.6,0.8875379939,0.9768282061,0.02317179392,0.2608695652,0.0612244898,0.0165742005,0.01231978335,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I tried changing the n_jobs parameter to 1, -1, but neither of these worked.",Solution Discussion,76,76,0.8,0.8905775076,0.9768282061,0.02317179392,0.6086956522,0.1428571429,0.0165742005,0.01231978335,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Any hint?,Solution Discussion,9,9,1,0.8936170213,0.9768282061,0.02317179392,0.08695652174,0.02040816327,0.0165742005,0.01231978335,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,it runs if I add the multiprocessing import and  the if statement as show below - I don't work with keras so I don't have more insight CODE,Observed Bug Behaviour,1906,139,0.3333333333,0.896656535,0.9814537694,0.0185462306,0.3943661972,0.2857142857,0.01231978335,0.004293692176,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"### Fitting 3 folds for each of 18 candidates, totalling 54 fits[Parallel(n_jobs=12)]: Done  26 tasks      | elapsed:   18.4s[Parallel(n_jobs=12)]: Done  54 out of  54 | elapsed:   23.7s finishedBest: 0.675781 using {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}0.621094 (0.036225) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'rmsprop'}0.675781 (0.006379) with: {'batch_size': 5, 'epochs': 5, 'init': 'glorot_uniform', 'optimizer': 'adam'}...0.651042 (0.025780) with: {'batch_size': 20, 'epochs': 5, 'init': 'uniform', 'optimizer': 'adam'}",Observed Bug Behaviour,602,602,0.6666666667,0.8996960486,0.9814537694,0.0185462306,1,0.7244897959,0.01231978335,0.004293692176,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"version info if neededsys 3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 12:04:33)[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]numpy 1.14.2pandas 0.22.0sklearn 0.19.1torch 0.4.0a0+9692519IPython 6.2.1keras 2.1.5 compiler   : GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)system     : Darwinrelease    : 17.5.0machine    : x86_64processor  : i386CPU cores  : 24interpreter: 64bit",Observed Bug Behaviour,412,412,1,0.9027355623,0.9814537694,0.0185462306,0.7042253521,0.5102040816,0.01231978335,0.004293692176,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Thank you @thomberg1 , but addingCODEdid not help.",Observed Bug Behaviour,100,50,0.5,0.905775076,0.9830658712,0.01693412879,1,0.07142857143,0.004293692176,0.03509089576,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,The problem is still the same,Observed Bug Behaviour,29,29,1,0.9088145897,0.9830658712,0.01693412879,0.8571428571,0.0612244898,0.004293692176,0.03509089576,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Same problem on my machine when using customized scoring function in CODE.,Observed Bug Behaviour,84,74,0.5,0.9118541033,0.9962410347,0.003758965267,1,0.1224489796,0.03509089576,0.001411219069,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"python 3.6.4,scikit-learn 0.19.1,windows 10.,CPU cores: 24",Observed Bug Behaviour,58,58,1,0.914893617,0.9962410347,0.003758965267,0.5833333333,0.07142857143,0.03509089576,0.001411219069,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@byrony can you provide code to reproduce?,Bug Reproduction,42,42,0.5,0.9179331307,0.9967708885,0.003229111537,1,0.07142857143,0.001411219069,0.007211566446,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"did you use CODEif __name__ == ""__main__""CODE?",Observed Bug Behaviour,42,46,1,0.9209726444,0.9967708885,0.003229111537,0.8571428571,0.0612244898,0.001411219069,0.007211566446,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,I've experienced a similar problem multiple times on my machine when using CODE or CODE as an argument for CODE but using the default scorer argument.,Observed Bug Behaviour,173,150,0.1428571429,0.9240121581,0.99947853,0.0005214699921,0.6428571429,0.2755102041,0.007211566446,0.0002286970723,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"*         Python 3.6.5,*         scikit-learn 0.19.1,*         Arch Linux,*         CPU cores: 8.",Observed Bug Behaviour,97,97,0.2857142857,0.9270516717,0.99947853,0.0005214699921,0.3333333333,0.1428571429,0.007211566446,0.0002286970723,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Here is the code I used:CODE,Observed Bug Behaviour,1509,28,0.4285714286,0.9300911854,0.99947853,0.0005214699921,0.1666666667,0.07142857143,0.007211566446,0.0002286970723,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"I know is a big dataset so I expected it would take some time to get results but then after 2 days running, it just stopped working (the script keeps executing but is not using any resource apart from RAM and swap).",Observed Bug Behaviour,215,215,0.5714285714,0.9331306991,0.99947853,0.0005214699921,1,0.4285714286,0.007211566446,0.0002286970723,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,![captura de pantalla de 2018-05-25 17-53-11] URL,Observed Bug Behaviour,146,50,0.7142857143,0.9361702128,0.99947853,0.0005214699921,0.2619047619,0.112244898,0.007211566446,0.0002286970723,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,![captura de pantalla de 2018-05-25 17-54-59] URL,Observed Bug Behaviour,146,50,0.8571428571,0.9392097264,0.99947853,0.0005214699921,0.2619047619,0.112244898,0.007211566446,0.0002286970723,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Thanks in advance!,Social Conversation,18,18,1,0.9422492401,0.99947853,0.0005214699921,0.07142857143,0.0306122449,0.007211566446,0.0002286970723,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@amueller I didn't use the CODE.,Observed Bug Behaviour,55,32,0.5,0.9452887538,0.9995643962,0.0004356038077,0.6,0.0612244898,0.0002286970723,0.00109431708,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,"Below is my code, it only works when CODE CODE",Observed Bug Behaviour,547,46,1,0.9483282675,0.9995643962,0.0004356038077,1,0.1020408163,0.0002286970723,0.00109431708,NONE,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,You're using XGBoost.,Investigation and Exploration,21,21,0.25,0.9513677812,0.9999752665,2.47E-05,0.2307692308,0.0306122449,0.00109431708,1.09E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"I don't know what they do internally, it's very possible that's the issue.",Investigation and Exploration,74,74,0.5,0.9544072948,0.9999752665,2.47E-05,1,0.1326530612,0.00109431708,1.09E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Can you try to see if adding the CODEif __name__CODE helps?,Investigation and Exploration,55,59,0.75,0.9574468085,0.9999752665,2.47E-05,0.8461538462,0.112244898,0.00109431708,1.09E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
7 2889_scikit-learn.doc,Otherwise I don't think there's a fix for that yet.,Solution Discussion,51,51,1,0.9604863222,0.9999752665,2.47E-05,0.7692307692,0.1020408163,0.00109431708,1.09E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,@Pazitos10 can you reproduce with synthetic data and/or smaller data?,Bug Reproduction,69,69,0.5,0.9635258359,0.9999756767,2.43E-05,0.625,0.1020408163,1.09E-06,1.02E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,I can't reproduce without your data and it would be good to reproduce in shorter time.,Social Conversation,86,86,1,0.9665653495,0.9999756767,2.43E-05,1,0.1632653061,1.09E-06,1.02E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@amueller Ok, I will run it again with 500k rows and will post the results.",Bug Reproduction,75,75,0.5,0.9696048632,0.9999794882,2.05E-05,1,0.1530612245,1.02E-05,4.82E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Thanks!,Social Conversation,7,7,1,0.9726443769,0.9999794882,2.05E-05,0.06666666667,0.01020408163,1.02E-05,4.82E-05,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@amueller, running the script with 50k rows works as expected.",Bug Reproduction,62,62,0.25,0.9756838906,0.9999975983,2.40E-06,0.2564102564,0.1020408163,4.82E-05,1.35E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"The script ends correctly, showing the results as follows (sorry, I meant 50k not 500k): ![captura de pantalla de 2018-05-26 13-09-00] URL  ![captura de pantalla de 2018-05-26 13-09-51] URL ",Bug Reproduction,382,190,0.5,0.9787234043,0.9999975983,2.40E-06,1,0.3979591837,4.82E-05,1.35E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,The problem is that I don't know if these results are going to be the best for my whole dataset.,Bug Reproduction,96,96,0.75,0.9817629179,0.9999975983,2.40E-06,0.5128205128,0.2040816327,4.82E-05,1.35E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Any advice?,Bug Reproduction,11,11,1,0.9848024316,0.9999975983,2.40E-06,0.05128205128,0.02040816327,4.82E-05,1.35E-06,NONE,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,Seems like you're running out of ram.,Investigation and Exploration,37,37,0.5,0.9878419453,0.9999981055,1.89E-06,0.4666666667,0.07142857143,1.35E-06,5.05E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"Maybe try using Keras instead, it's likely a better solution for large scale neural nets.",Solution Discussion,89,89,1,0.990881459,0.9999981055,1.89E-06,1,0.1530612245,1.35E-06,5.05E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
7 2889_scikit-learn.doc,"@amueller Oh, ok.",Social Conversation,17,17,1,0.9939209726,1,0,3,0.0306122449,5.05E-06,0,NONE,FALSE,FALSE,FALSE,TRUE
7 2889_scikit-learn.doc,I will try using Keras instead.,Solution Discussion,31,31,2,0.9969604863,1,0,6,0.0612244898,5.05E-06,0,NONE,FALSE,FALSE,FALSE,TRUE
7 2889_scikit-learn.doc,Thank you again!,Social Conversation,16,16,3,1,1,0,3,0.0306122449,5.05E-06,0,NONE,FALSE,FALSE,FALSE,TRUE
8 10521_scikit-learn.doc,Rethinking the CategoricalEncoder API ?,Solution Discussion,39,39,0.04545454545,0.004,0,1,0.08,0.07547169811,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"Based on some discussions we are having here and issues that are opened, we are having some doubts that CODE  URL  was the good choice of name (and since it is not released yet we have some room for change).",Solution Discussion,274,207,0.09090909091,0.008,0,1,0.84,0.7924528302,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,So summary of how it is now:,Motivation,28,28,0.1363636364,0.012,0,1,0.14,0.1320754717,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,-         The class name CODE says what type of data it accepts (categorical data),Motivation,98,82,0.1818181818,0.016,0,1,0.28,0.2641509434,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,-         The keyword argument CODE specifies *how* to encode those data,Motivation,78,72,0.2272727273,0.02,0,1,0.22,0.2075471698,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,But what to do in the following cases:,Motivation,38,38,0.2727272727,0.024,0,1,0.16,0.1509433962,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"-         We want to add more encoding options (eg binary encoding, mean target encoding, unary encoding, ...).",Motivation,111,111,0.3181818182,0.028,0,1,0.32,0.3018867925,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"-         We want to add an option specific to one of the encodings (eg for 'onehot' encoding to drop the first (redundant) column, or for 'ordinal' encoding base the order of the categories on the frequency, ...).",Motivation,214,214,0.3636363636,0.032,0,1,0.72,0.679245283,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"The problem here is that we then need to add additional keyword arguments to CODE that are or are not active depending on what you passed for CODE kwarg, which is not the nicest API design.",Motivation,211,189,0.4090909091,0.036,0,1,0.72,0.679245283,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,"For that last problem, we already had this with the CODE option, which was only relevant for 'onehot' and not for 'ordinal', and which we solved with having both 'onehot' and 'onehot-dense' encoding options and not a CODE keyword.",Solution Discussion,249,230,0.4545454545,0.04,0,1,0.8,0.7547169811,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,But such an approach also does not scale.,Solution Discussion,41,41,0.5,0.044,0,1,0.16,0.1509433962,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"There was a related discussion on the naming in that PR, as currently the name says *how* it encodes, not what type of data it gets (in the current design, it accepts already encoded integers, not actual categorical data.",Solution Discussion,221,221,0.5454545455,0.048,0,1,0.78,0.7358490566,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"In that regard, to be consistent with CategoricalEncoder, it might better be named OrdinalEncoder because it needs ordinal data as input).",Solution Discussion,138,138,0.5909090909,0.052,0,1,0.42,0.3962264151,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,What are the options forward:,Solution Discussion,29,29,0.6363636364,0.056,0,1,0.1,0.09433962264,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"1)         Keep things as we have it now in master, and be be OK with adding some new options to the single class (an important question which is hard to answer now, is how much new features we will want to add in the future).",Solution Discussion,226,226,0.6818181818,0.06,0,1,0.92,0.8679245283,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"2)         Switch the naming scheme and have a bunch of 'categorical encoders' where the name says how it encodes (OnehotEncoder, OrdinalEncoder, and later maybe BinaryEncoder, UnaryEncoder, ...)",Solution Discussion,195,195,0.7272727273,0.064,0,1,0.54,0.5094339623,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,So it is a bit a trade-off of potential build up of number of classes vs number of keyword arguments in a single class.,Solution Discussion,119,119,0.7727272727,0.068,0,1,0.5,0.4716981132,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"One problem with the second approach (and one of the reasons we went with CODE in the first place, even before we added the multiple encoding options), is that there is already a CODE, which has a different API than the CODE.",Solution Discussion,268,225,0.8181818182,0.072,0,1,0.84,0.7924528302,0,0.0003718520274,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
8 10521_scikit-learn.doc,"And, there is not really a good other name we could use for the encoder that does one-hot encoding.",Solution Discussion,99,99,0.8636363636,0.076,0,1,0.4,0.3773584906,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"However, I think that, with some temporary ugly hacks, we could reuse the name, if we are OK with deprecating the current attributes (and I think we agree it are not the most useful attributes).",Solution Discussion,194,194,0.9090909091,0.08,0,1,0.7,0.6603773585,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,"The idea would be that if you fit the class with string data, you get the new behaviour, and if you fit the class with integer data, you get a deprecation warning indicating the default behaviour will change (and indicating which keyword to specify to get rid of the warning).",Solution Discussion,276,276,0.9545454545,0.084,0,1,1,0.9433962264,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,cc @jnothman @amueller @GaelVaroquaux @rth,Contribution and Commitment,42,42,1,0.088,0,1,0.1,0.09433962264,0,0.0003718520274,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
8 10521_scikit-learn.doc,Thanks for the summary @jorisvandenbossche.,Social Conversation,43,43,0.5,0.092,0.0001767079666,0.999823292,0.09433962264,0.09433962264,0.0003718520274,0.00118794172,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I think I am in favor of option 2: reuse CODE class, deprecate the weird attributes and add a constructor parameter to select the behavior with a future warning that says that the default behavior will change but makes it easy to silence that warning just by passing a value for that option.",Solution Discussion,302,291,1,0.096,0.0001767079666,0.999823292,1,1,0.0003718520274,0.00118794172,MEMBER,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"The idea of reverting CategoricalEncoder makes me quite sad, but I thinkyou're right that future users would be less mystified by option 2.",Solution Discussion,139,139,0.3333333333,0.1,0.0007412302777,0.9992587697,0.9583333333,0.4339622642,0.00118794172,5.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,My mainconcern is that we have tried implementing this as a change to OHE for along time and it never flew.,Solution Discussion,107,107,0.6666666667,0.104,0.0007412302777,0.9992587697,0.875,0.3962264151,0.00118794172,5.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Perhaps it would be good to attempt themodifications to the OneHotEncoder docstring according to that proposedchange, so we can see if it looks sane.",Solution Discussion,149,149,1,0.108,0.0007412302777,0.9992587697,1,0.4528301887,0.00118794172,5.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,+1 to what Joel said,Social Conversation,20,20,0.3333333333,0.112,0.0007687859941,0.999231214,1,0.09433962264,5.80E-05,0.0007158783929,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,â£Sent from my phone.,Social Conversation,21,21,0.6666666667,0.116,0.0007687859941,0.999231214,0.8,0.07547169811,5.80E-05,0.0007158783929,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Please forgive typos and briefness.â,Social Conversation,36,36,1,0.12,0.0007687859941,0.999231214,1,0.09433962264,5.80E-05,0.0007158783929,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"To be clear, it would not be a revert, it would be a refactor / rename that keeps all functionality!",Solution Discussion,100,100,0.3333333333,0.124,0.001108978882,0.9988910211,0.8260869565,0.358490566,0.0007158783929,0.001908879324,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"But I also like the ""CategoricalEncoder"" name, that would indeed be sad.",Social Conversation,72,72,0.6666666667,0.128,0.001108978882,0.9988910211,0.5217391304,0.2264150943,0.0007158783929,0.001908879324,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"That said, I will quickly try to do the changes to have an idea how possible it is to integrate this in OnehotEncoder.",Solution Discussion,118,118,1,0.132,0.001108978882,0.9988910211,1,0.4339622642,0.0007158783929,0.001908879324,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,It's not yet complete (no deprecation warnings and new attributes are not yet calculated in old behaviour).,Task Progress,107,107,0.0625,0.136,0.002016098271,0.9979839017,0.5151515152,0.320754717,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,The main API question is about the format of the input data.,Solution Discussion,60,60,0.125,0.14,0.002016098271,0.9979839017,0.3636363636,0.2264150943,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"So as a recap, there are **two different ways we currently process the categorical data**:",Solution Discussion,90,90,0.1875,0.144,0.002016098271,0.9979839017,0.4545454545,0.2830188679,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"1)         As actual, not yet encoded (integer or string), categorical data (how it is done in CODE) -> infer categories from the unique values in the training data",Solution Discussion,180,164,0.25,0.148,0.002016098271,0.9979839017,0.8484848485,0.5283018868,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"2)         As integer, already encoded data (how it is done in the current CODE) -> infer categories from the maximum value in the training data",Solution Discussion,155,144,0.3125,0.152,0.002016098271,0.9979839017,0.7575757576,0.4716981132,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,The question is: **do we find both cases worth supporting?**,Solution Discussion,60,60,0.375,0.156,0.002016098271,0.9979839017,0.303030303,0.1886792453,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Thus, in the potentially merged OneHotEncoder, do we keep the ability to do both, or do we fully deprecate and then remove the ability to process ordinal input?",Solution Discussion,160,160,0.4375,0.16,0.002016098271,0.9979839017,0.8484848485,0.5283018868,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"If want the ability to process both, we can add a boolean keyword to specify the input data type (for now I use CODE, but other ideas are CODE,  ...)",Solution Discussion,182,149,0.5,0.164,0.002016098271,0.9979839017,0.9090909091,0.5660377358,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"For the deprecation period, we have to support both anyway, and also have to introduce a keyword to choose the behaviour (to be able to silence the warning and choose the new behaviour).",Solution Discussion,186,186,0.5625,0.168,0.002016098271,0.9979839017,1,0.6226415094,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,So in principle we could just keep the keyword afterwards.,Solution Discussion,58,58,0.625,0.172,0.002016098271,0.9979839017,0.303030303,0.1886792453,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Given that we want to handle both, an overview of how OneHotEncoder would work:",Solution Discussion,79,79,0.6875,0.176,0.002016098271,0.9979839017,0.4242424242,0.2641509434,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         for now CODE, and we infer the default based on the data",Solution Discussion,82,66,0.75,0.18,0.002016098271,0.9979839017,0.3939393939,0.2452830189,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,-         if int-like data (handled before by OneHotEncoder) CODE is internally set to True and a deprecation warning is raised.,Solution Discussion,139,128,0.8125,0.184,0.002016098271,0.9979839017,0.6363636364,0.3962264151,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"If the user wants to keep the current behaviour, it can manually specify it as CODE to silence the warning.",Solution Discussion,138,107,0.875,0.188,0.002016098271,0.9979839017,0.6060606061,0.3773584906,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"If the user wants to keep the current behaviour, it can manually specify it as",Usage,78,78,0.9375,0.192,0.002016098271,0.9979839017,0.4545454545,0.2830188679,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         if the input is not int-like, we set CODE internally to False and without warning use the new behaviour (= the current CategoricalEncoder behaviour)",Solution Discussion,169,158,1,0.196,0.002016098271,0.9979839017,0.7878787879,0.4905660377,0.001908879324,0.007460001584,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,I'm still not sure what you're suggesting is the practical difference due to inferring categories from the max value.,Motivation,117,117,1,0.2,0.005561168928,0.9944388311,1,0.358490566,0.007460001584,0.005415496481,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,@jnothman I suppose you acknowledge there *can* be a difference in practice?,Motivation,76,76,0.125,0.204,0.00813466941,0.9918653306,0.4444444444,0.2264150943,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,(the output you get depending on the data you have),Motivation,51,51,0.25,0.208,0.00813466941,0.9918653306,0.3703703704,0.1886792453,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"But whether this difference is important in practice, I don't know.",Social Conversation,67,67,0.375,0.212,0.00813466941,0.9918653306,0.4074074074,0.2075471698,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,That's where I would like to see feedback.,Social Conversation,42,42,0.5,0.216,0.00813466941,0.9918653306,0.2962962963,0.1509433962,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Whether anybody actually *wants* this ""max value""-based method, or whether we are fine with (in the future, after deprecation) only having the ""unique values""-based method.",Expected Behaviour,172,172,0.625,0.22,0.00813466941,0.9918653306,0.9259259259,0.4716981132,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I think I personally would never need this max-value based method, but the OneHotEncoder has been like that for many years (for good reason or not?).",Expected Behaviour,149,149,0.75,0.224,0.00813466941,0.9918653306,1,0.5094339623,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Actually deprecating the max-value based categorization would certainly make the implementation (after deprecation) simpler.,Solution Discussion,124,124,0.875,0.228,0.00813466941,0.9918653306,0.5555555556,0.2830188679,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"And if we choose for that route, I agree the option should rather be CODE rather than CODE/CODE",Solution Discussion,137,95,1,0.232,0.00813466941,0.9918653306,0.7037037037,0.358490566,0.005415496481,0.0003523935226,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"Remind me what the actual difference in output is, when n_values='auto',please?",Solution Discussion,79,79,0.5,0.236,0.008302130491,0.9916978695,0.7857142857,0.2075471698,0.0003523935226,0.0002821483201,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I had thought the active_features_ thing made them basicallyidentical, but I'm probably forgetting something.",Solution Discussion,109,109,1,0.24,0.008302130491,0.9916978695,1,0.2641509434,0.0003523935226,0.0002821483201,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Aha, that clarifies our misunderstanding :-)",Social Conversation,44,44,0.08333333333,0.244,0.00843621032,0.9915637897,0.1363636364,0.1132075472,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I misunderstood how the current OneHotEncoder is actually working.,Social Conversation,66,66,0.1666666667,0.248,0.00843621032,0.9915637897,0.2045454545,0.1698113208,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Suppose you have one feature with values [2, 3, 5, 2].",Investigation and Exploration,54,54,0.25,0.252,0.00843621032,0.9915637897,0.25,0.2075471698,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I thought the current OneHotEncoder would have categories [0, 1, 2, 3, 4, 5] (while current CategoricalEncoder would have categories [2, 3, 5]).",Investigation and Exploration,144,144,0.3333333333,0.256,0.00843621032,0.9915637897,0.5227272727,0.4339622642,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"But you are right that the CODE is also only [2, 3, 5], essentially making them the same with the default value of CODE.",Investigation and Exploration,147,120,0.4166666667,0.26,0.00843621032,0.9915637897,0.5454545455,0.4528301887,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"So it is only the case where you pass an integer to CODE (like CODE for categories=[0, 1, 2, 3, 4, 5] in the above case) to specify the number of categories that will actually be an API change (deprecated / removed).",Solution Discussion,230,216,0.5,0.264,0.00843621032,0.9915637897,0.9318181818,0.7735849057,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,Sorry for the confusion.,Social Conversation,24,24,0.5833333333,0.268,0.00843621032,0.9915637897,0.09090909091,0.07547169811,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"In that light, I think we even don't need the CODE option.",Solution Discussion,67,58,0.6666666667,0.272,0.00843621032,0.9915637897,0.2727272727,0.2264150943,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,The other difference is the handling of unseen categories.,Solution Discussion,58,58,0.75,0.276,0.00843621032,0.9915637897,0.2045454545,0.1698113208,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"With the current behaviour of the OneHotEncoder, if the unseen values are within the range(0, max), it will not raise an error even if CODE (the default).",Solution Discussion,173,154,0.8333333333,0.28,0.00843621032,0.9915637897,0.6136363636,0.5094339623,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,But also that can be solved separately by in such a case raising a warning that the user should set CODE manually to keep the existing behaviour.,Solution Discussion,166,145,0.9166666667,0.284,0.00843621032,0.9915637897,0.6136363636,0.5094339623,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"The only feature we would loose is the distinction between unknown categories that are within the range(0, max) (by the current OneHotEncoder not regarded as 'unknown') and those that are bigger than that (> max, those are currently already regarded as unknown by the OneHotEncoder).",Solution Discussion,283,283,1,0.288,0.00843621032,0.9915637897,1,0.8301886792,0.0002821483201,0.0005570969934,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"unless there is good reason to maintain current behaviour, weshould just have a legacy_mode to slowly bring us to the future.",Solution Discussion,125,125,1,0.292,0.008700948629,0.9912990514,1,0.3962264151,0.0005570969934,2.86E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Can you clarify to which aspect this ""no"" refers?",Solution Discussion,49,49,0.5,0.296,0.008714541549,0.9912854585,0.8181818182,0.1698113208,2.86E-05,0.006093236204,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,To the fact that I think a CODE is not needed?,Solution Discussion,55,46,1,0.3,0.008714541549,0.9912854585,1,0.2075471698,2.86E-05,0.006093236204,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"yes, to the idea that you can just make something that is both backwardscompatible and what we want going forward",Solution Discussion,113,113,1,0.304,0.01161011102,0.988389889,1,0.3773584906,0.006093236204,0.001702813758,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,That was not what I tried to suggest.,Social Conversation,37,37,0.25,0.308,0.0124193059,0.9875806941,0.2,0.1509433962,0.001702813758,0.001512314996,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I wanted to make clear that think it is possible to not have a CODE keyword, not by having it magically both backwards compat and what we want in the future, but by deprecating the behaviour of the existing keywords.",Solution Discussion,225,216,0.5,0.312,0.0124193059,0.9875806941,1,0.7547169811,0.001702813758,0.001512314996,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,So to be concrete: a non-default value of CODE can be deprecated and has to be replaced by CODE specification.,Solution Discussion,124,110,0.75,0.316,0.0124193059,0.9875806941,0.525,0.3962264151,0.001702813758,0.001512314996,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,CODE in case of integer data should be set explicitly by the user to choose either full ignoring or full erroring instead of current mix (and otherwise deprecation warning is raised).,Solution Discussion,194,183,1,0.32,0.0124193059,0.9875806941,0.775,0.5849056604,0.001702813758,0.001512314996,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"so if I do .fit([[5]]).transform([[4]]), for which values of n_values,categories and handle_umknown will that raise an error?",Usage,125,125,1,0.324,0.01313797378,0.9868620262,1,0.3396226415,0.001512314996,0.0001354311937,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"can we just make it so that during deprecation, categories must be setexplicitly, and legacy mode with warnings is otherwise in effect?",Solution Discussion,135,135,0.5,0.328,0.0132023321,0.9867976679,1,0.4150943396,0.0001354311937,0.0659277494,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Is thatwhat you are suggesting?,Social Conversation,31,31,1,0.332,0.0132023321,0.9867976679,0.2272727273,0.09433962264,0.0001354311937,0.0659277494,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Yes, it might be still missing case, but I *think* this is possible (will check by actual coding it next week).",Solution Discussion,111,111,0.08333333333,0.336,0.0445318871,0.9554681129,0.488372093,0.3962264151,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,The different 'legacy' cases:,Solution Discussion,29,29,0.1666666667,0.34,0.0445318871,0.9554681129,0.09302325581,0.07547169811,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         n_values='auto' (the default),Solution Discussion,39,39,0.25,0.344,0.0445318871,0.9554681129,0.09302325581,0.07547169811,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         handle_unknown='ignore'  -> fine, no change in behaviour",Solution Discussion,66,66,0.3333333333,0.348,0.0445318871,0.9554681129,0.1860465116,0.1509433962,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         handle_unknown='error' -> Problem, values in range are still ignored, values above range error",Solution Discussion,104,104,0.4166666667,0.352,0.0445318871,0.9554681129,0.3023255814,0.2452830189,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         Possible solution:,Solution Discussion,28,28,0.5,0.356,0.0445318871,0.9554681129,0.06976744186,0.05660377358,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         in fit, if the range is consecutive => fine, no change in behaviour (for all people that now combined LabelEncoder with it, which is a typical use case I think)",Solution Discussion,170,170,0.5833333333,0.36,0.0445318871,0.9554681129,0.6976744186,0.5660377358,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         if this is not the case: raise deprecation warning that they have to set categories explicitly to keep this behaviour (and internally use legacy mode),Solution Discussion,160,160,0.6666666667,0.364,0.0445318871,0.9554681129,0.6046511628,0.4905660377,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         n_values=value,Solution Discussion,24,24,0.75,0.368,0.0445318871,0.9554681129,0.06976744186,0.05660377358,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         this can be translated to categories=[range(value)] internally, and raise deprecation warning that user should do that themselves in the future",Solution Discussion,153,153,0.8333333333,0.372,0.0445318871,0.9554681129,0.488372093,0.3962264151,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         in this case CODE work as expected,Solution Discussion,75,44,0.9166666667,0.376,0.0445318871,0.9554681129,0.1860465116,0.1509433962,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"The deprecation warning in case of CODE will only be raise in CODE and not upon construction (which is not really ideal), but it is only in fit that we know that the user is passing it numeric data and not string data.",Solution Discussion,232,218,1,0.38,0.0445318871,0.9554681129,1,0.8113207547,0.0659277494,0.0003508368422,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,we don't usually raise warnings until fit in any case so don't worry aboutthat.,Solution Discussion,79,79,0.1666666667,0.384,0.04469860843,0.9553013916,0.6666666667,0.2641509434,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,that strategy sounds mostly good.,Social Conversation,33,33,0.3333333333,0.388,0.04469860843,0.9553013916,0.2380952381,0.09433962264,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I'm not actually sure if we should be sniffing for strings in the data,though.",Solution Discussion,78,78,0.5,0.392,0.04469860843,0.9553013916,0.7142857143,0.2830188679,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,You basically want it to be: legacy mode is active if categories isnot set *and* if the data is all integers?,Solution Discussion,109,109,0.6666666667,0.396,0.04469860843,0.9553013916,1,0.3962264151,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"One question: if categories and n_values parameters are their default, dowe publish categories_?",Solution Discussion,96,96,0.8333333333,0.4,0.04469860843,0.9553013916,0.619047619,0.2452830189,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"If n_values is set explicitly, do we publishcategories_?",Solution Discussion,56,56,1,0.404,0.04469860843,0.9553013916,0.380952381,0.1509433962,0.0003508368422,0.0622981545,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Yes indeed (in practice it will more or less be the same),Solution Discussion,57,57,0.04761904762,0.408,0.07430334202,0.925696658,0.2727272727,0.2264150943,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I personally would already as much as possible provide the attributes of the new interface, even in legacy mode.",Solution Discussion,112,112,0.09523809524,0.412,0.07430334202,0.925696658,0.4318181818,0.358490566,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,So in both case I would calculate CODE (even if it would be a bit more work),Solution Discussion,85,76,0.1428571429,0.416,0.07430334202,0.925696658,0.3863636364,0.320754717,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"So I tried to put the above logic in code (will push some updates to the PR), and I have one more question for the case of integer data when CODE or CODE is not set (typical case for 'legacy_mode').",Task Progress,212,198,0.1904761905,0.42,0.07430334202,0.925696658,0.9090909091,0.7547169811,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"The problem lies in the fact that if the inferred categories are simply a consecutive range (0, 1, 2, 3, ... max), there is no difference between the new and old (legacy) behaviour, and we don't necessarily need to raise a deprecation warning.",Solution Discussion,243,243,0.2380952381,0.424,0.07430334202,0.925696658,0.9545454545,0.7924528302,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Some possibilities to do in this specific case:,Solution Discussion,47,47,0.2857142857,0.428,0.07430334202,0.925696658,0.1818181818,0.1509433962,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"1)         Detect this case (that the inferred categories are a consecutive range), and in that case don't raise a warning.",Solution Discussion,123,123,0.3333333333,0.432,0.07430334202,0.925696658,0.4772727273,0.3962264151,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,-         This is possible to detect (with a little bit of extra code complexity) as we are already in fit anyhow,Solution Discussion,113,113,0.380952381,0.436,0.07430334202,0.925696658,0.4772727273,0.3962264151,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         I *think* this will be a common case when using OneHotEncoder with integer data, and a case where the user actually does not need to worry about our refactoring, so it would be nice to not bother him/her with a warning",Solution Discussion,228,228,0.4285714286,0.44,0.07430334202,0.925696658,0.9772727273,0.8113207547,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"2) Always raise a warning, and indicate in the warning message what to do if you are in such a case (in addition to an explanation what to do if you don't have a consecutive range):",Solution Discussion,181,181,0.4761904762,0.444,0.07430334202,0.925696658,0.8409090909,0.6981132075,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         If they know they have only consecutive ranges as categories, they want to ignore the warning, so we can add to the warning message an explanation how to do this (add a code sample with filterwarnings they can copy paste)",Solution Discussion,231,231,0.5238095238,0.448,0.07430334202,0.925696658,0.9318181818,0.7735849057,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         A potential advantage of this is that we can also add to the warning message that if they used the LabelEncoder to create the integers, they can now directly use OneHotEncoder (I think this currently is a typical usage pattern).",Solution Discussion,238,238,0.5714285714,0.452,0.07430334202,0.925696658,0.9318181818,0.7735849057,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"That way, the warning will also go away",Solution Discussion,39,39,0.619047619,0.456,0.07430334202,0.925696658,0.1818181818,0.1509433962,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,3) Always raise a warning but provide a keyword to silence it (eg CODE),Solution Discussion,86,71,0.6666666667,0.46,0.07430334202,0.925696658,0.3181818182,0.2641509434,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"-         If we find the advice to use a CODE statement (see point 2 above) too cumbersome, we could also add a keyword to obtain the same result",Solution Discussion,157,145,0.7142857143,0.464,0.07430334202,0.925696658,0.6363636364,0.5283018868,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,-         Disadvantage of this is introducing a keyword that will not be needed anymore in a few releases when the deprecations are cleaned up.,Solution Discussion,143,143,0.7619047619,0.468,0.07430334202,0.925696658,0.5454545455,0.4528301887,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I am personally in favor of option 1 or 2.,Social Conversation,42,42,0.8095238095,0.472,0.07430334202,0.925696658,0.2272727273,0.1886792453,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Using the LabelEncoder before OneHotEncoder seems to be a typical pattern (from a quick github search), and in those case you *always* have consecutive ranges, and there will never be a change in behaviour with the new implementation, so we shouldn't warn for it.",Solution Discussion,263,263,0.8571428571,0.476,0.07430334202,0.925696658,1,0.8301886792,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"On the other hand, if we warn we can point them to the fact that *if* they used LabelEncoder, they no longer need to do it.",Solution Discussion,123,123,0.9047619048,0.48,0.07430334202,0.925696658,0.5909090909,0.4905660377,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Which would be nice to actually give this advice explicitly.,Solution Discussion,60,60,0.9523809524,0.484,0.07430334202,0.925696658,0.2272727273,0.1886792453,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,The question is how frequently users have such consecutive integers as categories without having used LabelEncoder as the previous step ..,Motivation,138,138,1,0.488,0.07430334202,0.925696658,0.4772727273,0.3962264151,0.0622981545,0.000152943848,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"In case we don't provide the CODE keyword, the only way to obtain the new behaviour is by manually passing CODE, which can be a slight inconvenience.",Solution Discussion,180,149,0.25,0.492,0.07437602253,0.9256239775,0.6279069767,0.5094339623,0.000152943848,0.003060433641,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"That might be a reason to favor option 3 and give up my objection on introducing a temporary keyword CODE (but also not fully sure it is worth it, as this would be the only case\* where such a keyword is actually needed)",Solution Discussion,235,220,0.5,0.496,0.07437602253,0.9256239775,1,0.8113207547,0.000152943848,0.003060433641,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"\* this only case = integer data with inferred categories that are not consecutive range, and where you cannot / don't want to set the categories manually or set handle_unknown to ignore.",Solution Discussion,187,187,0.75,0.5,0.07437602253,0.9256239775,0.6976744186,0.5660377358,0.000152943848,0.003060433641,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Sorry for all the long text, but it's quite complex :)",Social Conversation,54,54,1,0.504,0.07437602253,0.9256239775,0.2558139535,0.2075471698,0.000152943848,0.003060433641,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"We're only talking about the case where n_values is unset, right?",Solution Discussion,65,65,0.25,0.508,0.07583037256,0.9241696274,0.5238095238,0.2075471698,0.003060433641,8.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I'm fine with 1., and it would not be any more expensive, since autoalready needs to examine the set of labels.",Solution Discussion,111,111,0.5,0.512,0.07583037256,0.9241696274,1,0.3962264151,0.003060433641,8.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I could also accept, forsimplicity, a variant of 3.",Solution Discussion,51,51,0.75,0.516,0.07583037256,0.9241696274,0.4285714286,0.1698113208,0.003060433641,8.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"that was just ""OneHotEncoder running in legacymode. Set categories='auto' for slightly different behaviour without awarning.""",Solution Discussion,125,125,1,0.52,0.07583037256,0.9241696274,0.7142857143,0.2830188679,0.003060433641,8.04E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Yes (the other case easily be translated in its equivalent CODE value, with a nice deprecation warning, and without different in new and legacy behaviour)",Solution Discussion,162,154,0.25,0.524,0.07586856219,0.9241314378,0.5555555556,0.4716981132,8.04E-05,0.0003477234814,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"Ah, that sounds like a good idea!",Social Conversation,33,33,0.5,0.528,0.07586856219,0.9241314378,0.1555555556,0.1320754717,8.04E-05,0.0003477234814,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,(irregardless of whether detecting the consecutive categories case or not).,Solution Discussion,75,75,0.75,0.532,0.07586856219,0.9241314378,0.2222222222,0.1886792453,8.04E-05,0.0003477234814,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"So we set in the code the default of CODE to None (without changing the semantics of its default), so we know if the user set it explicitly, and in that way it is a nice way to indicate CODE without needing that extra keyword.",Solution Discussion,249,226,1,0.536,0.07586856219,0.9241314378,1,0.8490566038,8.04E-05,0.0003477234814,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,"Yes, but only if we want to warn every time someone uses it without passingcategories.",Solution Discussion,86,86,0.5,0.54,0.07603380402,0.923966196,0.6,0.2830188679,0.0003477234814,0.09759957938,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"It's the cheap implementation approach, but it might beunnecessarily verbose for the users, which is why I would prefer 1 if itcan be done simply.",Solution Discussion,146,146,1,0.544,0.07603380402,0.923966196,1,0.4716981132,0.0003477234814,0.09759957938,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,What fresh hell is this :-/,Social Conversation,27,27,1,0.548,0.1224141434,0.8775858566,1,0.1132075472,0.09759957938,3.64E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,OR we could name the new one CODEDummyEncoderCODE ;) (though that is a bit conflicting with the DummyClassifier),Solution Discussion,108,112,1,0.552,0.122431435,0.877568565,1,0.3396226415,3.64E-05,3.70E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,@amueller Don't read all of the above!,Social Conversation,38,38,0.3333333333,0.556,0.122433192,0.877566808,0.3333333333,0.1320754717,3.70E-06,1.77E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I was just planning to make a nice summary for new readers of the issue.,Social Conversation,72,72,0.6666666667,0.56,0.122433192,0.877566808,0.7142857143,0.2830188679,3.70E-06,1.77E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,The above discussion is overly complicated (also because I was still not fully understanding the current complex behaviour of OneHotEncoder ... :-)),Social Conversation,148,148,1,0.564,0.122433192,0.877566808,1,0.3962264151,3.70E-06,1.77E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I think @GaelVaroquaux was against that because ""one-hot"" is known to be this in more fields (and we already use 'Dummy' for other things in scikit-learn ...)",Solution Discussion,158,158,1,0.568,0.1224416066,0.8775583934,1,0.5283018868,1.77E-05,3.89E-06,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Redoing this for consistency in naming is not worth it imho.,Motivation,60,60,0.3333333333,0.572,0.122443456,0.877556544,1,0.2075471698,3.89E-06,7.01E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,We are not consistent in naming anywhere.,Motivation,41,41,0.6666666667,0.576,0.122443456,0.877556544,0.6363636364,0.1320754717,3.89E-06,7.01E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Could you summarize the discussions that lead to this?,Solution Discussion,54,54,1,0.58,0.122443456,0.877556544,0.8181818182,0.1698113208,3.89E-06,7.01E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I think ""dummy"" is what statisticians use and it's what pandas uses.",Solution Discussion,68,68,1,0.584,0.1224467849,0.8775532151,1,0.2264150943,7.01E-06,1.69E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"The top post is still accurate and worth a read, and it summarizes the reasoning for not keeping CategoricalEncoder (which does not mean that we need to use OneHotEncoder instead of eg DummyEncoder, that's a separate question)",Solution Discussion,226,226,1,0.588,0.1224548297,0.8775451703,1,0.6981132075,1.69E-05,2.22E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I read the top post.,Social Conversation,20,20,0.3333333333,0.592,0.1224653711,0.8775346289,0.3125,0.09433962264,2.22E-05,0.0001037138308,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"That's what I referred to when I said ""redoing this for consistency is not worth it"".",Motivation,85,85,0.6666666667,0.596,0.1224653711,0.8775346289,1,0.3018867925,2.22E-05,0.0001037138308,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Can you explain that?,Motivation,21,21,1,0.6,0.1224653711,0.8775346289,0.25,0.07547169811,2.22E-05,0.0001037138308,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"With consistency, are you pointing to the naming scheme of ""what it accepts"" vs ""what it does"" ?",Motivation,96,96,0.3333333333,0.604,0.122514657,0.877485343,1,0.320754717,0.0001037138308,3.56E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"If so, that was only a minor reason.",Motivation,36,36,0.6666666667,0.608,0.122514657,0.877485343,0.4705882353,0.1509433962,0.0001037138308,3.56E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,For me it is mainly a question of scalability in adding more features to a single class.,Motivation,88,88,1,0.612,0.122514657,0.877485343,1,0.320754717,0.0001037138308,3.56E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I don't see how the proposed change would help with the missing values that much.,Motivation,81,81,0.3333333333,0.616,0.1225315788,0.8774684212,1,0.2830188679,3.56E-05,8.29E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,And having incompatible options is something that happens often in scikit-learn.,Motivation,80,80,0.6666666667,0.62,0.1225315788,0.8774684212,0.8,0.2264150943,3.56E-05,8.29E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Not ideal, but also not a big deal imho.",Motivation,40,40,1,0.624,0.1225315788,0.8774684212,0.6,0.1698113208,3.56E-05,8.29E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"It does not help *as such*, but it makes it less complex to have specific options specifically tailored to the different encoding types.",Motivation,136,136,0.25,0.628,0.1225709705,0.8774290295,0.9583333333,0.4339622642,8.29E-05,3.72E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Currently it is certainly still OK, there are not too many incompatible options (but also partly because I moved CODE into the CODE option).",Motivation,161,140,0.5,0.632,0.1225709705,0.8774290295,1,0.4528301887,8.29E-05,3.72E-05,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,And what if someone wants to add a 'binary encoding'?,Motivation,53,53,0.75,0.636,0.1225709705,0.8774290295,0.4166666667,0.1886792453,8.29E-05,3.72E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Or a '(mean) target encoder'?,Motivation,29,29,1,0.64,0.1225709705,0.8774290295,0.2083333333,0.09433962264,8.29E-05,3.72E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"The ""mean target encoder"" is CODECountTransformerCODE, there's a PR for that ;)",Potential New Issues and Requests,75,79,1,0.644,0.1225886321,0.8774113679,1,0.2264150943,3.72E-05,1.95E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,Do you have a link for that?,Potential New Issues and Requests,28,28,0.5,0.648,0.122597879,0.877402121,0.875,0.1320754717,1.95E-05,1.28E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Searching for ""CountTransformer"" does not give any results",Potential New Issues and Requests,58,58,1,0.652,0.122597879,0.877402121,1,0.1509433962,1.95E-05,1.28E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Sorry, CountFeaturizer #9614",Potential New Issues and Requests,28,28,1,0.656,0.1226039819,0.8773960181,1,0.05660377358,1.28E-05,0.0001134430832,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"It's certainly related, but not exactly a mean target encoding.",Potential New Issues and Requests,63,63,0.5,0.66,0.1226578912,0.8773421088,0.3225806452,0.1886792453,0.0001134430832,1.38E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"Also, it adds columns, not replaces, so will not yet work out of the box for string categorical data (but that is more feedback on that PR, not to discuss here).",Potential New Issues and Requests,161,161,1,0.664,0.1226578912,0.8773421088,1,0.5849056604,0.0001134430832,1.38E-05,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Why is it not mean target encoding?,Potential New Issues and Requests,35,35,0.5,0.668,0.1226644565,0.8773355435,0.7777777778,0.1320754717,1.38E-05,4.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,But yeah let's not divert too much here ;),Social Conversation,42,42,1,0.672,0.1226644565,0.8773355435,1,0.1698113208,1.38E-05,4.24E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,So as a summary of the actual questions we need to answer (in this order!):,Solution Discussion,75,75,0.1111111111,0.676,0.1226846147,0.8773153853,0.32,0.3018867925,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"If not, the idea is to split it in different classes, one class for each type of encoding (currently 'onehot' and 'ordinal' encoding).",Solution Discussion,134,134,0.2222222222,0.68,0.1226846147,0.8773153853,0.46,0.4339622642,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"2.         If we split in multiple classes, we could (ideally?) use OneHotEncoder for the 'onehot' encoding, but this class already exists.",Solution Discussion,139,139,0.3333333333,0.684,0.1226846147,0.8773153853,0.44,0.4150943396,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"So, do we integrate the new 'onehot' encoding (which supports strings and has different parameters) in the existing OneHotEncoder class?",Solution Discussion,136,136,0.4444444444,0.688,0.1226846147,0.8773153853,0.4,0.3773584906,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Or do we choose another name?,Solution Discussion,29,29,0.5555555556,0.692,0.1226846147,0.8773153853,0.12,0.1132075472,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,(eg DummyEncoder),Solution Discussion,17,17,0.6666666667,0.696,0.1226846147,0.8773153853,0.04,0.03773584906,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"3.         If we choose to integrate into the existing OneHotEncoder, are we OK with the following consequences: we deprecate a bunch of the keywords/attributes of OneHotEncoder, and a specific usecase (automatically ignoring unseen values within the *range* of seen values) will not be possible anymore after deprecation period.",Solution Discussion,329,329,0.7777777778,0.7,0.1226846147,0.8773153853,1,0.9433962264,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Most of the discussion above was about question 3 (the complex details of how to integrate CategoricalEncoder(encoding='onehot') into OneHotEncoder).,Solution Discussion,149,149,0.8888888889,0.704,0.1226846147,0.8773153853,0.38,0.358490566,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,But let's first agree on a decision for the first 2 questions.,Solution Discussion,62,62,1,0.708,0.1226846147,0.8773153853,0.24,0.2264150943,4.24E-05,0.002223912518,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,the other factor for me is that everyone thinks the current auto mode inOneHotEncoder is weird.,Motivation,95,95,0.25,0.712,0.1237414412,0.8762585588,0.7272727273,0.3018867925,0.002223912518,0.001335631772,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,its implementation converting coo to csr is alsoweird.,Motivation,54,54,0.5,0.716,0.1237414412,0.8762585588,0.3636363636,0.1509433962,0.002223912518,0.001335631772,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,it deserves a redesign.,Motivation,23,23,0.75,0.72,0.1237414412,0.8762585588,0.1818181818,0.07547169811,0.002223912518,0.001335631772,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"and telling people ""if you want to one hotencode strings, go to CategoricalEncoder instead"" is awkward, because OHEis already intended for categoricals...",Motivation,154,154,1,0.724,0.1237414412,0.8762585588,1,0.4150943396,0.002223912518,0.001335631772,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,hrm.,Social Conversation,4,4,0.25,0.728,0.1243761474,0.8756238526,0.06666666667,0.01886792453,0.001335631772,0.000559237429,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I guess we kept OneHotEncoder because it's more efficient when it can be used....,Motivation,81,81,0.5,0.732,0.1243761474,0.8756238526,1,0.2830188679,0.001335631772,0.000559237429,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Ideally we would get rid of all the weird behaviors.,Motivation,52,52,0.75,0.736,0.1243761474,0.8756238526,0.6666666667,0.1886792453,0.001335631772,0.000559237429,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I kinda had wanted to deprecate it but then we didn't...,Social Conversation,56,56,1,0.74,0.1243761474,0.8756238526,0.7333333333,0.2075471698,0.001335631772,0.000559237429,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,It's not much more efficient.,Solution Discussion,29,29,0.5,0.744,0.1246419028,0.8753580972,0.2777777778,0.09433962264,0.000559237429,0.06743403226,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"And if LabelEncoder had fast paths for intsin range [0, n_values-1], if justified, that would be good enough.",Solution Discussion,109,109,1,0.748,0.1246419028,0.8753580972,1,0.3396226415,0.000559237429,0.06743403226,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"@amueller, are you persuaded by the issue that we ultimately want different additional parameters (e.g. drop_first, nan handling) depending on the encoding, and that justifies having a different discrete encoder for each encoding format?",Motivation,237,237,1,0.752,0.1566872592,0.8433127408,1,0.641509434,0.06743403226,0.1994432533,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I'll try to look at this in the spring break in two weeks, ok?",Contribution and Commitment,62,62,0.5,0.756,0.2514647759,0.7485352241,1,0.2641509434,0.1994432533,0.01102518884,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,not sure if I'll have time before that :-/,Social Conversation,42,42,1,0.76,0.2514647759,0.7485352241,0.6428571429,0.1698113208,0.1994432533,0.01102518884,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I hope this isn't the wrong place to ask but what does the current implementation do with tables that are mixed categorical and non-categorical within one column?,Expected Behaviour,162,162,0.125,0.764,0.2567040608,0.7432959392,1,0.5283018868,0.01102518884,0.001582365613,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Taking the example from https://github.com/pandas-dev/pandas/issues/17418,Expected Behaviour,73,73,0.25,0.768,0.2567040608,0.7432959392,0.1785714286,0.09433962264,0.01102518884,0.001582365613,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Consider the dataframe CODE which equals: CODE,Expected Behaviour,372,46,0.375,0.772,0.2567040608,0.7432959392,0.25,0.1320754717,0.01102518884,0.001582365613,NONE,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,DictVectorizer gives exactly what I need in this case.,Expected Behaviour,54,54,0.5,0.776,0.2567040608,0.7432959392,0.3214285714,0.1698113208,0.01102518884,0.001582365613,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,CODE,Expected Behaviour,136,4,0.625,0.78,0.2567040608,0.7432959392,0.03571428571,0.01886792453,0.01102518884,0.001582365613,NONE,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,This gives: CODE,Expected Behaviour,181,16,0.75,0.784,0.2567040608,0.7432959392,0.1071428571,0.05660377358,0.01102518884,0.001582365613,NONE,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,We can see the features names of the columns with: CODE,Expected Behaviour,133,55,0.875,0.788,0.2567040608,0.7432959392,0.3928571429,0.2075471698,0.01102518884,0.001582365613,NONE,FALSE,TRUE,FALSE,FALSE
8 10521_scikit-learn.doc,It would be great if the new CategoricalEncoder had an option to do the same.,Expected Behaviour,77,77,1,0.792,0.2567040608,0.7432959392,0.5357142857,0.2830188679,0.01102518884,0.001582365613,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I don't think we intend to handle that kind of mixed case,Solution Discussion,57,57,1,0.796,0.2574560174,0.7425439826,1,0.2264150943,0.001582365613,0.004623535334,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Thatâs a shame.,Social Conversation,15,15,0.1666666667,0.8,0.2596531697,0.7403468303,0.15,0.05660377358,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,One simple sub case is where a column is numerical but has some missing values.,Motivation,79,79,0.3333333333,0.804,0.2596531697,0.7403468303,0.75,0.2830188679,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,A simple solution is to convert the NaNs into empty strings and then use DictVectorizer as in my example above.,Expected Behaviour,111,111,0.5,0.808,0.2596531697,0.7403468303,1,0.3773584906,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,This effectively creates a new feature for when the value is missing but leaves the numerical values unchanged otherwise.,Expected Behaviour,121,121,0.6666666667,0.812,0.2596531697,0.7403468303,0.95,0.358490566,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I have found this a very useful technique.,Social Conversation,42,42,0.8333333333,0.816,0.2596531697,0.7403468303,0.4,0.1509433962,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Will the new CategoricalEncoder be able to do something similar?,Expected Behaviour,64,64,1,0.82,0.2596531697,0.7403468303,0.5,0.1886792453,0.004623535334,0.005738313076,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,but that's not the same as handling arbitrary numeric values asdifferent from strings.,Solution Discussion,86,86,1,0.824,0.262380076,0.737619924,1,0.2452830189,0.005738313076,0.001223939954,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,That sounds good.,Social Conversation,17,17,0.125,0.828,0.262961705,0.737038295,0.1034482759,0.05660377358,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,You are right there are two use cases.,Social Conversation,38,38,0.25,0.832,0.262961705,0.737038295,0.275862069,0.1509433962,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Let me explain a particular example of where treating numeric values as different from strings has been useful for me.,Social Conversation,118,118,0.375,0.836,0.262961705,0.737038295,0.6896551724,0.3773584906,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,It may be that there is a better solution.,Social Conversation,42,42,0.5,0.84,0.262961705,0.737038295,0.3103448276,0.1698113208,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Say you have an integer numeric feature which takes a large range of values.,Potential New Issues and Requests,76,76,0.625,0.844,0.262961705,0.737038295,0.4827586207,0.2641509434,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"However you suspect that for some small values, the precise value is significant.",Potential New Issues and Requests,81,81,0.75,0.848,0.262961705,0.737038295,0.4482758621,0.2452830189,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,For larger values you suspect this isnât the case.,Potential New Issues and Requests,50,50,0.875,0.852,0.262961705,0.737038295,0.3103448276,0.1698113208,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"A simple thing to do is to convert all small values to strings, run DictVectorizer as above and then perform feature selection or just use your favorite classifier directly.",Potential New Issues and Requests,173,173,1,0.856,0.262961705,0.737038295,1,0.5471698113,0.001223939954,0.001681798573,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,So you're using it for a non-linear discretisation?,Potential New Issues and Requests,51,51,0.3333333333,0.86,0.2637609133,0.7362390867,0.3214285714,0.1698113208,0.001681798573,3.41E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"The next release islikely to include a fixed-width discretizer, but following on from a logtransform or a quantile transform it should act quite similar to what youwant...",Potential New Issues and Requests,171,171,0.6666666667,0.864,0.2637609133,0.7362390867,1,0.5283018868,0.001681798573,3.41E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,But the log transform might alone be sufficient in your setting.,Potential New Issues and Requests,64,64,1,0.868,0.2637609133,0.7362390867,0.3928571429,0.2075471698,0.001681798573,3.41E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,@jnothman  Yes in a sense except with a twist.,Social Conversation,46,46,0.2,0.872,0.2637770953,0.7362229047,0.4761904762,0.1886792453,3.41E-05,5.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Say I suspect that some of the values from 1...1024 are meaningful.,Potential New Issues and Requests,67,67,0.4,0.876,0.2637770953,0.7362229047,0.619047619,0.2452830189,3.41E-05,5.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,That is 22 indicates something specific which is quite different from 21 or 23.,Potential New Issues and Requests,79,79,0.6,0.88,0.2637770953,0.7362229047,0.6666666667,0.2641509434,3.41E-05,5.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Taking logs won't help here.,Potential New Issues and Requests,28,28,0.8,0.884,0.2637770953,0.7362229047,0.2380952381,0.09433962264,3.41E-05,5.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,But I want to leave all the values over 1024 as numerical as I don't think those specific values mean much.,Potential New Issues and Requests,107,107,1,0.888,0.2637770953,0.7362229047,1,0.3962264151,3.41E-05,5.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,It sounds like you know too much about your variable for a generictransform to be the sort of thing you need.,Potential New Issues and Requests,109,109,1,0.892,0.263803449,0.736196551,1,0.3962264151,5.55E-05,0.000213265213,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"@jnothman  To be a little clearer,  I don't know that 22 is significant.",Potential New Issues and Requests,72,72,0.3333333333,0.896,0.2639047948,0.7360952052,0.7142857143,0.2830188679,0.000213265213,0.01633755525,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I just suspect that *some* values are but I don't know which ones or how many there are.,Potential New Issues and Requests,88,88,0.6666666667,0.9,0.2639047948,0.7360952052,0.8571428571,0.3396226415,0.000213265213,0.01633755525,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I have found the ""convert to a string"" and then DictVectorizer method to be very useful for discovering which these are.",Potential New Issues and Requests,120,120,1,0.904,0.2639047948,0.7360952052,1,0.3962264151,0.000213265213,0.01633755525,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"@lesshaste For the issue about NaNs as separate category, see https://github.com/scikit-learn/scikit-learn/issues/10465",Potential New Issues and Requests,119,119,0.1666666667,0.908,0.2716685717,0.7283314283,0.4583333333,0.2075471698,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"If you want to further discuss the specific non-linear discretization or mixed numeric/string encoding, feel free to open a new issue.",Potential New Issues and Requests,134,134,0.3333333333,0.912,0.2716685717,0.7283314283,0.9583333333,0.4339622642,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"But would like to keep this one focused on the original issue, i.e. the *naming* and organisation in different classes of the CategoricalEncoder/OneHotEncoder.",Social Conversation,159,159,0.5,0.916,0.2716685717,0.7283314283,1,0.4528301887,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,@amueller that's fine.,Social Conversation,22,22,0.6666666667,0.92,0.2716685717,0.7283314283,0.125,0.05660377358,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I won't have time the coming two weeks to work on the PR that is blocked by this anyway.,Contribution and Commitment,88,88,0.8333333333,0.924,0.2716685717,0.7283314283,0.7916666667,0.358490566,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,After that I should also have time again to work on it.,Contribution and Commitment,55,55,1,0.928,0.2716685717,0.7283314283,0.5,0.2264150943,0.01633755525,1,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Sorry for being absent.,Social Conversation,23,23,0.5,0.932,0.7468790146,0.2531209854,1,0.07547169811,1,0.2943896655,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Thanks!,Social Conversation,7,7,1,0.936,0.7468790146,0.2531209854,0.25,0.01886792453,1,0.2943896655,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"@amueller no problem, for me the same :-)",Social Conversation,41,41,0.1428571429,0.94,0.8867760579,0.1132239421,0.1538461538,0.1509433962,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"But, I am now planning to look at this again.",Contribution and Commitment,45,45,0.2857142857,0.944,0.8867760579,0.1132239421,0.1923076923,0.1886792453,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,So if you could give this a look that would be welcome.,Contribution and Commitment,55,55,0.4285714286,0.948,0.8867760579,0.1132239421,0.2307692308,0.2264150943,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I have some work to do on the PR  URL , so don't review that yet in detail (you can look at it to have an idea of what we propose however).",Contribution and Commitment,191,139,0.5714285714,0.952,0.8867760579,0.1132239421,0.6153846154,0.6037735849,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I think the main question I want to see answered before I put a lot of time in it, is if you are OK with splitting up CategoricalEncoder into multiple classes, and in that case, if you are OK with re-using OneHotEncoder (which means deprecating some of its current (strange) features).",Solution Discussion,285,285,0.7142857143,0.956,0.8867760579,0.1132239421,1,0.9811320755,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,Those questions are summarized in https://github.com/scikit-learn/scikit-learn/issues/10521#issuecomment-363851328 and https://github.com/scikit-learn/scikit-learn/issues/10521#issuecomment-364802471.,Solution Discussion,200,200,0.8571428571,0.96,0.8867760579,0.1132239421,0.1538461538,0.1509433962,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"(and once we agree on that part, there is still a lot to discuss about the actual implementation in the PR :))",Task Progress,110,110,1,0.964,0.8867760579,0.1132239421,0.4230769231,0.4150943396,0.2943896655,0.05713600775,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"I updated the PR https://github.com/scikit-learn/scikit-learn/pull/10523, ready for review",Task Progress,90,90,1,0.968,0.9139276855,0.08607231452,1,0.1509433962,0.05713600775,0.03371730801,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,I'll cautiously say I'm back ;),Social Conversation,31,31,1,0.972,0.9299505024,0.07004949765,1,0.1132075472,0.03371730801,0.1469650278,MEMBER,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,IMHO the most important thing is a universal API (i.e. parameters and bbehavior patterns) for all of encoders we discuss,Expected Behaviour,120,120,0.5,0.976,0.9997898183,0.0002101816893,1,0.3773584906,0.1469650278,0.0004422918149,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,P.S. https://github.com/scikit-learn-contrib/categorical-encoding ?,Task Progress,67,67,1,0.98,0.9997898183,0.0002101816893,0.1,0.03773584906,0.1469650278,0.0004422918149,NONE,FALSE,FALSE,FALSE,FALSE
8 10521_scikit-learn.doc,"In the CODE package, all encoders have a CODE argument, similar to the CODE in the old OneHotEncoder (although it does not accept exactly the same kind of values).",Solution Discussion,198,163,1,0.984,1,0,29,0.5471698113,0.0004422918149,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
8 10521_scikit-learn.doc,See eg http://contrib.scikit-learn.org/categorical-encoding/onehot.html,Solution Discussion,71,71,2,0.988,1,0,3,0.05660377358,0.0004422918149,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
8 10521_scikit-learn.doc,So that is related to the current discussion we are having in https://github.com/scikit-learn/scikit-learn/pull/10523 about deprecating CODE or not.,Potential New Issues and Requests,166,148,3,0.992,1,0,18,0.3396226415,0.0004422918149,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
8 10521_scikit-learn.doc,For the rest I think there are not really  conflicting keywords (they have some others specific to dataframes which we won't add to sklearn at this point).,Solution Discussion,155,155,4,0.996,1,0,28,0.5283018868,0.0004422918149,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
8 10521_scikit-learn.doc,The naming for OneHotEncoder and OrdinalEncoder at least is consistent with the CODE package.,Solution Discussion,108,93,5,1,1,0,14,0.2641509434,0.0004422918149,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
9 15_spaCy.doc,Additional Language Support,Expected Behaviour,27,27,0.5,0.009259259259,0,1,0.5,0.05,0,0.01391101632,NONE,TRUE,FALSE,TRUE,FALSE
9 15_spaCy.doc,How can I add another language?,Solution Discussion,31,31,1,0.01851851852,0,1,1,0.1,0,0.01391101632,NONE,TRUE,FALSE,TRUE,FALSE
9 15_spaCy.doc,Would be glad to lend a hand...,Contribution and Commitment,31,31,1,0.02777777778,0.002853904604,0.9971460954,1,0.1166666667,0.01391101632,0.05217402879,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,+1.,Social Conversation,3,3,0.5,0.03703703704,0.01355763016,0.9864423698,0.1666666667,0.01666666667,0.05217402879,6.48E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,I would gladly lend a hand.,Contribution and Commitment,27,27,1,0.0462962963,0.01355763016,0.9864423698,1,0.1,0.05217402879,6.48E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Thanks everyone.,Social Conversation,16,16,0.04166666667,0.05555555556,0.0135709163,0.9864290837,0.03333333333,0.03333333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"The lexemes.bin data file has been constructed in a way that depends on various intermediate data files --- for instance, I processed an unannotated corpus into a list of word counts, and then smoothed the counts with another script, and then consumed the smoothed probabilities with the current quick-and-dirty make_lexicon.py script, which isn't even in this repository yet.",Solution Discussion,376,376,0.08333333333,0.06481481481,0.0135709163,0.9864290837,1,1,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I also need to set up a program to generate Brown clusters, and configure word2vec to generate word vectors.",Solution Discussion,108,108,0.125,0.07407407407,0.0135709163,0.9864290837,0.3166666667,0.3166666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Finally, I need to document the process, and document the tokenizer file formats, so that I can describe what you'll actually need to do to add new languages.",Solution Discussion,158,158,0.1666666667,0.08333333333,0.0135709163,0.9864290837,0.4666666667,0.4666666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Instead of doing these things, I've mostly been doing bug-fixes, improving the API docs, and trying to improve my deployment process, which at the moment feels very error-prone.",Task Progress,177,177,0.2083333333,0.09259259259,0.0135709163,0.9864290837,0.5166666667,0.5166666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,I'll say a little bit about what will be required to add new languages.,Solution Discussion,71,71,0.25,0.1018518519,0.0135709163,0.9864290837,0.2333333333,0.2333333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,1.         Select an unannotated corpus.,Solution Discussion,40,40,0.2916666667,0.1111111111,0.0135709163,0.9864290837,0.1,0.1,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,This will probably be Wikipedia --- it's a nice way to streamline things across languages.,Solution Discussion,90,90,0.3333333333,0.1203703704,0.0135709163,0.9864290837,0.25,0.25,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Another nice solution would be to run a language identification program over Common Crawl dumps, so that we can get text from wider genres.",Solution Discussion,139,139,0.375,0.1296296296,0.0135709163,0.9864290837,0.4,0.4,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,2.         Select an annotated corpus.,Solution Discussion,38,38,0.4166666667,0.1388888889,0.0135709163,0.9864290837,0.1,0.1,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,This will define the tokenization standards that we have to target.,Solution Discussion,67,67,0.4583333333,0.1481481481,0.0135709163,0.9864290837,0.1833333333,0.1833333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I'll be licensing the data, so you probably won't have direct access to it --- I'll have to do the actual training.",Solution Discussion,115,115,0.5,0.1574074074,0.0135709163,0.9864290837,0.3666666667,0.3666666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"It will probably be nice to give you a web API, so you can run things.",Solution Discussion,70,70,0.5416666667,0.1666666667,0.0135709163,0.9864290837,0.2666666667,0.2666666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"If the API you call is emailing me ""hey, train this model"", well...",Solution Discussion,67,67,0.5833333333,0.1759259259,0.0135709163,0.9864290837,0.2166666667,0.2166666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,That sucks.,Solution Discussion,11,11,0.625,0.1851851852,0.0135709163,0.9864290837,0.03333333333,0.03333333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,3.         Define tokenization rules.,Solution Discussion,37,37,0.6666666667,0.1944444444,0.0135709163,0.9864290837,0.08333333333,0.08333333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"This is mostly a list of prefix tokenization, a list of suffix tokenization, and a list of special-cases, which are exact-matched.",Solution Discussion,130,130,0.7083333333,0.2037037037,0.0135709163,0.9864290837,0.3833333333,0.3833333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"The ""How It Works"" page says a little bit more about this, but not enough.",Solution Discussion,74,74,0.75,0.212962963,0.0135709163,0.9864290837,0.25,0.25,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,4.         Write a lemmatizer and morphological analyser.,Solution Discussion,57,57,0.7916666667,0.2222222222,0.0135709163,0.9864290837,0.1333333333,0.1333333333,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"If there's a WordNet for the language you're targeting, and it's any good, I would prefer to lemmatize to WordNet sense-keys.",Solution Discussion,125,125,0.8333333333,0.2314814815,0.0135709163,0.9864290837,0.3666666667,0.3666666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,The BabelNet project is probably the useful way to go about this.,Solution Discussion,65,65,0.875,0.2407407407,0.0135709163,0.9864290837,0.2,0.2,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Having written all this, I'm thinking it might be nice to inter-operate closely with Gensim on this.",Solution Discussion,100,100,0.9166666667,0.25,0.0135709163,0.9864290837,0.3,0.3,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Gensim will give us the word2vec implementation, and would be a good way to handle the boot-strapping problem: if getting spaCy to work on a new language initially depends on processing a bunch of unannotated data with spaCy, then things are awkward.",Solution Discussion,250,250,0.9583333333,0.2592592593,0.0135709163,0.9864290837,0.7166666667,0.7166666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I'll think more about this, and probably reach out to Radim about it.",Task Progress,69,69,1,0.2685185185,0.0135709163,0.9864290837,0.2166666667,0.2166666667,6.48E-05,0.3353511726,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"When I was still using redshift, I used word2vec and gensim to generate word cluster with CODE.",Solution Discussion,106,95,0.3333333333,0.2777777778,0.08236964625,0.9176303537,0.85,0.2833333333,0.3353511726,0.426740286,NONE,FALSE,TRUE,FALSE,FALSE
9 15_spaCy.doc,"It was fast, but wasn't quite happy with the result until I found [Percy Liang's] URL  word clustering tool.",Solution Discussion,148,108,0.6666666667,0.287037037,0.08236964625,0.9176303537,1,0.3333333333,0.3353511726,0.426740286,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Took days to generate since I have large corpus.,Solution Discussion,48,48,1,0.2962962963,0.08236964625,0.9176303537,0.45,0.15,0.3353511726,0.426740286,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"If you need, I've a lot of resources for Portuguese (word2vec, Stanford NE Extractor, ConLL Floresta SintÃ¡tica, POS Tagger (trigram, bigram, n-gram)...) that I've trained for my project.",Solution Discussion,187,187,1,0.3055555556,0.1699172444,0.8300827556,1,0.5166666667,0.426740286,7.71E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,@brunoalano thanks but actually I am interested in Turkish for the beginning.,Expected Behaviour,77,77,1,0.3148148148,0.1699330677,0.8300669323,1,0.2,7.71E-05,0.1046411372,NONE,TRUE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Working on docs for this here: http://spacy.io/tutorials/add-a-language/,Task Progress,72,72,1,0.3240740741,0.1914006454,0.8085993546,1,0.1166666667,0.1046411372,0.01700768191,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,+1,Social Conversation,2,2,0.3333333333,0.3333333333,0.1948898442,0.8051101558,0.07142857143,0.01666666667,0.01700768191,0.005299459514,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Ideally we could develop the concept of explicit _partial support_ of a new language.,Solution Discussion,85,85,0.6666666667,0.3425925926,0.1948898442,0.8051101558,1,0.2333333333,0.01700768191,0.005299459514,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"For example, tokenisation really works already for most languages.",Solution Discussion,66,66,1,0.3518518519,0.1948898442,0.8051101558,0.6428571429,0.15,0.01700768191,0.005299459514,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I would be very interested in spaCy support for German, especially official support.",Expected Behaviour,84,84,0.5,0.3611111111,0.195977051,0.804022949,1,0.2166666667,0.005299459514,0.05049791913,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Thanks for the documentation on adding languages!,Social Conversation,49,49,1,0.3703703704,0.195977051,0.804022949,0.5384615385,0.1166666667,0.005299459514,0.05049791913,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,See Issue #124,Potential New Issues and Requests,14,14,1,0.3796296296,0.2063369155,0.7936630845,1,0.05,0.05049791913,0.409548798,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Perhaps the corpora from http://corporafromtheweb.org/ are useful here.,Solution Discussion,71,71,0.3333333333,0.3888888889,0.2903576062,0.7096423938,0.4444444444,0.1333333333,0.409548798,0.4682936827,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"They're large, come in several different languages (Dutch, English, French, German, Spanish, Swedish), and are tokenized pretty well.",Solution Discussion,133,133,0.6666666667,0.3981481481,0.2903576062,0.7096423938,1,0.3,0.409548798,0.4682936827,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"They're also POS-tagged and lemmatized, but I don't know whether that's needed here.",Solution Discussion,84,84,1,0.4074074074,0.2903576062,0.7096423938,0.7777777778,0.2333333333,0.409548798,0.4682936827,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I'm pleased to say that there's now excellent support for German, thanks to the great work from our first NLP employee Wolfgang Seeker.",Task Progress,135,135,0.125,0.4166666667,0.3864300618,0.6135699382,1,0.3833333333,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"We're still finishing up the blog post etc, but the model is uploaded and can be used from spaCy 0.100.7.",Task Progress,105,105,0.25,0.4259259259,0.3864300618,0.6135699382,0.8695652174,0.3333333333,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,CODE,Usage,43,4,0.375,0.4351851852,0.3864300618,0.6135699382,0.04347826087,0.01666666667,0.4682936827,0.03367017273,MEMBER,FALSE,TRUE,FALSE,FALSE
9 15_spaCy.doc,We're still refactoring and working on better processes for adding more languages.,Task Progress,82,82,0.5,0.4444444444,0.3864300618,0.6135699382,0.5217391304,0.2,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,I'm going to close this issue because it's old and most of the information here is now out of date.,Action on Issue,99,99,0.625,0.4537037037,0.3864300618,0.6135699382,0.8695652174,0.3333333333,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Obviously, there's still a lot to do to support more languages.",Task Progress,63,63,0.75,0.462962963,0.3864300618,0.6135699382,0.4782608696,0.1833333333,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,And I think the idea of partial language support is important and overdue.,Motivation,74,74,0.875,0.4722222222,0.3864300618,0.6135699382,0.5652173913,0.2166666667,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,But --- progress :),Social Conversation,19,19,1,0.4814814815,0.3864300618,0.6135699382,0.1739130435,0.06666666667,0.4682936827,0.03367017273,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,I'm also glad to help in adding Portuguese tools to spaCy.,Contribution and Commitment,58,58,0.5,0.4907407407,0.393337642,0.606662358,0.5789473684,0.1833333333,0.03367017273,3.13E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"By the way, anyone knows if there is corpora to train dependency parsers or just PoS-taggers to Dutch?",Solution Discussion,102,102,1,0.5,0.393337642,0.606662358,1,0.3166666667,0.03367017273,3.13E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Yes there are corpora for that: Lassy-Klein, Lassy-Groot, and SoNaR.",Solution Discussion,68,68,0.125,0.5092592593,0.3933440623,0.6066559377,0.8571428571,0.2,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Probably the best thing is to contact the [TST-centrale] URL .,Solution Discussion,86,62,0.25,0.5185185185,0.3933440623,0.6066559377,0.7857142857,0.1833333333,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"They are undergoing some changes in management, so they might be slow to respond.",Social Conversation,81,81,0.375,0.5277777778,0.3933440623,0.6066559377,1,0.2333333333,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"For questions about Lassy, you can email [Gertjan van Noord](http://www.let.rug.nl/~vannoord/).",Solution Discussion,95,95,0.5,0.537037037,0.3933440623,0.6066559377,0.7142857143,0.1666666667,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,For questions about SoNaR you can email [Nelleke Oostdijk] URL .,Solution Discussion,139,64,0.625,0.5462962963,0.3933440623,0.6066559377,0.7142857143,0.1666666667,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I trained a POS-tagger on the NLCOW14 corpus, which was automatically tagged.",Solution Discussion,77,77,0.75,0.5555555556,0.3933440623,0.6066559377,0.9285714286,0.2166666667,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"But if you need something fast, then [here] URL  is the repository.",Solution Discussion,110,67,0.875,0.5648148148,0.3933440623,0.6066559377,0.9285714286,0.2166666667,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"If you just need a parser, try [Alpino] URL .",Solution Discussion,84,45,1,0.5740740741,0.3933440623,0.6066559377,0.6428571429,0.15,3.13E-05,1.87E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Thanks for your reply!,Social Conversation,22,22,0.5,0.5833333333,0.3933478971,0.6066521029,0.1428571429,0.06666666667,1.87E-05,4.26E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"One more questions, does the license associated to those datasets allows to be incorporated into spaCy or use it to process dutch text not within a research context?",Solution Discussion,165,165,1,0.5925925926,0.3933478971,0.6066521029,1,0.4666666667,1.87E-05,4.26E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I think if you're a researcher yourself, and you don't contribute to SpaCy for money I think it should be OK.",Solution Discussion,109,109,0.08333333333,0.6018518519,0.3933566415,0.6066433585,0.5675675676,0.35,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,If you're a SpaCy employee it might technically be commercial use and the terms and conditions from the TST-centrale are different: I just checked and the license for Lassy-klein for commercial use costs 2000 euros.,Solution Discussion,215,215,0.1666666667,0.6111111111,0.3933566415,0.6066433585,1,0.6166666667,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Same for SoNar-klein.,Solution Discussion,21,21,0.25,0.6203703704,0.3933566415,0.6066433585,0.1081081081,0.06666666667,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,The larger corpora cost more.,Solution Discussion,29,29,0.3333333333,0.6296296296,0.3933566415,0.6066433585,0.1351351351,0.08333333333,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"Then again, SpaCy is open-source.",Solution Discussion,33,33,0.4166666667,0.6388888889,0.3933566415,0.6066433585,0.1621621622,0.1,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,So you can always try.,Social Conversation,22,22,0.5,0.6481481481,0.3933566415,0.6066433585,0.1351351351,0.08333333333,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"If it doesn't work, contact Gertjan to see whether he can help you.",Contribution and Commitment,67,67,0.5833333333,0.6574074074,0.3933566415,0.6066433585,0.3513513514,0.2166666667,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Else there's also [this free smaller treebank] URL  on his website.,Solution Discussion,102,67,0.6666666667,0.6666666667,0.3933566415,0.6066433585,0.3243243243,0.2,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,That should at least get you started.,Social Conversation,37,37,0.75,0.6759259259,0.3933566415,0.6066433585,0.1891891892,0.1166666667,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,And the people at the university of Groningen would probably be happy to see another parser for Dutch so they can compare Alpino to it :),Motivation,137,137,0.8333333333,0.6851851852,0.3933566415,0.6066433585,0.7027027027,0.4333333333,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Also look around on [Maarten van Gompel] URL 's GitHub [here] URL .,Solution Discussion,113,67,0.9166666667,0.6944444444,0.3933566415,0.6066433585,0.2972972973,0.1833333333,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"He's worked on memory-based POS tagging for Dutch, among other things.",Solution Discussion,70,70,1,0.7037037037,0.3933566415,0.6066433585,0.3243243243,0.2,4.26E-05,1.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Dank u wel for all the clarifications!,Social Conversation,38,38,1,0.712962963,0.3933594208,0.6066405792,1,0.1166666667,1.35E-05,0.01190727487,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"You're welcome, but I just realized I forgot to mention http://universaldependencies.org/ which also covers Dutch, and seems to overlap with Lassy.",Solution Discussion,147,147,0.5,0.7222222222,0.3958022492,0.6041977508,1,0.35,0.01190727487,0.2563539137,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Sorry!,Social Conversation,6,6,1,0.7314814815,0.3958022492,0.6041977508,0.04761904762,0.01666666667,0.01190727487,0.2563539137,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I new here but have been trolling for a while, would be glad to add Bahasa support",Contribution and Commitment,82,82,1,0.7407407407,0.448394353,0.551605647,1,0.2833333333,0.2563539137,0.0002826479106,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"@geovedi , were you working on Bahasa?",Task Progress,38,38,1,0.75,0.4484523395,0.5515476605,1,0.1,0.0002826479106,0.0001265968096,COLLABORATOR,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,@syllog1sm yes.,Task Progress,15,15,0.3333333333,0.7592592593,0.4484783114,0.5515216886,0.1818181818,0.03333333333,0.0001265968096,0.003118709101,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,it's been awhile tho.,Task Progress,21,21,0.6666666667,0.7685185185,0.4484783114,0.5515216886,0.3636363636,0.06666666667,0.0001265968096,0.003118709101,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,will catch up with the latest commit and regenerate the model.,Task Progress,62,62,1,0.7777777778,0.4484783114,0.5515216886,1,0.1833333333,0.0001265968096,0.003118709101,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,@geovedi do you have a fork or branch i can check out?,Task Progress,54,54,1,0.787037037,0.4491181279,0.5508818721,1,0.2,0.003118709101,0.04109506146,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Does anybody plan to add a support for Russian?,Task Progress,47,47,0.3333333333,0.7962962963,0.4575489558,0.5424510442,0.3214285714,0.15,0.04109506146,0.1583363574,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Could you please point me to corresponding doc/guide?,Solution Discussion,53,53,0.6666666667,0.8055555556,0.4575489558,0.5424510442,0.3214285714,0.15,0.04109506146,0.1583363574,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"I'm also reading pull requests about adding of a German support, do you think the work for adding of Russian support is going to be kind of similar?",Solution Discussion,148,148,1,0.8148148148,0.4575489558,0.5424510442,1,0.4666666667,0.04109506146,0.1583363574,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,http://spacy.io/tutorials/add-a-language/,Solution Discussion,41,41,0.5,0.8240740741,0.490032338,0.509967662,0.5,0.01666666667,0.1583363574,0.1838195117,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,is 404'ing,Solution Discussion,10,10,1,0.8333333333,0.490032338,0.509967662,1,0.03333333333,0.1583363574,0.1838195117,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,http://spacy.io/tutorials/add-a-language/,Solution Discussion,41,41,0.3333333333,0.8425925926,0.5277436984,0.4722563016,0.125,0.01666666667,0.1838195117,0.03798484879,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,is not working.,Solution Discussion,15,15,0.6666666667,0.8518518519,0.5277436984,0.4722563016,0.375,0.05,0.1838195117,0.03798484879,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,It seems page is not available (404 Error).,Solution Discussion,43,43,1,0.8611111111,0.5277436984,0.4722563016,1,0.1333333333,0.1838195117,0.03798484879,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,P.S: the URL is not working.,Solution Discussion,28,28,0.5,0.8703703704,0.5355364529,0.4644635471,1,0.1,0.03798484879,0.2918907521,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Thanks,Social Conversation,6,6,1,0.8796296296,0.5355364529,0.4644635471,0.1666666667,0.01666666667,0.03798484879,0.2918907521,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,https://spacy.io/docs/usage/adding-languages,Solution Discussion,44,44,1,0.8888888889,0.5954190914,0.4045809086,1,0.01666666667,0.2918907521,0.001011405608,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"@kaustubhn Sounds great â for more info on how to add languages, see the new link posted above.",Solution Discussion,95,95,1,0.8981481481,0.5956265856,0.4043734144,1,0.3,0.001011405608,1,MEMBER,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Hi @davidsbatista.,Social Conversation,18,18,0.5,0.9074074074,0.8007808704,0.1992191296,0.1818181818,0.03333333333,1,0.0001095095445,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Do you have some code to train a model in portuguese?,Solution Discussion,53,53,1,0.9166666667,0.8007808704,0.1992191296,1,0.1833333333,1,0.0001095095445,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Train what exactly?,Solution Discussion,19,19,0.5,0.9259259259,0.8008033367,0.1991966633,0.125,0.05,0.0001095095445,0.0006670641737,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,"For PoS and syntactic parsing there is public available data, for named-entity recognition, is not so easy, there is no public available dataset",Solution Discussion,144,144,1,0.9351851852,0.8008033367,0.1991966633,1,0.4,0.0001095095445,0.0006670641737,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,The training would be what's mentioned in the docs above.,Solution Discussion,57,57,0.3333333333,0.9444444444,0.8009401878,0.1990598122,1,0.1666666667,0.0006670641737,0.002272653465,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,At this point PoS would be enough for me.,Solution Discussion,41,41,0.6666666667,0.9537037037,0.8009401878,0.1990598122,0.9,0.15,0.0006670641737,0.002272653465,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,Were you able to implement this in spaCy?,Task Progress,41,41,1,0.962962963,0.8009401878,0.1990598122,0.8,0.1333333333,0.0006670641737,0.002272653465,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,got it: https://spacy.io/docs/usage/adding-languages,Solution Discussion,52,52,0.5,0.9722222222,0.8014064324,0.1985935676,1,0.05,0.002272653465,0.9680205697,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,:),Social Conversation,2,2,1,0.9814814815,0.8014064324,0.1985935676,0.3333333333,0.01666666667,0.002272653465,0.9680205697,NONE,FALSE,FALSE,FALSE,FALSE
9 15_spaCy.doc,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue,107,107,1,0.9907407407,1,0,18,0.3,0.9680205697,0,NONE,FALSE,FALSE,FALSE,TRUE
9 15_spaCy.doc,Please open a new issue for related bugs.,Action on Issue,41,41,2,1,1,0,8,0.1333333333,0.9680205697,0,NONE,FALSE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,[Enhancement] Redesigning TensorFlow's input pipelines,Solution Discussion,54,54,0.03703703704,0.001547987616,0,1,0.1063829787,0.07462686567,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"[**TL;DR:** We're designing a new input pipeline API for TensorFlow, and we'd like to collect your feature requests on this issue.]",Motivation,131,131,0.07407407407,0.003095975232,0,1,0.4893617021,0.3432835821,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,We've noticed that one of the biggest challenges in getting started with TensorFlow is how to load your own data into your programs.,Motivation,132,132,0.1111111111,0.004643962848,0,1,0.5106382979,0.3582089552,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"While TensorFlow has several methods that can be used to build complex input pipelines (such as [CODE] URL , [CODE] URL , etc.), they were designed for a particular use case (processing a static set of files repeatedly), and the average user experience with these methods is not great.",Motivation,453,285,0.1481481481,0.006191950464,0,1,1,0.7014925373,0,0.000766008561,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
10 7951_tensorflow.doc,For example:,Motivation,12,12,0.1851851852,0.00773993808,0,1,0.04255319149,0.02985074627,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"*         Once you reach the end of a pipeline, it becomes closed and you can never use it again in the same session.",Motivation,117,117,0.2222222222,0.009287925697,0,1,0.4893617021,0.3432835821,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,*         See #2514 and #4535 for feature requests about handling multiple epochs.,Motivation,82,82,0.2592592593,0.01083591331,0,1,0.2553191489,0.1791044776,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,*         See #7902 and numerous Stack Overflow questions for examples of processing different datasets in the same program.,Motivation,124,124,0.2962962963,0.01238390093,0,1,0.3829787234,0.2686567164,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"*         The current pipelines use TensorFlow queues and multiple Python threads, which can lead to poor performance (lock contention in the queues and the Python GIL) and hard-to-understand exceptions (CODE).",Motivation,233,210,0.3333333333,0.01393188854,0,1,0.6808510638,0.4776119403,0,0.000766008561,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
10 7951_tensorflow.doc,*         See #6845 for a discussion of input pipeline performance.,Motivation,67,67,0.3703703704,0.01547987616,0,1,0.2127659574,0.1492537313,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,*         See #7525 and [many more Stack Overflow questions] URL  for an example of the confusing error.,Motivation,167,104,0.4074074074,0.01702786378,0,1,0.3829787234,0.2686567164,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"*         The pipelines behave poorly if you forget to call CODE: in fact, they hang indefinitely and deadlock the user program.",Motivation,160,128,0.4444444444,0.01857585139,0,1,0.4468085106,0.3134328358,0,0.000766008561,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
10 7951_tensorflow.doc,*         See #7945 and [many Stack Overflow questions] URL  for some examples of users who have been bitten by this problem.,Motivation,177,125,0.4814814815,0.02012383901,0,1,0.4680851064,0.328358209,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,We're decided to start from a clean slate and redesign the input pipeline API.,Task Progress,78,78,0.5185185185,0.02167182663,0,1,0.2978723404,0.2089552239,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Solution Discussion,144,144,0.5555555556,0.02321981424,0,1,0.5531914894,0.3880597015,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"The existing methods will remain until TF 2.0 (at least), but we are planning to add a new set of methods for loading and manipulating datasets.",Task Progress,144,144,0.5925925926,0.02476780186,0,1,0.5531914894,0.3880597015,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,*         A CODE represents a collection of data elements.,Solution Discussion,63,58,0.6296296296,0.02631578947,0,1,0.1914893617,0.1343283582,0,0.000766008561,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
10 7951_tensorflow.doc,Each element  can be a tuple of one or more tensors (e.g. an image and its label).,Solution Discussion,82,82,0.6666666667,0.02786377709,0,1,0.3829787234,0.2686567164,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"We will provide methods for creating datasets from tensors, and deriving them from another dataset (e.g. by slicing its elements, repeating its elements, shuffling its elements, batching its elements, mapping a function over its elements, etc.).",Usage,245,245,0.7037037037,0.02941176471,0,1,0.7659574468,0.5373134328,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,*         An CODE can be created from a CODE.,Solution Discussion,56,45,0.7407407407,0.03095975232,0,1,0.1914893617,0.1343283582,0,0.000766008561,CONTRIBUTOR,TRUE,TRUE,TRUE,FALSE
10 7951_tensorflow.doc,"There will be explicit operations for initializing an iterator, so that it can be reused after you have processed all of the elements in a dataset.",Usage,147,147,0.7777777778,0.03250773994,0,1,0.5531914894,0.3880597015,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"A similar pattern turns up in many different settings, including [Java's Stream API] URL , [Scala's collections] URL  (and hence Spark's RDDs), and [.NET's Language Integrated Query] URL .",Motivation,374,188,0.8148148148,0.03405572755,0,1,0.5957446809,0.4179104478,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,We're announcing this plan early because we want to collect feedback on what features you&mdash;as TensorFlow users&mdash;would like to see in an input pipeline API.,Motivation,165,165,0.8518518519,0.03560371517,0,1,0.5319148936,0.3731343284,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,What other pain points have we missed?,Motivation,38,38,0.8888888889,0.03715170279,0,1,0.1489361702,0.1044776119,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,What features do you miss from other systems?,Motivation,45,45,0.9259259259,0.0386996904,0,1,0.170212766,0.1194029851,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,What other suggestions do you have?,Motivation,35,35,0.962962963,0.04024767802,0,1,0.1276595745,0.08955223881,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,We look forward to hearing from you!,Social Conversation,36,36,1,0.04179566563,0,1,0.1489361702,0.1044776119,0,0.000766008561,CONTRIBUTOR,TRUE,FALSE,TRUE,FALSE
10 7951_tensorflow.doc,"A must-have for one of our use cases is ad-hoc creation of data elements via a callback function (which creates tensors on the fly, e.g. using py_func() or through some other means).",Motivation,182,182,0.08333333333,0.04334365325,9.52E-05,0.9999047572,0.7083333333,0.5074626866,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"More specifically, we currently have a use case where we employ two queues; an outer one, using a string_input_producer (with shuffling), where each string denotes/points to a ""data set"", and the inner queue is then produced by generating a variable amount of samples from each ""data set"".",Motivation,289,289,0.1666666667,0.04489164087,9.52E-05,0.9999047572,1,0.7164179104,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Which and how many samples are generated differs per epoch (potentially conditional on past training behavior).,Motivation,111,111,0.25,0.04643962848,9.52E-05,0.9999047572,0.3333333333,0.2388059701,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Actually, we don't even use the nomenclature of an epoch anymore, since the same data is never seen twice, and above mentioned generation/sampling goes beyond the usual data augmentation.",Motivation,187,187,0.3333333333,0.0479876161,9.52E-05,0.9999047572,0.625,0.447761194,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Long story short: With a slightly out-of-the-ordinary use case, we've been hit by pretty much all of the problems you have mentioned above, and our workarounds have not been pretty.",Motivation,181,181,0.4166666667,0.04953560372,9.52E-05,0.9999047572,0.7083333333,0.5074626866,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We'd be extremely happy to see a very flexible mechanism, where such cases are supported, and data generation doesn't have to be shoehorned into forced-upon concepts like epochs, finitely repeating queues, etc.",Motivation,210,210,0.5,0.05108359133,9.52E-05,0.9999047572,0.7083333333,0.5074626866,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,(although they can be modeled by its primitives).,Motivation,49,49,0.5833333333,0.05263157895,9.52E-05,0.9999047572,0.1666666667,0.1194029851,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I am not sure how well the planned Dataset/Iterator API would support this.,Solution Discussion,75,75,0.6666666667,0.05417956656,9.52E-05,0.9999047572,0.2916666667,0.2089552239,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Edit: Things we still need of course, include multi-threaded data generation, and multi-threaded random shuffle producer-consumer queues.",Expected Behaviour,137,137,0.75,0.05572755418,9.52E-05,0.9999047572,0.4166666667,0.2985074627,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But without the bane of GIL -- maybe via easy C++/Eigen hooks and thread control on the native side?,Solution Discussion,100,100,0.8333333333,0.0572755418,9.52E-05,0.9999047572,0.3958333333,0.2835820896,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Back and forth, via pybind?",Solution Discussion,27,27,0.9166666667,0.05882352941,9.52E-05,0.9999047572,0.1041666667,0.07462686567,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Edit2: The new input pipeline should also take support for variable-sized tensors (i.e. different per example) into account, for both training and inference, e.g. in a fully-convolutional setting.",Expected Behaviour,196,196,1,0.06037151703,9.52E-05,0.9999047572,0.625,0.447761194,0.000766008561,0.0015177658,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kmhofmann We'll certainly support CODE inside a new-style input pipeline (as well as, in general, compositions of any other TensorFlow ops).",Solution Discussion,151,141,0.1428571429,0.06191950464,0.000283956448,0.9997160436,0.7586206897,0.328358209,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I'd like to understand more about your use case, though.",Motivation,56,56,0.2857142857,0.06346749226,0.000283956448,0.9997160436,0.3793103448,0.1641791045,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"How frequently do you move from one outer ""data set"" to the next?",Motivation,65,65,0.4285714286,0.06501547988,0.000283956448,0.9997160436,0.4482758621,0.1940298507,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Are there any specific operations that you perform at the end of a ""data set"" or can your training loop handle the concatenation of records from different ""data sets""?",Motivation,167,167,0.5714285714,0.06656346749,0.000283956448,0.9997160436,1,0.4328358209,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"(Think CODE in C#, CODE in Java and Scala.)",Usage,60,43,0.7142857143,0.06811145511,0.000283956448,0.9997160436,0.3103448276,0.1343283582,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"So I think you could implement your logic for sampling from a ""data set"" in one of these CODE functions.",Usage,111,104,0.8571428571,0.06965944272,0.000283956448,0.9997160436,0.6896551724,0.2985074627,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Let me know if any of this is unclear!,Social Conversation,38,38,1,0.07120743034,0.000283956448,0.9997160436,0.3103448276,0.1343283582,0.0015177658,0.0008184330671,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Oh good timing!,Social Conversation,15,15,0.07142857143,0.07275541796,0.0003857175286,0.9996142825,0.04918032787,0.0447761194,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Now I can stop writing my own (horrible) dataset class.,Motivation,55,55,0.1428571429,0.07430340557,0.0003857175286,0.9996142825,0.1639344262,0.1492537313,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Many of the things said already resonate with my experience.,Motivation,60,60,0.2142857143,0.07585139319,0.0003857175286,0.9996142825,0.1639344262,0.1492537313,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"To the extent possible, I would like to code dataset-independent tensorflow computations.",Expected Behaviour,89,89,0.2857142857,0.0773993808,0.0003857175286,0.9996142825,0.2131147541,0.1940298507,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I don't want to have 3 different gan classes: each with their own create graph and fit methods, simply because one dataset doesn't fit in memory, the other is an np.array, and the other is generated on the fly.",Motivation,210,210,0.3571428571,0.07894736842,0.0003857175286,0.9996142825,0.6393442623,0.5820895522,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The use case that affects me the most is [do n times: train for k iter/epoch, validate model, repeat].",Motivation,102,102,0.4285714286,0.08049535604,0.0003857175286,0.9996142825,0.3278688525,0.2985074627,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,There are clear problems with queues like you said.,Motivation,51,51,0.5,0.08204334365,0.0003857175286,0.9996142825,0.1475409836,0.1343283582,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"A minor issue for which I offer no solution is that while the scheduling(how long to train for before validate) is done perhaps by some method of a model class that I would like to be dataset-independent, whether it makes sense to talk in terms of iter or epoch is determined by the dataset--ruining some of the independence.",Motivation,325,325,0.5714285714,0.08359133127,0.0003857175286,0.9996142825,1,0.9104477612,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Some other ideas I jotted down while brainstorming my own class:,Expected Behaviour,64,64,0.6428571429,0.08513931889,0.0003857175286,0.9996142825,0.1803278689,0.1641791045,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         The dataset class (and not the model) should probably the one to have batch_size passed to it.,Expected Behaviour,104,104,0.7142857143,0.0866873065,0.0003857175286,0.9996142825,0.2950819672,0.2686567164,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"It's awkward to ask for batch_size as a parameter during fitting and during dataset/queue creation, and ideally the compute graph doesn't have batch_size baked in.",Motivation,163,163,0.7857142857,0.08823529412,0.0003857175286,0.9996142825,0.4262295082,0.3880597015,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"-         A ""verbose"" dataset class should keep track of it's own statistics.",Expected Behaviour,77,77,0.8571428571,0.08978328173,0.0003857175286,0.9996142825,0.1967213115,0.1791044776,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"It should maintain its own counters(tensors) that keep track of iterations, samples, and epochs.",Expected Behaviour,96,96,0.9285714286,0.09133126935,0.0003857175286,0.9996142825,0.2295081967,0.2089552239,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,In most use cases I imagine these being restored the same time model parameters are restored.,Expected Behaviour,93,93,1,0.09287925697,0.0003857175286,0.9996142825,0.262295082,0.2388059701,0.0008184330671,0.02236439613,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         Most importantly we need to address the dequeueing overhead.,Expected Behaviour,70,70,0.1666666667,0.09442724458,0.003166427653,0.9968335723,0.4,0.1492537313,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I've seen dozens and dozens of cases where (in the profiler; iirc MEMCpyWhatever) was really slow.,Motivation,98,98,0.3333333333,0.0959752322,0.003166427653,0.9968335723,0.68,0.2537313433,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This was mostly an issue where the GPU would get the data from the CPU.,Motivation,71,71,0.5,0.09752321981,0.003166427653,0.9968335723,0.6,0.223880597,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         It would be great if there is still a way to have an **input feed that comes from multi-threaded or multi-processing python**.,Expected Behaviour,136,136,0.6666666667,0.09907120743,0.003166427653,0.9968335723,1,0.3731343284,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The following is a great and reliable hack to do currently do that:CODE Where you can asynchronously feed the queue from python.,Expected Behaviour,184,128,0.8333333333,0.100619195,0.003166427653,0.9968335723,0.92,0.3432835821,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,-         It would also be wow to have **GPU resident queues**.,Expected Behaviour,63,63,1,0.1021671827,0.003166427653,0.9968335723,0.44,0.1641791045,0.02236439613,0.004893293226,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Good point.,Social Conversation,11,11,0.3333333333,0.1037151703,0.003774842471,0.9962251575,0.08695652174,0.02985074627,0.004893293226,0.03692313957,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"One thing is that currently the queue operations are ""baked in"" the computation graph, so it's hard to modify anything on the go.",Solution Discussion,129,129,0.6666666667,0.1052631579,0.003774842471,0.9962251575,1,0.3432835821,0.004893293226,0.03692313957,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,A higher abstraction can make it much easier without considering using control flows or other hacks.,Solution Discussion,100,100,1,0.1068111455,0.003774842471,0.9962251575,0.6956521739,0.2388059701,0.004893293226,0.03692313957,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For a lot of my use cases, my input data is either 1. not on the file system, or 2. require complex preprocessing unavailable in TensorFlow.",Motivation,140,140,0.08333333333,0.1083591331,0.008365735399,0.9916342646,0.8666666667,0.3880597015,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Let's **assume** that in most cases, you don't need to use the model itself to produce data (though sometimes it's not true).",Expected Behaviour,125,125,0.1666666667,0.1099071207,0.008365735399,0.9916342646,0.7333333333,0.328358209,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Then a solution I really like to see, is to be able to receive(similar to dequeue) tensors from a different process.",Expected Behaviour,116,116,0.25,0.1114551084,0.008365735399,0.9916342646,0.7,0.3134328358,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,(Like #4836),Expected Behaviour,12,12,0.3333333333,0.113003096,0.008365735399,0.9916342646,0.06666666667,0.02985074627,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The benefits are:,Motivation,17,17,0.4166666667,0.1145510836,0.008365735399,0.9916342646,0.1,0.0447761194,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"1.         Can use whatever tools/languages to produce data from any sources, as long as they're finally sent with certain message protocol.",Motivation,140,140,0.5,0.1160990712,0.008365735399,0.9916342646,0.7666666667,0.3432835821,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,2.         (theoretically) doesn't require an extra python thread in the training process.,Motivation,90,90,0.5833333333,0.1176470588,0.008365735399,0.9916342646,0.4333333333,0.1940298507,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"3.         If the message protocol supports pub/sub, then (1) multiple training sessions can subcribe and reuse the same input data, which is very useful when trying new models.",Motivation,177,177,0.6666666667,0.1191950464,0.008365735399,0.9916342646,1,0.447761194,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,(2) data can be generated from different machines if the pre-processing is too heavy for a single CPU.,Motivation,102,102,0.75,0.1207430341,0.008365735399,0.9916342646,0.6333333333,0.2835820896,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,These are the features I really missed from a private system I've been using.,Motivation,77,77,0.8333333333,0.1222910217,0.008365735399,0.9916342646,0.5,0.223880597,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,One disadvantage is that IPC/socket has smaller bandwidth than RAM but usually it's not a bottleneck.,Solution Discussion,101,101,0.9166666667,0.1238390093,0.008365735399,0.9916342646,0.5666666667,0.2537313433,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I know this feature may be too far away, but I hope the new design could allow such possible future feature.",Solution Discussion,108,108,1,0.1253869969,0.008365735399,0.9916342646,0.7,0.3134328358,0.03692313957,0.0188753671,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@mrry One ""data set"" can be composed of anything between ~500-30,000 dynamically generated samples.",Motivation,99,99,0.5,0.1269349845,0.01071263196,0.989287368,0.46875,0.223880597,0.0188753671,0.02492556229,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"At the moment, we don't perform specific operations at the end of each data set, i.e. everything gets put into the same (large) random shuffle queue, to mix samples between data sets.",Motivation,183,183,1,0.1284829721,0.01071263196,0.989287368,1,0.4776119403,0.0188753671,0.02492556229,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Please support reading hdf5 file directly.,Expected Behaviour,42,42,1,0.1300309598,0.01381178845,0.9861882115,1,0.08955223881,0.02492556229,0.003307324671,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Personally, I'm a very big fan of the CODE method of feeding data into the graph.",Motivation,88,81,0.2,0.1315789474,0.01422300953,0.9857769905,0.5,0.2388059701,0.003307324671,0.2125437083,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"It is by far the most flexible, makes debugging way easier and makes for much simpler code.",Motivation,91,91,0.4,0.133126935,0.01422300953,0.9857769905,0.53125,0.2537313433,0.003307324671,0.2125437083,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thus my biggest wish would be to make that method more performant.,Expected Behaviour,66,66,0.6,0.1346749226,0.01422300953,0.9857769905,0.375,0.1791044776,0.003307324671,0.2125437083,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Right now, this method starves my GPU all the time, which is a shame because most other DL frameworks (even those based on computational graphs) manage to make this much more performantly.",Motivation,188,188,0.8,0.1362229102,0.01422300953,0.9857769905,1,0.4776119403,0.003307324671,0.2125437083,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I assume there is more copying/handling going on in the background than would be necessary.,Solution Discussion,91,91,1,0.1377708978,0.01422300953,0.9857769905,0.5,0.2388059701,0.003307324671,0.2125437083,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I am glad to see this initiative.,Social Conversation,33,33,0.03225806452,0.1393188854,0.04064994448,0.9593500555,0.25,0.1044776119,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The input pipeline is definitely thesteepest part of the learning curve.,Motivation,72,72,0.06451612903,0.1408668731,0.04064994448,0.9593500555,0.3928571429,0.1641791045,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'd like:,Expected Behaviour,9,9,0.09677419355,0.1424148607,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Although, I have not use it yet, I liked what I read in the input pipeline documentation.",Social Conversation,89,89,0.1290322581,0.1439628483,0.04064994448,0.9593500555,0.6071428571,0.2537313433,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         More iterators!,Expected Behaviour,25,25,0.1612903226,0.1455108359,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,They are great.,Motivation,15,15,0.1935483871,0.1470588235,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Iterators implementing CODE are great for progress report.,Motivation,63,58,0.2258064516,0.1486068111,0.04064994448,0.9593500555,0.2857142857,0.1194029851,0.2125437083,0.01543061897,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,*         multiprocessing rather than threading,Expected Behaviour,47,47,0.2580645161,0.1501547988,0.04064994448,0.9593500555,0.1785714286,0.07462686567,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The CODE class described in the original post already exists in Python: it is a list of tuples.,Motivation,100,95,0.2903225806,0.1517027864,0.04064994448,0.9593500555,0.6428571429,0.2686567164,0.2125437083,0.01543061897,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"And what is a ""dataset"", anyway?",Motivation,32,32,0.3225806452,0.153250774,0.04064994448,0.9593500555,0.2142857143,0.08955223881,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,A collection of train/valid/test data or simply a collection of data?,Motivation,69,69,0.3548387097,0.1547987616,0.04064994448,0.9593500555,0.4642857143,0.1940298507,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is it just a file?,Motivation,18,18,0.3870967742,0.1563467492,0.04064994448,0.9593500555,0.1785714286,0.07462686567,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,directory?,Motivation,10,10,0.4193548387,0.1578947368,0.04064994448,0.9593500555,0.03571428571,0.01492537313,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,generator?,Motivation,10,10,0.4516129032,0.1594427245,0.04064994448,0.9593500555,0.03571428571,0.01492537313,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Are each data item (input/target) couple?,Motivation,41,41,0.4838709677,0.1609907121,0.04064994448,0.9593500555,0.25,0.1044776119,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is that always true?,Motivation,20,20,0.5161290323,0.1625386997,0.04064994448,0.9593500555,0.1428571429,0.05970149254,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is the dictionary part of the text dataset?,Motivation,43,43,0.5483870968,0.1640866873,0.04064994448,0.9593500555,0.2857142857,0.1194029851,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The choice of the data container is driven by a lot of constrains depending on its size and the execution environment.,Motivation,118,118,0.5806451613,0.1656346749,0.04064994448,0.9593500555,0.75,0.3134328358,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Instead of a CODE container, I would prefer to have a rich set of containers offering different trade-off with respect to memory/time complexity.",Expected Behaviour,150,145,0.6129032258,0.1671826625,0.04064994448,0.9593500555,0.8928571429,0.3731343284,0.2125437083,0.01543061897,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"In addition, I would like to have a rich set of iterators, splitters, loaders, dumpers, slicers, repeaters, servers, generators to actually work with data coming from various source.",Expected Behaviour,182,182,0.6451612903,0.1687306502,0.04064994448,0.9593500555,1,0.4179104478,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         The epoch concept does not have a clear semantic either.,Expected Behaviour,66,66,0.6774193548,0.1702786378,0.04064994448,0.9593500555,0.3928571429,0.1641791045,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"In my experience, it is best defined by CODE and CODE.",Solution Discussion,130,54,0.7096774194,0.1718266254,0.04064994448,0.9593500555,0.3928571429,0.1641791045,0.2125437083,0.01543061897,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Here my attempt to translate to small in-memory dataset some of the routines available in the TF's input pipeline for large dataset.,Expected Behaviour,132,132,0.7419354839,0.173374613,0.04064994448,0.9593500555,0.8214285714,0.3432835821,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Here some examples of what I would like to see available in TensorFlow:,Expected Behaviour,71,71,0.7741935484,0.1749226006,0.04064994448,0.9593500555,0.4642857143,0.1940298507,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [cycle_range] URL,Expected Behaviour,96,28,0.8064516129,0.1764705882,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [shuffle_iter] URL,Expected Behaviour,97,29,0.8387096774,0.1780185759,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [batch_iter] URL,Expected Behaviour,95,27,0.8709677419,0.1795665635,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [iter_shuffle_batch_range] URL,Expected Behaviour,109,41,0.9032258065,0.1811145511,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [iter_tensors_slice] URL,Expected Behaviour,103,35,0.935483871,0.1826625387,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [iter_shuffle_batch_tensors] URL,Expected Behaviour,111,43,0.9677419355,0.1842105263,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         [iter_shuffle_batch_window] URL,Expected Behaviour,110,42,1,0.1857585139,0.04064994448,0.9593500555,0.1071428571,0.0447761194,0.2125437083,0.01543061897,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,+1 to something like feed_dict.,Expected Behaviour,31,31,0.25,0.1873065015,0.04256853321,0.9574314668,0.2631578947,0.07462686567,0.01543061897,0.001149776305,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"That's the only way to learn by interacting with external world (training robot arms, Atari games, [Universe] URL  ).",Motivation,148,117,0.5,0.1888544892,0.04256853321,0.9574314668,1,0.2835820896,0.01543061897,0.001149776305,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It could be made more efficient by avoiding copies.,Solution Discussion,51,51,0.75,0.1904024768,0.04256853321,0.9574314668,0.4736842105,0.1343283582,0.01543061897,0.001149776305,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Like PyTorch, whose Tensors share memory buffers with underlying numpy arrays",Solution Discussion,77,77,1,0.1919504644,0.04256853321,0.9574314668,0.5789473684,0.1641791045,0.01543061897,0.001149776305,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I don't know TF as well as others here, so please take my comments with some skepticism:",Social Conversation,88,88,0.1111111111,0.193498452,0.04271149234,0.9572885077,0.3863636364,0.2537313433,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"-         With CODE I was able to solve most of my input-related problems, like loading .mat files in a symbolic-ish manner.",Motivation,132,124,0.2222222222,0.1950464396,0.04271149234,0.9572885077,0.5227272727,0.3432835821,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"The one I'm currently struggling with is the integration of CODE with the ability of picking the source from which the input should come, for having train/val data in the same symbolic variable.",Motivation,206,194,0.3333333333,0.1965944272,0.04271149234,0.9572885077,0.7727272727,0.5074626866,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,#8168,Motivation,5,5,0.4444444444,0.1981424149,0.04271149234,0.9572885077,0.02272727273,0.01492537313,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I understand these functions were initially thought for simple use cases, but it would be nice to have more control of the pipeline without the burden of managing _everything_ (e.g. using CODE but being forced to feed queues and manage threads kind of manually).",Motivation,282,262,0.5555555556,0.1996904025,0.04271149234,0.9572885077,1,0.6567164179,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"-         I think CODE-like solutions are not optimal for passing big chunks of data to the train function, like a batch of images, since they're basically a pause in the execution graph to force TF to interact with _python's runtime_.",Solution Discussion,242,235,0.6666666667,0.2012383901,0.04271149234,0.9572885077,0.9318181818,0.6119402985,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"An in-graph solution sounds better, with pointers to guide the graph execution, like CODE to indicate the input should come from the training pipeline, the model should set batchnorm and dropout (et al) to train mode etc.",Solution Discussion,249,221,0.7777777778,0.2027863777,0.04271149234,0.9572885077,0.8636363636,0.5671641791,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"This way, TF could better optimize/parallelize the execution, and all solutions would scale.",Solution Discussion,92,92,0.8888888889,0.2043343653,0.04271149234,0.9572885077,0.3181818182,0.2089552239,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For example, a CODE receives the number of epochs to be generated but there seems to be no way of knowing the epoch of one sample without counting how many we have already evaluated.",Motivation,200,182,1,0.2058823529,0.04271149234,0.9572885077,0.7727272727,0.5074626866,0.001149776305,0.005164577321,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,right now there are two very divergent paths to getting data into Tensorflow: feed_dict and queues.,Solution Discussion,99,99,0.125,0.2074303406,0.04335363766,0.9566463623,0.4571428571,0.2388059701,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"queues are wonderful until you don't have a way to manipulate your data natively -- for example, if you want to load a .wav file, chop it into parts, and convert it to a spectrogram.",Solution Discussion,182,182,0.25,0.2089783282,0.04335363766,0.9566463623,1,0.5223880597,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"at that point, you have to write a C++ op (doable, but a context switch + it makes a very inflexible pipeline) or pop back into Python land (slower, but very easy and flexible).",Solution Discussion,177,177,0.375,0.2105263158,0.04335363766,0.9566463623,0.9428571429,0.4925373134,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,it seems like the best compromise between speed and flexibility is to create a TF queue and then make a bunch of Python threads that feed it with data.,Solution Discussion,151,151,0.5,0.2120743034,0.04335363766,0.9566463623,0.8285714286,0.4328358209,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"this allows you to do flexible data processing in Python (roughly parallelized on the CPU, apart from GIL issues) while maintaining some amount of speed benefit.",Solution Discussion,161,161,0.625,0.213622291,0.04335363766,0.9566463623,0.7428571429,0.3880597015,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,what if you just formalized that?,Solution Discussion,33,33,0.75,0.2151702786,0.04335363766,0.9566463623,0.1714285714,0.08955223881,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"the interface would be: push_data, end_of_data (for signaling the end of an epoch), and a dequeue_batch function that feeds the model.",Solution Discussion,134,134,0.875,0.2167182663,0.04335363766,0.9566463623,0.6,0.3134328358,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"then your code could just load data in Python and stuff it onto the queue in parallel, while the model sits totally separate from all of that.",Solution Discussion,142,142,1,0.2182662539,0.04335363766,0.9566463623,0.7714285714,0.4029850746,0.005164577321,0.043809073,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We should make feed_dict faster (likely by not copying the numpy.arrays like @yaroslavvb mentioned), but that's orthogonal to this change.",Potential New Issues and Requests,138,138,0.5,0.2198142415,0.04880070327,0.9511992967,0.9523809524,0.2985074627,0.043809073,0.001787522968,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"No matter how much we optimize it, feed_dict will never be the fastest way to feed data into a training job.",Potential New Issues and Requests,108,108,1,0.2213622291,0.04880070327,0.9511992967,1,0.3134328358,0.043809073,0.001787522968,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,CODE specifically may not be essential.,Solution Discussion,46,39,0.3333333333,0.2229102167,0.04902295757,0.9509770424,0.1395348837,0.08955223881,0.001787522968,0.0009069948543,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"To be more precise, we need support for pipelines where learning is done in an online fashion, and training data is generated by a system responding to actions of a TensorFlow network (learning Atari simulator, robotics simulator, robot interacting with real world, etc).",Expected Behaviour,271,271,0.6666666667,0.2244582043,0.04902295757,0.9509770424,1,0.6417910448,0.001787522968,0.0009069948543,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"This is necessary for most of the applications at OpenAI, here's one example -- https://github.com/openai/universe-starter-agent",Motivation,128,128,1,0.226006192,0.04902295757,0.9509770424,0.3488372093,0.223880597,0.001787522968,0.0009069948543,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The fastest option would be to create a TensorFlow op that maintains state, takes actions as input, and generates the training data.",Solution Discussion,132,132,0.25,0.2275541796,0.04913573011,0.9508642699,1,0.328358209,0.0009069948543,0.001568663379,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Then add a placeholder to specify the action.,Solution Discussion,45,45,0.5,0.2291021672,0.04913573011,0.9508642699,0.3636363636,0.1194029851,0.0009069948543,0.001568663379,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"My guess is that you're looking for something that can be done completely in Python, though.",Solution Discussion,92,92,0.75,0.2306501548,0.04913573011,0.9508642699,0.7272727273,0.2388059701,0.0009069948543,0.001568663379,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,There may be some mid-point between the two.,Solution Discussion,44,44,1,0.2321981424,0.04913573011,0.9508642699,0.4090909091,0.1343283582,0.0009069948543,0.001568663379,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I am not sure it this concept has been brought up yet, but I will at least put the problem in my own terms.",Social Conversation,107,107,0.1428571429,0.23374613,0.04933077218,0.9506692278,0.48,0.3582089552,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"In dealing with RL problems and the training replay buffer, I couldn't find an easy way to use the Queues to speed up this feeding of samples through the feed_dict.",Motivation,164,164,0.2857142857,0.2352941176,0.04933077218,0.9506692278,0.6,0.447761194,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Also, when randomly creating a sample set, it seemed like the samples were consumed when I wanted them left in the buffer.",Motivation,122,122,0.4285714286,0.2368421053,0.04933077218,0.9506692278,0.44,0.328358209,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"What I was hoping to do is feed (possibly through feed_dict, or file) a Queue with a new sample and once the size of the buffer is exceeded, the oldest sample is removed from the buffer.",Motivation,186,186,0.5714285714,0.2383900929,0.04933077218,0.9506692278,0.72,0.5373134328,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"So some concept of ""sample age"" would be nice.",Expected Behaviour,46,46,0.7142857143,0.2399380805,0.04933077218,0.9506692278,0.18,0.1343283582,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I am sure using a circular buffer will work to fix to a number of samples, but ""age"" might be of interest as well, maybe passed as part of the tuple, but in the RL case, simply the sequence of the sample being added might cover the age (FIFO).",Solution Discussion,243,243,0.8571428571,0.2414860681,0.04933077218,0.9506692278,0.98,0.7313432836,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Again, it may have just not been clear to me how to use the queues, but being able to randomly pull a mini-batch from this sample buffer and not remove the samples so a new set of samples can be collected (possibly with prior sampled examples) would be nice.",Expected Behaviour,258,258,1,0.2430340557,0.04933077218,0.9506692278,1,0.7462686567,0.001568663379,0.00540277799,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I may not understand the distributed settings that TF data input pipeline API is targeting to solve.,Social Conversation,100,100,0.1666666667,0.2445820433,0.05000253453,0.9499974655,0.85,0.2537313433,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I can pick up pytorch's dataset API in 5 minutes and it's good enough for all the popular academic datasets.,Motivation,108,108,0.3333333333,0.246130031,0.05000253453,0.9499974655,1,0.2985074627,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,http://pytorch.org/docs/data.html,Motivation,33,33,0.5,0.2476780186,0.05000253453,0.9499974655,0.05,0.01492537313,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It's great to see new efforts to solve the pain points in TF dataset API.,Social Conversation,73,73,0.6666666667,0.2492260062,0.05000253453,0.9499974655,0.75,0.223880597,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Looking forward to a simple/beautiful/flexible API with minimum number of classes/concepts introduced.,Social Conversation,102,102,0.8333333333,0.2507739938,0.05000253453,0.9499974655,0.75,0.223880597,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks.,Social Conversation,7,7,1,0.2523219814,0.05000253453,0.9499974655,0.05,0.01492537313,0.00540277799,0.0003827497926,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@lming Yeah, the first two comments here cover that: by making a Dataset implementation that uses [py_func] URL , it'd be equivalent to the PyTorch implementation.",Solution Discussion,213,163,1,0.253869969,0.05005012429,0.9499498757,1,0.3880597015,0.0003827497926,5.70E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I second @lming's sentiment above.,Social Conversation,34,34,0.125,0.2554179567,0.05005721213,0.9499427879,0.125,0.07462686567,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Our biggest issue with the current data loading scheme is just that it's very complicated and involves a lot of new concepts.,Motivation,125,125,0.25,0.2569659443,0.05005721213,0.9499427879,0.55,0.328358209,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We don't find it spectacularly difficult to write a multithreaded data loader ourselves in Python, and generally we don't find it overly difficult to ensure that our data loading and preprocessing runs sufficiently quickly that it doesn't actually bottleneck training.",Motivation,268,268,0.375,0.2585139319,0.05005721213,0.9499427879,1,0.5970149254,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Where we're stuck is that to optimally follow recommendations, we end up in an awkward situation, one of:",Motivation,105,105,0.5,0.2600619195,0.05005721213,0.9499427879,0.45,0.2686567164,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         Using CODE and suffering any relevant performance hits,Motivation,71,64,0.625,0.2616099071,0.05005721213,0.9499427879,0.225,0.1343283582,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,-         Feeding from a separate thread and dealing with some one-off queue boilerplate (except this didn't speed things up at all when we tried it),Motivation,149,149,0.75,0.2631578947,0.05005721213,0.9499427879,0.65,0.3880597015,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"-         Reimplementing our data loading and transformation pipeline with TF primitives, perhaps with CODE, but still using the TF API for managing queue runners",Motivation,167,162,0.875,0.2647058824,0.05005721213,0.9499427879,0.6,0.3582089552,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"The Python threading API isn't perfect, but in general when we're doing mostly non-GIL-taking tasks in NumPy or whatever, the TF queue API seems more of a burden than a help.",Motivation,174,174,1,0.26625387,0.05005721213,0.9499427879,0.825,0.4925373134,5.70E-05,0.0003781690105,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,A couple of concrete use cases that come up for us:,Motivation,51,51,0.1666666667,0.2678018576,0.05010423233,0.9498957677,0.2340425532,0.1641791045,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         One of our models is a localization model.,Motivation,52,52,0.3333333333,0.2693498452,0.05010423233,0.9498957677,0.1914893617,0.1343283582,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We use scikit-image CODE objects to apply cropping and resizing operations for this model, because those objects let us easily translate our model output back to the original input coordinate space.",Motivation,211,198,0.5,0.2708978328,0.05010423233,0.9498957677,0.6808510638,0.4776119403,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,It seems tricky to square this with a fully tensor-based API.,Motivation,61,61,0.6666666667,0.2724458204,0.05010423233,0.9498957677,0.2553191489,0.1791044776,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"-         We have data that comes from a large number of imbalanced segments, and in training we use some custom stratified sampling logic to ensure we present examples from each segment evenly.",Motivation,194,194,0.8333333333,0.273993808,0.05010423233,0.9498957677,0.6808510638,0.4776119403,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"It's relatively straightforward for us to, in Python, generate a new draw from our original data set for every epoch, but it seems like in the API proposed above, we'd have to figure out how to implement this behavior as an CODE, which seems less straightforward.",Motivation,269,263,1,0.2755417957,0.05010423233,0.9498957677,1,0.7014925373,0.0003781690105,0.199242644,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"We primarily deal with time series data, and prefer to not have to batch preprocess the whole dataset prior to training every unique model input architecture.",Motivation,158,158,0.25,0.2770897833,0.07487735986,0.9251226401,0.7428571429,0.3880597015,0.199242644,0.03685646374,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"In fact, the preprocessed dataset size for one input architecture variant can be easily an order of magnitude larger than the unprocessed file set size.",Motivation,152,152,0.5,0.2786377709,0.07487735986,0.9251226401,0.7142857143,0.3731343284,0.199242644,0.03685646374,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If you're planning to deprecate the current queues paradigm, I would like to know that the CODE and CODE would enable the same flexibility.",Expected Behaviour,150,139,0.75,0.2801857585,0.07487735986,0.9251226401,0.6857142857,0.3582089552,0.199242644,0.03685646374,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"For my use case it seems like CODE could represent a collection of time series, and the CODE would behave like a python iterator/generator and could handle any preprocessing to form batches of examples?",Expected Behaviour,213,202,1,0.2817337461,0.07487735986,0.9251226401,1,0.5223880597,0.199242644,0.03685646374,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"feature request: control mechanism for queues, especially in combination with TFRecordReader's/TextFileReader's read() method, which automatically dequeues.",Expected Behaviour,156,156,0.5,0.2832817337,0.07945996255,0.9205400374,1,0.2537313433,0.03685646374,0.2293928428,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Reason: the automatic preevaluation of pending enqueues.,Motivation,56,56,1,0.2848297214,0.07945996255,0.9205400374,0.4117647059,0.1044776119,0.03685646374,0.2293928428,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"MXNet [IIterator] URL  is a more relevant example than Java's Stream API, Scala's collections (and hence Spark's RDDs), and .NET's Language Integrated Query.",Solution Discussion,227,157,0.2,0.286377709,0.1079818594,0.8920181406,0.8888888889,0.3582089552,0.2293928428,1,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The design enables flexible composition of various components of the input pipeline such as  [ImageRecordIter] URL , [ImageNormalizeIter] URL , [BatchLoader] URL , [PrefetcherIter] URL  and [ImageAugmenter] URL .",Solution Discussion,602,212,0.4,0.2879256966,0.1079818594,0.8920181406,1,0.4029850746,0.2293928428,1,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,CODE,Solution Discussion,492,4,0.6,0.2894736842,0.1079818594,0.8920181406,0.03703703704,0.01492537313,0.2293928428,1,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Caffe [DB] URL  is simpler but still usable.,Solution Discussion,111,44,0.8,0.2910216718,0.1079818594,0.8920181406,0.3333333333,0.1343283582,0.2293928428,1,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Ideally, the newly designed API should be able to load existing datasets of Caffe & MXNet with easy to implement [plugins] URL .",Expected Behaviour,199,128,1,0.2925696594,0.1079818594,0.8920181406,0.7777777778,0.3134328358,0.2293928428,1,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Just my 2 cents.,Social Conversation,16,16,0.25,0.2941176471,0.2323183319,0.7676816681,0.1,0.05970149254,1,0.3601548304,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Happy for this decision.,Social Conversation,24,24,0.5,0.2956656347,0.2323183319,0.7676816681,0.1,0.05970149254,1,0.3601548304,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I think that a *huge* effort should be placed in tutorials: the hugest difficulty I am having -- and some colleagues with me -- is that the documentation that you can find is quite lousy and not very self-contained.,Motivation,215,215,0.75,0.2972136223,0.2323183319,0.7676816681,1,0.5970149254,1,0.3601548304,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I would be happy to help, of course.",Contribution and Commitment,36,36,1,0.2987616099,0.2323183319,0.7676816681,0.2,0.1194029851,1,0.3601548304,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Unfortunately the documentation is still lacking further explanations.,Expected Behaviour,70,70,0.1666666667,0.3003095975,0.2770987131,0.7229012869,0.4210526316,0.1194029851,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I can only find some basic infos in the C++ API docs.,Motivation,53,53,0.3333333333,0.3018575851,0.2770987131,0.7229012869,0.6315789474,0.1791044776,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Would be really interested to read something for the Python API + some example code.,Expected Behaviour,84,84,0.5,0.3034055728,0.2770987131,0.7229012869,0.7368421053,0.2089552239,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If you need any help, feel free to contact me or e.g. @petrux also offered help.",Contribution and Commitment,80,80,0.6666666667,0.3049535604,0.2770987131,0.7229012869,0.8421052632,0.2388059701,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I think he is right, that extending the documentation and providing better tutorials is highly important.",Motivation,105,105,0.8333333333,0.306501548,0.2770987131,0.7229012869,0.8421052632,0.2388059701,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Because otherwise the people will stick with feed_dict inputs until TensorFlow 3.0 and moan about bad performance of TF,Motivation,119,119,1,0.3080495356,0.2770987131,0.7229012869,1,0.2835820896,0.3601548304,0.003376036402,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I ended up doing some benchmarking for other reasons, and observed comparable performance between CODE and using queues: https://github.com/tensorflow/tensorflow/issues/9322#issuecomment-295775991",Solution Discussion,203,196,1,0.3095975232,0.2775184776,0.7224815224,1,0.2835820896,0.003376036402,0.001660279021,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Feed dict overhead is essentially the cost of doing an extra memcpy (Python->TensorFlow CPU->TensorFlow GPU) vs. using native ops like queues which do (TensorFlow CPU->TensorFlow GPU).,Solution Discussion,184,184,0.5,0.3111455108,0.2777249108,0.7222750892,1,0.3880597015,0.001660279021,0.0007705893431,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"So if this memcpy is small, there should be negligible.",Solution Discussion,55,55,1,0.3126934985,0.2777249108,0.7222750892,0.3846153846,0.1492537313,0.001660279021,0.0007705893431,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"That makes sense, and it's what I was assuming.",Social Conversation,47,47,0.5,0.3142414861,0.2778207232,0.7221792768,0.2727272727,0.1343283582,0.0007705893431,0.03560947306,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I think that makes the advice against CODE a bit overblown, though â really the issue seems more like inefficient data feeding that starves the GPUs, rather than the use of CODE itself.",Solution Discussion,199,185,1,0.3157894737,0.2778207232,0.7221792768,1,0.4925373134,0.0007705893431,0.03560947306,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@yaroslavvb correct me if I'm wrong but this isn't entirely right.,Social Conversation,66,66,0.2,0.3173374613,0.2822482794,0.7177517206,0.3333333333,0.1641791045,0.03560947306,0.002163656075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Unless you haven't implemented some input pipeline using Pythons Queue library or something similar it will be additionally the time of loading data from disk into memory and eventually preprocess them.,Solution Discussion,202,202,0.4,0.3188854489,0.2822482794,0.7177517206,0.9393939394,0.4626865672,0.03560947306,0.002163656075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For Images and especially larger batch size, this might take quite a while.",Solution Discussion,75,75,0.6,0.3204334365,0.2822482794,0.7177517206,0.3939393939,0.1940298507,0.03560947306,0.002163656075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Here is where you can really speed things up using TFs input queues because they will load e.g. images into disk ( + preprocess ) on CPU while you are training/evaluating your network on GPU.,Solution Discussion,191,191,0.8,0.3219814241,0.2822482794,0.7177517206,1,0.4925373134,0.03560947306,0.002163656075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"When computations are done, you can directly grab the next batch on copy the data on the GPU, without waiting for native Python to load new data into memory.",Solution Discussion,157,157,1,0.3235294118,0.2822482794,0.7177517206,0.8787878788,0.4328358209,0.03560947306,0.002163656075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kratzert, that's precisely what @taion means by",Social Conversation,48,48,0.5,0.3250773994,0.2825173008,0.7174826992,0.4117647059,0.1044776119,0.002163656075,0.000434665323,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"It's hard to do asynchronous preprocessing well, so most users benefit from CODE doing it for them.",Solution Discussion,105,99,1,0.326625387,0.2825173008,0.7174826992,1,0.2537313433,0.002163656075,0.000434665323,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Is it?,Social Conversation,6,6,0.2,0.3281733746,0.2825713456,0.7174286544,0.05714285714,0.02985074627,0.000434665323,0.0005756516163,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"By no means I want to defend TFs input queues, but as I read the post of @yaroslavvb he states that the additional time comes (only) from passing memory between native Python and TF ( + GPU).",Solution Discussion,191,191,0.4,0.3297213622,0.2825713456,0.7174286544,1,0.5223880597,0.000434665323,0.0005756516163,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The only thing I wanted to add is, that if you can't store all your trainings data in memory, also loading memory from disk into memory adds up time to one training cycle.",Solution Discussion,171,171,0.6,0.3312693498,0.2825713456,0.7174286544,0.9428571429,0.4925373134,0.000434665323,0.0005756516163,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I can't find any of this statement in the post of @taion, but could be a misunderstanding of my side as I'm not a English native speaker.",Social Conversation,137,137,0.8,0.3328173375,0.2825713456,0.7174286544,0.7714285714,0.4029850746,0.000434665323,0.0005756516163,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"And I know, that for many cases asynchronous preprocessing is not possible, but for the cases it is (simple training of image classification CNN) TFs input queues help quite a lot.",Solution Discussion,180,180,1,0.3343653251,0.2825713456,0.7174286544,0.8857142857,0.4626865672,0.000434665323,0.0005756516163,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,That also applies to CODE.,Solution Discussion,32,26,0.3333333333,0.3359133127,0.2826429201,0.7173570799,0.1724137931,0.07462686567,0.0005756516163,0.0003837677442,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Data doesn't just appear in the graph without reading it from disk, regardless of whether you do it via Python or TensorFlow's execution engine.",Solution Discussion,144,144,0.6666666667,0.3374613003,0.2826429201,0.7173570799,0.8275862069,0.3582089552,0.0005756516163,0.0003837677442,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Anyway, I find memapped NumPy arrays via [joblib.cache.Memory] URL  and feed_dict to be quite performant (GPU load over 90% throughout a training session), despite the extra copy.",Solution Discussion,219,179,1,0.3390092879,0.2826429201,0.7173570799,1,0.4328358209,0.0005756516163,0.0003837677442,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Ah okay so maybe a misunderstanding.,Social Conversation,36,36,0.1111111111,0.3405572755,0.2826906364,0.7173093636,0.1621621622,0.08955223881,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thought I made myself clearer.,Social Conversation,30,30,0.2222222222,0.3421052632,0.2826906364,0.7173093636,0.1351351351,0.07462686567,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I know that data does not appear magically in memory if I use TF.,Solution Discussion,65,65,0.3333333333,0.3436532508,0.2826906364,0.7173093636,0.3783783784,0.2089552239,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But TF makes it quite easy to place e.g. image loading + preprocessing explicitly on CPU and graph computation on GPU and both is done in parallel.,Solution Discussion,147,147,0.4444444444,0.3452012384,0.2826906364,0.7173093636,0.7027027027,0.3880597015,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"So while GPU calculates ops on some data, CPU is already loading the next data into memory.",Solution Discussion,91,91,0.5555555556,0.346749226,0.2826906364,0.7173093636,0.4594594595,0.2537313433,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"And since this is done in parallel, we are effectively reducing the computational time by the amount of loading data from disk (since this takes usually less time then one forward + backward pass through the networks graph).",Solution Discussion,224,224,0.6666666667,0.3482972136,0.2826906364,0.7173093636,1,0.552238806,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But yes this only applies for working with CPU + GPU and has no effect if you use CPU only.,Solution Discussion,91,91,0.7777777778,0.3498452012,0.2826906364,0.7173093636,0.5135135135,0.2835820896,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,edit: The maybe only thing I like of TFs input queues is that I the state of the queues (and batch producers) can be observed in Tensorboard.,Solution Discussion,141,141,0.8888888889,0.3513931889,0.2826906364,0.7173093636,0.7297297297,0.4029850746,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,For the rest I fought quite some time to get them running with all the preprocessing I wanted and with queues for testing and validation in the same run.,Solution Discussion,153,153,1,0.3529411765,0.2826906364,0.7173093636,0.7837837838,0.4328358209,0.0003837677442,0.1209962692,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I would say that aside from the steep learning curve of input pipeline which can be overcome with documentation too, the key missing points are:",Expected Behaviour,144,144,0.125,0.3544891641,0.2977348857,0.7022651143,0.5952380952,0.3731343284,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"1.         A decent way to make custom preprocessing of the data, whether it be based on queue's or not, the idea of being able to foresee all possible data input needs is doomed.",Motivation,179,179,0.25,0.3560371517,0.2977348857,0.7022651143,0.8095238095,0.5074626866,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"2.         An easy and established way to change the input pipeline of a graph, after it has been created, because it is the most typical usage pattern.",Motivation,152,152,0.375,0.3575851393,0.2977348857,0.7022651143,0.6666666667,0.4179104478,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Current CODE provides such functionality, but it is rather hacky.",Motivation,72,65,0.5,0.3591331269,0.2977348857,0.7022651143,0.2380952381,0.1492537313,0.1209962692,0.001143668596,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,And documented too (when it comes to CODE).,Motivation,58,43,0.625,0.3606811146,0.2977348857,0.7022651143,0.1904761905,0.1194029851,0.1209962692,0.001143668596,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,3.         A way to control and monitor the epochs - currently they are rather deeply hidden and unaccessible even simple checks.,Motivation,129,129,0.75,0.3622291022,0.2977348857,0.7022651143,0.5,0.3134328358,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I'd support @nicolasdespres for ""no Dataset"" pledge, mainly because all-in-one bundle is not flexible, not future proof and also - not consistent with the TF's paradigm of providing small, stable, well-defined and assemble-able blocks for building custom models.",Motivation,262,262,0.875,0.3637770898,0.2977348857,0.7022651143,1,0.6268656716,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Having some bundles, predefined ""easy-starter"" wrappers should be welcomed.",Expected Behaviour,75,75,1,0.3653250774,0.2977348857,0.7022651143,0.2380952381,0.1492537313,0.1209962692,0.001143668596,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I think TF does not really require another attempt to unify the data pre-processing to put it directly *into* the graph.,Solution Discussion,120,120,0.09090909091,0.366873065,0.2978770854,0.7021229146,0.7096774194,0.328358209,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Things get worse if one need custom stuff and on-the-fly generation/modification of data.,Solution Discussion,89,89,0.1818181818,0.3684210526,0.2978770854,0.7021229146,0.5161290323,0.2388059701,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Typically these modifications are not part of the forward model for a good reason: these operations do not require any backpropagation.,Solution Discussion,135,135,0.2727272727,0.3699690402,0.2978770854,0.7021229146,0.6774193548,0.3134328358,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Hence, they should be only loosely coupled.",Solution Discussion,43,43,0.3636363636,0.3715170279,0.2978770854,0.7021229146,0.2258064516,0.1044776119,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,So the ideal input pipeline (everything without backprop) should be quite simple and slim: It should consist of a queue operation which receives data (list of tensors) from **some** source (sockets).,Solution Discussion,199,199,0.4545454545,0.3730650155,0.2978770854,0.7021229146,1,0.4626865672,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,#8728 is a good step in this direction with the pros:,Solution Discussion,53,53,0.5454545455,0.3746130031,0.2978770854,0.7021229146,0.3548387097,0.1641791045,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"-         you can use any library for preprocessing (opencv, nltk, ...)",Solution Discussion,71,71,0.6363636364,0.3761609907,0.2978770854,0.7021229146,0.3225806452,0.1492537313,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         prefetching is totally parallel and can be done at any/multiple machine,Solution Discussion,81,81,0.7272727273,0.3777089783,0.2978770854,0.7021229146,0.4193548387,0.1940298507,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         the sender-code can be put into any place -- even directly in game-engines or render-engines,Solution Discussion,102,102,0.8181818182,0.3792569659,0.2978770854,0.7021229146,0.6129032258,0.2835820896,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         data generation can be done in any programming language (without custom ops),Solution Discussion,86,86,0.9090909091,0.3808049536,0.2978770854,0.7021229146,0.4193548387,0.1940298507,0.001143668596,0.01002173327,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I am not sure, if you really need something else and I do not understand why you really need CODE *in* the graph.",Solution Discussion,128,113,1,0.3823529412,0.2978770854,0.7021229146,0.7419354839,0.3432835821,0.001143668596,0.01002173327,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I don't think the proposal here is to get rid of queues entirely, is it?",Solution Discussion,72,72,0.25,0.3839009288,0.2991231524,0.7008768476,0.223880597,0.223880597,0.01002173327,0.1413171275,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Dataset-style abstractions are pretty common in this space, and they're quite useful.",Solution Discussion,85,85,0.5,0.3854489164,0.2991231524,0.7008768476,0.1940298507,0.1940298507,0.01002173327,0.1413171275,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The existence of a higher-level abstraction doesn't preclude the lower-level API from also existing.,Solution Discussion,100,100,0.75,0.386996904,0.2991231524,0.7008768476,0.2388059701,0.2388059701,0.01002173327,0.1413171275,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"In fact for these kinds of higher-level abstractions, sooner seems better than later â one of the greatest frustrations of reading published TF research code is that the vast majority of codebases use their own idiosyncratic layers library, as opposed to e.g. the ones in CODE or CODE, and these libraries are all different, which makes it more difficult than it should be to share work.",Motivation,409,387,1,0.3885448916,0.2991231524,0.7008768476,1,1,0.01002173327,0.1413171275,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,I often try to use TensorFlow on very large inputs (potentially >1GB minibatch) with relatively light computation on each minibatch.,Motivation,132,132,0.1666666667,0.3900928793,0.3166940255,0.6833059745,0.65625,0.3134328358,0.1413171275,0.04972082678,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"These inputs are in a HDF5 file or a Numpy array either on disk or in memory, so I typically feed with CODEfeed_dictCODE, potentially asynchronously into a queue.",Motivation,158,162,0.3333333333,0.3916408669,0.3166940255,0.6833059745,0.875,0.4179104478,0.1413171275,0.04972082678,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"When running with multiple GPUs, TensorFlow is not able to even saturate the PCI-e bandwidth to the GPUs because of the memcpy from the feed_dict to the CPU tensor.",Motivation,164,164,0.5,0.3931888545,0.3166940255,0.6833059745,0.9375,0.447761194,0.1413171275,0.04972082678,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"As @yaroslavvb mentioned, the CODEfeed_dictCODE memcpy (on a single CPU core?) can be a huge performance bottleneck, and I'd like to see this addressed in any refactor of TensorFlow's input handling.",Motivation,195,199,0.6666666667,0.3947368421,0.3166940255,0.6833059745,1,0.4776119403,0.1413171275,0.04972082678,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@jhseu You mentioned that you consider removing the CODEfeed_dictCODE copy as orthogonal to this issue.,Potential New Issues and Requests,99,103,0.8333333333,0.3962848297,0.3166940255,0.6833059745,0.46875,0.223880597,0.1413171275,0.04972082678,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Do you know if there's any issue or work being done on removing the copy (at least in some cases, like row-major Numpy arrays with nice strides)?",Potential New Issues and Requests,145,145,1,0.3978328173,0.3166940255,0.6833059745,0.875,0.4179104478,0.1413171275,0.04972082678,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@eamartin there have been a number of changes since the beginning of March by @alextp to speed up feed_dict; when the memory is aligned with 16 bytes, I think we share buffers with numpy, so nightly releases may be faster for you.",Potential New Issues and Requests,230,230,0.3333333333,0.399380805,0.3228761377,0.6771238623,1,0.6268656716,0.04972082678,0.01426913622,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The 16 byte alignment issue comes from Eigen, unfortunately, which requires the beginning of the memory addresses to be aligned with 16 bytes.",Potential New Issues and Requests,142,142,0.6666666667,0.4009287926,0.3228761377,0.6771238623,0.5476190476,0.3432835821,0.04972082678,0.01426913622,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I'm not sure why Eigen was not written to handle unaligned first and last ""packets"" so it wouldn't matter.",Potential New Issues and Requests,106,106,1,0.4024767802,0.3228761377,0.6771238623,0.4523809524,0.2835820896,0.04972082678,0.01426913622,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Would it be possible for numpy to share buffers with tensorflow variableswhen they are returned from a session run?,Potential New Issues and Requests,115,115,0.5,0.4040247678,0.3246503118,0.6753496882,0.6785714286,0.2835820896,0.01426913622,0.02224733169,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I realise this will probably raise all sorts of mutability and stateissues, but these should be avoidable by setting the WRITABLE flag on thereturned numpy arrays to false.",Potential New Issues and Requests,172,172,1,0.4055727554,0.3246503118,0.6753496882,1,0.4179104478,0.01426913622,0.02224733169,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks for the info @vrv (and for the features @alextp ).,Social Conversation,57,57,0.3333333333,0.407120743,0.3274164665,0.6725835335,0.625,0.1492537313,0.02224733169,0.03860581352,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I did a little looking around, and it looks like https://github.com/tensorflow/tensorflow/commits?author=alextp&since=2017-03-01T06:00:00Z&until=2017-04-01T05:00:00Z are the relevant commits.",Potential New Issues and Requests,191,191,0.6666666667,0.4086687307,0.3274164665,0.6725835335,0.9375,0.223880597,0.02224733169,0.03860581352,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"From my checking, these didn't make it into TF 1.1 but hopefully will be in 1.2.",Potential New Issues and Requests,80,80,1,0.4102167183,0.3274164665,0.6725835335,1,0.2388059701,0.02224733169,0.03860581352,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Another thing that would be cool would be the ability for Session's to return Futures that could then be used as input to other Session runs.,Expected Behaviour,141,141,0.3333333333,0.4117647059,0.3322165772,0.6677834228,1,0.3880597015,0.03860581352,0.04548767515,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Said future could then be passed through the graph until the Tensor it represents requires evaluation.,Expected Behaviour,102,102,0.6666666667,0.4133126935,0.3322165772,0.6677834228,0.6153846154,0.2388059701,0.03860581352,0.04548767515,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This concept is inspired by [dask distributed] URL  and other executor frameworks -- I think the flexibility offered by this abstraction is great!,Motivation,178,146,1,0.4148606811,0.3322165772,0.6677834228,0.9230769231,0.3582089552,0.03860581352,0.04548767515,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@sjperkins sadly the way our current unit tests are written makes them break if variables are returned without extra copies (because many tests do a = session.run(variable); session.run(update_variable); b = session.run(variable); assertDifferent(a, b) (which fails if they share buffers).",Solution Discussion,289,289,0.3333333333,0.4164086687,0.3378723543,0.6621276457,1,0.552238806,0.04548767515,0.008149211342,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I considered making a ConfigProto option to share buffers even when they are not exclusively owned by the C-python bridge but didn't.,Solution Discussion,133,133,0.6666666667,0.4179566563,0.3378723543,0.6621276457,0.6216216216,0.3432835821,0.04548767515,0.008149211342,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Should be easy to do from the commits listed above, if you're interested.",Contribution and Commitment,73,73,1,0.419504644,0.3378723543,0.6621276457,0.3513513514,0.1940298507,0.04548767515,0.008149211342,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,My primary request is that however you build the new input pipeline system that it should be completely separate from the rest of the graph.,Expected Behaviour,140,140,0.1666666667,0.4210526316,0.3388855985,0.6611144015,0.625,0.3731343284,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm giving a shot at migrating to tensorflow for our deep learning models for devices; but the input pipeline is so tightly bound to the rest of the compute graph that its like performing surgery to run inference against it.,Motivation,224,224,0.3333333333,0.4226006192,0.3388855985,0.6611144015,1,0.5970149254,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Example: I trained using TFRecords and input queues; I got my weights/model.,Motivation,76,76,0.5,0.4241486068,0.3388855985,0.6611144015,0.325,0.1940298507,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I want to perform inference by running my prediction operation; but because the input queue runners etc are part of the graph before that; I am stuck with that mechanism for performing inference.,Motivation,195,195,0.6666666667,0.4256965944,0.3388855985,0.6611144015,0.825,0.4925373134,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,See issue here: http://stackoverflow.com/questions/43708616/tensorflow-inference,Motivation,80,80,0.8333333333,0.427244582,0.3388855985,0.6611144015,0.1,0.05970149254,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I like the tf record and queue runner thing now that I'm used to it; the issue is the tight binding to the graph....,Motivation,116,116,1,0.4287925697,0.3388855985,0.6611144015,0.625,0.3731343284,0.008149211342,0.0001124836492,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"This is why tools like tf.estimator.Estimator were developed, to allow foreasier separation of concerns between training and inference and to allowfor swapping of input pipelines.",Usage,179,179,0.5,0.4303405573,0.3388995843,0.6611004157,1,0.3880597015,0.0001124836492,0.3801876085,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Can you use Estimator to write your model?,Usage,42,42,1,0.4318885449,0.3388995843,0.6611004157,0.3076923077,0.1194029851,0.0001124836492,0.3801876085,MEMBER,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Currently I am worried that my training/prediction preprocessing will diverge over time.,Motivation,88,88,0.2,0.4334365325,0.3861707704,0.6138292296,0.4333333333,0.1940298507,0.3801876085,0.001120764685,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I would be interested in a pipeline where:,Expected Behaviour,42,42,0.4,0.4349845201,0.3861707704,0.6138292296,0.2666666667,0.1194029851,0.3801876085,0.001120764685,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"*         Preprocessing and post processing can be serialized with the inference in a single model and then used from another language (no CODE, but able to provide implementation at runtime)",Expected Behaviour,199,191,0.6,0.4365325077,0.3861707704,0.6138292296,1,0.447761194,0.3801876085,0.001120764685,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"*         There is a clearer distinction between input shapes, for training you usually want batches, but for prediction you often care only about single examples",Motivation,162,162,0.8,0.4380804954,0.3861707704,0.6138292296,0.8333333333,0.3731343284,0.3801876085,0.001120764685,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The preprocessing and post processing do not require backprop, but they sill need to carry some values with them (normalization divisors or one hot mappings).",Expected Behaviour,158,158,1,0.439628483,0.3861707704,0.6138292296,0.8333333333,0.3731343284,0.3801876085,0.001120764685,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@mirosval, it seems to me that this might be what CODE is intended for eventually.",Usage,92,82,1,0.4411764706,0.3863101223,0.6136898777,1,0.223880597,0.001120764685,0.1106294504,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Not sure if this was mentioned above and I missed it, but I would appreciate a much easier way to switch between train and validation data sets.",Expected Behaviour,144,144,0.2,0.4427244582,0.4000653979,0.5999346021,0.54,0.4029850746,0.1106294504,0.0001180823828,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"When using CODE, this is very simple, and this is what I'm used to.",Motivation,74,67,0.4,0.4442724458,0.4000653979,0.5999346021,0.28,0.2089552239,0.1106294504,0.0001180823828,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I've recently been trying to make the switch from CODE, but this has been (at least in my limited experience) a major difficulty.",Motivation,136,129,0.6,0.4458204334,0.4000653979,0.5999346021,0.48,0.3582089552,0.1106294504,0.0001180823828,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"The tutorial page [here] URL  mainly just suggests using separate processes, but this can be a pain, especially if I want to do early stopping based on the validation data.",Motivation,226,172,0.8,0.4473684211,0.4000653979,0.5999346021,0.62,0.4626865672,0.1106294504,0.0001180823828,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If I could create some sort of input method (Queue, Dataset, whatever) where I can cleanly swap between training and validation inputs, that would be much nicer (again, CODE is great for this, but if it will always be slower, it'd be nice to have a more performant alternative).",Motivation,285,278,1,0.4489164087,0.4000653979,0.5999346021,1,0.7462686567,0.1106294504,0.0001180823828,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@neighthan: yes this is something that @mrry has planned as well :),Task Progress,67,67,1,0.4504643963,0.4000800799,0.5999199201,1,0.1791044776,0.0001180823828,0.008691270556,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kdavis-mozilla that sounds interesting, but the link appears to be dead.",Social Conversation,73,73,0.5,0.4520123839,0.4011607218,0.5988392782,1,0.1791044776,0.008691270556,0.00137881541,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is there another reference?,Social Conversation,27,27,1,0.4535603715,0.4011607218,0.5988392782,0.3333333333,0.05970149254,0.008691270556,0.00137881541,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@neighthan Sorry, fixed.",Social Conversation,24,24,1,0.4551083591,0.4013321589,0.5986678411,1,0.0447761194,0.00137881541,0.005091284808,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Very promising!,Social Conversation,15,15,0.2,0.4566563467,0.4019651913,0.5980348087,0.07692307692,0.02985074627,0.005091284808,0.001827732055,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,That is one of my biggest issues with the current API.,Motivation,54,54,0.4,0.4582043344,0.4019651913,0.5980348087,0.4230769231,0.1641791045,0.005091284808,0.001827732055,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"That said, looking at SwitchableDataSet, it seems like implementing new kinds of data feeding use cases will be mostly done by implementing use-case specific classes.",Usage,166,166,0.6,0.459752322,0.4019651913,0.5980348087,1,0.3880597015,0.005091284808,0.001827732055,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Will the new programming model also feature an API to, say, implement what the SwitchableDataSet offers and beyond from more generic, lower-level primitives?",Solution Discussion,157,157,0.8,0.4613003096,0.4019651913,0.5980348087,0.9230769231,0.3582089552,0.005091284808,0.001827732055,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm just wondering about what things users will come up with (w.r.t. data generation and usage) that would otherwise require (specific) additions to the API...,Motivation,159,159,1,0.4628482972,0.4019651913,0.5980348087,0.9615384615,0.3731343284,0.005091284808,0.001827732055,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Am I correct to assume that https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/learn/python/learn/dataframe is part of the new input pipeline initiative?,Task Progress,174,174,0.1111111111,0.4643962848,0.402192445,0.597807555,0.5,0.223880597,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Is there any code out there that uses this, even if that code is undocumented?",Usage,78,78,0.2222222222,0.4659442724,0.402192445,0.597807555,0.5,0.223880597,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'd like to see an example of it in use.,Usage,40,40,0.3333333333,0.4674922601,0.402192445,0.597807555,0.3666666667,0.1641791045,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I also assume that the dataframes and transforms are intended to be closely integrated with estimators?,Solution Discussion,103,103,0.4444444444,0.4690402477,0.402192445,0.597807555,0.5333333333,0.2388059701,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"At the moment, I don't see how estimators fit (nicely) with the dataframes and transforms.",Solution Discussion,90,90,0.5555555556,0.4705882353,0.402192445,0.597807555,0.5,0.223880597,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I see where you have ways to generate feed_fns from dataframes for estimators, but it seems more like an adapter to another approach, instead of part of the pipeline design.",Solution Discussion,173,173,0.6666666667,0.4721362229,0.402192445,0.597807555,1,0.447761194,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I understand this is all very new and under development.,Social Conversation,56,56,0.7777777778,0.4736842105,0.402192445,0.597807555,0.3333333333,0.1492537313,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I really like what I see!,Social Conversation,25,25,0.8888888889,0.4752321981,0.402192445,0.597807555,0.2,0.08955223881,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Keep up the good work.,Social Conversation,22,22,1,0.4767801858,0.402192445,0.597807555,0.1666666667,0.07462686567,0.001827732055,0.008699923145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@vonclites That's for interacting with Pandas DataFrame/Series, not the new Dataset construct.",Solution Discussion,94,94,1,0.4783281734,0.4032741628,0.5967258372,1,0.1940298507,0.008699923145,0.0004494256208,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@jimfleming It seems to be more general than that.,Solution Discussion,50,50,0.3333333333,0.479876161,0.4033300428,0.5966699572,0.3333333333,0.1343283582,0.0004494256208,0.0005059219333,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"There are methods to create TensorFlowDataFrames from csv files, dicts, numpy arrays, TFRecords, as well as from pandas.",Solution Discussion,120,120,0.6666666667,0.4814241486,0.4033300428,0.5966699572,0.6666666667,0.2686567164,0.0004494256208,0.0005059219333,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"It follows the nomenclature of pandas, but it also resembles Spark's pipeline, as @mrry mentioned, and has many of the features he described in the original post.",Solution Discussion,162,162,1,0.4829721362,0.4033300428,0.5966699572,1,0.4029850746,0.0004494256208,0.0005059219333,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I agree that it's fairly generalized and it may be the basis for futurework but this has been available for quite a while and most of the fileshaven't been updated in months.,Solution Discussion,174,174,1,0.4845201238,0.4033929473,0.5966070527,1,0.4776119403,0.0005059219333,7.84E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@jimfleming Good point,Social Conversation,22,22,1,0.4860681115,0.4034026931,0.5965973069,1,0.0447761194,7.84E-05,0.24574369,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,First documentation on master under CODE: https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data,Task Progress,131,118,0.5,0.4876160991,0.4339575966,0.5660424034,1,0.1044776119,0.24574369,0.01344561339,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,All this seems pretty amazing !,Social Conversation,31,31,1,0.4891640867,0.4339575966,0.5660424034,0.7142857143,0.07462686567,0.24574369,0.01344561339,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Very nice indeed.,Social Conversation,17,17,0.25,0.4907120743,0.4356293768,0.5643706232,0.5,0.0447761194,0.01344561339,0.0007517572389,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The following iterators would be great:,Expected Behaviour,39,39,0.5,0.4922600619,0.4356293768,0.5643706232,1,0.08955223881,0.01344561339,0.0007517572389,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         [chain](https://docs.python.org/2/library/itertools.html#itertools.chain),Expected Behaviour,83,83,0.75,0.4938080495,0.4356293768,0.5643706232,0.6666666667,0.05970149254,0.01344561339,0.0007517572389,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         [product](https://docs.python.org/2/library/itertools.html#itertools.product),Expected Behaviour,87,87,1,0.4953560372,0.4356293768,0.5643706232,0.6666666667,0.05970149254,0.01344561339,0.0007517572389,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Below is why we need it:,Motivation,24,24,0.07692307692,0.4969040248,0.4357228476,0.5642771524,0.2727272727,0.08955223881,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Assume there is a large training data set which is in text format, and we need to convert it into tfrecord format.",Motivation,114,114,0.1538461538,0.4984520124,0.4357228476,0.5642771524,1,0.328358209,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Then we started a map-reduce job, converted it into 10 tfrecord files, started 10 workers to read them, Perfect!",Motivation,112,112,0.2307692308,0.5,0.4357228476,0.5642771524,0.9090909091,0.2985074627,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Then we want to run it faster, we would change the worker count to 20, 30, 40, ...",Motivation,82,82,0.3076923077,0.5015479876,0.4357228476,0.5642771524,0.7727272727,0.2537313433,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,it would be great if we could do this without re-generate the training data.,Motivation,76,76,0.3846153846,0.5030959752,0.4357228476,0.5642771524,0.6818181818,0.223880597,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Solution:,Solution Discussion,9,9,0.4615384615,0.5046439628,0.4357228476,0.5642771524,0.04545454545,0.01492537313,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"First, we need to pass an offset and length together with the filename into Dataset 's constructor.",Solution Discussion,99,99,0.5384615385,0.5061919505,0.4357228476,0.5642771524,0.7272727273,0.2388059701,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Only filename is not enough.,Solution Discussion,28,28,0.6153846154,0.5077399381,0.4357228476,0.5642771524,0.2272727273,0.07462686567,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Second, the file format it self must be seekable(aka. splitable).",Solution Discussion,65,65,0.6923076923,0.5092879257,0.4357228476,0.5642771524,0.4545454545,0.1492537313,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,it should be one of the following:,Solution Discussion,34,34,0.7692307692,0.5108359133,0.4357228476,0.5642771524,0.3181818182,0.1044776119,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,1.         Text format,Solution Discussion,22,22,0.8461538462,0.5123839009,0.4357228476,0.5642771524,0.1818181818,0.05970149254,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,2.         Blocked binary format with paddings.,Solution Discussion,47,47,0.9230769231,0.5139318885,0.4357228476,0.5642771524,0.3181818182,0.1044776119,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,3.         Has an index file.,Solution Discussion,29,29,1,0.5154798762,0.4357228476,0.5642771524,0.2727272727,0.08955223881,0.0007517572389,0.0001445491238,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This new API is faster than the old one.,Solution Discussion,40,40,0.3333333333,0.5170278638,0.4357408203,0.5642591797,0.4736842105,0.1343283582,0.0001445491238,0.02256391463,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I've integrated this new dataset API into my factoration machine trainer, and it saved me 20% training time.",Solution Discussion,108,108,0.6666666667,0.5185758514,0.4357408203,0.5642591797,1,0.2835820896,0.0001445491238,0.02256391463,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks @mrry,Social Conversation,12,12,1,0.520123839,0.4357408203,0.5642591797,0.1052631579,0.02985074627,0.0001445491238,0.02256391463,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I feel like the default code for looping over a dataset is a bit ugly with an exception breaking out of a CODE loop:CODE,Usage,237,120,0.3333333333,0.5216718266,0.4385463379,0.5614536621,1,0.3731343284,0.02256391463,0.02590584966,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Wouldn't there be a way to have an CODE tensor indicating when the iterator is empty?,Expected Behaviour,91,85,0.6666666667,0.5232198142,0.4385463379,0.5614536621,0.64,0.2388059701,0.02256391463,0.02590584966,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Like:CODE,Expected Behaviour,135,9,1,0.5247678019,0.4385463379,0.5614536621,0.08,0.02985074627,0.02256391463,0.02590584966,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,If you're using a MonitoredSession and its variants you should still be able to do this: CODE,Usage,191,93,1,0.5263157895,0.4417673799,0.5582326201,1,0.2537313433,0.02590584966,0.01145704499,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Edit: Sorry, it totally works.",Social Conversation,30,30,0.25,0.5278637771,0.4431919084,0.5568080916,0.3333333333,0.07462686567,0.01145704499,0.1250288844,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@jimfleming you're right again ;),Social Conversation,33,33,0.5,0.5294117647,0.4431919084,0.5568080916,0.3333333333,0.07462686567,0.01145704499,0.1250288844,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"CODEthe above code prints nothing, just exits after attempting to run past the last batch.",Usage,213,90,0.75,0.5309597523,0.4431919084,0.5568080916,1,0.223880597,0.01145704499,0.1250288844,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"However, the following will print ""hit exception"" forever, unless CODE is used. CODE",Usage,269,84,1,0.5325077399,0.4431919084,0.5568080916,0.8666666667,0.1940298507,0.01145704499,0.1250288844,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Do the [High Performance Benchmarks example] URL  recommendations still apply now that the new [Dataset API] URL  exists?,Solution Discussion,248,121,0.25,0.5340557276,0.4587375589,0.5412624411,0.5405405405,0.2985074627,0.1250288844,0.003916059713,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For instance in the benchmark [RecordInput](https://github.com/tensorflow/tensorflow/blob/e4296aefff97e6edd3d7cee9a09b9dd77da4c034/tensorflow/python/ops/data_flow_ops.py#L2074) is [split into minibatches](https://github.com/tensorflow/benchmarks/blob/master/scripts/tf_cnn_benchmarks/preprocessing.py#L356), which I tried to incorporate via #10143 just before I found this.",Solution Discussion,373,373,0.5,0.5356037152,0.4587375589,0.5412624411,1,0.552238806,0.1250288844,0.003916059713,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If those recommendations are all good ones, the datasets API might benefit from the addition of those very same recommendations.",Solution Discussion,128,128,0.75,0.5371517028,0.4587375589,0.5412624411,0.5405405405,0.2985074627,0.1250288844,0.003916059713,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Might I suggest updating the benchmarks in accordance with this API and vice versa?,Solution Discussion,83,83,1,0.5386996904,0.4587375589,0.5412624411,0.3783783784,0.2089552239,0.1250288844,0.003916059713,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I've had my head down for a while, so there's lots to respond to here:",Social Conversation,70,70,0.03703703704,0.540247678,0.4592244679,0.5407755321,0.3404255319,0.2388059701,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         @sjperkins: Adding CODE and CODE iterators shouldn't be too hard.,Solution Discussion,103,75,0.07407407407,0.5417956656,0.4592244679,0.5407755321,0.2340425532,0.1641791045,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,I'd like to understand your use case a little better.,Motivation,53,53,0.1111111111,0.5433436533,0.4592244679,0.5407755321,0.2340425532,0.1641791045,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Do you imagine that most uses will combine exactly two datasets (and hence we might use method chaining to combine them, e.g. CODE, CODE) or will it be more common to combine more datasets (and hence we'd take a similar approach to CODE, e.g. CODE, CODE)?",Motivation,340,255,0.1481481481,0.5448916409,0.4592244679,0.5407755321,1,0.7014925373,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Also note that, if you need CODE in the short term, I think you can write CODE.",Workarounds,192,79,0.1851851852,0.5464396285,0.4592244679,0.5407755321,0.3617021277,0.2537313433,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,You could also fake out CODE with CODE and CODE but that would be quite ugly :).,Workarounds,108,80,0.2222222222,0.5479876161,0.4592244679,0.5407755321,0.3617021277,0.2537313433,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,*         @snnn: Thanks for kicking the tires!,Social Conversation,46,46,0.2592592593,0.5495356037,0.4592244679,0.5407755321,0.1489361702,0.1044776119,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It's great to hear that the new API brought a speedup for your code...,Solution Discussion,70,70,0.2962962963,0.5510835913,0.4592244679,0.5407755321,0.2978723404,0.2089552239,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"we've definitely favored flexibility over performance with the initial version of the API, but look out for improvements over the coming versions.",Task Progress,146,146,0.3333333333,0.5526315789,0.4592244679,0.5407755321,0.4893617021,0.3432835821,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Right now you can use CODE and CODE to select a sub-dataset from the files, but it is not very efficient, because they materialize the skipped-over inputs before discarding them.",Workarounds,202,178,0.3703703704,0.5541795666,0.4592244679,0.5407755321,0.6808510638,0.4776119403,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I could imagine adding an CODE method internally, which would allow iterators to specialize their behavior in this case (or fall back to using CODE in a loop).",Solution Discussion,188,159,0.4074074074,0.5557275542,0.4592244679,0.5407755321,0.5957446809,0.4179104478,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"This also seems like it would be important for checkpointing iterators, which might be useful for fault tolerance.",Solution Discussion,114,114,0.4444444444,0.5572755418,0.4592244679,0.5407755321,0.3829787234,0.2686567164,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"*         @omoindrot: I agree that the CODE construction is pretty ugly, and we should try to find ways to improve it.",Motivation,126,118,0.4814814815,0.5588235294,0.4592244679,0.5407755321,0.4468085106,0.3134328358,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"The current version is designed to be a drop-in replacement for the queues, which use CODE to signal completion, and various other classes are designed to catch that exception.",Solution Discussion,199,176,0.5185185185,0.560371517,0.4592244679,0.5407755321,0.6382978723,0.447761194,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Exposing an CODE property would be possible, but it would be tricky to make it work in the way you suggest, because (to avoid an exception being raised) you'd need to guard the training subgraph with a CODE.",Solution Discussion,281,207,0.5555555556,0.5619195046,0.4592244679,0.5407755321,0.829787234,0.5820895522,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Another possibility would be to change the Python API for iterators to use two ops: CODE and CODE (e.g. like the C++ CODE protocol), but that would introduce an additional CODE call, and make it harder to share the iterator between threads.",Solution Discussion,295,240,0.5925925926,0.5634674923,0.4592244679,0.5407755321,0.8936170213,0.6268656716,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,One possibility I've considered is to create a wrapper that turns an CODE-consuming step into a Python iterator.,Solution Discussion,118,112,0.6296296296,0.5650154799,0.4592244679,0.5407755321,0.4255319149,0.2985074627,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,e.g. Some straw-man code: CODE,Solution Discussion,307,30,0.6666666667,0.5665634675,0.4592244679,0.5407755321,0.1276595745,0.08955223881,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,*         @jimfleming and @vonclites: Thanks for looking into the CODE integration.,Social Conversation,97,83,0.7037037037,0.5681114551,0.4592244679,0.5407755321,0.2340425532,0.1641791045,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"It's great to hear that it ""just works""!",Social Conversation,40,40,0.7407407407,0.5696594427,0.4592244679,0.5407755321,0.170212766,0.1194029851,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I think we'll still need to do something better for the more advanced cases where we might want to reinitialize an iterator in the same session.,Solution Discussion,144,144,0.7777777778,0.5712074303,0.4592244679,0.5407755321,0.5531914894,0.3880597015,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"*         @ahundt: From our initial experiments, the *peak* performance of the benchmark input pipeline is still slightly higher than what you get from using the CODE API.",Solution Discussion,184,171,0.8148148148,0.572755418,0.4592244679,0.5407755321,0.5744680851,0.4029850746,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"However, the peak performance is much higher than the throughput of actually using the data to train a model like Inception or ResNet, so you might not notice the difference in regular use.",Solution Discussion,189,189,0.8518518519,0.5743034056,0.4592244679,0.5407755321,0.7021276596,0.4925373134,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We're investigating how to close the gap, and it's very likely that we'll incorporate some of the ideas from the benchmark code into the CODE implementation.",Solution Discussion,162,157,0.8888888889,0.5758513932,0.4592244679,0.5407755321,0.5531914894,0.3880597015,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"In particular, one current limitation of the CODE and CODE implementation is that the entire pipeline runs on a single device, whereas the more explicit code in the benchmarks is able to split the processing across multiple CPU and GPU devices.",Solution Discussion,255,244,0.9259259259,0.5773993808,0.4592244679,0.5407755321,0.8723404255,0.6119402985,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"For the best performance, it's going to be important to integrate optimizations like the CODE for prefetching data to the GPU before it is needed, and we're working on a way to do that more transparently.",Solution Discussion,213,204,0.962962963,0.5789473684,0.4592244679,0.5407755321,0.7659574468,0.5373134328,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"For now, you can manually pipeline the output of an CODE op with the CODE op in a similar manner to the benchmark code.",Workarounds,151,119,1,0.580495356,0.4592244679,0.5407755321,0.5106382979,0.3582089552,0.003916059713,0.008479027653,CONTRIBUTOR,TRUE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,This is fantastic!,Social Conversation,18,18,0.2,0.5820433437,0.4602787203,0.5397212797,0.09375,0.0447761194,0.008479027653,0.0006250222677,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm using it now and loving it.,Social Conversation,31,31,0.4,0.5835913313,0.4602787203,0.5397212797,0.21875,0.1044776119,0.008479027653,0.0006250222677,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@vrv @mrry is the ability to swap between train and validation datasets already there or is that still coming?,Task Progress,110,110,0.6,0.5851393189,0.4602787203,0.5397212797,0.59375,0.2835820896,0.008479027653,0.0006250222677,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I see the reinitializable iterators give us the ability to use the same iterator with multiple datasets but each time you run an init op, it essentially starts over on that dataset.",Usage,181,181,0.8,0.5866873065,0.4602787203,0.5397212797,1,0.4776119403,0.008479027653,0.0006250222677,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm currently using the new CODE and CODE apis along with CODE to accomplish this but is there a more direct/natural way in the works?,Usage,150,134,1,0.5882352941,0.4602787203,0.5397212797,0.8125,0.3880597015,0.008479027653,0.0006250222677,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Hi @mrry,Social Conversation,8,8,1,0.5897832817,0.4603564334,0.5396435666,1,0.02985074627,0.0006250222677,0.008566062512,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks for the workarounds.,Social Conversation,27,27,1,0.5913312693,0.4614215074,0.5385784926,1,0.05970149254,0.008566062512,0.01269843694,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Wanted to let you know I migrated from queues to Dataset and it's been great.,Social Conversation,77,77,0.125,0.592879257,0.4630003862,0.5369996138,0.7894736842,0.223880597,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Definitely going in the right direction.,Social Conversation,40,40,0.25,0.5944272446,0.4630003862,0.5369996138,0.3157894737,0.08955223881,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,There's been a few things that are currently missing and I had to work around:,Motivation,78,78,0.375,0.5959752322,0.4630003862,0.5369996138,0.7894736842,0.223880597,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,-         Support for SparseTensors.,Expected Behaviour,36,36,0.5,0.5975232198,0.4630003862,0.5369996138,0.2105263158,0.05970149254,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,CODE supports SparseTensor and automatic batching of SparseTensor would make my life a whole lot easier,Motivation,109,103,0.625,0.5990712074,0.4630003862,0.5369996138,0.8421052632,0.2388059701,0.01269843694,0.02260310577,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Additionally, I had this idea where you could maybe implement a random test/train split functionality right into Dataset.",Expected Behaviour,121,121,0.75,0.600619195,0.4630003862,0.5369996138,1,0.2835820896,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This could make things easier too.,Motivation,34,34,0.875,0.6021671827,0.4630003862,0.5369996138,0.3157894737,0.08955223881,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Keep up the good work!,Social Conversation,22,22,1,0.6037151703,0.4630003862,0.5369996138,0.2631578947,0.07462686567,0.01269843694,0.02260310577,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@lhlmgr The way i understand that example is that iterator needs to be reinitialized every time you switch between train and validation.,Solution Discussion,136,136,0.25,0.6052631579,0.4658107767,0.5341892233,0.7857142857,0.328358209,0.02260310577,0.1856733495,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"This isn't the end of the world but for large datasets where we are shuffling minibatches, we want a reasonable CODE which means each initialization is quite slow.",Solution Discussion,172,163,0.5,0.6068111455,0.4658107767,0.5341892233,1,0.4179104478,0.02260310577,0.1856733495,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,I find the CODE approach with two separate datasets/iterators to work better/faster in that case.,Solution Discussion,102,97,0.75,0.6083591331,0.4658107767,0.5341892233,0.6071428571,0.2537313433,0.02260310577,0.1856733495,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,That way we can periodically run through validation data without losing our place int the training set.,Solution Discussion,103,103,1,0.6099071207,0.4658107767,0.5341892233,0.6071428571,0.2537313433,0.02260310577,0.1856733495,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Maybe here is a good place to refer to my Dataset related questions:,Usage,68,68,0.3333333333,0.6114551084,0.488896746,0.511103254,1,0.1940298507,0.1856733495,0.06171840406,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,https://stackoverflow.com/questions/44132579/feed-data-into-a-tf-contrib-data-dataset-like-a-queue,Usage,98,98,0.6666666667,0.613003096,0.488896746,0.511103254,0.07692307692,0.01492537313,0.1856733495,0.06171840406,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,https://stackoverflow.com/questions/44132307/tf-contrib-data-dataset-repeat-with-shuffle-notice-epoch-end-mixed-epochs,Usage,118,118,1,0.6145510836,0.488896746,0.511103254,0.07692307692,0.01492537313,0.1856733495,0.06171840406,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I really like the new Dataset/Iterator API!,Social Conversation,43,43,0.25,0.6160990712,0.4965705946,0.5034294054,0.2666666667,0.1194029851,0.06171840406,0.0130944201,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Here is a feature that would help my use-case:,Motivation,46,46,0.5,0.6176470588,0.4965705946,0.5034294054,0.3333333333,0.1492537313,0.06171840406,0.0130944201,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"What I'd like is for CODE and CODE there to output elements in the same order (because they share the CODE step), but with different functions (CODE/CODE) applied.",Expected Behaviour,182,163,0.75,0.6191950464,0.4965705946,0.5034294054,1,0.447761194,0.06171840406,0.0130944201,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"That is, I would like to create input pipelines that share some processing, and then diverge at some point for additional processing.",Expected Behaviour,133,133,1,0.6207430341,0.4965705946,0.5034294054,0.7333333333,0.328358209,0.06171840406,0.0130944201,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,What @drasmuss suggests is very useful for segmentation tasks where both labels and images need to be augmented.,Motivation,112,112,0.5,0.6222910217,0.4981987086,0.5018012914,0.4864864865,0.2686567164,0.0130944201,0.02428476177,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For example the images could very reasonably use bilinear interpolation, but interpolating label values is not okay because a label pixel boundary of 0 and 2 should not be interpolated to the completely different label of 1.",Motivation,224,224,1,0.6238390093,0.4981987086,0.5018012914,1,0.552238806,0.0130944201,0.02428476177,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I am only starting to read into the new API, but I want to share two problems that I had with the old Input Queues in concurrence with using MonitoredSession with SessionRunHooks.",Motivation,179,179,0.1666666667,0.6253869969,0.5012181902,0.4987818098,0.5245901639,0.4776119403,0.02428476177,0.003761840049,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We also used two separate queues, one handling input data_files as string names and the other one the resulting input data with preprocessing being done in between those two.",Motivation,174,174,0.3333333333,0.6269349845,0.5012181902,0.4987818098,0.4754098361,0.4328358209,0.02428476177,0.003761840049,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,We needed to make sure that the enqueue operations fills at least a certain multiple of the batch size into the first queue for our code to run without problems (otherwise the second input queue stalled),Motivation,203,203,0.5,0.6284829721,0.5012181902,0.4987818098,0.5901639344,0.5373134328,0.02428476177,0.003761840049,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Now when I switched from a normal Session to using MonitoredSession and added a logging hook and told it to log the 'accuracy' tensor, it tried in vain to evaluate the first session run call as the hook had added that tensor to the fetch list, but with the queue being still empty there was no way to evaluate accuracy yet.",Motivation,323,323,0.6666666667,0.6300309598,0.5012181902,0.4987818098,1,0.9104477612,0.02428476177,0.003761840049,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Problematic was that the program just stopped and waited for some process to begin filling the queue, but there was non, so it just did nothing, but also didn't throw an exception or give any kind of warning, which made understanding what was happening a bit difficult.",Motivation,269,269,0.8333333333,0.6315789474,0.5012181902,0.4987818098,0.7704918033,0.7014925373,0.02428476177,0.003761840049,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Aside from that, we use two different input pipelines for training and validation data that we connect to the network part of our graph alternating through a switch implemented through CODE.",Motivation,210,190,1,0.633126935,0.5012181902,0.4987818098,0.5081967213,0.4626865672,0.02428476177,0.003761840049,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,1.         Anything that helps me analyze if and where the bottleneck lies in the input pipeline would be great.,Motivation,112,112,0.1428571429,0.6346749226,0.5016859242,0.4983140758,0.5263157895,0.2985074627,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For example, a way to monitor the number of examples in the buffers along the input pipeline would be helpful.",Expected Behaviour,110,110,0.2857142857,0.6362229102,0.5016859242,0.4983140758,0.5263157895,0.2985074627,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Or the number of items processed per thread of a .map() operation  Basically, something along the lines of how the queues create summaries for the number of images they are holding.",Expected Behaviour,181,181,0.4285714286,0.6377708978,0.5016859242,0.4983140758,0.8421052632,0.4776119403,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"2.         I think others have mentioned something like this, but a way to create a Dataset from a streaming source of data.",Expected Behaviour,124,124,0.5714285714,0.6393188854,0.5016859242,0.4983140758,0.6052631579,0.3432835821,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Something that provides similar functionality as the generator feed function in https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/estimator/inputs/queues/feeding_functions.py  (but it would be cool if the source of the data could be from an arbitrary source, maybe using a kind of publisher/subscriber model?)",Motivation,330,330,0.7142857143,0.6408668731,0.5016859242,0.4983140758,1,0.5671641791,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks for the hard work.,Social Conversation,25,25,0.8571428571,0.6424148607,0.5016859242,0.4983140758,0.1315789474,0.07462686567,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm digging the new API.,Social Conversation,24,24,1,0.6439628483,0.5016859242,0.4983140758,0.1315789474,0.07462686567,0.003761840049,0.03050902669,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,In the last couple of days I was playing around quite a bit with the new Input API and I think the CODE and CODE classes improve highly the clearness and readability of code (compared to the old input queues).,Usage,220,209,0.04166666667,0.6455108359,0.5054793089,0.4945206911,1,0.5970149254,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Also switching between e.g. training and validation dataset within one session works quite effortless.,Usage,102,102,0.08333333333,0.6470588235,0.5054793089,0.4945206911,0.35,0.2089552239,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But I have also some questions and suggestions.,Social Conversation,47,47,0.125,0.6486068111,0.5054793089,0.4945206911,0.2,0.1194029851,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Maybe first a question: Is the CODE class implemented based on queues?,Solution Discussion,75,70,0.1666666667,0.6501547988,0.5054793089,0.4945206911,0.3,0.1791044776,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Because from the post here it doesn't get clear to me if or if not.,Solution Discussion,67,67,0.2083333333,0.6517027864,0.5054793089,0.4945206911,0.375,0.223880597,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,In Tensorboard there is no additional information added with the new API about the status of any queue (how many objects are currently queued).,Solution Discussion,143,143,0.25,0.653250774,0.5054793089,0.4945206911,0.6,0.3582089552,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Also observing my CPU/GPU resources/workload I can see, that the GPU workload drops to zero often (I guess in between batches).",Solution Discussion,127,127,0.2916666667,0.6547987616,0.5054793089,0.4945206911,0.575,0.3432835821,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Then a suggestion:,Solution Discussion,18,18,0.3333333333,0.6563467492,0.5054793089,0.4945206911,0.075,0.0447761194,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I think the CODE could be improved, if shuffling is not done only on the _n_ ( = buffer_size) samples in memory, but somehow on the whole list of inputs.",Solution Discussion,168,153,0.375,0.6578947368,0.5054793089,0.4945206911,0.7,0.4179104478,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,For example: I'm storing path to images and labels in a text file.,Solution Discussion,66,66,0.4166666667,0.6594427245,0.5054793089,0.4945206911,0.325,0.1940298507,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,If shuffling is not done already in the text file you can often have thousands of lines after each other of the same class.,Solution Discussion,123,123,0.4583333333,0.6609907121,0.5054793089,0.4945206911,0.6,0.3582089552,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,If I now only work with CODE it can easily happen (depending of the buffer_size) that all elements that get shuffled are anyhow of the same class.,Solution Discussion,161,146,0.5,0.6625386997,0.5054793089,0.4945206911,0.675,0.4029850746,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,The only.,Social Conversation,9,9,0.5416666667,0.6640866873,0.5054793089,0.4945206911,0.05,0.02985074627,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Maybe some toy example (ignoring labels and only working with image paths) to make my point clearer.,Solution Discussion,100,100,0.5833333333,0.6656346749,0.5054793089,0.4945206911,0.425,0.2537313433,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,For reasons of readability I work with a very small CODE and list of file names.,Solution Discussion,89,80,0.625,0.6671826625,0.5054793089,0.4945206911,0.4,0.2388059701,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,But I guess everyone can imagine the same just with thousands of filenames in the list and a buffer_size e.g. of 5000.,Solution Discussion,118,118,0.6666666667,0.6687306502,0.5054793089,0.4945206911,0.55,0.328358209,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,CODE,Solution Discussion,685,4,0.7083333333,0.6702786378,0.5054793089,0.4945206911,0.025,0.01492537313,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,This would print something like:CODE,Solution Discussion,360,36,0.75,0.6718266254,0.5054793089,0.4945206911,0.15,0.08955223881,0.03050902669,0.04958391229,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"So since there is only a shuffling between the 3 examples in the buffer, the first samples (same for batches) will all have samples only of one class.",Solution Discussion,150,150,0.7916666667,0.673374613,0.5054793089,0.4945206911,0.7,0.4179104478,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,So unless the shuffling isn't done already in the list of filenames you'll have troubles training any network.,Solution Discussion,110,110,0.8333333333,0.6749226006,0.5054793089,0.4945206911,0.45,0.2686567164,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"And if the available dataset of images is huge, increasing the buffer_size is often not a solution.",Solution Discussion,99,99,0.875,0.6764705882,0.5054793089,0.4945206911,0.425,0.2537313433,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Another problem I see, is that like shuffling currently is implemented, there is no true shuffling of the entire dataset possible.",Solution Discussion,130,130,0.9166666667,0.6780185759,0.5054793089,0.4945206911,0.525,0.3134328358,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The only workaround I found was pre-shuffling the filelist I read from the text file before creating the dataset.,Workarounds,113,113,0.9583333333,0.6795665635,0.5054793089,0.4945206911,0.5,0.2985074627,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"But once the dataset is created, it's only possible to shuffle in the range of the buffer_size.",Workarounds,95,95,1,0.6811145511,0.5054793089,0.4945206911,0.425,0.2537313433,0.03050902669,0.04958391229,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@mrry  Thanks for the a preview of the new API; I think this is a good starting point!,Social Conversation,86,86,0.1111111111,0.6826625387,0.5116443977,0.4883556023,0.4130434783,0.2835820896,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"One function that still seems to be missing, but would be essential for one of our primary use cases (see comment above: https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-283186552) is a CODEused as inCODE function, where one element of CODE is mapped to one **or more** elements for CODE; i.e. #CODE >= #CODE.",Expected Behaviour,412,326,0.2222222222,0.6842105263,0.5116443977,0.4883556023,1,0.6865671642,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"As far as I understand it, CODE preserves a 1:1 mapping, which is not sufficient for our use case.",Motivation,109,98,0.3333333333,0.6857585139,0.5116443977,0.4883556023,0.4130434783,0.2835820896,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,One concrete example of why this would be useful:,Motivation,49,49,0.4444444444,0.6873065015,0.5116443977,0.4883556023,0.1956521739,0.1343283582,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Assume CODE is a list of large images (e.g. 8192x8192 each) [with corresponding labels].,Motivation,94,88,0.5555555556,0.6888544892,0.5116443977,0.4883556023,0.3043478261,0.2089552239,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Then, CODE is created by (randomly) iterating over each element CODE of CODE, and for each of these elements the function CODE samples a (variable) number of sub-images [and sub-labels] (e.g. 256x256 each) from CODE, taken from various regions of CODE.",Motivation,266,252,0.6666666667,0.6904024768,0.5116443977,0.4883556023,0.9347826087,0.6417910448,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"For example, in one instance, CODE might return 142 new {image, label} pairs that will be added to CODE.",Motivation,112,104,0.7777777778,0.6919504644,0.5116443977,0.4883556023,0.4130434783,0.2835820896,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"In another instance, it might return 389 new pairs, etc.",Motivation,56,56,0.8888888889,0.693498452,0.5116443977,0.4883556023,0.2173913043,0.1492537313,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The number of elements generated each time is variable and conditional on the properties of element CODE.,Motivation,105,105,1,0.6950464396,0.5116443977,0.4883556023,0.3695652174,0.2537313433,0.04958391229,0.003143434467,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@kmhofmann I think you can map one example to multiple examples with CODE.,Usage,90,74,0.5,0.6965944272,0.5120352412,0.4879647588,0.7222222222,0.1940298507,0.003143434467,0.0002672122887,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Inside your flatmap function, create a new Dataset object with one or multiple examples for every input example.",Usage,112,112,1,0.6981424149,0.5120352412,0.4879647588,1,0.2686567164,0.003143434467,0.0002672122887,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@EdeMeijer That could be -- it's really hard to tell, as the documentation is quite sparse, with no examples.",Usage,109,109,0.2,0.6996904025,0.5120684655,0.4879315345,0.6785714286,0.2835820896,0.0002672122887,0.0005771785436,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,(There seem to be two places containing some amount of separate documentation: either on [GitHub] URL  or on [tensorflow.org](https://www.tensorflow.org/versions/r1.2/api_docs/python/tf/contrib/data/Dataset#flat_map)),Usage,290,217,0.4,0.7012383901,0.5120684655,0.4879315345,1,0.4179104478,0.0002672122887,0.0005771785436,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,One thing I notice is that the arguments CODE and CODE from CODE are missing in CODE; does that mean no parallel processing is possible?,Usage,172,136,0.6,0.7027863777,0.5120684655,0.4879315345,0.8928571429,0.3731343284,0.0002672122887,0.0005771785436,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Or is this a TODO?,Task Progress,18,18,0.8,0.7043343653,0.5120684655,0.4879315345,0.1785714286,0.07462686567,0.0002672122887,0.0005771785436,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Hard to scope both functionality and feature set...,Usage,51,51,1,0.7058823529,0.5120684655,0.4879315345,0.2857142857,0.1194029851,0.0002672122887,0.0005771785436,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I based my suggestion on the one flat_map code example on the github page you linked.,Usage,85,85,0.3333333333,0.7074303406,0.5121402298,0.4878597702,0.7272727273,0.2388059701,0.0005771785436,0.0001414952691,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"There, single string tensors come in (file names) and whole Datasets are emitted in the map function, so that seems pretty clear.",Usage,129,129,0.6666666667,0.7089783282,0.5121402298,0.4878597702,1,0.328358209,0.0005771785436,0.0001414952691,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I guess the parallel processing from CODE is a TODO, I'm sure they'd love a PR :)",Task Progress,84,81,1,0.7105263158,0.5121402298,0.4878597702,0.8181818182,0.2686567164,0.0005771785436,0.0001414952691,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Ah, thanks, I missed that, as it was in an example about text processing.",Social Conversation,73,73,0.5,0.7120743034,0.5121578228,0.4878421772,1,0.2089552239,0.0001414952691,0.07840110346,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Still, the function description in the documentation seems a bit sparse, consisting of CODE.",Usage,147,92,1,0.713622291,0.5121578228,0.4878421772,1,0.2089552239,0.0001414952691,0.07840110346,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,input_fn has to return features and labels only.,Expected Behaviour,48,48,0.5,0.7151702786,0.5219059395,0.4780940605,0.4705882353,0.1194029851,0.07840110346,0.05557964708,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,What about extra params which can be used while training progress to customise loss for given input?,Expected Behaviour,100,100,1,0.7167182663,0.5219059395,0.4780940605,1,0.2537313433,0.07840110346,0.05557964708,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Another feature request: it'd be great if there was an CODE operator, which would return the current iterator value (like CODE), but not advance the iterator.",Expected Behaviour,188,158,0.5,0.7182662539,0.5288165167,0.4711834833,1,0.4029850746,0.05557964708,0.1827564093,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,This would make it easier to coordinate multiple elements of a model that all want to read from the iterator before advancing it one step.,Motivation,138,138,1,0.7198142415,0.5288165167,0.4711834833,0.9259259259,0.3731343284,0.05557964708,0.1827564093,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Hi, firstly thanks for this API, Im very keen on using it.",Social Conversation,58,58,0.1111111111,0.7213622291,0.551539804,0.448460196,0.3611111111,0.1940298507,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Primarily I am interested in using it to switch between training and validation datasets in the same process.,Motivation,109,109,0.2222222222,0.7229102167,0.551539804,0.448460196,0.5,0.2686567164,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,However I'm confused how one does that in this new paradigm.,Usage,60,60,0.3333333333,0.7244582043,0.551539804,0.448460196,0.3055555556,0.1641791045,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For instance I see no way to ""get an iterator"" in the middle of a dataset.",Usage,74,74,0.4444444444,0.726006192,0.551539804,0.448460196,0.4444444444,0.2388059701,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,As an example here is a piece of code that demonstrates what I'd like to do.,Usage,76,76,0.5555555556,0.7275541796,0.551539804,0.448460196,0.4722222222,0.2537313433,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Every few steps in an epoch, I'd like to run a validation op, but the output of this code shows that the iterator never advances ahead of item 0 in either dataset.",Usage,163,163,0.6666666667,0.7291021672,0.551539804,0.448460196,0.9166666667,0.4925373134,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,How does one do that?,Usage,21,21,0.7777777778,0.7306501548,0.551539804,0.448460196,0.1388888889,0.07462686567,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"CODE In the above, since we run an init each time to get an iterator pointing to its required dataset, we end up running a training and validation on the first item of each dataset, always.",Usage,957,189,0.8888888889,0.7321981424,0.551539804,0.448460196,1,0.5373134328,0.1827564093,0.002095453319,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,How does one modify this to get the updated position of the iterator in each dataset?,Usage,85,85,1,0.73374613,0.551539804,0.448460196,0.4444444444,0.2388059701,0.1827564093,0.002095453319,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@nirmalthacker Every time you run an iterator init op, it restarts the iterator.",Usage,80,80,0.3333333333,0.7352941176,0.5518003453,0.4481996547,0.7647058824,0.1940298507,0.002095453319,0.004343090399,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Take a look at the documentation here [here](https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/data#creating-an-iterator).,Usage,144,144,0.6666666667,0.7368421053,0.5518003453,0.4481996547,1,0.2537313433,0.002095453319,0.004343090399,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This approach has the limitations i discussed [here](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-303909270).,Solution Discussion,130,130,1,0.7383900929,0.5518003453,0.4481996547,0.6470588235,0.1641791045,0.002095453319,0.004343090399,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@jasonkriss , I see - thanks!",Social Conversation,29,29,0.3333333333,0.7399380805,0.5523403498,0.4476596502,0.3333333333,0.05970149254,0.004343090399,0.001784978089,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"This is what I have now, and it handles what I wanted.",Usage,54,54,0.6666666667,0.7414860681,0.5523403498,0.4476596502,1,0.1791044776,0.004343090399,0.001784978089,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is this what you meant? CODE,Usage,1061,28,1,0.7430340557,0.5523403498,0.4476596502,0.5,0.08955223881,0.004343090399,0.001784978089,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"@nirmalthacker Yep, that's essentially what I meant.",Usage,52,52,0.3333333333,0.7445820433,0.5525622877,0.4474377123,0.3888888889,0.1044776119,0.001784978089,0.1924676673,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Although, at each validation step, I will reinit the validation iterator and run through the full validation dataset.",Usage,117,117,0.6666666667,0.746130031,0.5525622877,0.4474377123,1,0.2686567164,0.001784978089,0.1924676673,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But that's certainly the gist of it.,Usage,36,36,1,0.7476780186,0.5525622877,0.4474377123,0.3888888889,0.1044776119,0.001784978089,0.1924676673,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm trying migrating input pipeline from tf.train.string_input_producer & tf.train.shuffle_batch to Dataset APIs.,Usage,113,113,0.25,0.7492260062,0.5764930385,0.4235069615,0.5,0.1641791045,0.1924676673,0.003144961394,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The parameter ""allow_smaller_final_batch"" in tf.train.shuffle_batch(...) is useful when I'd like to assure all batches are evenly divisible by number of gpus.",Usage,158,158,0.5,0.7507739938,0.5764930385,0.4235069615,1,0.328358209,0.1924676673,0.003144961394,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"(I'm doing data parallelization on multiple gpus, and the batch_size is multiple of num_gpus).",Usage,94,94,0.75,0.7523219814,0.5764930385,0.4235069615,0.6363636364,0.2089552239,0.1924676673,0.003144961394,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is there any setting for Dataset APIs to drop the final smaller batch if any?,Usage,77,77,1,0.753869969,0.5764930385,0.4235069615,0.6818181818,0.223880597,0.1924676673,0.003144961394,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@winston-li I think you could just use CODE for that.,Usage,60,53,0.3333333333,0.7554179567,0.5768840719,0.4231159281,0.8461538462,0.1641791045,0.003144961394,0.0003822408168,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"If you know your batch size is for example 32, then something likeCODE",Usage,142,70,0.6666666667,0.7569659443,0.5768840719,0.4231159281,1,0.1940298507,0.003144961394,0.0003822408168,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,should do the trick.,Usage,20,20,1,0.7585139319,0.5768840719,0.4231159281,0.3076923077,0.05970149254,0.003144961394,0.0003822408168,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@ppwwyyxx I believe a custom pipeline could be designed using TF server with distributed runtime, i.e. IPC send/recv ops.",Solution Discussion,121,121,0.1666666667,0.7600619195,0.5769315984,0.4230684016,0.7142857143,0.2985074627,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It's included in C API so it won't be too hard to port it to other languages.,Solution Discussion,77,77,0.3333333333,0.7616099071,0.5769315984,0.4230684016,0.6071428571,0.2537313433,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,A down side is that you do need package the whole TF runtime wherever you need this pipeline.,Solution Discussion,93,93,0.5,0.7631578947,0.5769315984,0.4230684016,0.6428571429,0.2686567164,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"We are actually working on a out-of-band data plane for TF, but it is still a great deal of ongoing work.",Task Progress,105,105,0.6666666667,0.7647058824,0.5769315984,0.4230684016,0.8214285714,0.3432835821,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The design would be similar to the [ExternalShuffleService] URL  in Spark, using an in-memory storage such as LevelDB or LMDB, and a reader client in TF.",Solution Discussion,266,153,0.8333333333,0.76625387,0.5769315984,0.4230684016,1,0.4179104478,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If performance is a primary concern then it should be tightly integrated with hardware, i.e. GPU/NVMe/RNIC, etc.",Solution Discussion,112,112,1,0.7678018576,0.5769315984,0.4230684016,0.6785714286,0.2835820896,0.0003822408168,0.03325240618,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@EdeMeijer  Thanks.,Social Conversation,19,19,0.125,0.7693498452,0.5810660853,0.4189339147,0.046875,0.0447761194,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I thought it should work, but after some experiments, I can't make it work as expected.",Usage,87,87,0.25,0.7708978328,0.5810660853,0.4189339147,0.25,0.2388059701,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I followed the guidelines of dataset README.md, with pseudo code like following: def _parse_function(example_proto):features = {""image"": tf.FixedLenFeature((), tf.string, default_value=""""),""label"": tf.FixedLenFeature((), tf.int32, default_value=0)}parsed_features = tf.parse_single_example(example_proto, features)return parsed_features[""image""], parsed_features[""label""] BATCH_SIZE = 256filenames = [""/var/data/file1.tfrecord"", ""/var/data/file2.tfrecord""]dataset = tf.contrib.data.TFRecordDataset(filenames)dataset = dataset.map(_parse_function)dataset = dataset.batch(BATCH_SIZE)dataset = dataset.filter(lambda imgs, lbls: tf.shape(imgs)[0] == BATCH_SIZE)iterator = dataset.make_initializable_iterator()next_element = iterator.get_next()images, labels = next_element # Training cycles for 100 epochs.for _ in range(100):sess.run(iterator.initializer)while True:try:images_r, labels_r = sess.run([images, labels])print(images_r.shape)except tf.errors.OutOfRangeError:break",Usage,973,973,0.375,0.7724458204,0.5810660853,0.4189339147,1,0.9552238806,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"After applied the filter, no data available in training cycles.",Usage,63,63,0.5,0.773993808,0.5810660853,0.4189339147,0.15625,0.1492537313,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I found the dataset (after batch, prior to filter) was in this form:",Usage,68,68,0.625,0.7755417957,0.5810660853,0.4189339147,0.203125,0.1940298507,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"(<tf.Tensor 'arg0:0' shape=(?, 43200) dtype=float32>, <tf.Tensor 'arg1:0' shape=(?, 36) dtype=float32>)",Usage,103,103,0.75,0.7770897833,0.5810660853,0.4189339147,0.21875,0.2089552239,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Looks like the batch dimension is ""?"" (None?), so the predicate always fails...",Usage,79,79,0.875,0.7786377709,0.5810660853,0.4189339147,0.1875,0.1791044776,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,or I did something wrong?,Usage,25,25,1,0.7801857585,0.5810660853,0.4189339147,0.078125,0.07462686567,0.03325240618,0.00639731668,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@winston-li seeing ""?"" as shape is because at that point you're looking at the 'static' shape of the tensor, which isn't always defined (the graph doesn't know in advance how many examples there will be).",Usage,204,204,0.25,0.7817337461,0.5818615051,0.4181384949,1,0.5223880597,0.00639731668,0.009301532526,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"However, CODE evaluates the dynamic, real-time shape of a tensor, so I thought this should work.",Usage,104,96,0.5,0.7832817337,0.5818615051,0.4181384949,0.4857142857,0.2537313433,0.00639731668,0.009301532526,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"However, what I **did** find was that, obviously, we should use Tensorflow ops instead of standard comparisons since the result of CODE is a tensor and not a normal array.",Usage,179,171,0.75,0.7848297214,0.5818615051,0.4181384949,0.8571428571,0.447761194,0.00639731668,0.009301532526,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"My tf version's filter is broken, but if yours works could you try this instead? CODE",Usage,177,85,1,0.786377709,0.5818615051,0.4181384949,0.4571428571,0.2388059701,0.00639731668,0.009301532526,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"@EdeMeijer Thank you very much, it works in my case :-)",Social Conversation,55,55,1,0.7879256966,0.5830180248,0.4169819752,1,0.1641791045,0.009301532526,0.004980837062,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It would be nice so see something in this flavor: CODE,Expected Behaviour,149,54,0.5,0.7894736842,0.5836373245,0.4163626755,0.6875,0.1641791045,0.004980837062,0.00636830506,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,which will sort items by chunk of 10000 (similar to CODE) using the given comparison function.,Expected Behaviour,107,94,1,0.7910216718,0.5836373245,0.4163626755,1,0.2388059701,0.004980837062,0.00636830506,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I would like to ask again (since there was no reply to my [comment](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-305435143) above: Am I right, that the new input pipeline isn't implemented using Queues?",Solution Discussion,223,223,0.2,0.7925696594,0.5844291371,0.4155708629,0.7142857143,0.447761194,0.00636830506,0.1964778875,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I did some tests using the new input pipeline to load an preprocess images, but it seems everything is done sequentially and their is only a negligible performance improvement over using e.g. OpenCV to load and preprocess images.",Solution Discussion,229,229,0.4,0.7941176471,0.5844291371,0.4155708629,0.9047619048,0.5671641791,0.00636830506,0.1964778875,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I was hoping the new input pipeline would be build on top of queues, since they provide major performance boosts but make it quite hard to work with (e.g. having seperate input pipelines with queues to switch between training and validation datasets).",Solution Discussion,251,251,0.6,0.7956656347,0.5844291371,0.4155708629,1,0.6268656716,0.00636830506,0.1964778875,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,This is quite easy with the new API but it seems there is no real performance boost.,Solution Discussion,84,84,0.8,0.7972136223,0.5844291371,0.4155708629,0.4047619048,0.2537313433,0.00636830506,0.1964778875,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Anybody observed the same or opposite?,Solution Discussion,38,38,1,0.7987616099,0.5844291371,0.4155708629,0.1428571429,0.08955223881,0.00636830506,0.1964778875,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kratzert I, too, have experienced issues with getting GPUs to 100% usage and keeping them there.",Solution Discussion,97,97,0.5,0.8003095975,0.6088585046,0.3911414954,0.3333333333,0.2388059701,0.1964778875,0.0008759473312,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The Dataset API, it seems, is implemented less efficiently and though it is a welcome change regarding code clarity and simplicity as well as a more natural way of doing training and validation, it cannot (yet) substitute queues for high data rate usecases, such as computer vision.",Solution Discussion,282,282,1,0.8018575851,0.6088585046,0.3911414954,1,0.7164179104,0.1964778875,0.0008759473312,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@kratzert You are right.,Social Conversation,24,24,0.3333333333,0.8034055728,0.6089674168,0.3910325832,0.1290322581,0.05970149254,0.0008759473312,0.000271284095,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The new input pipeline do not have queues.,Solution Discussion,42,42,0.6666666667,0.8049535604,0.6089674168,0.3910325832,0.2580645161,0.1194029851,0.0008759473312,0.000271284095,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"If you aren't satisfied with the shuffling it provides, you can do it outside TF: You can load all the filenames into memory then shuffle them in any way you like.",Workarounds,163,163,1,0.806501548,0.6089674168,0.3910325832,1,0.4626865672,0.0008759473312,0.000271284095,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@snnn Yes I know and I do exactly this.,Social Conversation,39,39,0.125,0.8080495356,0.6090011473,0.3909988527,0.2432432432,0.1343283582,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But by doing this I can't find a way to shuffle the entire data in e.g. my training data every epoch.,Workarounds,101,101,0.25,0.8095975232,0.6090011473,0.3909988527,0.5675675676,0.3134328358,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I can shuffle e.g. the list of filenames before creating a dataset, but once I start a session to my knowledge I can only shuffle the data from the dataset that I have in memory using dataset.shuffle(buffer_size).",Workarounds,213,213,0.375,0.8111455108,0.6090011473,0.3909988527,1,0.552238806,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But with images this can be hardly done for the entire dataset in memory.,Workarounds,73,73,0.5,0.8126934985,0.6090011473,0.3909988527,0.3783783784,0.2089552239,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"And I can't shuffle the filenames again and create a new dataset from them, once inside the session or am I wrong?",Workarounds,114,114,0.625,0.8142414861,0.6090011473,0.3909988527,0.5945945946,0.328358209,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@vvekic Thanks for your reply, so I know it's not only me having performance issues.",Social Conversation,84,84,0.75,0.8157894737,0.6090011473,0.3909988527,0.4054054054,0.223880597,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Of course the code clarity and simplicity of working with the new dataset class is a huge step forward and very welcome.,Social Conversation,120,120,0.875,0.8173374613,0.6090011473,0.3909988527,0.5945945946,0.328358209,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But it seems that for training computer vision networks queues are still the way to go (unfortunately) as the performance boost is immense.,Solution Discussion,139,139,1,0.8188854489,0.6090011473,0.3909988527,0.6216216216,0.3432835821,0.000271284095,0.000261613555,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kratzert Using queues increases your performance by overlapping data loading latency, and this is independent of what you use to load your data.",Solution Discussion,145,145,0.25,0.8204334365,0.6090336754,0.3909663246,0.7931034483,0.3432835821,0.000261613555,0.0001603273732,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"You can always insert queues or StagingArea in the input pipeline, regardless of whether the actual data loading is done by dataset API, the old input operators, or Python.",Workarounds,172,172,0.5,0.8219814241,0.6090336754,0.3909663246,1,0.4328358209,0.000261613555,0.0001603273732,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@byronyi What I meant is to receive tensors from non-TF processes.,Solution Discussion,66,66,0.75,0.8235294118,0.6090336754,0.3909663246,0.4137931034,0.1791044776,0.000261613555,0.0001603273732,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Because as @PatWie pointed out above, data processing doesn't really need to happen in the graph.",Solution Discussion,97,97,1,0.8250773994,0.6090336754,0.3909663246,0.5517241379,0.2388059701,0.000261613555,0.0001603273732,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@ppwwyyxx do you have any example code for combining queues and the new dataset api?,Usage,84,84,0.5,0.826625387,0.6090536099,0.3909463901,1,0.223880597,0.0001603273732,0.009944877922,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Sounds awesome and I will definitely try this out later.,Social Conversation,56,56,1,0.8281733746,0.6090536099,0.3909463901,0.6666666667,0.1492537313,0.0001603273732,0.009944877922,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@snnn Well I'll look into it, but since my knowledge in C++ isn't so profound we'll see how successfully I'll be.",Social Conversation,113,113,0.5,0.8297213622,0.610290121,0.389709879,0.84,0.3134328358,0.009944877922,0.006779557496,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Anyway, I think this could be a feature that more people than I might be interested in and should/could possibly be integrated into master.",Potential New Issues and Requests,139,139,1,0.8312693498,0.610290121,0.389709879,1,0.3731343284,0.009944877922,0.006779557496,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@kratzert https://www.tensorflow.org/performance/performance_models and the associated code shows how to use StagingArea.,Workarounds,121,121,1,0.8328173375,0.6111330672,0.3888669328,1,0.1641791045,0.006779557496,0.02902485329,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@kratzert it is certainly possible to re-shuffle the filenames for every epoch, I'm doing exactly that for my own training.",Workarounds,123,123,0.3333333333,0.8343653251,0.6147419151,0.3852580849,1,0.3134328358,0.02902485329,0.001498933696,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,You can use an initializable iterator together with a placeholder to achieve this.,Workarounds,82,82,0.6666666667,0.8359133127,0.6147419151,0.3852580849,0.619047619,0.1940298507,0.02902485329,0.001498933696,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm doing something like this:CODE,Workarounds,419,34,1,0.8374613003,0.6147419151,0.3852580849,0.2857142857,0.08955223881,0.02902485329,0.001498933696,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@EdeMeijer That's smart.,Social Conversation,24,24,0.2,0.8390092879,0.6149282872,0.3850717128,0.1666666667,0.0447761194,0.001498933696,0.123123279,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thank you very much.,Social Conversation,20,20,0.4,0.8405572755,0.6149282872,0.3850717128,0.2222222222,0.05970149254,0.001498933696,0.123123279,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I should have come to this on my own!,Social Conversation,37,37,0.6,0.8421052632,0.6149282872,0.3850717128,0.5,0.1343283582,0.001498933696,0.123123279,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Here is a complete working code snippet for anybody interested: CODE,Workarounds,973,68,0.8,0.8436532508,0.6149282872,0.3850717128,0.6111111111,0.1641791045,0.001498933696,0.123123279,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,This shuffles as desired on every epoch the entire dataset and gives an output e.g. like this: CODE,Workarounds,777,99,1,0.8452012384,0.6149282872,0.3850717128,1,0.2686567164,0.001498933696,0.123123279,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Currently the tutorial says that we can useCODEto get shuffled data.,Usage,146,68,0.2,0.846749226,0.6302370014,0.3697629986,0.6875,0.1641791045,0.123123279,0.6886518758,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,The pattern is also used in [CODE](https://github.com/tensorflow/tensorflow/blob/1efd7f171ba30421b5d8369a93526395a721c0d9/tensorflow/contrib/data/python/ops/dataset_ops.py#L595),Usage,210,177,0.4,0.8482972136,0.6302370014,0.3697629986,1,0.2388059701,0.123123279,0.6886518758,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,However calling CODE before CODE could lead to the shuffle across multiple epochs.,Usage,91,82,0.6,0.8498452012,0.6302370014,0.3697629986,0.8125,0.1940298507,0.123123279,0.6886518758,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"For example, the following codeCODEgets 3 CODE before getting a CODE.",Usage,742,69,0.8,0.8513931889,0.6302370014,0.3697629986,0.6875,0.1641791045,0.123123279,0.6886518758,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Are there any concerns about calling CODE before CODE?,Usage,63,54,1,0.8529411765,0.6302370014,0.3697629986,0.5625,0.1343283582,0.123123279,0.6886518758,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Just want to add something here, I implemented a **multiprocess-based** data feeding pipeline for multi-task learning.",Solution Discussion,118,118,0.2,0.8544891641,0.7158615465,0.2841384535,1,0.2686567164,0.6886518758,0.01649590529,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It can achieve avg. GPU utilization >90% and quad-core CPU utilization >95%.,Solution Discussion,76,76,0.4,0.8560371517,0.7158615465,0.2841384535,0.7222222222,0.1940298507,0.6886518758,0.01649590529,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Less prone to memory leak and particularly good for days-long training.,Solution Discussion,71,71,0.6,0.8575851393,0.7158615465,0.2841384535,0.6666666667,0.1791044776,0.6886518758,0.01649590529,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Not saying it's perfect, but at least works much better than current TF queue API in my case.",Solution Discussion,93,93,0.8,0.8591331269,0.7158615465,0.2841384535,1,0.2686567164,0.6886518758,0.01649590529,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,If anyone interested: https://hanxiao.github.io/2017/07/07/Get-10x-Speedup-in-Tensorflow-Multi-Task-Learning-using-Python-Multiprocessing/,Solution Discussion,138,138,1,0.8606811146,0.7158615465,0.2841384535,0.2222222222,0.05970149254,0.6886518758,0.01649590529,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,That was already done in [TensorPack] URL  for a while now by @ppwwyyxx.,Solution Discussion,107,72,0.25,0.8622291022,0.7179125891,0.2820874109,0.7777777778,0.2089552239,0.01649590529,0.01478320176,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,There you also get further speedup using ZMQ -- plus it has a nice interface using Python generators.,Solution Discussion,101,101,0.5,0.8637770898,0.7179125891,0.2820874109,1,0.2686567164,0.01649590529,0.01478320176,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For me, the way tensorpack handles input data, is the most elegant way.",Solution Discussion,71,71,0.75,0.8653250774,0.7179125891,0.2820874109,0.7222222222,0.1940298507,0.01649590529,0.01478320176,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I hope to see something like this in a future TF.,Social Conversation,49,49,1,0.866873065,0.7179125891,0.2820874109,0.6111111111,0.1641791045,0.01649590529,0.01478320176,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@PatWie thanks for pointing this out!,Social Conversation,37,37,0.3333333333,0.8684210526,0.7197506803,0.2802493197,0.75,0.08955223881,0.01478320176,0.1554452775,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I just quickly checked @ppwwyyxx repo really awesome!,Social Conversation,53,53,0.6666666667,0.8699690402,0.7197506803,0.2802493197,1,0.1194029851,0.01478320176,0.1554452775,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Thanks again,Social Conversation,12,12,1,0.8715170279,0.7197506803,0.2802493197,0.25,0.02985074627,0.01478320176,0.1554452775,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It would be great to have GPU resident queues.,Expected Behaviour,46,46,1,0.8730650155,0.7390781978,0.2609218022,1,0.1343283582,0.1554452775,0.008995129102,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@xieqihuiPG See [StagingArea] URL  and [MapStagingArea] URL,Solution Discussion,177,60,1,0.8746130031,0.7401966204,0.2598033796,1,0.1194029851,0.008995129102,0.1736946043,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Would greatly appreciate:,Expected Behaviour,25,25,0.1428571429,0.8761609907,0.7617931948,0.2382068052,0.2,0.0447761194,0.1736946043,0.06663052939,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,1.         Efficient random sampling:,Expected Behaviour,37,37,0.2857142857,0.8777089783,0.7617931948,0.2382068052,0.3333333333,0.07462686567,0.1736946043,0.06663052939,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,CODE,Expected Behaviour,25,4,0.4285714286,0.8792569659,0.7617931948,0.2382068052,0.06666666667,0.01492537313,0.1736946043,0.06663052939,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,2.         Dynamical changing and resizing methods:,Expected Behaviour,51,51,0.5714285714,0.8808049536,0.7617931948,0.2382068052,0.4666666667,0.1044776119,0.1736946043,0.06663052939,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"CODE etc., e.g. for creating streaming buffers, replay memory objects...",Expected Behaviour,101,72,0.7142857143,0.8823529412,0.7617931948,0.2382068052,0.6666666667,0.1492537313,0.1736946043,0.06663052939,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,3.         Meta- and descriptive statistic integration into dataset object and supportive methods like CODE,Expected Behaviour,123,107,0.8571428571,0.8839009288,0.7617931948,0.2382068052,1,0.223880597,0.1736946043,0.06663052939,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,4.         Closer integration with HDF5 anyway,Expected Behaviour,46,46,1,0.8854489164,0.7617931948,0.2382068052,0.4666666667,0.1044776119,0.1736946043,0.06663052939,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,#11591 We need efficient sampling/shuffling for large datasets,Expected Behaviour,62,62,1,0.886996904,0.7700777998,0.2299222002,1,0.1343283582,0.06663052939,0.88547434,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,What about supporting custom ops to create a Dataset?,Expected Behaviour,53,53,0.2,0.8885448916,0.8801745557,0.1198254443,0.2142857143,0.1343283582,0.88547434,0.1191105139,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"For example, let's say I have a Python function which returns a new batch on each call (a generator).",Motivation,101,101,0.4,0.8900928793,0.8801745557,0.1198254443,0.4523809524,0.2835820896,0.88547434,0.1191105139,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I want to wrap this function using CODE and use it to build a CODE.,Motivation,80,67,0.6,0.8916408669,0.8801745557,0.1198254443,0.3571428571,0.223880597,0.88547434,0.1191105139,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,This doesn't seem to be supported?,Motivation,34,34,0.8,0.8931888545,0.8801745557,0.1198254443,0.1428571429,0.08955223881,0.88547434,0.1191105139,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"I currently use this method with CODE ops and it works nicely but I'd like to find a way to do this for evaluation as well (and figured maybe Dataset is a good way to do this with the ""reintializable"" iterator).",Motivation,225,211,1,0.8947368421,0.8801745557,0.1198254443,1,0.6268656716,0.88547434,0.1191105139,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,@mrry This is great work and definitely very useful for creating nice learning APIs on top of TensorFlow.,Social Conversation,105,105,0.5,0.8962848297,0.8949843368,0.1050156632,1,0.2686567164,0.1191105139,0.0385452454,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Also, if my description is terribly unclear, please let me know and I'll try to clarify.",Social Conversation,88,88,1,0.8978328173,0.8949843368,0.1050156632,0.8888888889,0.2388059701,0.1191105139,0.0385452454,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The new input pipelines are great!,Social Conversation,34,34,0.1428571429,0.899380805,0.8997769167,0.1002230833,0.1071428571,0.08955223881,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Some workarounds are,Workarounds,20,20,0.2857142857,0.9009287926,0.8997769167,0.1002230833,0.05357142857,0.0447761194,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,*         closing the queue in the background thread such that a CODE is raised when the queue is exhausted (but then we can't reopen it again #4535),Workarounds,172,149,0.4285714286,0.9024767802,0.8997769167,0.1002230833,0.4821428571,0.4029850746,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,*         setting a timeout on the CODE of the training op and assuming that a timeout is due to the queue being exhausted (but the network connection might be down or our workers might be too slow),Workarounds,207,198,0.5714285714,0.9040247678,0.8997769167,0.1002230833,0.6607142857,0.552238806,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,*         counting the number of items we've processed and comparing with the expected number of items in the iterator (but that's fiddly and sometimes we don't even know how long the iterator is),Workarounds,196,196,0.7142857143,0.9055727554,0.8997769167,0.1002230833,0.6071428571,0.5074626866,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"*         adding an CODE field to the queue CODE and letting the background thread enqueue an item with CODE together with an assertion around the dequeue operation (but using CODE will dequeue elements from the next epoch if the number of items per epoch is not an integer multiple of the batch size, see also #2514)",Workarounds,349,317,0.8571428571,0.907120743,0.8997769167,0.1002230833,1,0.8358208955,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,Looking forward to hear whether we've just not been using the datasets API right.,Usage,81,81,1,0.9086687307,0.8997769167,0.1002230833,0.2678571429,0.223880597,0.0385452454,0.125435556,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I think the queues are nice enough.,Social Conversation,35,35,0.1,0.9102167183,0.9153731312,0.08462686876,0.4375,0.1044776119,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'd like to see two things improved though:,Expected Behaviour,43,43,0.2,0.9117647059,0.9153731312,0.08462686876,0.5625,0.1343283582,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"An easier way of inputting data from native python other than using placeholders, and managing threads.",Expected Behaviour,103,103,0.3,0.9133126935,0.9153731312,0.08462686876,1,0.2388059701,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Maybe a class CODE that takes a tensorflow queue delegate and a python function CODE.,Solution Discussion,125,85,0.4,0.9148606811,0.9153731312,0.08462686876,0.9375,0.223880597,0.125435556,0.2620248075,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,CODE returns a (possibly nested) tuple of np.array or lists.,Solution Discussion,60,60,0.5,0.9164086687,0.9153731312,0.08462686876,0.625,0.1492537313,0.125435556,0.2620248075,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,The InputQueue starts CODE that calls CODE and puts these on the CODE.,Solution Discussion,90,70,0.6,0.9179566563,0.9153731312,0.08462686876,0.8125,0.1940298507,0.125435556,0.2620248075,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,The threads are daemons so shuts down when the main process does.,Solution Discussion,65,65,0.7,0.919504644,0.9153731312,0.08462686876,0.75,0.1791044776,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"Anyway, that's just my thoughts.",Social Conversation,32,32,0.8,0.9210526316,0.9153731312,0.08462686876,0.3125,0.07462686567,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,It's probably a lot harder than this due to the static requirements of tensorflow.,Solution Discussion,82,82,0.9,0.9226006192,0.9153731312,0.08462686876,0.875,0.2089552239,0.125435556,0.2620248075,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Maybe you just have to provide the sizes when you create the CODE.,Solution Discussion,72,66,1,0.9241486068,0.9153731312,0.08462686876,0.8125,0.1940298507,0.125435556,0.2620248075,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,I am using the new api CODE now.,Social Conversation,37,32,0.1111111111,0.9256965944,0.9479523715,0.05204762849,0.380952381,0.1194029851,0.2620248075,0.005625200409,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,But still find the problem that how to dynamically feed data to the Dataset.,Usage,76,76,0.2222222222,0.927244582,0.9479523715,0.05204762849,0.6666666667,0.2089552239,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,There are two similar questions in [here] URL  and [here] URL @albertz.,Usage,276,71,0.3333333333,0.9287925697,0.9479523715,0.05204762849,0.619047619,0.1940298507,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"As you can see, the real-world problems are more than just feeding into a series of images or texts.",Motivation,100,100,0.4444444444,0.9303405573,0.9479523715,0.05204762849,0.9523809524,0.2985074627,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,So I would really appreciate if you could let me to feed the data **freely** in terms of **when** and **how**.,Expected Behaviour,110,110,0.5555555556,0.9318885449,0.9479523715,0.05204762849,1,0.3134328358,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I can image two options.,Solution Discussion,24,24,0.6666666667,0.9334365325,0.9479523715,0.05204762849,0.2380952381,0.07462686567,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,One is efficient distributed reading through CODE.,Solution Discussion,57,50,0.7777777778,0.9349845201,0.9479523715,0.05204762849,0.3333333333,0.1044776119,0.2620248075,0.005625200409,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Although it is slow, but with multi-processing, it is just a matter of machine.",Solution Discussion,79,79,0.8888888889,0.9365325077,0.9479523715,0.05204762849,0.7142857143,0.223880597,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The other one is to _wrap_ some mature and widely accepted implementation.,Solution Discussion,74,74,1,0.9380804954,0.9479523715,0.05204762849,0.5714285714,0.1791044776,0.2620248075,0.005625200409,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,use staging area you can even hide all preprocessing and input time.,Usage,68,68,1,0.939628483,0.9486517891,0.05134821091,1,0.1791044776,0.005625200409,0.06755432044,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm trying to test the example in the [doc](https://www.tensorflow.org/versions/r1.3/programmers_guide/datasets#preprocessing_data_with_datasetmap),Usage,147,147,0.5,0.9411764706,0.957051255,0.04294874501,1,0.1940298507,0.06755432044,0.001667404682,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,But seems that this call is passing only 1 argument to the function:,Usage,68,68,1,0.9427244582,0.957051255,0.04294874501,1,0.1940298507,0.06755432044,0.001667404682,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@eaplatanios one relevant PR for zip/unzip is https://github.com/tensorflow/tensorflow/issues/10837,Solution Discussion,99,99,1,0.9442724458,0.9572585742,0.04274142579,1,0.1343283582,0.001667404682,0.1037944145,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@bhack I haven't been able to make it work with more than one parameter in return from the function given to py_func.,Usage,117,117,0.3333333333,0.9458204334,0.9701640056,0.02983599443,1,0.328358209,0.1037944145,0.0001913748963,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'm using python3 and didn't tried with python2.,Usage,48,48,0.6666666667,0.9473684211,0.9701640056,0.02983599443,0.3636363636,0.1194029851,0.1037944145,0.0001913748963,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is your problem similar ?,Usage,25,25,1,0.9489164087,0.9701640056,0.02983599443,0.1818181818,0.05970149254,0.1037944145,0.0001913748963,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,@AMairesse The first problem was solved with https://github.com/tensorflow/tensorflow/commit/2139e7d8b10764f2245f34548f6fbfc25d29bff8,Task Progress,133,133,1,0.9504643963,0.9701878005,0.02981219955,1,0.1194029851,0.0001913748963,0.04231472009,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@bhack Thanks, will try that soon, I was using a workaround which I'm not proud of :-)",Social Conversation,86,86,0.5,0.9520123839,0.9754490635,0.02455093652,0.6538461538,0.2537313433,0.04231472009,0.09283260295,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The fix in the documentation is one month old and prior to v1.3 release, the tensorflow.org website is not updated when there is a new release ?",Task Progress,144,144,1,0.9535603715,0.9754490635,0.02455093652,1,0.3880597015,0.04231472009,0.09283260295,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,And Dataset do not stably init variable defined in the map function as https://github.com/tensorflow/tensorflow/issues/12648,Potential New Issues and Requests,124,124,1,0.9551083591,0.9869915419,0.01300845813,1,0.2089552239,0.09283260295,0.005682714673,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,I'd like to re-raise an earlier performance-related question by @kratzert that seems to have fallen out of focus.,Social Conversation,113,113,0.25,0.9566563467,0.9876981106,0.01230188943,0.875,0.3134328358,0.005682714673,0.0468741252,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,The performance gain of using the new Dataset API is negligible.,Solution Discussion,64,64,0.5,0.9582043344,0.9876981106,0.01230188943,0.4583333333,0.1641791045,0.005682714673,0.0468741252,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@ppwwyyxx stated that queues and StagingArea can still be used with the Dataset API, but I still haven't seen a working example of this.",Usage,136,136,0.75,0.959752322,0.9876981106,0.01230188943,1,0.3582089552,0.005682714673,0.0468741252,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Do we have one?,Usage,15,15,1,0.9613003096,0.9876981106,0.01230188943,0.1666666667,0.05970149254,0.005682714673,0.0468741252,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"@vvekic, I experimented a bit with queues and the Dataset API after realising in horror that of the 0.8s/step in my inference loop, 0.2s is data fetching (with GPU at 0% utilization), raising to almost 2 seconds if the HDD is being used by something else at the same time.",Usage,272,272,0.25,0.9628482972,0.9935262739,0.006473726055,1,0.7611940299,0.0468741252,0.02821456383,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,My pipeline looks as follows: CODE,Usage,738,34,0.5,0.9643962848,0.9935262739,0.006473726055,0.1176470588,0.08955223881,0.0468741252,0.02821456383,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I still have to run this on a big dataset and check if there's any performance improvement, but at least it seems to execute correctly.",Usage,135,135,0.75,0.9659442724,0.9935262739,0.006473726055,0.4901960784,0.3731343284,0.0468741252,0.02821456383,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"The catch is, I couldn't find a way to iterate over the data more than once (which luckily enough is not my use-case), because the only iterator that won't raise an error when the CODEs spawn the threads is the CODE.",Usage,240,216,1,0.9674922601,0.9935262739,0.006473726055,0.8235294118,0.6268656716,0.0468741252,0.02821456383,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"I don't know if I'm right here, but I have a question about the dataset API.",Social Conversation,76,76,0.2,0.9690402477,0.9970343733,0.002965626714,0.6666666667,0.2388059701,0.02821456383,0.02385162338,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,"My dataset contains one column with sequences and one with sequence length which i want treat different, because i want to pad the sequences.",Usage,141,141,0.4,0.9705882353,0.9970343733,0.002965626714,1,0.3582089552,0.02821456383,0.02385162338,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,Is it possible to address a single column in the dataset so that it is treated different from the other column?,Usage,111,111,0.6,0.9721362229,0.9970343733,0.002965626714,0.875,0.3134328358,0.02821456383,0.02385162338,NONE,FALSE,FALSE,FALSE,FALSE
10 7951_tensorflow.doc,E.g.: CODE,Usage,372,10,0.8,0.9736842105,0.9970343733,0.002965626714,0.08333333333,0.02985074627,0.02821456383,0.02385162338,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"Edit: After writing this, i found it out: CODE",Usage,412,46,1,0.9752321981,0.9970343733,0.002965626714,0.375,0.1343283582,0.02821456383,0.02385162338,NONE,FALSE,TRUE,FALSE,FALSE
10 7951_tensorflow.doc,"This issue thread is becoming a bit unwieldy and it's getting hard to keep track of the individual discussions, so I'm going to lock it after responding to a few of the recent comments.",Action on Issue,185,185,1,0.9767801858,1,0,34,0.5074626866,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,In response to a few recent questions:,Usage,38,38,2,0.9783281734,1,0,7,0.1044776119,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"*         @GPhilo ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-325698349)) and @kratzert ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308845375)): The Dataset API includes methods for prefetching, so it shouldn't be necessary to add a queue here, and you can retain the other advantages of Datasets (like reinitialization etc.).",Usage,386,386,3,0.979876161,1,0,42,0.6268656716,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"Passing CODE to the CODE call, and following that with CODE will run your CODE function in parallel and should decently increase the performance.",Usage,238,145,4,0.9814241486,1,0,24,0.3582089552,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,CODE,Usage,329,4,5,0.9829721362,1,0,1,0.01492537313,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,(You can try it by downloading the current nightly build.),Usage,58,58,6,0.9845201238,1,0,10,0.1492537313,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"In reponse to @kratzert's [specific question](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308845375) about the implementation, the CODE and CODE classes don't use TensorFlow's previous producer/consumer queues (such as CODE or CODE), but they do include simpler (and more efficient) implementations of the core ideas.",Solution Discussion,379,339,7,0.9860681115,1,0,42,0.6268656716,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,"For example, CODE will start a background thread to populate a ordered buffer that *acts like* a CODE, so that downstream pipeline stages need not block.",Solution Discussion,179,153,8,0.9876160991,1,0,26,0.3880597015,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,"However, the [CODE implementation] URL  is much simpler, because it doesn't need to support as many different concurrent operations as a CODE.",Solution Discussion,290,142,9,0.9891640867,1,0,23,0.3432835821,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,I answered @albertz's Stack Overflow question about doing this [here] URL .,Usage,116,75,10,0.9907120743,1,0,11,0.1641791045,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"I think this will also work for @rasmusbergpalm's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-322407451), because you can create concurrent generators, and for @tillahoffmann's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-321976369) and @sirfz's [request](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-321091444) as well.",Solution Discussion,404,404,11,0.9922600619,1,0,33,0.4925373134,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"This API is very new though, so if you have any feedback, please let us know!",Social Conversation,77,77,12,0.9938080495,1,0,16,0.2388059701,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,The programmers' guide has [more details](https://www.tensorflow.org/programmers_guide/datasets#creating_an_iterator) about how to use this feature.,Usage,148,148,13,0.9953560372,1,0,14,0.2089552239,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,"*         @guillaumekln ([link](https://github.com/tensorflow/tensorflow/issues/7951#issuecomment-308789560)) If you want to batch sequences with different lengths, you can use the CODE transformation.",Usage,224,201,14,0.9969040248,1,0,21,0.3134328358,0.02385162338,0,CONTRIBUTOR,TRUE,TRUE,FALSE,TRUE
10 7951_tensorflow.doc,Have a look at [how this is used in the NMT model code](https://github.com/tensorflow/nmt/blob/04c8c04a8b4e805f3d0a9c42b4d17c85f1324c55/nmt/utils/iterator_utils.py#L194) for an example.,Usage,185,185,15,0.9984520124,1,0,22,0.328358209,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
10 7951_tensorflow.doc,Thanks again to all of you for your continued interest in this part of TensorFlow!,Social Conversation,82,82,16,1,1,0,15,0.223880597,0.02385162338,0,CONTRIBUTOR,TRUE,FALSE,FALSE,TRUE
11 9393_scikit-learn.doc,Debian test failures (was test_preserve_trustworthiness_approximately fails on 32bit: AssertionError: 0.89166666666666661 not greater than 0.9),Observed Bug Behaviour,143,143,0.25,0.004291845494,0,1,0.6363636364,0.2058823529,0,0.02663056991,MEMBER,TRUE,FALSE,TRUE,FALSE
11 9393_scikit-learn.doc,building 0.19b2 on debian/ubuntus ...,Observed Bug Behaviour,37,37,0.5,0.008583690987,0,1,0.2272727273,0.07352941176,0,0.02663056991,MEMBER,TRUE,FALSE,TRUE,FALSE
11 9393_scikit-learn.doc,"still ongoing but I see consistent failure on Debian stretch (nd90, current stable) and testing (nd100), 32bit only (ok on amd64 build):CODE",Observed Bug Behaviour,2171,140,0.75,0.01287553648,0,1,1,0.3235294118,0,0.02663056991,MEMBER,TRUE,TRUE,TRUE,FALSE
11 9393_scikit-learn.doc,in both cases python-numpy is CODE (i.e. 1.12.1 numpy) and passed ok with numpy 1.8.2 in Debian jessie.,Observed Bug Behaviour,111,103,1,0.01716738197,0,1,0.8636363636,0.2794117647,0,0.02663056991,MEMBER,TRUE,TRUE,TRUE,FALSE
11 9393_scikit-learn.doc,ping @ogrisel?,Contribution and Commitment,14,14,1,0.02145922747,0.009005396465,0.9909946035,1,0.02941176471,0.02663056991,0.01958514047,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Interesting, it's a only on a combo of numpy 1.12.1 and 32 bit python...",Observed Bug Behaviour,72,72,0.25,0.02575107296,0.01562830973,0.9843716903,0.9333333333,0.2058823529,0.01958514047,0.0006046437747,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Those tests pass with 32 bit python and numpy 1.13.1 on our wheel building travis:,Bug Reproduction,82,82,0.5,0.03004291845,0.01562830973,0.9843716903,1,0.2205882353,0.01958514047,0.0006046437747,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,https://travis-ci.org/MacPython/scikit-learn-wheels,Bug Reproduction,51,51,0.75,0.03433476395,0.01562830973,0.9843716903,0.06666666667,0.01470588235,0.01958514047,0.0006046437747,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@tomMoral if you want to play with docker, this is a good opportunity ;)",Contribution and Commitment,72,72,1,0.03862660944,0.01562830973,0.9843716903,0.9333333333,0.2058823529,0.01958514047,0.0006046437747,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@ogrisel I will give it a try :),Contribution and Commitment,32,32,1,0.04291845494,0.01583277614,0.9841672239,1,0.1176470588,0.0006046437747,0.00144962568,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@yarikoptic I am unable to reproduce the failure on 32bit debian CODE on docker.,Bug Reproduction,84,80,0.3333333333,0.04721030043,0.01632298172,0.9836770183,0.7777777778,0.2058823529,0.00144962568,0.1491477665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,I tried installing python and scikit dependency using CODE and the test passed for both CODE and CODE.,Bug Reproduction,130,102,0.6666666667,0.05150214592,0.01632298172,0.9836770183,1,0.2647058824,0.00144962568,0.1491477665,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Do you have a specific configuration that could explain the difference?,Bug Reproduction,71,71,1,0.05579399142,0.01632298172,0.9836770183,0.6111111111,0.1617647059,0.00144962568,0.1491477665,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@yarikoptic @tomMoral how can you install numpy 1.12.1 on debian stretch?,Bug Reproduction,73,73,0.5,0.06008583691,0.06675880694,0.9332411931,1,0.1617647059,0.1491477665,0.02842550899,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Which repo did you use to produce this failure?,Bug Reproduction,47,47,1,0.0643776824,0.06675880694,0.9332411931,0.8181818182,0.1323529412,0.1491477665,0.02842550899,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@ogrisel I installed the CODE package, which uses version 1.12.1 and used branch CODE for CODE.",Bug Reproduction,114,95,0.5,0.0686695279,0.07637118021,0.9236288198,1,0.2352941176,0.02842550899,0.004140653057,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,EDIT: I used this docker image: CODE,Bug Reproduction,69,36,1,0.07296137339,0.07637118021,0.9236288198,0.4375,0.1029411765,0.02842550899,0.004140653057,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Indeed I was using an older image (jessie).,Bug Reproduction,43,43,0.5,0.07725321888,0.0777713839,0.9222286161,0.4705882353,0.1176470588,0.004140653057,0.1410011326,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I confirm I cannot reproduce the issue on stretch with the following 32 bit image: CODE.,Bug Reproduction,121,88,1,0.08154506438,0.0777713839,0.9222286161,1,0.25,0.004140653057,0.1410011326,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"@yarikoptic, we would like to release.",Task Progress,38,38,0.5,0.08583690987,0.1254523425,0.8745476575,0.2727272727,0.08823529412,0.1410011326,0.4013025222,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"We need a way to reproduce the error, or we will need to skip the tests / lower the condition on certain architectures.",Investigation and Exploration,119,119,1,0.09012875536,0.1254523425,0.8745476575,1,0.3235294118,0.1410011326,0.4013025222,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"oh -- I have managed to miss your message @jnothman and 0.13.0 came out without the fix, my bad.",Task Progress,96,96,0.5,0.09442060086,0.2611568478,0.7388431522,0.8636363636,0.2794117647,0.4013025222,0.02749488936,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I will release debian packages as is (without i386 build for some) and later give you exact instruction on how to reproduce.,Task Progress,124,124,1,0.09871244635,0.2611568478,0.7388431522,1,0.3235294118,0.4013025222,0.02749488936,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Right.,Social Conversation,6,6,0.3333333333,0.1030042918,0.2704545226,0.7295454774,0.0625,0.01470588235,0.02749488936,0.002183761982,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I see in the logs there an alarming number of fails for a final release :(((,Potential New Issues and Requests,76,76,0.6666666667,0.1072961373,0.2704545226,0.7295454774,1,0.2352941176,0.02749488936,0.002183761982,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,And none of them are about CODE CODE,Potential New Issues and Requests,2929,36,1,0.1115879828,0.2704545226,0.7295454774,0.5,0.1176470588,0.02749488936,0.002183761982,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,The last is the most confusing to me tbh.,Social Conversation,41,41,1,0.1158798283,0.2711929838,0.7288070162,1,0.1323529412,0.002183761982,0.004772231277,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"yeah, that 32bit issue didn't reproduce in current build.",Bug Reproduction,57,57,0.3333333333,0.1201716738,0.2728067621,0.7271932379,1,0.1323529412,0.004772231277,0.004433478825,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I guess it is not fully deterministic...,Investigation and Exploration,40,40,0.6666666667,0.1244635193,0.2728067621,0.7271932379,0.7777777778,0.1029411765,0.004772231277,0.004433478825,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"will try to reproduce now ""locally""",Bug Reproduction,35,35,1,0.1287553648,0.2728067621,0.7271932379,0.6666666667,0.08823529412,0.004772231277,0.004433478825,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,and do we need to fix the other test failures for scikit-learn 0.19 to shipwith Debian?,Task Progress,87,87,1,0.1330472103,0.2743059878,0.7256940122,1,0.25,0.004433478825,0.001495897677,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,That last failure is not confusing after a little investigation.,Potential New Issues and Requests,64,64,0.5,0.1373390558,0.2748118407,0.7251881593,0.625,0.1470588235,0.001495897677,0.0001153346778,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,It's a result of CODE being the same as CODE on a machine with 1 core.,Potential New Issues and Requests,83,70,1,0.1416309013,0.2748118407,0.7251881593,1,0.2352941176,0.001495897677,0.0001153346778,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"@rth, do you mind looking into the CODE failure above?",Potential New Issues and Requests,78,54,1,0.1459227468,0.2748508423,0.7251491577,1,0.1470588235,0.0001153346778,0.01003549822,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"@yarikoptic On this link I see ""No entry in i386 database, check Packages-arch-specific"" (with ""Suite: experimental"").",Bug Reproduction,118,118,0.25,0.1502145923,0.2782444475,0.7217555525,1,0.2647058824,0.01003549822,0.0003149258267,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Is there another way of getting this i386 build for debian?,Bug Reproduction,59,59,0.5,0.1545064378,0.2782444475,0.7217555525,0.6111111111,0.1617647059,0.01003549822,0.0003149258267,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,or did I miss something?,Bug Reproduction,24,24,0.75,0.1587982833,0.2782444475,0.7217555525,0.2777777778,0.07352941176,0.01003549822,0.0003149258267,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Thanks.,Social Conversation,7,7,1,0.1630901288,0.2782444475,0.7217555525,0.05555555556,0.01470588235,0.01003549822,0.0003149258267,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"yeah, i clicked the logs column after failing to work it out",Bug Reproduction,60,60,1,0.1673819742,0.2783509428,0.7216490572,1,0.1764705882,0.0003149258267,0.007023674687,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Thank you very much for looking into those!,Social Conversation,43,43,0.2,0.1716738197,0.2807260694,0.7192739306,0.2222222222,0.1176470588,0.007023674687,0.0006692173817,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,FWIW -- locally I had only the test_multi_output_classification_partial_fit_parallelism to popup and indeed it was due to inability to do multiprocessing in my case (absent bound to /dev/shm I guess):CODE,Potential New Issues and Requests,356,204,0.4,0.1759656652,0.2807260694,0.7192739306,0.8333333333,0.4411764706,0.007023674687,0.0006692173817,MEMBER,TRUE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,it passes just fine when I have /dev/shm mounted and joblib does not complaint.,Potential New Issues and Requests,79,79,0.6,0.1802575107,0.2807260694,0.7192739306,0.4166666667,0.2205882353,0.007023674687,0.0006692173817,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,well -- for unstable Debian -- no.,Task Progress,34,34,0.8,0.1845493562,0.2807260694,0.7192739306,0.1944444444,0.1029411765,0.007023674687,0.0006692173817,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"But if we want to have it propagate into testing and thus become a part of the next Debian stable release (Whenever that would be) -- yes, should get addressed one way (fixed) or another (disabled)",Task Progress,197,197,1,0.1888412017,0.2807260694,0.7192739306,1,0.5294117647,0.007023674687,0.0006692173817,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,re original CODE,Bug Reproduction,57,16,0.25,0.1931330472,0.2809523721,0.7190476279,0.07894736842,0.04411764706,0.0006692173817,5.94E-05,MEMBER,TRUE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,-         specific to older versions of something (yet to figure out since numpy as nscipy are the same) since is not reproducible on current debian sid but reproducible on testing (from few days back) and other older releases.,Bug Reproduction,227,227,0.5,0.1974248927,0.2809523721,0.7190476279,1,0.5588235294,0.0006692173817,5.94E-05,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,before I spend more time -- is there specific meaning for the threshold to be 0.9?,Investigation and Exploration,82,82,0.75,0.2017167382,0.2809523721,0.7190476279,0.4210526316,0.2352941176,0.0006692173817,5.94E-05,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,may be it could just be relaxed a little? ;),Investigation and Exploration,44,44,1,0.2060085837,0.2809523721,0.7190476279,0.2631578947,0.1470588235,0.0006692173817,5.94E-05,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"btw these are the values I see for t, init, methodCODE",Investigation and Exploration,220,54,1,0.2103004292,0.2809724567,0.7190275433,1,0.1617647059,5.94E-05,0.0110061742,MEMBER,TRUE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,i think .9 is somewhat arbitrary but we'd like to be sure that thevariation isn't pointing to something more sinister,Investigation and Exploration,117,117,1,0.2145922747,0.2846943058,0.7153056942,1,0.3088235294,0.0110061742,0.09406233598,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@jnothman how could we discover? ;),Investigation and Exploration,35,35,1,0.2188841202,0.3165024357,0.6834975643,1,0.08823529412,0.09406233598,0.03928665156,MEMBER,TRUE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,By pinpointing where this and other machines diverge in their calculation...,Investigation and Exploration,76,76,0.5,0.2231759657,0.3297876142,0.6702123858,0.7333333333,0.1617647059,0.03928665156,0.06296237465,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Not that that's easy to do without at least a VM of the target machine.,Investigation and Exploration,71,71,1,0.2274678112,0.3297876142,0.6702123858,1,0.2205882353,0.03928665156,0.06296237465,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@rth could the CODE failure be because of floating point error (i.e. a small number was in Xt.data instead of 0, and so was not removed)?",Potential New Issues and Requests,172,137,1,0.2317596567,0.3510789777,0.6489210223,1,0.3823529412,0.06296237465,7.77E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"@amueller, CODE already is marked with CODE suggesting perhaps that this assertion is brittle.",Potential New Issues and Requests,143,94,0.3333333333,0.2360515021,0.3511052513,0.6488947487,0.5833333333,0.2058823529,7.77E-05,0.009464004531,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,The test is failing where the importances in a model are being asserted identical to the importance in a similar model trained with sample_weight=3*orig_weights.,Potential New Issues and Requests,161,161,0.6666666667,0.2403433476,0.3511052513,0.6488947487,1,0.3529411765,7.77E-05,0.009464004531,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Any ideas how to fix here?,Potential New Issues and Requests,26,26,1,0.2446351931,0.3511052513,0.6488947487,0.25,0.08823529412,7.77E-05,0.009464004531,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@jnothman So far I am not able to reproduce the CODE failure above.,Potential New Issues and Requests,91,67,0.1,0.2489270386,0.3543056001,0.6456943999,0.3611111111,0.1911764706,0.009464004531,0.003096425316,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"Tried to build scikit-learn 0.19.2 it in a Debian sid/unstable i386 VM, were scipy and numpy 1.2.1 were installed with apt-get.",Potential New Issues and Requests,127,127,0.2,0.2532188841,0.3543056001,0.6456943999,0.6666666667,0.3529411765,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I consistently get the failure about CODE (that was resolved since as far as I understand) but not the one about hashing.,Potential New Issues and Requests,175,121,0.3,0.2575107296,0.3543056001,0.6456943999,0.6111111111,0.3235294118,0.009464004531,0.003096425316,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,I don't think it's due to floating point error.,Potential New Issues and Requests,47,47,0.4,0.2618025751,0.3543056001,0.6456943999,0.25,0.1323529412,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"So the test fails on [this line](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/feature_extraction/tests/test_feature_hasher.py#L122), where the expected values are CODE and  CODE (and I get those in the 32bit VM as well).",Potential New Issues and Requests,265,240,0.5,0.2660944206,0.3543056001,0.6456943999,1,0.5294117647,0.009464004531,0.003096425316,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,This test assumes that the hash value of the tested tokens always produces the same results (in which case two of those produce a collision).,Potential New Issues and Requests,141,141,0.6,0.2703862661,0.3543056001,0.6456943999,0.6944444444,0.3676470588,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"And it looks like mumurhash3 [doesn't actually produce the same results in 64bit and 32bit](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/utils/src/MurmurHash3.cpp#L5), which would explain why this test fail.",Potential New Issues and Requests,227,227,0.7,0.2746781116,0.3543056001,0.6456943999,0.8888888889,0.4705882353,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,This doesn't explain why I can't reproduce it though.,Potential New Issues and Requests,53,53,0.8,0.2789699571,0.3543056001,0.6456943999,0.25,0.1323529412,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Since this basically tests that in CODE we can disable the CODE functionality (enabled by default) and it doesn't validate any new functionality, it might be OK to skip it on failure on 32 bit?",Potential New Issues and Requests,216,193,0.9,0.2832618026,0.3543056001,0.6456943999,0.9722222222,0.5147058824,0.009464004531,0.003096425316,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,What do you think?,Potential New Issues and Requests,18,18,1,0.2875536481,0.3543056001,0.6456943999,0.1111111111,0.05882352941,0.009464004531,0.003096425316,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Ha!,Social Conversation,3,3,0.1428571429,0.2918454936,0.3553526876,0.6446473124,0.0625,0.01470588235,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I had no idea it worked differently on 64-bit and 32-bit...,Potential New Issues and Requests,59,59,0.2857142857,0.2961373391,0.3553526876,0.6446473124,0.8125,0.1911764706,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,strangechoice of hash function :\,Social Conversation,33,33,0.4285714286,0.3004291845,0.3553526876,0.6446473124,0.25,0.05882352941,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I'm okay with @skip_if_32bit here.,Potential New Issues and Requests,34,34,0.5714285714,0.30472103,0.3553526876,0.6446473124,0.3125,0.07352941176,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Not quite satisfying as we don'tunderstand what's going on...,Social Conversation,61,61,0.7142857143,0.3090128755,0.3553526876,0.6446473124,0.5625,0.1323529412,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Is this testing a collision where the sign alternates and hence the valuelands up at 0?,Potential New Issues and Requests,87,87,0.8571428571,0.313304721,0.3553526876,0.6446473124,1,0.2352941176,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Or just testing that values are stored in the same spot dueto collision?,Potential New Issues and Requests,72,72,1,0.3175965665,0.3553526876,0.6446473124,0.8125,0.1911764706,0.003096425316,0.01032797867,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,The former I think.,Potential New Issues and Requests,19,19,0.1666666667,0.321888412,0.358845198,0.641154802,0.05882352941,0.05882352941,0.01032797867,0.001373656731,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Despite that comment in murmurhash3, I'm not sure the hash value is actually platform dependent: after all this test passes on Appveyor 32bit and 64bit (and it works fine for me on i386) .",Potential New Issues and Requests,188,188,0.3333333333,0.3261802575,0.358845198,0.641154802,0.4852941176,0.4852941176,0.01032797867,0.001373656731,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,But it does seem like a plausible suspect.,Potential New Issues and Requests,42,42,0.5,0.330472103,0.358845198,0.641154802,0.1176470588,0.1176470588,0.01032797867,0.001373656731,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"We could try to make this test more robust, by just taking a large number of tokens N, hashing them with a hash table size = 1 (or any small number), and checking that with CODE the sum of hashed values is equal to CODE, and that it's strictly lower than CODE if  CODE (since some +1 / -1 are bound to cancel out if N is large enough).",Potential New Issues and Requests,368,335,0.6666666667,0.3347639485,0.358845198,0.641154802,1,1,0.01032797867,0.001373656731,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,That would be less dependent on the actual hashing implementation...,Potential New Issues and Requests,68,68,0.8333333333,0.339055794,0.358845198,0.641154802,0.1470588235,0.1470588235,0.01032797867,0.001373656731,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Still, for a Debian release of 0.19.0 I'm not sure how this could work: can you apply some patches on the original .tar.gz to skip tests/modify code when needed?",Potential New Issues and Requests,161,161,1,0.3433476395,0.358845198,0.641154802,0.4411764706,0.4411764706,0.01032797867,0.001373656731,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,we're going to release a bug-fix release in any case.,Potential New Issues and Requests,53,53,0.5,0.347639485,0.3593097139,0.6406902861,0.9166666667,0.1617647059,0.001373656731,0.0004426917871,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,i had wondered iffinding and data close to 0 would help here.,Potential New Issues and Requests,61,61,1,0.3519313305,0.3593097139,0.6406902861,1,0.1764705882,0.001373656731,0.0004426917871,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Right, I don't think the value of zero matters.",Potential New Issues and Requests,47,47,0.5,0.356223176,0.3594594146,0.6405405854,0.18,0.1323529412,0.0004426917871,0.001263501754,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"It could be a +1 - 1 = 0or a +3 - 2 = 1 (instead of 3+2=5) as long the value in the hash bucketis lower than the sum of the absolute value of hashed terms, it issufficient to determine whether CODE is used or not duringthe hash collisions, I think..",Potential New Issues and Requests,261,249,1,0.3605150215,0.3594594146,0.6405405854,1,0.7352941176,0.0004426917871,0.001263501754,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"Yes, I think you're right.",Social Conversation,26,26,0.5,0.364806867,0.3598866805,0.6401133195,1,0.07352941176,0.001263501754,0.2982430454,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,We're not calling eliminate_zeros anywhere.,Potential New Issues and Requests,43,43,1,0.3690987124,0.3598866805,0.6401133195,1,0.07352941176,0.001263501754,0.2982430454,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I can confirm that test_preserve_trustworthiness_approximately also failed on a 64 bit Mac.,Bug Reproduction,91,91,0.25,0.3733905579,0.4607405818,0.5392594182,0.5454545455,0.1764705882,0.2982430454,0.003789469322,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Error message: AssertionError: 0.89166666666666661 not greater than 0.9,Bug Reproduction,71,71,0.5,0.3776824034,0.4607405818,0.5392594182,0.3636363636,0.1176470588,0.2982430454,0.003789469322,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"2,4 GHz Intel Core i58 GB 1600 MHz DDR3",Bug Reproduction,39,39,0.75,0.3819742489,0.4607405818,0.5392594182,0.4090909091,0.1323529412,0.2982430454,0.003789469322,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Python 3.6.1numpy 1.13.1scikit-learn master branch, last commit hash d6a42354145c92cf88093cbcc70b13f639319c38numpy was installed from pip, so this is with Accelerate.OSX version 10.12.4",Bug Reproduction,185,185,1,0.3862660944,0.4607405818,0.5392594182,1,0.3235294118,0.2982430454,0.003789469322,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"FYI, I can not reproduce on my OSX version with the same numpy version, Accelerate as well.",Bug Reproduction,91,91,1,0.3905579399,0.4620220291,0.5379779709,1,0.25,0.003789469322,0.1520017818,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I also tried on macOS (El Capitan) with Accelerate and could not reproduce either.,Bug Reproduction,82,82,1,0.3948497854,0.5134229685,0.4865770315,1,0.2058823529,0.1520017818,0.0001312190945,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,We probably need to raise a CODE if CODE.,Potential New Issues and Requests,77,41,1,0.3991416309,0.5134673415,0.4865326585,1,0.1323529412,0.0001312190945,0.01113877455,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,The n_jobs=1 issue has been fixed.,Potential New Issues and Requests,34,34,0.1111111111,0.4034334764,0.5172340308,0.4827659692,0.3157894737,0.08823529412,0.01113877455,3.63E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,We appear to have the following issues:,Potential New Issues and Requests,39,39,0.2222222222,0.4077253219,0.5172340308,0.4827659692,0.3684210526,0.1029411765,0.01113877455,3.63E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"*         [x] CODE: [mips] URL , [powerpc] URL , [hppa] URL , [ppc64] URL , [s390x] URL , [sparc64] URL  fixed in #9710",Potential New Issues and Requests,763,119,0.3333333333,0.4120171674,0.5172340308,0.4827659692,1,0.2794117647,0.01113877455,3.63E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"*         [x] CODE [arm64] URL ,  [ppc64] URL , [ppc64el] URL , [s390x] URL .",Potential New Issues and Requests,513,77,0.4444444444,0.4163090129,0.5172340308,0.4827659692,0.6315789474,0.1764705882,0.01113877455,3.63E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,PR in #9733,Potential New Issues and Requests,11,11,0.5555555556,0.4206008584,0.5172340308,0.4827659692,0.1578947368,0.04411764706,0.01113877455,3.63E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,*         [x] CODE PR in #9808,Action on Issue,71,30,0.6666666667,0.4248927039,0.5172340308,0.4827659692,0.3157894737,0.08823529412,0.01113877455,3.63E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,*         [ ] CODE (not listed above): [mips] URL .,Potential New Issues and Requests,176,51,0.7777777778,0.4291845494,0.5172340308,0.4827659692,0.4210526316,0.1176470588,0.01113877455,3.63E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,PR in ~#9734~ #9830,Potential New Issues and Requests,19,19,0.8888888889,0.4334763948,0.5172340308,0.4827659692,0.2105263158,0.05882352941,0.01113877455,3.63E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,*         [x] CODE (fixed in #9544),Potential New Issues and Requests,89,35,1,0.4377682403,0.5172340308,0.4827659692,0.3157894737,0.08823529412,0.01113877455,3.63E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"The original issue with CODE remains the most concerning, IMO.",Social Conversation,103,62,1,0.4420600858,0.5172462918,0.4827537082,1,0.1470588235,3.63E-05,0.0520553054,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"Hm none of the links at CODEtest_preserve_trustworthyness_approximatelyCODE above have failures for that, right?",Investigation and Exploration,108,112,0.5,0.4463519313,0.5348493196,0.4651506804,1,0.1911764706,0.0520553054,4.56E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Or I'm blind.,Social Conversation,13,13,1,0.4506437768,0.5348493196,0.4651506804,0.2307692308,0.04411764706,0.0520553054,4.56E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,have we seen this before:,Potential New Issues and Requests,25,25,0.5,0.4549356223,0.5348647334,0.4651352666,1,0.07352941176,4.56E-05,0.02112247576,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,from [kfreebsd-amd64] URL,Potential New Issues and Requests,143,26,1,0.4592274678,0.5348647334,0.4651352666,0.8,0.05882352941,4.56E-05,0.02112247576,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@jnothman I just tried, but I'm not able to run e.g. a ppc64 Docker image on my amd64 system.",Potential New Issues and Requests,93,93,0.1428571429,0.4635193133,0.5420075121,0.4579924879,1,0.2794117647,0.02112247576,0.002129547778,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"With the CODE below I get an error,CODE",Potential New Issues and Requests,121,39,0.2857142857,0.4678111588,0.5420075121,0.4579924879,0.4736842105,0.1323529412,0.02112247576,0.002129547778,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,at the first CODE suggesting there is [a platform conflict] URL .,Potential New Issues and Requests,111,65,0.4285714286,0.4721030043,0.5420075121,0.4579924879,0.5789473684,0.1617647059,0.02112247576,0.002129547778,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Using CODE as the first line this works fine for amd64.,Potential New Issues and Requests,64,55,0.5714285714,0.4763948498,0.5420075121,0.4579924879,0.5789473684,0.1617647059,0.02112247576,0.002129547778,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,So unless I missed something it doesn't look like this could be reproducible in Docker.,Potential New Issues and Requests,87,87,0.7142857143,0.4806866953,0.5420075121,0.4579924879,0.7894736842,0.2205882353,0.02112247576,0.002129547778,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Will need to find a VM image instead...,Potential New Issues and Requests,39,39,0.8571428571,0.4849785408,0.5420075121,0.4579924879,0.4210526316,0.1176470588,0.02112247576,0.002129547778,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,**Dockerfile**CODEbuilt withCODE,Potential New Issues and Requests,825,32,1,0.4892703863,0.5420075121,0.4579924879,0.1052631579,0.02941176471,0.02112247576,0.002129547778,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"Actually, the above Docker setup with conda wouldn't have worked anyway for other platforms, it should have been, something along the lines of, I think,CODE",Potential New Issues and Requests,599,156,0.5,0.4935622318,0.5427276402,0.4572723598,0.7878787879,0.3823529412,0.002129547778,0.01188879527,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"but this still wouldn't help unless someone has access to non amd64 platforms and is able to run it there, using the [appropriate Docker Debian image](https://github.com/docker-library/official-images#architectures-other-than-amd64) ...",Potential New Issues and Requests,236,236,1,0.4978540773,0.5427276402,0.4572723598,1,0.4852941176,0.002129547778,0.01188879527,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@rth, okay.",Social Conversation,11,11,0.25,0.5021459227,0.5467479566,0.4532520434,0.1818181818,0.02941176471,0.01188879527,0.03044075803,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Thanks for trying.,Social Conversation,18,18,0.5,0.5064377682,0.5467479566,0.4532520434,0.2727272727,0.04411764706,0.01188879527,0.03044075803,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"No, I must have sorted these things incorrectly.",Social Conversation,48,48,0.75,0.5107296137,0.5467479566,0.4532520434,0.7272727273,0.1176470588,0.01188879527,0.03044075803,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@yarikoptic, I can't find the CODE failure under 0.19.0-1 logs.",Investigation and Exploration,104,63,1,0.5150214592,0.5467479566,0.4532520434,1,0.1617647059,0.01188879527,0.03044075803,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"@yarikoptic, any suggestion of how we can reproduce these test environments?",Bug Reproduction,76,76,1,0.5193133047,0.5570418067,0.4429581933,1,0.1617647059,0.03044075803,0.01794179397,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@jnothman any ideas about the CODEtest_pairwise_parallelCODE failure?,Potential New Issues and Requests,65,69,1,0.5236051502,0.5631090057,0.4368909943,1,0.1029411765,0.01794179397,0.009345907346,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"test_pairwise_parallel I had missed, but I also suspect it's something we'll find impossible to debug...",Potential New Issues and Requests,104,104,0.5,0.5278969957,0.5662694188,0.4337305812,1,0.2205882353,0.009345907346,0.003751139534,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Terminated after 150 minutes of inactivity during parallel execution of a simple function,Potential New Issues and Requests,89,89,1,0.5321888412,0.5662694188,0.4337305812,0.8666666667,0.1911764706,0.009345907346,0.003751139534,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I'm guessing CODE has failed because of precision errors due to partitioning the ensemble summation across jobs.,Potential New Issues and Requests,135,112,0.5,0.5364806867,0.5675379045,0.4324620955,1,0.25,0.003751139534,0.000437512086,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,I'll submit a PR to reduce precision of the test.,Potential New Issues and Requests,49,49,1,0.5407725322,0.5675379045,0.4324620955,0.5882352941,0.1470588235,0.003751139534,0.000437512086,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@priidukull is your test failure reproducible?,Bug Reproduction,46,46,0.3333333333,0.5450643777,0.5676858537,0.4323141463,0.6,0.08823529412,0.000437512086,0.005325768668,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Could you help us debug?,Contribution and Commitment,24,24,0.6666666667,0.5493562232,0.5676858537,0.4323141463,0.5,0.07352941176,0.000437512086,0.005325768668,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Which CODE and CODE combination is the first to fail?,Investigation and Exploration,59,53,1,0.5536480687,0.5676858537,0.4323141463,1,0.1470588235,0.000437512086,0.005325768668,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,What I've done is to reduce the size of X... with something like:,Investigation and Exploration,65,65,0.25,0.5579399142,0.5694868162,0.4305131838,0.5384615385,0.2058823529,0.005325768668,0.0007054752894,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,And then I debugged through the code on both of my environments and the best I could tell was that the divergence happened in C-code.,Investigation and Exploration,133,133,0.5,0.5622317597,0.5694868162,0.4305131838,1,0.3823529412,0.005325768668,0.0007054752894,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,But I could not tell where exactly with full certainty because it is tough to debug.,Investigation and Exploration,84,84,0.75,0.5665236052,0.5694868162,0.4305131838,0.6153846154,0.2352941176,0.005325768668,0.0007054752894,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,CODE,Investigation and Exploration,439,4,1,0.5708154506,0.5694868162,0.4305131838,0.03846153846,0.01470588235,0.005325768668,0.0007054752894,NONE,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,What do you mean by the divergence?,Investigation and Exploration,35,35,0.3333333333,0.5751072961,0.5697253798,0.4302746202,0.5833333333,0.1029411765,0.0007054752894,0.001821873532,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,What were you comparing it against?,Investigation and Exploration,35,35,0.6666666667,0.5793991416,0.5697253798,0.4302746202,0.5,0.08823529412,0.0007054752894,0.001821873532,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,The different methods and inits produce different trustworthiness scores on all platforms.,Investigation and Exploration,90,90,1,0.5836909871,0.5697253798,0.4302746202,1,0.1764705882,0.0007054752894,0.001821873532,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@priidukull, could you please provide the output of: CODE and of:CODE",Investigation and Exploration,885,69,0.3333333333,0.5879828326,0.5703414647,0.4296585353,1,0.1764705882,0.001821873532,0.0110293102,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Thanks.,Social Conversation,7,7,0.6666666667,0.5922746781,0.5703414647,0.4296585353,0.08333333333,0.01470588235,0.001821873532,0.0110293102,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"For reference, I have:CODEandCODE",Investigation and Exploration,2748,33,1,0.5965665236,0.5703414647,0.4296585353,0.4166666667,0.07352941176,0.001821873532,0.0110293102,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,CODE CODE,Investigation and Exploration,2848,9,1,0.6008583691,0.5740711375,0.4259288625,1,0.02941176471,0.0110293102,0.006827881986,NONE,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,So the error is reducing much more slowly...,Investigation and Exploration,44,44,0.2,0.6051502146,0.5763800548,0.4236199452,0.2962962963,0.1176470588,0.006827881986,0.01015048758,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@priidukull, What did you mean by telling that the divergence happened in C code?",Investigation and Exploration,81,81,0.4,0.6094420601,0.5763800548,0.4236199452,0.5185185185,0.2058823529,0.006827881986,0.01015048758,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Do you have another system you're comparing against?,Investigation and Exploration,52,52,0.6,0.6137339056,0.5763800548,0.4236199452,0.2962962963,0.1176470588,0.006827881986,0.01015048758,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"@tommoral, if we continue to not be able to reproduce this bug, what kind of debugging output do you think would help us understand what's going wrong?",Investigation and Exploration,151,151,0.8,0.6180257511,0.5763800548,0.4236199452,1,0.3970588235,0.006827881986,0.01015048758,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Or what kind of more low-level unit tests might help us hone in on it?,Investigation and Exploration,70,70,1,0.6223175966,0.5763800548,0.4236199452,0.5925925926,0.2352941176,0.006827881986,0.01015048758,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I was putting print statements into the code and comparing the values of the variable X during different stages of execution...,Investigation and Exploration,127,127,0.5,0.6266094421,0.5798125448,0.4201874552,1,0.3088235294,0.01015048758,0.0002044255366,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,one environment my Mac desktop and another one that I had set up with docker running on my Mac.,Investigation and Exploration,95,95,1,0.6309012876,0.5798125448,0.4201874552,0.9047619048,0.2794117647,0.01015048758,0.0002044255366,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Great.,Social Conversation,6,6,0.1111111111,0.635193133,0.5798816734,0.4201183266,0.05882352941,0.01470588235,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,It's extremely helpful to have someone reporting the issue who isalso capable and willing to debug it.,Social Conversation,102,102,0.2222222222,0.6394849785,0.5798816734,0.4201183266,1,0.25,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,If only I could reproduce it on mymac.,Bug Reproduction,38,38,0.3333333333,0.643776824,0.5798816734,0.4201183266,0.4705882353,0.1176470588,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I've wasted lots of time failing to set up an appropriate debianvirtual machine.,Bug Reproduction,80,80,0.4444444444,0.6480686695,0.5798816734,0.4201183266,0.8235294118,0.2058823529,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Do you recall which C function was responsible for the divergence?,Investigation and Exploration,66,66,0.5555555556,0.652360515,0.5798816734,0.4201183266,0.6470588235,0.1617647059,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Is theinput to TSNE._tsne identical on both platforms?,Investigation and Exploration,54,54,0.6666666667,0.6566523605,0.5798816734,0.4201183266,0.4705882353,0.1176470588,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I've just realised we have a higher level of verbosity available to us.,Investigation and Exploration,71,71,0.7777777778,0.660944206,0.5798816734,0.4201183266,0.8235294118,0.2058823529,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Perhaps comparing outputs at verbose=20 will be more informative.,Investigation and Exploration,65,65,0.8888888889,0.6652360515,0.5798816734,0.4201183266,0.5294117647,0.1323529412,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Might aswell limit n_iter to 250, as we know divergence precedes that.",Investigation and Exploration,70,70,1,0.669527897,0.5798816734,0.4201183266,0.7058823529,0.1764705882,0.0002044255366,1.11E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Let's use verbose=100 just to be sure (there are some things reported atverbose=20),Investigation and Exploration,83,83,1,0.6738197425,0.5798854101,0.4201145899,1,0.1911764706,1.11E-05,0.0002506975331,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Ping @tommoral, @ogrisel",Contribution and Commitment,24,24,1,0.678111588,0.579970186,0.420029814,1,0.04411764706,0.0002506975331,0.008870065471,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Unfortunately, that's not the issue here (although it should be fixed):compute_gradient is only ever called with stop=-1.",Potential New Issues and Requests,121,121,1,0.6824034335,0.5829696883,0.4170303117,1,0.25,0.008870065471,0.01255525015,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@priidukull your verbose=20 output would be welcome.,Investigation and Exploration,52,52,0.5,0.686695279,0.5872153731,0.4127846269,1,0.1029411765,0.01255525015,0.008422193983,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I'm otherwise at a loss.,Social Conversation,24,24,1,0.6909871245,0.5872153731,0.4127846269,0.7142857143,0.07352941176,0.01255525015,0.008422193983,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Where can I set verbose=20?,Investigation and Exploration,27,27,1,0.69527897,0.5900634231,0.4099365769,1,0.07352941176,0.008422193983,2.42E-05,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Sorry,Social Conversation,5,5,0.5,0.6995708155,0.5900715971,0.4099284029,1,0.01470588235,2.42E-05,0.0003256305423,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,CODE,Investigation and Exploration,410,4,1,0.7038626609,0.5900715971,0.4099284029,1,0.01470588235,2.42E-05,0.0003256305423,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Ran: CODE,Investigation and Exploration,477,9,0.5,0.7081545064,0.5901817124,0.4098182876,1,0.02941176471,0.0003256305423,0.001873670543,NONE,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Output: https://gist.github.com/priidukull/1453adb7cf2bca2093b2dd9d6646f64e,Investigation and Exploration,75,75,1,0.7124463519,0.5901817124,0.4098182876,1,0.02941176471,0.0003256305423,0.001873670543,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,@priidukull thanks for that.,Social Conversation,28,28,0.25,0.7167381974,0.590815313,0.409184687,0.2,0.05882352941,0.001873670543,0.0005473217492,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"But the verbose output you have sent had substantial discrepancy with what it should, and not just in the numbers.",Investigation and Exploration,114,114,0.5,0.7210300429,0.590815313,0.409184687,1,0.2941176471,0.001873670543,0.0005473217492,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Are you certain that the library is correctly compiled?,Investigation and Exploration,55,55,0.75,0.7253218884,0.590815313,0.409184687,0.45,0.1323529412,0.001873670543,0.0005473217492,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Do you get this error when running the test on the wheel version of scikit-learn 0.19?,Investigation and Exploration,86,86,1,0.7296137339,0.590815313,0.409184687,0.85,0.25,0.001873670543,0.0005473217492,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Or maybe that comment was wrong and I was just confused because your outputisn't complete: the beginning is cut off,Investigation and Exploration,115,115,1,0.7339055794,0.5910003954,0.4089996046,1,0.2941176471,0.0005473217492,0.0005279841985,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Uups, I missed that.",Social Conversation,20,20,0.25,0.7381974249,0.5911789386,0.4088210614,0.2352941176,0.05882352941,0.0005279841985,0.0004692809194,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"The output is more than 1Mb in size, so I did not find a pastebin for that.",Investigation and Exploration,75,75,0.5,0.7424892704,0.5911789386,0.4088210614,1,0.25,0.0005279841985,0.0004692809194,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Can run the test again.,Investigation and Exploration,23,23,0.75,0.7467811159,0.5911789386,0.4088210614,0.2941176471,0.07352941176,0.0005279841985,0.0004692809194,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,How do you suggest that I send the output to you?,Investigation and Exploration,49,49,1,0.7510729614,0.5911789386,0.4088210614,0.6470588235,0.1617647059,0.0005279841985,0.0004692809194,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"you can email my personal address for the, thanks",Investigation and Exploration,49,49,1,0.7553648069,0.5913376307,0.4086623693,1,0.1323529412,0.0004692809194,5.18E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,or zip it,Investigation and Exploration,9,9,1,0.7596566524,0.5913393822,0.4086606178,1,0.04411764706,5.18E-06,0.03477789442,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,[output.txt.zip] URL,Investigation and Exploration,91,21,1,0.7639484979,0.6030998789,0.3969001211,1,0.02941176471,0.03477789442,1.97E-05,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Test code: CODE,Investigation and Exploration,482,15,1,0.7682403433,0.6031065348,0.3968934652,1,0.04411764706,1.97E-05,0.002100196138,NONE,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,@priidukull Thanks for the log.,Social Conversation,31,31,0.2,0.7725321888,0.6038167374,0.3961832626,0.15625,0.07352941176,0.002100196138,0.008826555982,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"I tried to read it but there is only the logs after iteration 200 (""QuadTree"" is way too verbose and I think we lose the beginning as the log growth too big).",Investigation and Exploration,158,158,0.4,0.7768240343,0.6038167374,0.3961832626,1,0.4705882353,0.002100196138,0.008826555982,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Could you please check it out and re-run the same code?,Investigation and Exploration,55,55,0.6,0.7811158798,0.6038167374,0.3961832626,0.375,0.1764705882,0.002100196138,0.008826555982,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,It prints the squared norm of the gradient and the error at each iteration so we can see which part of the code is diverging.,Investigation and Exploration,125,125,0.8,0.7854077253,0.6038167374,0.3961832626,0.78125,0.3676470588,0.002100196138,0.008826555982,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Here is the output for the first 100 iterations (it is still too big for the gist)[output.text] URL,Investigation and Exploration,162,100,1,0.7896995708,0.6038167374,0.3961832626,0.5625,0.2647058824,0.002100196138,0.008826555982,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Test code: CODE,Investigation and Exploration,509,15,0.5,0.7939914163,0.6068015265,0.3931984735,1,0.04411764706,0.008826555982,0.05176800464,NONE,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,[output2.txt.zip] URL,Investigation and Exploration,93,22,1,0.7982832618,0.6068015265,0.3931984735,0.6666666667,0.02941176471,0.008826555982,0.05176800464,NONE,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Thanks again.,Social Conversation,13,13,0.07692307692,0.8025751073,0.6243074007,0.3756925993,0.05555555556,0.02941176471,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Still all we can compare by is error, and not, say, gradients:",Investigation and Exploration,62,62,0.1538461538,0.8068669528,0.6243074007,0.3756925993,0.3333333333,0.1764705882,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,The first 20:CODE,Investigation and Exploration,1476,17,0.2307692308,0.8111587983,0.6243074007,0.3756925993,0.1111111111,0.05882352941,0.05176800464,0.02547446062,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"We see that the first error is a small numerical imprecision at line 5, but that this quite quickly blows out.",Investigation and Exploration,110,110,0.3076923077,0.8154506438,0.6243074007,0.3756925993,0.5833333333,0.3088235294,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"I'm not sure that this is quite sufficient to say that there is nothing fundamentally broken in the implementation (e.g. accessing randomly initialised memory), but that:",Investigation and Exploration,170,170,0.3846153846,0.8197424893,0.6243074007,0.3756925993,0.7222222222,0.3823529412,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"*         it is more susceptible to numerical imprecision than we would like, but perhaps we should (seek contributions that) investigate stability improvements",Investigation and Exploration,160,160,0.4615384615,0.8240343348,0.6243074007,0.3756925993,0.6111111111,0.3235294118,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,*         the test is brittle and already provides only weak assurances in asserting t > 0.9,Investigation and Exploration,92,92,0.5384615385,0.8283261803,0.6243074007,0.3756925993,0.4166666667,0.2205882353,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"*         given this, we can probably get away with lowering the threshold, with a comment referencing this issue",Solution Discussion,113,113,0.6153846154,0.8326180258,0.6243074007,0.3756925993,0.5,0.2647058824,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"However, we may also be able to improve stability by choosing a better random data production approach; this random seed produces data where the following are the smallest differences between any pairwise distances in X: CODE",Solution Discussion,483,225,0.6923076923,0.8369098712,0.6243074007,0.3756925993,1,0.5294117647,0.05176800464,0.02547446062,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,"That's very small differences for float32 data, and a large range in exponent from min to max.",Investigation and Exploration,94,94,0.7692307692,0.8412017167,0.6243074007,0.3756925993,0.4722222222,0.25,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Is there a reason this test needs to use randn?,Investigation and Exploration,47,47,0.8461538462,0.8454935622,0.6243074007,0.3756925993,0.2777777778,0.1470588235,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Can it have a higher variance?,Solution Discussion,30,30,0.9230769231,0.8497854077,0.6243074007,0.3756925993,0.1666666667,0.08823529412,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Multiplying X by 1000 will mean at least the pairwise distances are much more distinguished in a float32, which I *think* may help.",Solution Discussion,131,131,1,0.8540772532,0.6243074007,0.3756925993,0.6388888889,0.3382352941,0.05176800464,0.02547446062,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,So I guess that's a question to @priidukull too.,Solution Discussion,48,48,0.3333333333,0.8583690987,0.6329218471,0.3670781529,1,0.1323529412,0.02547446062,0.02946766485,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Does the following CODE easily pass for you?,Solution Discussion,92,44,0.6666666667,0.8626609442,0.6329218471,0.3670781529,0.8888888889,0.1176470588,0.02547446062,0.02946766485,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,CODE,Solution Discussion,458,4,1,0.8669527897,0.6329218471,0.3670781529,0.1111111111,0.01470588235,0.02547446062,0.02946766485,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,I think @albertcthomas's [fix] URL  in #9340 is the right fix:,Solution Discussion,162,62,0.1666666667,0.8712446352,0.6428866359,0.3571133641,0.3636363636,0.1764705882,0.02946766485,0.0004678996657,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,-         This test generates training data as 32 bit float,Solution Discussion,59,59,0.3333333333,0.8755364807,0.6428866359,0.3571133641,0.303030303,0.1470588235,0.02946766485,0.0004678996657,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,-         The Barnes Hut Cython code works on 32 bit float,Solution Discussion,58,58,0.5,0.8798283262,0.6428866359,0.3571133641,0.3333333333,0.1617647059,0.02946766485,0.0004678996657,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,-         The Python validation of the CODE code would therefore upcast 32-bit float data into 64 bit floats before casting down back to 32 bit float to call into the Cython code.,Solution Discussion,185,179,0.6666666667,0.8841201717,0.6428866359,0.3571133641,1,0.4852941176,0.02946766485,0.0004678996657,MEMBER,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Upcasting from 32 bit to 64 bit is platform specific (the new bits are not necessarily set to zero) and can explain the non deterministic behaviour with observed on some platforms / machines.,Solution Discussion,191,191,0.8333333333,0.8884120172,0.6428866359,0.3571133641,0.9696969697,0.4705882353,0.02946766485,0.0004678996657,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,We need to pass 32 bit to 32 bit cython code without upcasting (which also wastes memory for nothing).,Solution Discussion,102,102,1,0.8927038627,0.6428866359,0.3571133641,0.5757575758,0.2794117647,0.02946766485,0.0004678996657,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Just to be sure we are on the same page, the fix I suggested in #9340 consists in having CODE in a CODE I added in this same PR.",Solution Discussion,163,128,0.5,0.8969957082,0.6430448609,0.3569551391,0.8787878788,0.4264705882,0.0004678996657,0.0002096052377,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,The CODE in master already has a CODE (see [here](https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L659)) (#9340 is older than the tSNE memory usage fix that was merged in July).,Solution Discussion,247,212,1,0.9012875536,0.6430448609,0.3569551391,1,0.4852941176,0.0004678996657,0.0002096052377,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,Ah then there is something I do not understand.,Social Conversation,47,47,0.5,0.9055793991,0.6431157411,0.3568842589,1,0.1323529412,0.0002096052377,0.002426517307,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Will need to investigate further.,Social Conversation,33,33,1,0.9098712446,0.6431157411,0.3568842589,0.5555555556,0.07352941176,0.0002096052377,0.002426517307,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,+1 for trying with larger variance or even a different distribution (e.g. uniform).,Solution Discussion,83,83,1,0.9141630901,0.6439362924,0.3560637076,1,0.1911764706,0.002426517307,0.02351100859,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Actually, multiplying the data by 100 does not make the algorithm more stable with the PCA init, quite the opposite actually.",Investigation and Exploration,125,125,0.2,0.9184549356,0.6518867777,0.3481132223,0.6363636364,0.3088235294,0.02351100859,0.005246346584,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"On the original machine, the exact method + PCA init was triggering the instability according to: https://github.com/scikit-learn/scikit-learn/issues/9393#issuecomment-322214890",Investigation and Exploration,177,177,0.4,0.9227467811,0.6518867777,0.3481132223,0.4848484848,0.2352941176,0.02351100859,0.005246346584,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Changing the random seed can have a large impact on the outcome.,Solution Discussion,64,64,0.6,0.9270386266,0.6518867777,0.3481132223,0.3636363636,0.1764705882,0.02351100859,0.005246346584,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,So maybe the rounding errors can indeed also have a large impact.,Solution Discussion,65,65,0.8,0.9313304721,0.6518867777,0.3481132223,0.3636363636,0.1764705882,0.02351100859,0.005246346584,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"By increasing the number of samples to 100 (instead of 50), the trustworthiness gets much better (and therefore much more stable) but the test is significantly slower (couple of seconds on my machine).",Solution Discussion,201,201,1,0.9356223176,0.6518867777,0.3481132223,1,0.4852941176,0.02351100859,0.005246346584,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Ok after playing extensively with different random seeds and platforms (mkl vs openblas PCA for the init) I think that 0.9 is just too strict.,Investigation and Exploration,142,142,0.125,0.9399141631,0.6536608828,0.3463391172,1,0.3676470588,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,We could keep the 0.9 threshold and stabilize this test by:,Solution Discussion,59,59,0.25,0.9442060086,0.6536608828,0.3463391172,0.44,0.1617647059,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,-         running TSNE on larger datasets (in which case the trustworthiness score gets more stable),Solution Discussion,100,100,0.375,0.9484978541,0.6536608828,0.3463391172,0.6,0.2205882353,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,-         running the tests several times with different random seeds and make an assertion on the median score.,Solution Discussion,112,112,0.5,0.9527896996,0.6536608828,0.3463391172,0.72,0.2647058824,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,However both approaches are too expensive in my opinion.,Solution Discussion,56,56,0.625,0.9570815451,0.6536608828,0.3463391172,0.36,0.1323529412,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,While running my test with several hundred seeds on the original 50 samples random dataset I have never seen this score go below 0.87.,Solution Discussion,134,134,0.75,0.9613733906,0.6536608828,0.3463391172,0.96,0.3529411765,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,So I think setting it to 0.85 should fix the issue.,Solution Discussion,51,51,0.875,0.9656652361,0.6536608828,0.3463391172,0.44,0.1617647059,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,I will submit a PR.,Action on Issue,19,19,1,0.9699570815,0.6536608828,0.3463391172,0.2,0.07352941176,0.005246346584,1,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"FWIW, this issue still happens on 32bit debian stretch with 0.19.1CODE",Observed Bug Behaviour,677,70,1,0.974248927,0.9918209935,0.008179006543,1,0.1617647059,1,0.0008629382027,MEMBER,TRUE,TRUE,FALSE,FALSE
11 9393_scikit-learn.doc,It looks like that PR was not copied across correctly to 0.19.1.,Task Progress,64,64,0.25,0.9785407725,0.9921128047,0.007887195265,0.4285714286,0.1764705882,0.0008629382027,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,My fault.,Social Conversation,9,9,0.5,0.982832618,0.9921128047,0.007887195265,0.07142857143,0.02941176471,0.0008629382027,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"Should be working in master, though, and seeing as the solution was simplyto lower the threshold to 0.85, I don't think we're going to make anotherbug-fix release.",Task Progress,163,163,0.75,0.9871244635,0.9921128047,0.007887195265,1,0.4117647059,0.0008629382027,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,Feel free to patch for Debian.,Contribution and Commitment,30,30,1,0.991416309,0.9921128047,0.007887195265,0.2142857143,0.08823529412,0.0008629382027,1.80E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,You can cherry-pick 6c99d797 if you wish.,Action on Issue,41,41,1,0.9957081545,0.9921188768,0.007881123162,1,0.1176470588,1.80E-05,0.02330589243,MEMBER,FALSE,FALSE,FALSE,FALSE
11 9393_scikit-learn.doc,"there was apparently also a 32bit failure on windows for 0.19.1, but I don't think it was this one.",Potential New Issues and Requests,99,99,1,1,1,0,19,0.2794117647,0.02330589243,0,MEMBER,FALSE,FALSE,FALSE,TRUE
12 8191_tensorflow.doc,ValueError: Attempt to reuse RNNCell with a different variable scope than its first use.,Observed Bug Behaviour,88,88,0.09090909091,0.003717472119,0,1,0.1728395062,0.09523809524,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,I am not sure if I am the first who met the following error:,Observed Bug Behaviour,60,60,0.1818181818,0.007434944238,0,1,0.1728395062,0.09523809524,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,ValueError: Attempt to reuse RNNCell,Observed Bug Behaviour,36,36,0.2727272727,0.01115241636,0,1,0.06172839506,0.03401360544,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,<tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.BasicLSTMCell object at 0x10210d5c0> with a different variable scope than its first use.,Observed Bug Behaviour,142,142,0.3636363636,0.01486988848,0,1,0.1728395062,0.09523809524,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/basic_lstm_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/basic_lstm_cell'.",Observed Bug Behaviour,149,149,0.4545454545,0.01858736059,0,1,0.2469135802,0.1360544218,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,Please create a new instance of the cell if you would like it to use a different set of weights.,Observed Bug Behaviour,96,96,0.5454545455,0.02230483271,0,1,0.2469135802,0.1360544218,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"If before you were using: MultiRNNCell([BasicLSTMCell(...)] * num_layers), change to: MultiRNNCell([BasicLSTMCell(...) for _ in range(num_layers)]).",Observed Bug Behaviour,148,148,0.6363636364,0.02602230483,0,1,0.1604938272,0.08843537415,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Observed Bug Behaviour,172,172,0.7272727273,0.02973977695,0,1,0.3703703704,0.2040816327,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Observed Bug Behaviour,219,219,0.8181818182,0.03345724907,0,1,0.4691358025,0.2585034014,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"with the code fragment: import tensorflow as tffrom tensorflow.contrib import rnn hidden_size = 100batch_size  = 100num_steps   = 100num_layers  = 100is_training = Truekeep_prob   = 0.4 input_data = tf.placeholder(tf.float32, [batch_size, num_steps])lstm_cell = rnn.BasicLSTMCell(hidden_size, forget_bias=0.0, state_is_tuple=True) if is_training and keep_prob < 1:lstm_cell = rnn.DropoutWrapper(lstm_cell)cell = rnn.MultiRNNCell([lstm_cell for _ in range(num_layers)], state_is_tuple=True) _initial_state = cell.zero_state(batch_size, tf.float32) iw = tf.get_variable(""input_w"", [1, hidden_size])ib = tf.get_variable(""input_b"", [hidden_size])inputs = [tf.nn.xw_plus_b(i_, iw, ib) for i_ in tf.split(input_data, num_steps, 1)] if is_training and keep_prob < 1:inputs = [tf.nn.dropout(input_, keep_prob) for input_ in inputs] outputs, states = rnn.static_rnn(cell, inputs, initial_state=_initial_state)",Observed Bug Behaviour,900,900,0.9090909091,0.03717472119,0,1,1,0.5510204082,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,"I had googled around with no luck, can anyone show me a way out?",Contribution and Commitment,64,64,1,0.04089219331,0,1,0.1728395062,0.09523809524,0,0.0005278053632,NONE,TRUE,FALSE,TRUE,FALSE
12 8191_tensorflow.doc,I am getting the same error when trying to run the translate example (even when doing the small self test) which can be found here: https://github.com/tensorflow/models/tree/master/tutorials/rnn/translate,Bug Reproduction,204,204,1,0.04460966543,0.0001284045093,0.9998715955,1,0.1768707483,0.0005278053632,0.002242104842,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I met the same issue.,Bug Reproduction,21,21,0.1111111111,0.04832713755,0.0006738638626,0.9993261361,0.1315789474,0.03401360544,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"If you are all using compiled version on master branch, I believe that we are the same issue caused by the [recent commit] URL .",Investigation and Exploration,213,128,0.2222222222,0.05204460967,0.0006738638626,0.9993261361,0.6315789474,0.1632653061,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,As the commit message says:,Investigation and Exploration,27,27,0.3333333333,0.05576208178,0.0006738638626,0.9993261361,0.1315789474,0.03401360544,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"
REFERENCE",Investigation and Exploration,101,10,0.4444444444,0.0594795539,0.0006738638626,0.9993261361,0.05263157895,0.01360544218,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"
REFERENCE",Investigation and Exploration,232,10,0.5555555556,0.06319702602,0.0006738638626,0.9993261361,0.05263157895,0.01360544218,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"
REFERENCE",Investigation and Exploration,89,10,0.6666666667,0.06691449814,0.0006738638626,0.9993261361,0.05263157895,0.01360544218,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"
REFERENCE",Investigation and Exploration,41,10,0.7777777778,0.07063197026,0.0006738638626,0.9993261361,0.05263157895,0.01360544218,0.002242104842,0.0004410639692,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"From my case, which is running the [ptb tutorial] URL , the solution is just to add a parameter named with CODE like this at line 112:",Solution Discussion,200,134,0.8888888889,0.07434944238,0.0006738638626,0.9993261361,0.6842105263,0.1768707483,0.002242104842,0.0004410639692,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"From my case, which is running the [ptb tutorial] URL , the solution is just to add a parameter named with CODE like this at line 112: def lstm_cell():return tf.contrib.rnn.BasicLSTMCell(size, forget_bias=0.0, state_is_tuple=True, reuse=tf.get_variable_scope().reuse) Then it works.",Solution Discussion,348,282,1,0.0780669145,0.0006738638626,0.9993261361,1,0.2585034014,0.002242104842,0.0004410639692,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo Could you please take a look at this?,Contribution and Commitment,46,46,1,0.08178438662,0.0007811659222,0.9992188341,1,0.0612244898,0.0004410639692,0.002700374697,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The issue replicates for me when using the Windows/GPU build 105 on the [Shakespeare RNN Repo] URL .,Bug Reproduction,156,100,0.5,0.08550185874,0.001438113183,0.9985618868,1,0.1224489796,0.002700374697,0.000477730304,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"When running the code with the Win 1.0.0/GPU Release, there is no issue.",Bug Reproduction,72,72,1,0.08921933086,0.001438113183,0.9985618868,0.7777777778,0.09523809524,0.002700374697,0.000477730304,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"That repo looks like it's targeted at tf 1.0, not intermediate releases.",Investigation and Exploration,72,72,1,0.09293680297,0.00155433543,0.9984456646,1,0.08163265306,0.000477730304,0.0008163895906,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"@tongda , I am using the Release Version of Tensorflow 1.0, working on MacOS in cpu mode.",Bug Reproduction,89,89,0.5,0.09665427509,0.001752946722,0.9982470533,0.8888888889,0.1088435374,0.0008163895906,0.0002569016662,NONE,TRUE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I will switch to the master branch to see if it work by adding the ""reuse"" parameter, thanks.",Solution Discussion,93,93,1,0.1003717472,0.001752946722,0.9982470533,1,0.1224489796,0.0008163895906,0.0002569016662,NONE,TRUE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"doncat99: if you do, please ensure your code queries the tensorflow versionand raises a flag if the version is lower than the master branch version.",Solution Discussion,148,148,0.5,0.1040892193,0.001815445769,0.9981845542,1,0.1700680272,0.0002569016662,0.01544625718,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,you may need to check against: from tensorflow.core import versionsversions.GIT_VERSION,Solution Discussion,87,87,1,0.1078066914,0.001815445769,0.9981845542,0.44,0.07482993197,0.0002569016662,0.01544625718,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo So what would be the suggested changes to the Shakepeare RNN to allow it to work with the intermediate stable release?,Solution Discussion,127,127,0.25,0.1115241636,0.005573211817,0.9944267882,1,0.1496598639,0.01544625718,0.04704112764,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Here is the key architectural section of the code, which now fails with build#105:CODE",Solution Discussion,1455,86,0.5,0.1152416357,0.005573211817,0.9944267882,0.6818181818,0.1020408163,0.01544625718,0.04704112764,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I do not seem to find any documentation regarding a CODE flag?,Solution Discussion,65,62,0.75,0.1189591078,0.005573211817,0.9944267882,0.5454545455,0.08163265306,0.01544625718,0.04704112764,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks in advance.,Social Conversation,18,18,1,0.1226765799,0.005573211817,0.9944267882,0.1363636364,0.02040816327,0.01544625718,0.04704112764,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Use: multicell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(INTERNALSIZE),input_keep_prob=pkeep) for _ in range(NLAYERS)], state_is_tuple=False)  Which creates a separate grucell object for each layer.",Solution Discussion,207,207,1,0.126394052,0.01701737918,0.9829826208,1,0.1496598639,0.04704112764,0.003676957012,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I don't understand why I am getting this error with the [seq2seq tutorial model] URL :CODE,Bug Reproduction,262,90,0.5,0.1301115242,0.01791190943,0.9820880906,1,0.1088435374,0.003676957012,0.0007664331927,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,[Source](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L129) where the cell is created withCODE,Bug Reproduction,200,139,1,0.1338289963,0.01791190943,0.9820880906,0.9375,0.1020408163,0.003676957012,0.0007664331927,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo Thanks for getting back to this issue.,Social Conversation,47,47,0.3333333333,0.1375464684,0.01809836732,0.9819016327,0.4705882353,0.05442176871,0.0007664331927,0.005198313254,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Unfortunately, the suggested change leaves matters as they are, with the aforementioned error.",Solution Discussion,94,94,0.6666666667,0.1412639405,0.01809836732,0.9819016327,0.7647058824,0.08843537415,0.0007664331927,0.005198313254,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Given the above comment regarding the **seq2seq tutorial**, I suspect we are all in the same boat?",Social Conversation,98,98,1,0.1449814126,0.01809836732,0.9819016327,1,0.1156462585,0.0007664331927,0.005198313254,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Are you sure it's the exact same error?,Solution Discussion,39,39,0.5,0.1486988848,0.01936301317,0.9806369868,1,0.05442176871,0.005198313254,0.00388105441,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Please copy and paste it here.,Solution Discussion,30,30,1,0.1524163569,0.01936301317,0.9806369868,0.75,0.04081632653,0.005198313254,0.00388105441,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"My bad, I just went through the change process to the relevant code again (from scratch) and re-ran it as proposed.",Solution Discussion,115,115,0.3333333333,0.156133829,0.02030719624,0.9796928038,1,0.1496598639,0.00388105441,0.005971272817,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The error has indeed been removed and the Old Bard is hallucinating just fine now ð,Solution Discussion,83,83,0.6666666667,0.1598513011,0.02030719624,0.9796928038,0.7272727273,0.1088435374,0.00388105441,0.005971272817,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"So, thx, not sure where I went wrong yesterday, but it was clearly on me.",Social Conversation,73,73,1,0.1635687732,0.02030719624,0.9796928038,0.6818181818,0.1020408163,0.00388105441,0.005971272817,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I met the same problem when using the Release Version of Tensorflow 1.0 and working on MacOS in cpu mode.,Bug Reproduction,105,105,0.5,0.1672862454,0.02175988772,0.9782401123,1,0.1360544218,0.005971272817,0.0008504453773,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Even if add the ""reuse"" parameterCODE",Solution Discussion,246,37,1,0.1710037175,0.02175988772,0.9782401123,0.3,0.04081632653,0.005971272817,0.0008504453773,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,your multicell looks wrong...,Solution Discussion,29,29,0.5,0.1747211896,0.02196678411,0.9780332159,0.5714285714,0.02721088435,0.0008504453773,0.0977297843,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"you should be using ""cell() for _ inrange(...)""",Solution Discussion,47,47,1,0.1784386617,0.02196678411,0.9780332159,1,0.04761904762,0.0008504453773,0.0977297843,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I was trying to run the translate example: python2.7 translate.py --data_dir data/ --train_dir train/ --size=256 --num_layers=2 --steps_per_checkpoint=50,Bug Reproduction,153,153,0.1,0.1821561338,0.04574248984,0.9542575102,0.4473684211,0.1156462585,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It seems the way to use MultiRNNCell is correct:,Bug Reproduction,48,48,0.2,0.1858736059,0.04574248984,0.9542575102,0.2368421053,0.0612244898,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,cell = tf.contrib.rnn.MultiRNNCell([single_cell() for _ in range(num_layers)]),Bug Reproduction,78,78,0.3,0.1895910781,0.04574248984,0.9542575102,0.1578947368,0.04081632653,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,But I got the same error:,Bug Reproduction,25,25,0.4,0.1933085502,0.04574248984,0.9542575102,0.1578947368,0.04081632653,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7fba0683de90> with a different variable scope than its first use.,Bug Reproduction,176,176,0.5,0.1970260223,0.04574248984,0.9542575102,0.5,0.1292517007,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.",Bug Reproduction,233,233,0.6,0.2007434944,0.04574248984,0.9542575102,0.6052631579,0.156462585,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Please create a new instance of the cell if you would like it to use a different set of weights.,Bug Reproduction,96,96,0.7,0.2044609665,0.04574248984,0.9542575102,0.5263157895,0.1360544218,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).",Bug Reproduction,136,136,0.8,0.2081784387,0.04574248984,0.9542575102,0.3421052632,0.08843537415,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).",Bug Reproduction,172,172,0.9,0.2118959108,0.04574248984,0.9542575102,0.7894736842,0.2040816327,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction,219,219,1,0.2156133829,0.04574248984,0.9542575102,1,0.2585034014,0.0977297843,0.03037586316,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@bowu - did you have any luck with this?,Task Progress,40,40,0.25,0.219330855,0.05313233101,0.946867669,0.5714285714,0.05442176871,0.03037586316,0.004152670075,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"if you haven't tried it yet, reinstall tensorflow from the latest source.",Solution Discussion,73,73,0.5,0.2230483271,0.05313233101,0.946867669,0.8571428571,0.08163265306,0.03037586316,0.004152670075,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"there were some changes to some of the core_rnn files, among a few others.",Solution Discussion,74,74,0.75,0.2267657993,0.05313233101,0.946867669,1,0.09523809524,0.03037586316,0.004152670075,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,works for me now.,Solution Discussion,17,17,1,0.2304832714,0.05313233101,0.946867669,0.2857142857,0.02721088435,0.03037586316,0.004152670075,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"@robmsylvester I reinstall tensorflow from the latest source, still the same error.",Solution Discussion,83,83,0.3333333333,0.2342007435,0.05414259275,0.9458574073,1,0.08163265306,0.004152670075,0.04899488558,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I was on branch master and the latest commit is CODE.,Solution Discussion,98,53,0.6666666667,0.2379182156,0.05414259275,0.9458574073,0.9166666667,0.07482993197,0.004152670075,0.04899488558,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,What's the latest commit when you build your repo?,Solution Discussion,50,50,1,0.2416356877,0.05414259275,0.9458574073,0.75,0.0612244898,0.004152670075,0.04899488558,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Hi, I am using Tensorflow r1.0 using GPU built using source.",Bug Reproduction,60,60,0.1428571429,0.2453531599,0.06606207042,0.9339379296,0.2444444444,0.07482993197,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I am trying to follow the unmodified Seq2Seq translation tutorial, but I'm getting the same error.",Bug Reproduction,98,98,0.2857142857,0.249070632,0.06606207042,0.9339379296,0.3555555556,0.1088435374,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"i.e. > ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x7f0fb51ebb00> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/embedding_attention_decoder/attention_decoder/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell'.....",Bug Reproduction,422,422,0.4285714286,0.2527881041,0.06606207042,0.9339379296,1,0.306122449,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The relevant portion of the code in my seq2seq_model.py is:CODE,Bug Reproduction,356,63,0.5714285714,0.2565055762,0.06606207042,0.9339379296,0.2444444444,0.07482993197,0.04899488558,0.0006557222206,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,What can I do to solve the problem?,Solution Discussion,35,35,0.7142857143,0.2602230483,0.06606207042,0.9339379296,0.1777777778,0.05442176871,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"adding ""reuse=tf.get_variable_scope().reuse"" to the call where the GRUCell is created doesn't help.",Solution Discussion,99,99,0.8571428571,0.2639405204,0.06606207042,0.9339379296,0.2888888889,0.08843537415,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks a ton!,Social Conversation,13,13,1,0.2676579926,0.06606207042,0.9339379296,0.06666666667,0.02040816327,0.04899488558,0.0006557222206,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"@prashantserai - see what happens if you remove the MultiRNNCell line from above, effectively making your network just one layer.",Investigation and Exploration,129,129,0.2,0.2713754647,0.06622159454,0.9337784055,0.4871794872,0.1292517007,0.0006557222206,0.0061573337,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Does it work then?,Investigation and Exploration,18,18,0.4,0.2750929368,0.06622159454,0.9337784055,0.1025641026,0.02721088435,0.0006557222206,0.0061573337,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It might be a bug somewhere in MultiRNNCell.,Investigation and Exploration,44,44,0.6,0.2788104089,0.06622159454,0.9337784055,0.2051282051,0.05442176871,0.0006557222206,0.0061573337,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I've read about that somewhere recently, probably on stack overflow.",Social Conversation,68,68,0.8,0.282527881,0.06622159454,0.9337784055,0.2820512821,0.07482993197,0.0006557222206,0.0061573337,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"If you implement the stacked lstm/gru yourself, you don't get this error, and you can implement the same functionality (actually more, because you're free to do whatever you want with bidirectional architectures, weird residual and skip connections, etc.)",Solution Discussion,255,255,1,0.2862453532,0.06622159454,0.9337784055,1,0.2653061224,0.0006557222206,0.0061573337,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@robmsylvester The same error persisted even when I tried with num_layers=1 which should effectively skip that line.,Investigation and Exploration,116,116,0.3333333333,0.2899628253,0.06771955093,0.9322804491,1,0.1156462585,0.0061573337,0.001820264,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Any other ideas?,Contribution and Commitment,16,16,0.6666666667,0.2936802974,0.06771955093,0.9322804491,0.1764705882,0.02040816327,0.0061573337,0.001820264,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks for the input.,Social Conversation,21,21,1,0.2973977695,0.06771955093,0.9322804491,0.2352941176,0.02721088435,0.0061573337,0.001820264,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Hmmm.,Social Conversation,5,5,0.25,0.3011152416,0.06816238482,0.9318376152,0.04,0.006802721088,0.001820264,0.0002230832021,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,One thing that stands out to me is in the referenced legacy seq2seq file: CODE,Investigation and Exploration,110,78,0.5,0.3048327138,0.06816238482,0.9318376152,0.6,0.1020408163,0.001820264,0.0002230832021,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,This line appears to be used because the same architecture is used on both the encoder and decoder side.,Investigation and Exploration,104,104,0.75,0.3085501859,0.06816238482,0.9318376152,0.76,0.1292517007,0.001820264,0.0002230832021,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"They make a copy of the cell, then pass the cell argument along to the attention decoder embedding function, then to the attention decoder itself.",Investigation and Exploration,146,146,1,0.312267658,0.06816238482,0.9318376152,1,0.1700680272,0.001820264,0.0002230832021,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@robmsylvester  shouldn't making changes in the scopes of the cells work?,Investigation and Exploration,73,73,0.25,0.3159851301,0.06821665651,0.9317833435,1,0.08163265306,0.0002230832021,5.71E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It's working for the other two examples as well.,Investigation and Exploration,48,48,0.5,0.3197026022,0.06821665651,0.9317833435,0.75,0.0612244898,0.0002230832021,5.71E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"In my opinion, this would be a very ugly workaround;",Workarounds,52,52,0.75,0.3234200743,0.06821665651,0.9317833435,0.8333333333,0.06802721088,0.0002230832021,5.71E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,a cleaner solution must exist; maybe we are missing something?,Workarounds,62,62,1,0.3271375465,0.06821665651,0.9317833435,0.8333333333,0.06802721088,0.0002230832021,5.71E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I'll play with it in a few hours and see if I can track something down.,Social Conversation,71,71,1,0.3308550186,0.06823054198,0.931769458,1,0.1088435374,5.71E-05,0.01223409639,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"In fact, the copy.deepcopy is there because these are legacy functions andwe don't have the resources to maintain/update them.",Investigation and Exploration,126,126,0.5,0.3345724907,0.07120685343,0.9287931466,1,0.1360544218,0.01223409639,0.0001133215202,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Keep in mind it wouldhave to be a backwards compatible change.,Potential New Issues and Requests,62,62,1,0.3382899628,0.07120685343,0.9287931466,0.55,0.07482993197,0.01223409639,0.0001133215202,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo - I'll think about it.,Social Conversation,31,31,0.25,0.3420074349,0.07123442229,0.9287655777,0.1162790698,0.03401360544,0.0001133215202,0.0004233834388,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I do have a translator that works pretty similar to this one but creates cells through a separate class that allows for inserting bidirectional layers where you want, residuals where you want, merging inputs with concat vs. sum, and a few other things.",Potential New Issues and Requests,252,252,0.5,0.3457249071,0.07123442229,0.9287655777,1,0.2925170068,0.0001133215202,0.0004233834388,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I think I could migrate my class over to this tutorial pretty easily by using static RNN's.,Potential New Issues and Requests,91,91,0.75,0.3494423792,0.07123442229,0.9287655777,0.3953488372,0.1156462585,0.0001133215202,0.0004233834388,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I'll let you know.,Social Conversation,18,18,1,0.3531598513,0.07123442229,0.9287655777,0.09302325581,0.02721088435,0.0001133215202,0.0004233834388,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo i am running Tensorflow r1.0 (tensorflow-1.0.1-cp36-cp36m-linux_x86_64) on Red Hat and have the latest version of the translation tutorial from Github..,Bug Reproduction,161,161,0.5,0.3568773234,0.07133742303,0.928662577,1,0.1700680272,0.0004233834388,0.001538799449,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,is there a way you know to make this work currently?,Task Progress,52,52,1,0.3605947955,0.07133742303,0.928662577,0.44,0.07482993197,0.0004233834388,0.001538799449,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It's unfortunate that the translation tutorial does not work with TF 1.0.,Task Progress,73,73,0.25,0.3643122677,0.07171178222,0.9282882178,0.4285714286,0.08163265306,0.001538799449,8.78E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We should fix that.,Task Progress,19,19,0.5,0.3680297398,0.07171178222,0.9282882178,0.1428571429,0.02721088435,0.001538799449,8.78E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@lukaszkaiser can you take a look?,Contribution and Commitment,34,34,0.75,0.3717472119,0.07171178222,0.9282882178,0.2142857143,0.04081632653,0.001538799449,8.78E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We're working on a new tutorial but it's still a few weeks off and will require a nightly version of TensorFlow (or TF 1.1 or 1.2) to work.,Task Progress,139,139,1,0.375464684,0.07171178222,0.9282882178,1,0.1904761905,0.001538799449,8.78E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,lukasz; it's hard for me to identify from the various comments which part of the tutorial is faulty in TF 1.0.,Social Conversation,110,110,1,0.3791821561,0.07171391845,0.9282860816,1,0.1428571429,8.78E-06,0.000334150158,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo  It's [this ] URL  tutorial.,Investigation and Exploration,106,37,0.3333333333,0.3828996283,0.07179521051,0.9282047895,0.2258064516,0.04761904762,0.000334150158,3.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The error is in [this](https://github.com/tensorflow/models/blob/master/tutorials/rnn/translate/seq2seq_model.py#L122) cluster of lines.,Investigation and Exploration,136,136,0.6666666667,0.3866171004,0.07179521051,0.9282047895,0.5161290323,0.1088435374,0.000334150158,3.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"The cells passed here are used for both the backward and forward phase of the legacy seq2seq model, which throws an error because of same cells being used with different scopes.",Investigation and Exploration,177,177,1,0.3903345725,0.07179521051,0.9282047895,1,0.2108843537,0.000334150158,3.55E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@iamgroot42 do you want to make a PR with the needed changes?,Contribution and Commitment,61,61,0.3333333333,0.3940520446,0.07180384202,0.928196158,0.8571428571,0.08163265306,3.55E-05,0.003490777468,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"That would be great, I currently don't have the cycles to do that myself.",Social Conversation,73,73,0.6666666667,0.3977695167,0.07180384202,0.928196158,1,0.09523809524,3.55E-05,0.003490777468,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks!,Social Conversation,7,7,1,0.4014869888,0.07180384202,0.928196158,0.07142857143,0.006802721088,3.55E-05,0.003490777468,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I noticed that the TF 1.0  works fine with the newest version of translation tutorial if compiled from the source on branch remotes/origin/r1.0CODEthen build and install TensorFlow, it works fine.",Bug Reproduction,299,196,0.5,0.405204461,0.0726530785,0.9273469215,1,0.2244897959,0.003490777468,0.03893715568,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"On branch remotes/origin/r1.1 it has the ""different variable scope"" error.",Bug Reproduction,74,74,1,0.4089219331,0.0726530785,0.9273469215,0.3636363636,0.08163265306,0.003490777468,0.03893715568,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"@prashantserai Don't exactly know, but what you met seems to be another issue.",Potential New Issues and Requests,78,78,1,0.4126394052,0.08212571125,0.9178742888,1,0.08843537415,0.03893715568,0.003060393013,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@bowu Same error here.,Bug Reproduction,22,22,0.5,0.4163568773,0.08287024378,0.9171297562,0.4,0.02721088435,0.003060393013,5.45E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Mac OX Sierra, TensorFlow 1.1.0-rc1, Python 2.7.10 & Python 3.6.1.",Bug Reproduction,66,66,1,0.4200743494,0.08287024378,0.9171297562,1,0.06802721088,0.003060393013,5.45E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,here's a full traceback..,Workarounds,25,25,1,0.4237918216,0.08288349415,0.9171165058,1,0.03401360544,5.45E-05,0.005311634774,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thank you so much everyone...!!!!!,Social Conversation,34,34,0.1666666667,0.4275092937,0.08417570887,0.9158242911,0.1612903226,0.03401360544,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,_Here's my thoughts at the end of this:_,Solution Discussion,40,40,0.3333333333,0.4312267658,0.08417570887,0.9158242911,0.2580645161,0.05442176871,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@oxwsds comment **that the tutorial (in it's current form) works without any need for modification when Tensorflow is compiled from the branch remotes/origin/r1.0 was TRUE**.,Solution Discussion,174,174,0.5,0.4349442379,0.08417570887,0.9158242911,0.8709677419,0.1836734694,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Although, the sad bit was that the version of Tensorflow I had for which modifications within Tensorflow code were needed, and the version in remotes/origin/r1.0 were both identically labelled.",Solution Discussion,193,193,0.6666666667,0.43866171,0.08417570887,0.9158242911,1,0.2108843537,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"It is slightly messy to implement, but I could do it, which is saying something :-P",Social Conversation,83,83,0.8333333333,0.4423791822,0.08417570887,0.9158242911,0.5161290323,0.1088435374,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The error in my last two comments before this was due to my mistake.,Social Conversation,68,68,1,0.4460966543,0.08417570887,0.9158242911,0.4516129032,0.09523809524,0.005311634774,0.006280741429,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks for the feedback!,Social Conversation,24,24,0.3333333333,0.4498141264,0.08570368789,0.9142963121,0.3333333333,0.02721088435,0.006280741429,0.01683649271,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Seems there's something different between the TFon pypi and at that tag?,Investigation and Exploration,72,72,0.6666666667,0.4535315985,0.08570368789,0.9142963121,1,0.08163265306,0.006280741429,0.01683649271,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Gunhan, is that possible?",Contribution and Commitment,25,25,1,0.4572490706,0.08570368789,0.9142963121,0.3333333333,0.02721088435,0.006280741429,0.01683649271,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,For information I had this issue while trying to stack LSTM cells:,Bug Reproduction,66,66,0.125,0.4609665428,0.08979967049,0.9102003295,0.4615384615,0.08163265306,0.01683649271,0.03567836101,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,My orginial code was:CODE,Bug Reproduction,312,25,0.25,0.4646840149,0.08979967049,0.9102003295,0.1923076923,0.03401360544,0.01683649271,0.03567836101,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"Then, with the following code, creating the model was ok, but I couldn't share the variable with another model.",Solution Discussion,111,111,0.375,0.468401487,0.08979967049,0.9102003295,0.7307692308,0.1292517007,0.01683649271,0.03567836101,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"(for instance if you create a train_model and a valid_model supposed to share tensors, it will fail)",Solution Discussion,100,100,0.5,0.4721189591,0.08979967049,0.9102003295,0.6538461538,0.1156462585,0.01683649271,0.03567836101,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,CODE,Solution Discussion,369,4,0.625,0.4758364312,0.08979967049,0.9102003295,0.03846153846,0.006802721088,0.01683649271,0.03567836101,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,So finally I used CODE to be the function like CODE in [tensorflow/models/tutorials/rnn/ptb/ptb_word_lm.py#L112](https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py#L112).,Solution Discussion,218,201,0.75,0.4795539033,0.08979967049,0.9102003295,1,0.1768707483,0.01683649271,0.03567836101,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I now have:CODE,Solution Discussion,849,15,0.875,0.4832713755,0.08979967049,0.9102003295,0.1538461538,0.02721088435,0.01683649271,0.03567836101,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,It is now fully working,Solution Discussion,23,23,1,0.4869888476,0.08979967049,0.9102003295,0.1923076923,0.03401360544,0.01683649271,0.03567836101,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"trying to get this thing running, which results in the same error: https://gist.github.com/danijar/c7ec9a30052127c7a1ad169eeb83f159#file-blog_tensorflow_sequence_classification-py-L38",Bug Reproduction,183,183,0.3333333333,0.4907063197,0.09847950355,0.9015204965,1,0.08843537415,0.03567836101,0.01542216894,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@pltrdy 's solution didn't do it for me oddly.,Solution Discussion,46,46,0.6666666667,0.4944237918,0.09847950355,0.9015204965,0.6153846154,0.05442176871,0.03567836101,0.01542216894,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I'm getting CODE,Solution Discussion,191,16,1,0.4981412639,0.09847950355,0.9015204965,0.2307692308,0.02040816327,0.03567836101,0.01542216894,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,@aep did you use the function of https://github.com/tensorflow/models/blob/master/tutorials/rnn/ptb/ptb_word_lm.py#L112 I mention at the end of my post (now edited to be more clear),Solution Discussion,181,181,1,0.5018587361,0.1022314094,0.8977685906,1,0.1496598639,0.01542216894,0.09927558477,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,cells=[]for _ in range(15):cell = create_lstm_cell(config)cells.append(cell)lsmt_layers = rnn.MultiRNNCell(cells),Solution Discussion,113,113,0.5,0.5055762082,0.1263831775,0.8736168225,1,0.04081632653,0.09927558477,0.002197250879,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,it solved my problem,Solution Discussion,20,20,1,0.5092936803,0.1263831775,0.8736168225,0.6666666667,0.02721088435,0.09927558477,0.002197250879,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Managed to fix this issue by installing older version of Tensorflow:CODE,Solution Discussion,101,72,0.5,0.5130111524,0.1269177248,0.8730822752,1,0.08163265306,0.002197250879,0.03407322991,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I was receiving the error when executing the seq2seq tutorial,Bug Reproduction,61,61,1,0.5167286245,0.1269177248,0.8730822752,0.8333333333,0.06802721088,0.002197250879,0.03407322991,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"In regards to what @ebrevdo said, I think the solution is not to fix the legacy seq2seq code, but to update the tutorial to use the CODE package instead, which is actively maintained.",Solution Discussion,196,183,0.3333333333,0.5204460967,0.1352070615,0.8647929385,1,0.2244897959,0.03407322991,0.00125745356,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,It is quite demoralizing when the first tensorflow program you ever run spits out a bunch of errors.,Social Conversation,100,100,0.6666666667,0.5241635688,0.1352070615,0.8647929385,0.5454545455,0.1224489796,0.03407322991,0.00125745356,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"If I have some time this week, I'll submit a PR.",Contribution and Commitment,48,48,1,0.5278810409,0.1352070615,0.8647929385,0.3333333333,0.07482993197,0.03407322991,0.00125745356,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We're working on a new seq2seq tutorial.,Task Progress,40,40,0.3333333333,0.531598513,0.1355129749,0.8644870251,0.5384615385,0.04761904762,0.00125745356,0.03511934773,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We had hoped to release by end oflast month but are getting delayed.,Task Progress,68,68,0.6666666667,0.5353159851,0.1355129749,0.8644870251,1,0.08843537415,0.00125745356,0.03511934773,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It will use the new API.,Solution Discussion,24,24,1,0.5390334572,0.1355129749,0.8644870251,0.4615384615,0.04081632653,0.00125745356,0.03511934773,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo I meet the same error when running the sequence_to_sequence model on the tensorflow1.1 website.,Bug Reproduction,104,104,0.3333333333,0.5427509294,0.1440568111,0.8559431889,1,0.1020408163,0.03511934773,0.004494533216,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,And I have try to use 'reuse' parameter but failed.,Solution Discussion,51,51,0.6666666667,0.5464684015,0.1440568111,0.8559431889,0.6666666667,0.06802721088,0.03511934773,0.004494533216,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Could you tell me when the new seq2seq tutorial will be released?,Task Progress,65,65,1,0.5501858736,0.1440568111,0.8559431889,0.8,0.08163265306,0.03511934773,0.004494533216,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Looks like at the same time as tf 1.2, since we will rely on some newfeatures of that release.",Task Progress,94,94,1,0.5539033457,0.1451502414,0.8548497586,1,0.1292517007,0.004494533216,0.02814194594,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo I am as well facing the same issue and unable to progress with seq2seq.,Bug Reproduction,80,80,0.3333333333,0.5576208178,0.1519966151,0.8480033849,0.7142857143,0.1020408163,0.02814194594,0.00832954705,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It will be really helpful if you could let us/me know what is a probable date for a new tutorial.,Task Progress,97,97,0.6666666667,0.56133829,0.1519966151,0.8480033849,1,0.1428571429,0.02814194594,0.00832954705,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks a lot for your help.,Social Conversation,27,27,1,0.5650557621,0.1519966151,0.8480033849,0.2857142857,0.04081632653,0.02814194594,0.00832954705,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Installing using CODE (Tensorflow 1.0) is working for me (translate tutorial).,Solution Discussion,103,78,1,0.5687732342,0.1540230276,0.8459769724,1,0.07482993197,0.00832954705,0.001071629999,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I have version 1.1.0-rc2.,Bug Reproduction,25,25,1,0.5724907063,0.1542837338,0.8457162662,1,0.03401360544,0.001071629999,0.06612589558,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,TF1.2 will solve this problem?,Task Progress,30,30,0.3333333333,0.5762081784,0.1703708442,0.8296291558,0.4545454545,0.03401360544,0.06612589558,0.0413883417,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Please help me how to continue training the model.,Usage,50,50,0.6666666667,0.5799256506,0.1703708442,0.8296291558,0.8181818182,0.0612244898,0.06612589558,0.0413883417,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,TF 1.0 works but doesn't have devicewrapper api for multiple GPUs.,Usage,66,66,1,0.5836431227,0.1703708442,0.8296291558,1,0.07482993197,0.06612589558,0.0413883417,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Having the same problem with tensor flow 1.1.,Bug Reproduction,45,45,0.5,0.5873605948,0.1804398016,0.8195601984,1,0.05442176871,0.0413883417,0.002511347281,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Still working on a solution,Social Conversation,27,27,1,0.5910780669,0.1804398016,0.8195601984,0.625,0.03401360544,0.0413883417,0.002511347281,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"I tried several things, at the end I was able to use tensorflow 1.1 but had to make these changes: (based on Tshzzz above) Remove this:CODE And add this:cells=[]for _ in range(NLAYERS):cell = rnn.DropoutWrapper(tf.contrib.rnn.GRUCell(INTERNALSIZE), input_keep_prob=pkeep)cells.append(cell)multicell = rnn.MultiRNNCell(cells, state_is_tuple=False)",Solution Discussion,414,346,1,0.594795539,0.1810507623,0.8189492377,1,0.2857142857,0.002511347281,0.0007677384667,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"@ebrevdo Congratulations, TF 1.2 just got released - was the new tutorial also released somewhere or is it being released anytime soon?",Task Progress,135,135,0.5,0.5985130112,0.1812375377,0.8187624623,1,0.1428571429,0.0007677384667,0.005664414752,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks,Social Conversation,6,6,1,0.6022304833,0.1812375377,0.8187624623,0.04761904762,0.006802721088,0.0007677384667,0.005664414752,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We'll plan to have an announcement when it's released.,Task Progress,54,54,0.5,0.6059479554,0.1826155768,0.8173844232,1,0.0612244898,0.005664414752,0.04210161464,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Working on it.,Task Progress,14,14,1,0.6096654275,0.1826155768,0.8173844232,0.3333333333,0.02040816327,0.005664414752,0.04210161464,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"For anyone using tensorflow-gpu==1.1.0  and getting this error, switching to 1.0.0 via pip install tensorflow-gpu==1.0.0 is not going to fix the problem, at least didn't work for me.",Solution Discussion,182,182,0.3333333333,0.6133828996,0.1928580592,0.8071419408,1,0.2108843537,0.04210161464,0.004226002744,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I ran into this issue on both mac and ubuntu and compiling from source worked both times.,Solution Discussion,89,89,0.6666666667,0.6171003717,0.1928580592,0.8071419408,0.5483870968,0.1156462585,0.04210161464,0.004226002744,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,So:pip install https://storage.googleapis.com/tensorflow/linux/gpu/tensorflow_gpu-1.0.0-cp34-cp34m-linux_x86_64.whl,Solution Discussion,115,115,1,0.6208178439,0.1928580592,0.8071419408,0.1290322581,0.02721088435,0.04210161464,0.004226002744,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ajaanbaahu Still waiting for tf1.2 new seq2seq tutorial.,Social Conversation,57,57,1,0.624535316,0.1938861613,0.8061138387,1,0.05442176871,0.004226002744,0.01155879506,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It worked for me using CODE.,Solution Discussion,53,28,1,0.6282527881,0.1966981854,0.8033018146,1,0.04081632653,0.01155879506,0.02950560135,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"As the rookie, I raise some of my opinion.",Social Conversation,42,42,0.2,0.6319702602,0.2038763093,0.7961236907,0.75,0.0612244898,0.02950560135,0.04042101496,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The following code will make this similar mistake occure:(Piece of my code)CODE,Bug Reproduction,333,79,0.4,0.6356877323,0.2038763093,0.7961236907,1,0.08163265306,0.02950560135,0.04042101496,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,The error dump as the following:CODE,Bug Reproduction,3013,36,0.6,0.6394052045,0.2038763093,0.7961236907,0.5833333333,0.04761904762,0.02950560135,0.04042101496,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"But after I do the revision, It can work.",Solution Discussion,41,41,0.8,0.6431226766,0.2038763093,0.7961236907,0.75,0.0612244898,0.02950560135,0.04042101496,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,CODE,Solution Discussion,490,4,1,0.6468401487,0.2038763093,0.7961236907,0.08333333333,0.006802721088,0.02950560135,0.04042101496,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,None of those workarounds worked for me with Tensorflow 1.1,Workarounds,59,59,0.3333333333,0.6505576208,0.2137099354,0.7862900646,1,0.06802721088,0.04042101496,0.04734857901,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I'm using CODE model with CODE cells.,Bug Reproduction,52,37,0.6666666667,0.6542750929,0.2137099354,0.7862900646,0.7,0.04761904762,0.04042101496,0.04734857901,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I had to reverse back to 1.0.1: `pip3 install tensorflow==1.0,Solution Discussion,61,61,1,0.6579925651,0.2137099354,0.7862900646,1,0.06802721088,0.04042101496,0.04734857901,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Anyone have these issues when working with legacy_seq2seq.rnn_decoder()?,Bug Reproduction,72,72,1,0.6617100372,0.2252288995,0.7747711005,1,0.05442176871,0.04734857901,0.005343317335,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"@oxwsds As you said, I change input args cell of tf.contrib.legacy_seq2seq.embedding_attention_seq2seq to two different cell {encoder_cells, decoder_cells}.",Solution Discussion,156,156,0.1666666667,0.6654275093,0.226528822,0.773471178,0.8095238095,0.1156462585,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Finally, I get seq2seq model worked.",Solution Discussion,36,36,0.3333333333,0.6691449814,0.226528822,0.773471178,0.2857142857,0.04081632653,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"After 73200 setps, I get perplexity 5.54.",Solution Discussion,41,41,0.5,0.6728624535,0.226528822,0.773471178,0.3333333333,0.04761904762,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Then I run decode part,>> Who is the president of the United States?Qui est le prÃ©sident des Ãtats-Unis ?",Solution Discussion,106,106,0.6666666667,0.6765799257,0.226528822,0.773471178,1,0.1428571429,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Problem solved.,Solution Discussion,15,15,0.8333333333,0.6802973978,0.226528822,0.773471178,0.09523809524,0.01360544218,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks.,Social Conversation,7,7,1,0.6840148699,0.226528822,0.773471178,0.04761904762,0.006802721088,0.005343317335,0.08527687651,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,So I change the related part in CODE to CODE,Solution Discussion,628,44,1,0.687732342,0.2472749838,0.7527250162,1,0.06802721088,0.08527687651,0.03955727952,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"@supermeatboy82 , Could you share your code?",Solution Discussion,44,44,1,0.6914498141,0.2568984803,0.7431015197,1,0.04081632653,0.03955727952,0.02156039818,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Upgrading to Tensorflow 1.2.0 and generating the cells in a loop instead of list multiplication fixed this for me.,Solution Discussion,114,114,1,0.6951672862,0.2621436948,0.7378563052,1,0.1292517007,0.02156039818,0.01915311683,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I would like to update everyone that I downgraded the tensorflow to 1.0.0 (tensorflow-GPU) and it is working for me.,Solution Discussion,116,116,0.2,0.6988847584,0.2668032658,0.7331967342,1,0.1428571429,0.01915311683,0.02402499291,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The models are performing as expected.,Solution Discussion,38,38,0.4,0.7026022305,0.2668032658,0.7331967342,0.2857142857,0.04081632653,0.01915311683,0.02402499291,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I assume that the CPU version of 1.0.0 should function as expected?,Solution Discussion,67,67,0.6,0.7063197026,0.2668032658,0.7331967342,0.5714285714,0.08163265306,0.01915311683,0.02402499291,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Or?.,Social Conversation,4,4,0.8,0.7100371747,0.2668032658,0.7331967342,0.04761904762,0.006802721088,0.01915311683,0.02402499291,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thanks :),Social Conversation,9,9,1,0.7137546468,0.2668032658,0.7331967342,0.09523809524,0.01360544218,0.01915311683,0.02402499291,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Hi guys, I don't know if you're still interested on it, but I found that the problem is related to the operation of copying the cell passed as params to the CODE function.",Investigation and Exploration,196,171,0.125,0.717472119,0.272648067,0.727351933,1,0.2244897959,0.02402499291,0.006610382458,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,This is because the same cell definition is used both for encoder and decoder.,Investigation and Exploration,78,78,0.25,0.7211895911,0.272648067,0.727351933,0.4242424242,0.09523809524,0.02402499291,0.006610382458,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I think the tutorial is deprecated since it uses a seq2seq model with bucketing in contrast to a dynamic seq2seq.,Investigation and Exploration,113,113,0.375,0.7249070632,0.272648067,0.727351933,0.6060606061,0.1360544218,0.02402499291,0.006610382458,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"But, I'm pasting a modified function that works.",Solution Discussion,48,48,0.5,0.7286245353,0.272648067,0.727351933,0.2424242424,0.05442176871,0.02402499291,0.006610382458,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The function is updated in the file CODE.,Solution Discussion,94,41,0.625,0.7323420074,0.272648067,0.727351933,0.2424242424,0.05442176871,0.02402499291,0.006610382458,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"thanks,",Social Conversation,7,7,0.75,0.7360594796,0.272648067,0.727351933,0.0303030303,0.006802721088,0.02402499291,0.006610382458,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Fabio,Social Conversation,5,5,0.875,0.7397769517,0.272648067,0.727351933,0.0303030303,0.006802721088,0.02402499291,0.006610382458,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,CODE,Solution Discussion,4772,4,1,0.7434944238,0.272648067,0.727351933,0.0303030303,0.006802721088,0.02402499291,0.006610382458,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,@fabiofumarola Thank you for the function.,Social Conversation,42,42,0.125,0.7472118959,0.2742562411,0.7257437589,0.3529411765,0.04081632653,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Looks really helpful.,Social Conversation,21,21,0.25,0.750929368,0.2742562411,0.7257437589,0.1764705882,0.02040816327,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I also saw that the tutorial is deprecated.,Investigation and Exploration,43,43,0.375,0.7546468401,0.2742562411,0.7257437589,0.4705882353,0.05442176871,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I am still waiting for an official tutorial release.,Social Conversation,52,52,0.5,0.7583643123,0.2742562411,0.7257437589,0.5294117647,0.0612244898,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Looks like you have used the new api.,Solution Discussion,37,37,0.625,0.7620817844,0.2742562411,0.7257437589,0.4705882353,0.05442176871,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Do you have any code that can be looked up to start coding on the new api?,Solution Discussion,74,74,0.75,0.7657992565,0.2742562411,0.7257437589,1,0.1156462585,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Any help is well appreciated.,Social Conversation,29,29,0.875,0.7695167286,0.2742562411,0.7257437589,0.2941176471,0.03401360544,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thank you once again :),Social Conversation,23,23,1,0.7732342007,0.2742562411,0.7257437589,0.2941176471,0.03401360544,0.006610382458,0.005351860947,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@syw2014 Did you fix your issue?,Task Progress,32,32,1,0.7769516729,0.2755582421,0.7244417579,1,0.04081632653,0.005351860947,0.05920818041,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,it says CODEafter using the update that @fabiofumarola posted.,Solution Discussion,152,62,0.5,0.780669145,0.2899624105,0.7100375895,1,0.0612244898,0.05920818041,0.0002065892845,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,Can you guys please help me?,Contribution and Commitment,28,28,1,0.7843866171,0.2899624105,0.7100375895,0.6666666667,0.04081632653,0.05920818041,0.0002065892845,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Yes because the update I have proposed require you to change theembedding_attention_seq2seq Function.,Solution Discussion,101,101,0.5,0.7881040892,0.2900126696,0.7099873304,0.6842105263,0.08843537415,0.0002065892845,4.60E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,If you go to the source file in youtensorflow release you can change the method definition you re self.,Solution Discussion,103,103,1,0.7918215613,0.2900126696,0.7099873304,1,0.1292517007,0.0002065892845,4.60E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Yes i did the same thing.,Social Conversation,25,25,0.25,0.7955390335,0.2900238703,0.7099761297,0.5454545455,0.04081632653,4.60E-05,0.0009023003557,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I changed the function in seq2seq.py file in the tensorflow release.,Solution Discussion,68,68,0.5,0.7992565056,0.2900238703,0.7099761297,1,0.07482993197,4.60E-05,0.0009023003557,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Still i am getting the same error.,Solution Discussion,34,34,0.75,0.8029739777,0.2900238703,0.7099761297,0.6363636364,0.04761904762,4.60E-05,0.0009023003557,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Is there one more argument to the function?,Solution Discussion,43,43,1,0.8066914498,0.2900238703,0.7099761297,0.7272727273,0.05442176871,4.60E-05,0.0009023003557,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Yes, now in you code you need to specify to rnn_cells.",Solution Discussion,54,54,0.5,0.8104089219,0.290243382,0.709756618,1,0.07482993197,0.0009023003557,0.008897341264,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,One for the encoderand another for the decoder.,Solution Discussion,47,47,1,0.8141263941,0.290243382,0.709756618,0.7272727273,0.05442176871,0.0009023003557,0.008897341264,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I am totally new to this.,Social Conversation,25,25,0.25,0.8178438662,0.2924079275,0.7075920725,0.2727272727,0.04081632653,0.008897341264,0.0004811714811,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Maybe this a pretty basic question but could you tell what argument to be passed as the decoder cell in this code?,Solution Discussion,114,114,0.5,0.8215613383,0.2924079275,0.7075920725,1,0.1496598639,0.008897341264,0.0004811714811,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I am trying to develop the seq2seq as shown in the tensorflow tutorial using own dataset.,Solution Discussion,89,89,0.75,0.8252788104,0.2924079275,0.7075920725,0.7272727273,0.1088435374,0.008897341264,0.0004811714811,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,CODE,Solution Discussion,7712,4,1,0.8289962825,0.2924079275,0.7075920725,0.04545454545,0.006802721088,0.008897341264,0.0004811714811,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,Okay!,Social Conversation,5,5,0.3333333333,0.8327137546,0.2925249869,0.7074750131,0.5,0.006802721088,0.0004811714811,0.0001064391661,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,thanks though!,Social Conversation,14,14,0.6666666667,0.8364312268,0.2925249869,0.7074750131,1,0.01360544218,0.0004811714811,0.0001064391661,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,:),Social Conversation,2,2,1,0.8401486989,0.2925249869,0.7074750131,0.5,0.006802721088,0.0004811714811,0.0001064391661,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@ebrevdo  is there any update on when the new tutorial of seq2seq using new api will come out?,Task Progress,94,94,0.3333333333,0.843866171,0.2925508814,0.7074491186,1,0.1292517007,0.0001064391661,5.39E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Thank you.,Social Conversation,10,10,0.6666666667,0.8475836431,0.2925508814,0.7074491186,0.1052631579,0.01360544218,0.0001064391661,5.39E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Amazing work!.,Social Conversation,14,14,1,0.8513011152,0.2925508814,0.7074491186,0.1052631579,0.01360544218,0.0001064391661,5.39E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,yeah waiting for the new tutorial...,Social Conversation,36,36,0.3333333333,0.8550185874,0.2925639875,0.7074360125,0.2857142857,0.04081632653,5.39E-05,7.24E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,would be great to know if it's planned to be released anytime soon.. @ebrevdo,Task Progress,77,77,0.6666666667,0.8587360595,0.2925639875,0.7074360125,0.7142857143,0.1020408163,5.39E-05,7.24E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"tried to take code in the kernel tests and retrofit the beam search with the legacy seq2seq, but it was challenging...",Solution Discussion,118,118,1,0.8624535316,0.2925639875,0.7074360125,1,0.1428571429,5.39E-05,7.24E-05,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,We're hoping for this coming week!,Task Progress,34,34,1,0.8661710037,0.2925815969,0.7074184031,1,0.04081632653,7.24E-05,0.1696890683,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Hi guys,",Social Conversation,8,8,1,0.8698884758,0.33386356,0.66613644,1,0.01360544218,0.1696890683,0.04382956016,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@tshi1983I got the same problem with tensorflow 1.1-gpu for ubuntu.,Bug Reproduction,67,67,0.2,0.873605948,0.3445264171,0.6554735829,0.5789473684,0.07482993197,0.04382956016,0.06892677638,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I upgrade to tf 1.2. It still doesn't work.,Solution Discussion,43,43,0.4,0.8773234201,0.3445264171,0.6554735829,0.4736842105,0.0612244898,0.04382956016,0.06892677638,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Then I change the function embedding_attention_seq2seq in filetensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.pyto the one as @fabiofumarola suggested above.,Solution Discussion,162,162,0.6,0.8810408922,0.3445264171,0.6554735829,1,0.1292517007,0.04382956016,0.06892677638,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Now it starts training.,Solution Discussion,23,23,0.8,0.8847583643,0.3445264171,0.6554735829,0.2105263158,0.02721088435,0.04382956016,0.06892677638,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I haven't tested decoding yet.,Solution Discussion,30,30,1,0.8884758364,0.3445264171,0.6554735829,0.2631578947,0.03401360544,0.04382956016,0.06892677638,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"Move the code on cell definition into seq2seq_f: CODEThen ""python translate.py --data_dir data/ --train_dir checkpoint/ --size=256 --num_layers=2 --steps_per_checkpoint=50"" can work.",Solution Discussion,552,182,1,0.8921933086,0.361294926,0.638705074,1,0.1360544218,0.06892677638,0.002231306666,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,@huxuanlai it works!,Social Conversation,20,20,0.5,0.8959107807,0.3618377584,0.6381622416,0.5,0.02040816327,0.002231306666,0.05363264296,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"At least it's training now, thx!",Social Conversation,32,32,1,0.8996282528,0.3618377584,0.6381622416,1,0.04081632653,0.002231306666,0.05363264296,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,@huxuanlai Works for me as well.,Social Conversation,32,32,1,0.9033457249,0.3748855098,0.6251144902,1,0.04081632653,0.05363264296,0.05261488518,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I am receiving the same CODE but with CODE.,Potential New Issues and Requests,142,43,0.25,0.907063197,0.3876856611,0.6123143389,0.75,0.0612244898,0.05261488518,0.05332661552,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I am running tf 1.2.1 (GPU)  on ubuntu 16.04 lts.,Potential New Issues and Requests,49,49,0.5,0.9107806691,0.3876856611,0.6123143389,0.9166666667,0.07482993197,0.05261488518,0.05332661552,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,This only seems to occur when I have more than 1 bucket.,Potential New Issues and Requests,56,56,0.75,0.9144981413,0.3876856611,0.6123143389,1,0.08163265306,0.05261488518,0.05332661552,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,full traceback:CODE,Potential New Issues and Requests,7027,19,1,0.9182156134,0.3876856611,0.6123143389,0.25,0.02040816327,0.05261488518,0.05332661552,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"@Tshzzz @jtubertthx, your solution worked for me.",Solution Discussion,49,49,0.3333333333,0.9219330855,0.4006589622,0.5993410378,1,0.04761904762,0.05332661552,0.02817813763,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,My tf verstion is 1.1.0.,Bug Reproduction,24,24,0.6666666667,0.9256505576,0.4006589622,0.5993410378,0.7142857143,0.03401360544,0.05332661552,0.02817813763,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,I changed from:CODEto:CODE,Solution Discussion,498,26,1,0.9293680297,0.4006589622,0.5993410378,0.7142857143,0.03401360544,0.05332661552,0.02817813763,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,I'm facing this error:CODE,Potential New Issues and Requests,120,26,0.3333333333,0.9330855019,0.4075141407,0.5924858593,0.2631578947,0.03401360544,0.02817813763,0.06521718752,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,The error points to this function in seq2seq_model.py which is line 142 in seq2seq_model.py: CODE,Potential New Issues and Requests,420,97,0.6666666667,0.936802974,0.4075141407,0.5924858593,0.7894736842,0.1020408163,0.02817813763,0.06521718752,NONE,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,"Anyone who came across with this error and managed  to solve this, please help me correct this issue.",Potential New Issues and Requests,101,101,1,0.9405204461,0.4075141407,0.5924858593,1,0.1292517007,0.02817813763,0.06521718752,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x11d32cbd0> with a different variable scope than its first use. First use of cell was with scope 'rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'rnn/multi_rnn_cell/cell_1/gru_cell'. Please create a new instance of the cell if you would like it to use a different set of weights. If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]). If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse). In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction,936,936,0.3333333333,0.9442379182,0.4233801806,0.5766198194,1,0.9523809524,0.06521718752,0.3845326686,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"the origin code:from tensorflow.contrib import rnninputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.GRUCell(10)cell = rnn.DropoutWrapper(cell=cell, input_keep_prob=keep_prob)cell = rnn.MultiRNNCell([cell for _ in range(5)], state_is_tuple=True) outs, states = tf.nn.dynamic_rnn(cell=cell, inputs=look_up, dtype=tf.float32)",Bug Reproduction,419,419,0.6666666667,0.9479553903,0.4233801806,0.5766198194,0.2642857143,0.2517006803,0.06521718752,0.3845326686,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"solution:inputs = tf.placeholder(dtype=tf.int32, shape=[None, None], name=""inputs"")keep_prob = tf.placeholder(dtype=tf.float32, name=""keep_prob"")cell = rnn.MultiRNNCell([rnn.DropoutWrapper(rnn.GRUCell(10), input_keep_prob=keep_prob) for _ in range(5)] , state_is_tuple=True)",Solution Discussion,274,274,1,0.9516728625,0.4233801806,0.5766198194,0.15,0.1428571429,0.06521718752,0.3845326686,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Do you have this issue with the tf nightlies?,Investigation and Exploration,45,45,1,0.9553903346,0.5169293032,0.4830706968,1,0.0612244898,0.3845326686,0.2231277001,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,AttributeError: 'NoneType' object has no attribute 'update' in tf=1.3,Potential New Issues and Requests,69,69,1,0.9591078067,0.5712118187,0.4287881813,1,0.0612244898,0.2231277001,0.358409507,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,"ValueError: Attempt to reuse RNNCell <tensorflow.contrib.rnn.python.ops.core_rnn_cell_impl.GRUCell object at 0x117f7cbd0> with a different variable scope than its first use.  First use of cell was with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_0/gru_cell', this attempt is with scope 'embedding_attention_seq2seq/rnn/multi_rnn_cell/cell_1/gru_cell'.  Please create a new instance of the cell if you would like it to use a different set of weights.  If before you were using: MultiRNNCell([GRUCell(...)] * num_layers), change to: MultiRNNCell([GRUCell(...) for _ in range(num_layers)]).  If before you were using the same cell instance as both the forward and reverse cell of a bidirectional RNN, simply create two instances (one for forward, one for reverse).  In May 2017, we will start transitioning this cell's behavior to use existing stored weights, if any, when it is called with scope=None (which can lead to silent model degradation, so this error will remain until then.)",Bug Reproduction,997,997,1,0.9628252788,0.6584056975,0.3415943025,1,1,0.358409507,0.2555781183,NONE,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,It has been 14 days with no activity and the CODE label was assigned.,Action on Issue,88,69,0.5,0.9665427509,0.7205827521,0.2794172479,1,0.09523809524,0.2555781183,0.1484095414,MEMBER,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,Please update the label and/or status accordingly.,Action on Issue,50,50,1,0.970260223,0.7205827521,0.2794172479,0.5,0.04761904762,0.2555781183,0.1484095414,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Nagging Awaiting TensorFlower: It has been 14 days with no activityand the CODE label was assigned.,Action on Issue,118,99,0.5,0.9739776952,0.7566878311,0.2433121689,1,0.1088435374,0.1484095414,0.0001320700021,MEMBER,FALSE,TRUE,FALSE,FALSE
12 8191_tensorflow.doc,Please update the label and/or status accordingly.,Action on Issue,50,50,1,0.9776951673,0.7566878311,0.2433121689,0.4375,0.04761904762,0.1484095414,0.0001320700021,MEMBER,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,The solution is to move to a newer version of TF.,Solution Discussion,49,49,0.3333333333,0.9814126394,0.7567199611,0.2432800389,1,0.07482993197,0.0001320700021,1,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,This thread has drastically diverged from its original issue.,Action on Issue,61,61,0.6666666667,0.9851301115,0.7567199611,0.2432800389,0.8181818182,0.0612244898,0.0001320700021,1,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,Closing.,Action on Issue,8,8,1,0.9888475836,0.7567199611,0.2432800389,0.09090909091,0.006802721088,0.0001320700021,1,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
12 8191_tensorflow.doc,If you want instant solution you can try what i tried :,Solution Discussion,55,55,1,0.9925650558,1,0,11,0.07482993197,1,0,NONE,FALSE,FALSE,FALSE,TRUE
12 8191_tensorflow.doc,CODE,Solution Discussion,29,4,2,0.9962825279,1,0,1,0.006802721088,1,0,NONE,FALSE,TRUE,FALSE,TRUE
12 8191_tensorflow.doc,"The issue is with tenorflow 1.1 version , it worked for me.",Solution Discussion,59,59,3,1,1,0,11,0.07482993197,1,0,NONE,FALSE,FALSE,FALSE,TRUE
13 125_spaCy.doc,For spaCy to work out of the box with [Apache Spark] URL  the language modles need to be pickled so that they can be initialised on the master node and then sent to the workers.,Motivation,197,177,0.125,0.003584229391,0,1,1,0.2352941176,0,0.0054583822,NONE,TRUE,FALSE,TRUE,FALSE
13 125_spaCy.doc,"This currently doesn't work with plain pickle, failing as follows: CODE",Motivation,304,71,0.25,0.007168458781,0,1,0.3055555556,0.07189542484,0,0.0054583822,NONE,TRUE,TRUE,TRUE,FALSE
13 125_spaCy.doc,"Apache Spark ships with a package called [cloudpickle] URL  which is meant to support a wider set of Python constructs, but serialisation with cloudpickle also fails resulting in a segmentation fault: CODE",Motivation,386,205,0.375,0.01075268817,0,1,0.9166666667,0.2156862745,0,0.0054583822,NONE,TRUE,TRUE,TRUE,FALSE
13 125_spaCy.doc,"By default Apache Spark uses pickle, but can be told to use cloudpickle instead.",Motivation,80,80,0.5,0.01433691756,0,1,0.3888888889,0.09150326797,0,0.0054583822,NONE,TRUE,FALSE,TRUE,FALSE
13 125_spaCy.doc,Currently a feasable workaround is lazy loading of the language models on the worker nodes: CODE,Workarounds,192,96,0.625,0.01792114695,0,1,0.4444444444,0.1045751634,0,0.0054583822,NONE,TRUE,TRUE,TRUE,FALSE
13 125_spaCy.doc,The above works.,Workarounds,16,16,0.75,0.02150537634,0,1,0.08333333333,0.01960784314,0,0.0054583822,NONE,TRUE,FALSE,TRUE,FALSE
13 125_spaCy.doc,"Nevertheless, I wonder if it would be possible to make the English() object pickleable?",Expected Behaviour,87,87,0.875,0.02508960573,0,1,0.3888888889,0.09150326797,0,0.0054583822,NONE,TRUE,FALSE,TRUE,FALSE
13 125_spaCy.doc,"If not too difficult from your end, having the language models pickleable would provide a better out of box experience for Apache Spark users.",Motivation,142,142,1,0.02867383513,0,1,0.6666666667,0.1568627451,0,0.0054583822,NONE,TRUE,FALSE,TRUE,FALSE
13 125_spaCy.doc,I've spent a little time looking into this now.,Social Conversation,47,47,0.08333333333,0.03225806452,0.00192271851,0.9980772815,0.3225806452,0.06535947712,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The workflow that's a little bit tricky to support is something like this:,Solution Discussion,74,74,0.1666666667,0.03584229391,0.00192271851,0.9980772815,0.4193548387,0.08496732026,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         Create an CODE instance,Solution Discussion,40,33,0.25,0.0394265233,0.00192271851,0.9980772815,0.1612903226,0.03267973856,0.0054583822,0.0004639102472,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"-         Change the state of some binary data, e.g. modify the lexicon",Solution Discussion,71,71,0.3333333333,0.04301075269,0.00192271851,0.9980772815,0.3870967742,0.07843137255,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         Send it to workers, with new state preserved",Solution Discussion,54,54,0.4166666667,0.04659498208,0.00192271851,0.9980772815,0.2903225806,0.05882352941,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Now, when I say ""a little bit tricky""...If this is a requirement, we can do it.",Solution Discussion,79,79,0.5,0.05017921147,0.00192271851,0.9980772815,0.5483870968,0.1111111111,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It'll mean writing out all the state to binary data strings, shipping ~1gb to each worker, and then loading from the strings.",Solution Discussion,125,125,0.5833333333,0.05376344086,0.00192271851,0.9980772815,0.7419354839,0.1503267974,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"The patch will touch every class, and it might be fiddly, especially to keep efficiency nice.",Solution Discussion,93,93,0.6666666667,0.05734767025,0.00192271851,0.9980772815,0.5161290323,0.1045751634,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But there's no real problem.,Solution Discussion,28,28,0.75,0.06093189964,0.00192271851,0.9980772815,0.1612903226,0.03267973856,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The question is whether this work-flow is really important.,Solution Discussion,59,59,0.8333333333,0.06451612903,0.00192271851,0.9980772815,0.3225806452,0.06535947712,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I would've thought that the better way to do things was to divide the documents in the master node, and then send a reference to a function like this: CODE",Solution Discussion,289,155,0.9166666667,0.06810035842,0.00192271851,0.9980772815,1,0.2026143791,0.0054583822,0.0004639102472,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,Does PySpark not work this way?,Solution Discussion,31,31,1,0.07168458781,0.00192271851,0.9980772815,0.1935483871,0.03921568627,0.0054583822,0.0004639102472,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Yes the way you suggest is similar to what I am doing now with a lazy loaded CODE object.,Solution Discussion,96,89,0.3333333333,0.0752688172,0.002086131182,0.9979138688,0.4318181818,0.1241830065,0.0004639102472,1.03E-05,NONE,TRUE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"I mainly created this issue in case someone else is running into similar problems when trying spaCy on Spark, as the error messages raised by Spark when failing to pickle the language models are not very helpful (workers just crash because of segmentation fault).",Motivation,263,263,0.6666666667,0.07885304659,0.002086131182,0.9979138688,1,0.2875816993,0.0004639102472,1.03E-05,NONE,TRUE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This issue can be closed from my end.,Action on Issue,37,37,1,0.08243727599,0.002086131182,0.9979138688,0.1818181818,0.0522875817,0.0004639102472,1.03E-05,NONE,TRUE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks.,Social Conversation,7,7,0.5,0.08602150538,0.002089762575,0.9979102374,0.07692307692,0.006535947712,1.03E-05,0.004147527693,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Let's leave it open for now and think about it a bit more.,Action on Issue,58,58,1,0.08960573477,0.002089762575,0.9979102374,1,0.08496732026,1.03E-05,0.004147527693,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"@honnibal When you say ""writing out all the state"", can you clarify what is involved here?",Solution Discussion,90,90,0.5,0.09318996416,0.003550731773,0.9964492682,1,0.1045751634,0.004147527693,5.52E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Which objects inside of CODE's state are easy to serialize and which ones aren't?,Solution Discussion,82,81,1,0.09677419355,0.003550731773,0.9964492682,0.875,0.09150326797,0.004147527693,5.52E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,Good question.,Social Conversation,14,14,0.1428571429,0.1003584229,0.003570184789,0.9964298152,0.01307189542,0.01307189542,5.52E-05,0.005931074288,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,A quick summary:,Solution Discussion,16,16,0.2857142857,0.1039426523,0.003570184789,0.9964298152,0.01960784314,0.01960784314,5.52E-05,0.005931074288,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"| Class | Instance | Changes if | Frequently changes? | Size | Description || --- | --- | --- | --- | --- | --- || CODE | CODE | Any unseen token is processed | Yes | 9mb | Mapping table of strings to integers. Serialized as list of strings. || CODE | CODE | User writes Lexeme properties | Maybe | 80mb | Pre-computed attributes for every lexical type in the vocabulary. || CODE | CODE | User updates word vectors | Maybe | 200mb to 1gb | Word vectors. || CODE | CODE | User adds to gazetteer | Yes | <1mb | User-custom entity recognition behaviour. || CODE | CODE | Shouldn't, but must check. | Think no? | Small | I think the serializer reads data off the vocab. But need to double check. || CODE | CODE | Training | No | 490mb | Parser's statistical model. Immutable in normal use. || CODE | CODE | Training | No | 38mb | NER statistical model. Immutable in normal use. || CODE | CODE | Training | No | 12mb | POS statistical model. Immutable in normal use. |",Solution Discussion,1158,963,0.4285714286,0.1075268817,0.003570184789,0.9964298152,1,1,5.52E-05,0.005931074288,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"Really everything could be serialized, because everything knows how to write itself to disk and load itself back, usually in a binary format.",Solution Discussion,141,141,0.5714285714,0.1111111111,0.003570184789,0.9964298152,0.1503267974,0.1503267974,5.52E-05,0.005931074288,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"One super simple way to do the serialization would be to dump to a directory, tar it, send the bits, untar, load.",Solution Discussion,113,113,0.7142857143,0.1146953405,0.003570184789,0.9964298152,0.1437908497,0.1437908497,5.52E-05,0.005931074288,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'm sure we can do better than that, though, In standard use, the only things likely to change are within CODE.",Solution Discussion,114,111,0.8571428571,0.1182795699,0.003570184789,0.9964298152,0.137254902,0.137254902,5.52E-05,0.005931074288,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"If nothing is written to the NLP class, then serialization with Pickle is super simple: we can just tell it to load with the arguments originally passed to the constructor.",Solution Discussion,172,172,1,0.1218637993,0.003570184789,0.9964298152,0.1960784314,0.1960784314,5.52E-05,0.005931074288,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Just to chime in: Based on my experience with Spark, it sounds like loading English locally at each worker is best.",Solution Discussion,115,115,0.06666666667,0.1254480287,0.005659409379,0.9943405906,0.75,0.137254902,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Does this summary of pros/cons sound about right?,Solution Discussion,49,49,0.1333333333,0.1290322581,0.005659409379,0.9943405906,0.3214285714,0.05882352941,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Pros,Solution Discussion,4,4,0.2,0.1326164875,0.005659409379,0.9943405906,0.03571428571,0.006535947712,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         Less communication (so faster),Solution Discussion,40,40,0.2666666667,0.1362007168,0.005659409379,0.9943405906,0.1785714286,0.03267973856,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         If the English object will be used on workers multiple times, it'd be important to cache it to prevent re-loading.",Solution Discussion,124,124,0.3333333333,0.1397849462,0.005659409379,0.9943405906,0.8214285714,0.1503267974,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         Simpler to implement,Solution Discussion,30,30,0.4,0.1433691756,0.005659409379,0.9943405906,0.1428571429,0.02614379085,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         This seems like the biggest argument---the cost of dev time.,Solution Discussion,70,70,0.4666666667,0.146953405,0.005659409379,0.9943405906,0.4642857143,0.08496732026,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Also, serialization might have to be updated if the English object gets updated.",Solution Discussion,80,80,0.5333333333,0.1505376344,0.005659409379,0.9943405906,0.4642857143,0.08496732026,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         Less memory used on driver,Solution Discussion,36,36,0.6,0.1541218638,0.005659409379,0.9943405906,0.2142857143,0.03921568627,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         It's much better to do heavy work on workers than on the driver.,Solution Discussion,74,74,0.6666666667,0.1577060932,0.005659409379,0.9943405906,0.5,0.09150326797,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If an executor dies, things are often recoverable, but more may be lost when the driver dies.",Solution Discussion,93,93,0.7333333333,0.1612903226,0.005659409379,0.9943405906,0.6071428571,0.1111111111,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Cons,Solution Discussion,4,4,0.8,0.164874552,0.005659409379,0.9943405906,0.03571428571,0.006535947712,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         Need to ensure configuration/setup of English is identical across workers,Solution Discussion,83,83,0.8666666667,0.1684587814,0.005659409379,0.9943405906,0.4285714286,0.07843137255,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         This was the part I was not sure about: Is there any setup required, or is it sufficient to just load the English object at each worker?",Solution Discussion,146,146,0.9333333333,0.1720430108,0.005659409379,0.9943405906,1,0.1830065359,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If there is some setup, then it'd be worth discussing what needs to be communicated for each worker to do the same setup.",Solution Discussion,121,121,1,0.1756272401,0.005659409379,0.9943405906,0.8571428571,0.1568627451,0.005931074288,2.51E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks.,Social Conversation,7,7,0.07142857143,0.1792114695,0.005668237209,0.9943317628,0.0243902439,0.006535947712,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Okay so.,Social Conversation,8,8,0.1428571429,0.1827956989,0.005668237209,0.9943317628,0.0487804878,0.01307189542,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"To be clear, the **wrong** way to do this is to batch the texts into jobs yourself, and then map over the jobs, right?",Solution Discussion,118,118,0.2142857143,0.1863799283,0.005668237209,0.9943317628,0.5853658537,0.1568627451,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Instead if the task is per text, we should let Spark map over the texts, and it's our/user's job to make that work.",Solution Discussion,115,115,0.2857142857,0.1899641577,0.005668237209,0.9943317628,0.5853658537,0.1568627451,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It's also wrong to let Spark see the English instance as a shared variable.,Solution Discussion,75,75,0.3571428571,0.1935483871,0.005668237209,0.9943317628,0.3414634146,0.09150326797,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It needs to be private to the workers, because we really don't want the workers to transfer it back to the driver.",Solution Discussion,114,114,0.4285714286,0.1971326165,0.005668237209,0.9943317628,0.5365853659,0.1437908497,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"In terms of the trade-offs, my perspective is that we're happy to take on implementation complexity.",Solution Discussion,100,100,0.5,0.2007168459,0.005668237209,0.9943317628,0.4146341463,0.1111111111,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The library is very willing to do work so that users don't have to.,Solution Discussion,67,67,0.5714285714,0.2043010753,0.005668237209,0.9943317628,0.3414634146,0.09150326797,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,They key priority is that the library should make the right thing easy.,Solution Discussion,71,71,0.6428571429,0.2078853047,0.005668237209,0.9943317628,0.3170731707,0.08496732026,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Whatever our recommended workflow is, it should be the obvious and least-effort thing to do.",Solution Discussion,92,92,0.7142857143,0.2114695341,0.005668237209,0.9943317628,0.3902439024,0.1045751634,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"But if there's an important trade-off to make, we don't want to have a silent default that just picks an option, and then the user gets a bad result and has to go back and figure out what went wrong.",Solution Discussion,199,199,0.7857142857,0.2150537634,0.005668237209,0.9943317628,1,0.2679738562,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I worry that adding this pickling capability will lead users down the wrong track.,Solution Discussion,82,82,0.8571428571,0.2186379928,0.005668237209,0.9943317628,0.3414634146,0.09150326797,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It seems to me that it makes the whole thing transparent, when actually there's a meaningful decision here, that maybe the user needs to make.",Solution Discussion,142,142,0.9285714286,0.2222222222,0.005668237209,0.9943317628,0.6097560976,0.1633986928,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Masking that decision isn't necessarily a good service to them.,Solution Discussion,63,63,1,0.2258064516,0.005668237209,0.9943317628,0.243902439,0.06535947712,2.51E-05,0.002335900037,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If it's a pure map operation, then it is better to let Spark handle the map, if only because it can then handle distributing the work and providing some fault tolerance.",Solution Discussion,169,169,0.05263157895,0.229390681,0.006491059444,0.9935089406,0.7209302326,0.2026143791,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It's not wrong, but it is not ideal since 1GB is a fairly big object.",Solution Discussion,69,69,0.1052631579,0.2329749104,0.006491059444,0.9935089406,0.3720930233,0.1045751634,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It'd be nice to design an API which encouraged minimal communication: either (a) load it on the driver and broadcast it (transfer only once) or (b) load it on each worker (once).,Solution Discussion,178,178,0.1578947368,0.2365591398,0.006491059444,0.9935089406,0.7674418605,0.2156862745,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The API could potentially handle this under the hood.,Solution Discussion,53,53,0.2105263158,0.2401433692,0.006491059444,0.9935089406,0.2093023256,0.05882352941,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If you're not worried about development effort, then actually serialization sounds like the best option.",Solution Discussion,104,104,0.2631578947,0.2437275986,0.006491059444,0.9935089406,0.3488372093,0.09803921569,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But you could hide it from the user.,Solution Discussion,36,36,0.3157894737,0.247311828,0.006491059444,0.9935089406,0.1860465116,0.0522875817,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Here's what I'm thinking:,Solution Discussion,25,25,0.3684210526,0.2508960573,0.006491059444,0.9935089406,0.09302325581,0.02614379085,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         Goal: Have users use the same English object on the driver or in Spark jobs, and not worry about communicating the big object.",Expected Behaviour,136,136,0.4210526316,0.2544802867,0.006491059444,0.9935089406,0.5581395349,0.1568627451,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         Implementation A: Simpler, but requires user to be aware of local vs. distributed operations",Solution Discussion,102,102,0.4736842105,0.2580645161,0.006491059444,0.9935089406,0.3488372093,0.09803921569,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         When the user wants to do a distributed operation, they call CODE on the driver, and English handles the map under the hood.",Solution Discussion,149,134,0.5263157895,0.2616487455,0.006491059444,0.9935089406,0.5581395349,0.1568627451,0.002335900037,0.0006598181736,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"-         Under the hood, English could broadcast itself (requiring pickling), or just load itself locally on each worker.",Solution Discussion,122,122,0.5789473684,0.2652329749,0.006491059444,0.9935089406,0.4186046512,0.1176470588,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         Implementation B: More complex, but user can be oblivious",Solution Discussion,67,67,0.6315789474,0.2688172043,0.006491059444,0.9935089406,0.2325581395,0.06535947712,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"-         Within English, make the big objects transient (i.e., specify that via CODE for pickling).",Solution Discussion,110,100,0.6842105263,0.2724014337,0.006491059444,0.9935089406,0.3488372093,0.09803921569,0.002335900037,0.0006598181736,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"-         Store those big objects in broadcast variables (initialized on the driver in the constructor), which are then read when needed on the workers.",Solution Discussion,152,152,0.7368421053,0.2759856631,0.006491059444,0.9935089406,0.5581395349,0.1568627451,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Both of these options require pickling, but B requires somewhat more complex pickling.",Solution Discussion,86,86,0.7894736842,0.2795698925,0.006491059444,0.9935089406,0.3023255814,0.08496732026,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"After thinking more about it, I'd recommend broadcasting English (unless you think it will grow far beyond 1GB in the future).",Solution Discussion,126,126,0.8421052632,0.2831541219,0.006491059444,0.9935089406,0.5348837209,0.1503267974,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,That will be easier for handling English's settings or parameters.,Solution Discussion,66,66,0.8947368421,0.2867383513,0.006491059444,0.9935089406,0.2325581395,0.06535947712,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I think it's OK to hide things from the user.,Solution Discussion,45,45,0.9473684211,0.2903225806,0.006491059444,0.9935089406,0.2325581395,0.06535947712,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"As far as I can tell, the main things the user needs to be aware of are (a) whether any options they set will be used both on the driver and on workers and (b) when a data object is local vs. distributed.",Solution Discussion,204,204,1,0.29390681,0.006491059444,0.9935089406,1,0.2810457516,0.002335900037,0.0006598181736,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Okay, thanks.",Social Conversation,13,13,1,0.2974910394,0.006723480804,0.9932765192,1,0.01307189542,0.0006598181736,0.003579172558,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Can I expect tempfiles and tempdirs to work?,Solution Discussion,44,44,0.5,0.3010752688,0.007984246554,0.9920157534,0.7272727273,0.0522875817,0.003579172558,0.01837091521,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Is the file system shared between the driver and all children?,Solution Discussion,62,62,1,0.3046594982,0.007984246554,0.9920157534,1,0.07189542484,0.003579172558,0.01837091521,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Just pushed v0.95.,Task Progress,18,18,0.25,0.3082437276,0.01445541281,0.9855445872,0.15,0.01960784314,0.01837091521,0.01064935216,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Everything should now pickle.,Task Progress,29,29,0.5,0.311827957,0.01445541281,0.9855445872,0.2,0.02614379085,0.01837091521,0.01064935216,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The only known issue is that you shouldn't begin training a model and then pickle it part way through training.,Task Progress,111,111,0.75,0.3154121864,0.01445541281,0.9855445872,1,0.1307189542,0.01837091521,0.01064935216,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Please keep an eye out for other issues, and report them :)",Social Conversation,59,59,1,0.3189964158,0.01445541281,0.9855445872,0.6,0.07843137255,0.01837091521,0.01064935216,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It seems like the pickler tries to pickle a Vocab, Tokenizer, Tagger, Parser, and Matcher object.",Solution Discussion,97,97,0.25,0.3225806452,0.01820665371,0.9817933463,0.64,0.1045751634,0.01064935216,0.001404504327,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"When it gets to the [Tokenizer](https://github.com/honnibal/spaCy/blob/master/spacy/tokenizer.pyx#L22), it doesn't seem to have a doesn't seem to have a CODE implemented.",Solution Discussion,178,170,0.5,0.3261648746,0.01820665371,0.9817933463,1,0.1633986928,0.01064935216,0.001404504327,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"I don't see Tokenizer in the above list of ""state objects that need pickling""; do we not expect the pickler to find the Tokenizer object?",Solution Discussion,137,137,0.75,0.3297491039,0.01820665371,0.9817933463,1,0.1633986928,0.01064935216,0.001404504327,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks in advance for any hints.,Social Conversation,32,32,1,0.3333333333,0.01820665371,0.9817933463,0.24,0.03921568627,0.01064935216,0.001404504327,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This is odd â I definitely thought I'd done this.,Social Conversation,49,49,0.5,0.3369175627,0.01870139123,0.9812986088,1,0.07189542484,0.001404504327,0.00111366228,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'll figure this out, thanks.",Social Conversation,29,29,1,0.3405017921,0.01870139123,0.9812986088,0.4545454545,0.03267973856,0.001404504327,0.00111366228,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,FWIW: tests/test_pickle.py passes for me as well.,Solution Discussion,49,49,0.5,0.3440860215,0.01909367945,0.9809063205,0.5714285714,0.0522875817,0.00111366228,0.2664044078,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,There seems to be something different between CODE and CODE that I don't understand.,Solution Discussion,114,84,1,0.3476702509,0.01909367945,0.9809063205,1,0.09150326797,0.00111366228,0.2664044078,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,Reopening this.,Action on Issue,15,15,0.05882352941,0.3512544803,0.1129347971,0.8870652029,0.04347826087,0.01307189542,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The current pickling implementation was only supposed to be an exploratory kludge.,Task Progress,82,82,0.1176470588,0.3548387097,0.1129347971,0.8870652029,0.2608695652,0.07843137255,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"However, I didn't leave a TODO and the status of it got lost.",Task Progress,61,61,0.1764705882,0.3584229391,0.1129347971,0.8870652029,0.2826086957,0.08496732026,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The root of the problem is that a number of spaCy classes carry large binary data structures.,Investigation and Exploration,93,93,0.2352941176,0.3620071685,0.1129347971,0.8870652029,0.3695652174,0.1111111111,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Common usage is to load this data and consider it immutable, however you can write to these models, e.g. to change the word vectors, and pickle should not silently dump these changes.",Solution Discussion,183,183,0.2941176471,0.3655913978,0.1129347971,0.8870652029,0.6956521739,0.2091503268,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,On the other hand it's harsh to assume we always need to write out the state.,Solution Discussion,77,77,0.3529411765,0.3691756272,0.1129347971,0.8870652029,0.347826087,0.1045751634,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This would mean that users who follow the pattern of keeping the data immutable have to write out ~1gb of data to pickle the models.,Solution Discussion,132,132,0.4117647059,0.3727598566,0.1129347971,0.8870652029,0.5652173913,0.1699346405,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This makes average usage of Spark etc really problematic.,Solution Discussion,57,57,0.4705882353,0.376344086,0.1129347971,0.8870652029,0.1956521739,0.05882352941,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"We could do this implicitly with copy-on-write semantics, but I don't think it's great to invoke some method where it may or may not write out 1gb of data to disk, depending on the entire execution history of the program.",Solution Discussion,221,221,0.5294117647,0.3799283154,0.1129347971,0.8870652029,0.9347826087,0.2810457516,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"We could have a more explicit version of copy-on-write, where all the classes track whether they've been changed, and then the models should refuse to be pickled if the state is unclean.",Solution Discussion,186,186,0.5882352941,0.3835125448,0.1129347971,0.8870652029,0.7608695652,0.2287581699,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Users would then explicitly save the state after they change it.,Solution Discussion,64,64,0.6470588235,0.3870967742,0.1129347971,0.8870652029,0.2391304348,0.07189542484,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I think this is a recipe for having long-running processes suddenly die, though. Mostly Python is designed around the assumption that things can either be pickled or they can't.",Solution Discussion,177,177,0.7058823529,0.3906810036,0.1129347971,0.8870652029,0.652173913,0.1960784314,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It's surprising to find that your pickle works, sometimes, depending on state, but then your long-running process dies because you didn't meet the assumed invariant.",Solution Discussion,165,165,0.7647058824,0.394265233,0.1129347971,0.8870652029,0.5652173913,0.1699346405,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"And then next time you run, you get an error in that other place in your code where the classes get pickled.",Solution Discussion,108,108,0.8235294118,0.3978494624,0.1129347971,0.8870652029,0.4782608696,0.1437908497,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I've been thinking for a while that context managers are the idiomatic standard for dealing with this problem.,Solution Discussion,110,110,0.8823529412,0.4014336918,0.1129347971,0.8870652029,0.4130434783,0.1241830065,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"The idea would be that if you want to write to any of this loaded data, you have to open it within a context manager, so that the changes are explicitly scoped, and you explicitly decide whether you want to save the changes or dump them.",Solution Discussion,237,237,0.9411764706,0.4050179211,0.1129347971,0.8870652029,1,0.3006535948,0.2664044078,0.0007474630201,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Ignoring the naming of everything, this might look like: CODE",Solution Discussion,686,61,1,0.4086021505,0.1129347971,0.8870652029,0.2173913043,0.06535947712,0.2664044078,0.0007474630201,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"Having a bit of experience in spark, using Spacy with spark will always be tricky as the stringstore will evolve differently in all the workers so a string converted to an int will not necessarily be equivalent to the same int on another worker.",Solution Discussion,245,245,0.25,0.4121863799,0.1131980914,0.8868019086,0.7333333333,0.2875816993,0.0007474630201,1.62E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,So any shuffling of Spacy data across nodes will result in strange things.,Solution Discussion,74,74,0.5,0.4157706093,0.1131980914,0.8868019086,0.2166666667,0.08496732026,0.0007474630201,1.62E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Knowing this, serializing the English instance is of little interest.",Solution Discussion,69,69,0.75,0.4193548387,0.1131980914,0.8868019086,0.1666666667,0.06535947712,0.0007474630201,1.62E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"To avoid dependency hell (making sure the same version of spacy and it's data is installed on each node), a much better approach would be to broadcast the library and the data models as broadcast objec (which takes less space and is sent as a torrent file)t, un-serialize them in a temp directory and lazy load them from there.",Solution Discussion,327,327,1,0.4229390681,0.1131980914,0.8868019086,1,0.3921568627,0.0007474630201,1.62E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"That's a problem for some usages, yes.",Solution Discussion,38,38,0.1666666667,0.4265232975,0.1132038136,0.8867961864,0.2,0.04575163399,1.62E-05,2.22E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"But the tokenizer is over 100x faster than the rest of the library, so you can simply tokenize all the text in a single process, to initialize the CODE before you send out the batches.",Solution Discussion,193,184,0.3333333333,0.4301075269,0.1132038136,0.8867961864,1,0.2287581699,1.62E-05,2.22E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,There will also be use-cases where you only care that the activity on each shard is internally consistent.,Solution Discussion,106,106,0.5,0.4336917563,0.1132038136,0.8867961864,0.5428571429,0.1241830065,1.62E-05,2.22E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"For instance, if you want to just recognise entities and store them in textual form, you don't care that the CODE instances can diverge between your shards.",Motivation,165,156,0.6666666667,0.4372759857,0.1132038136,0.8867961864,0.7714285714,0.1764705882,1.62E-05,2.22E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,We think it's important to support Spark as best we can.,Solution Discussion,56,56,0.8333333333,0.4408602151,0.1132038136,0.8867961864,0.3142857143,0.07189542484,1.62E-05,2.22E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,We can at least pickle our data correctly :),Social Conversation,44,44,1,0.4444444444,0.1132038136,0.8867961864,0.2571428571,0.05882352941,1.62E-05,2.22E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I agree with both things you said, you could indeed tokenize all texts in one process before sending them out, but if you need to use Spark (and I mean need not want to because it's cool), chances are that this would still be blocking as all the data would have to go through a single node.",Solution Discussion,290,290,0.1428571429,0.4480286738,0.1132116388,0.8867883612,1,0.3725490196,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"And for your second use case, I still think that bundling the Spacy data and classes then lazy loading them would be easier than adding serialization to all your classes.",Solution Discussion,170,170,0.2857142857,0.4516129032,0.1132116388,0.8867883612,0.5263157895,0.1960784314,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'm saying that because before playing with Spacy on apache-storm, I painfully implemented a serializable nlp pipeline in scala on Spark.",Solution Discussion,137,137,0.4285714286,0.4551971326,0.1132116388,0.8867883612,0.3859649123,0.1437908497,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Extract from the [spark 1.6.0 manual] URL  CODE,Solution Discussion,330,47,0.5714285714,0.458781362,0.1132116388,0.8867883612,0.1578947368,0.05882352941,2.22E-05,2.36E-05,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"**edit** Also, Spacy uses compiled C-libraries that need to be installed on all the nodes.",Solution Discussion,90,90,0.7142857143,0.4623655914,0.1132116388,0.8867883612,0.2807017544,0.1045751634,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,So installing Spacy on all the machines and just packaging the data to be lazy-loaded seems the easiest solution to me.,Solution Discussion,119,119,0.8571428571,0.4659498208,0.1132116388,0.8867883612,0.3859649123,0.1437908497,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,[confer] URL,Solution Discussion,107,13,1,0.4695340502,0.1132116388,0.8867883612,0.0350877193,0.01307189542,2.22E-05,2.36E-05,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Hmm.,Social Conversation,4,4,0.5,0.4731182796,0.1132199653,0.8867800347,0.2,0.006535947712,2.36E-05,0.0654089151,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I do see your argument.,Social Conversation,23,23,1,0.476702509,0.1132199653,0.8867800347,1,0.03267973856,2.36E-05,0.0654089151,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"With the new improvements in loading time (down to 15s from about 100s), and the addition of multi-threading, I'm not nearly as keen on supporting in-memory pickling as I was before.",Solution Discussion,182,182,0.2,0.4802867384,0.1362602962,0.8637397038,0.75,0.2156862745,0.0654089151,0.02443361297,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I think @aborsu is right: the problem of serializing such that pickle can work is basically the same as the problem of loading from disk, so there's no reason to believe unpickling the classes would be faster than just loading them as new objects.",Solution Discussion,247,247,0.4,0.4838709677,0.1362602962,0.8637397038,1,0.2875816993,0.0654089151,0.02443361297,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The important thing is to have a workflow for users that want to use spaCy with a map/reduce framework like Spark.,Solution Discussion,114,114,0.6,0.4874551971,0.1362602962,0.8637397038,0.5,0.1437908497,0.0654089151,0.02443361297,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I think supporting the pickle protocol is not necessarily the best way to do that.,Solution Discussion,82,82,0.8,0.4910394265,0.1362602962,0.8637397038,0.3409090909,0.09803921569,0.0654089151,0.02443361297,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thoughts?,Solution Discussion,9,9,1,0.4946236559,0.1362602962,0.8637397038,0.02272727273,0.006535947712,0.0654089151,0.02443361297,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I also had issues with pickling with [SFrame] URL , which behaves similarly to how Spark has been described to work here.",Motivation,153,121,0.2,0.4982078853,0.1448670515,0.8551329485,0.8076923077,0.137254902,0.02443361297,0.06319984844,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"To avoid pickling and unpickling data that could just be read from disk (on a single machine), I've been using the following CODE proxy object.",Solution Discussion,151,143,0.4,0.5017921147,0.1448670515,0.8551329485,1,0.1699346405,0.02443361297,0.06319984844,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,CODE,Solution Discussion,770,4,0.6,0.5053763441,0.1448670515,0.8551329485,0.03846153846,0.006535947712,0.02443361297,0.06319984844,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"I had originally implemented the proxy using thread-local storage, but this works just as well for my purposes.",Solution Discussion,111,111,0.8,0.5089605735,0.1448670515,0.8551329485,0.7307692308,0.1241830065,0.02443361297,0.06319984844,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Just my 2Â¢...,Social Conversation,14,14,1,0.5125448029,0.1448670515,0.8551329485,0.1153846154,0.01960784314,0.02443361297,0.06319984844,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Hi guys,",Social Conversation,8,8,0.1111111111,0.5161290323,0.1671292372,0.8328707628,0.07692307692,0.01307189542,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Relative noob here looking for a recommendation.,Social Conversation,48,48,0.2222222222,0.5197132616,0.1671292372,0.8328707628,0.2692307692,0.04575163399,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"My goal: POS tag the English language Wikipedia dump (approx 23GB, maybe 3B words).",Motivation,83,83,0.3333333333,0.523297491,0.1671292372,0.8328707628,0.5769230769,0.09803921569,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Can someone tell me either:,Solution Discussion,27,27,0.4444444444,0.5268817204,0.1671292372,0.8328707628,0.1923076923,0.03267973856,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"A)         DON'T DO IT, go for something smaller; or",Solution Discussion,52,52,0.5555555556,0.5304659498,0.1671292372,0.8328707628,0.3846153846,0.06535947712,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,B)         A distillation of the above discussion into the current recommended workflow?,Solution Discussion,88,88,0.6666666667,0.5340501792,0.1671292372,0.8328707628,0.5,0.08496732026,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Unfortunately, I can't quite follow the conversation.",Social Conversation,53,53,0.7777777778,0.5376344086,0.1671292372,0.8328707628,0.2692307692,0.04575163399,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,P.S. Thanks Matthew for spaCy!,Social Conversation,30,30,0.8888888889,0.541218638,0.1671292372,0.8328707628,0.1923076923,0.03267973856,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'm using that and following your sense2vec implementation, with a few changes, to attempt the [word clustering that is mentioned on Google Code word2vec page] URL .",Motivation,205,165,1,0.5448028674,0.1671292372,0.8328707628,1,0.1699346405,0.06319984844,2.60E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I was planning on doing that until... I ran out of memory.,Solution Discussion,58,58,0.09090909091,0.5483870968,0.1671383829,0.8328616171,0.3157894737,0.07843137255,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I was using the scikit-learn word count module, so YMMV.",Solution Discussion,56,56,0.1818181818,0.5519713262,0.1671383829,0.8328616171,0.2894736842,0.07189542484,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"They also have a good implementation of word2vec, but it unfortunately the scikit pipeline does not always use iterators and would need quite a bit of memory (>24GB including paging when I tried a _much_ smaller dataset).",Solution Discussion,221,221,0.2727272727,0.5555555556,0.1671383829,0.8328616171,1,0.2483660131,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I recommend starting with something smaller, such as using only the Wikipedia page titles, to test out your pipeline.",Solution Discussion,117,117,0.3636363636,0.5591397849,0.1671383829,0.8328616171,0.5,0.1241830065,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Debugging would go more quickly too :+1:,Solution Discussion,40,40,0.4545454545,0.5627240143,0.1671383829,0.8328616171,0.1842105263,0.04575163399,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If you are on a Mac, you can enable multithreading per the instructions in #267 .",Solution Discussion,81,81,0.5454545455,0.5663082437,0.1671383829,0.8328616171,0.3947368421,0.09803921569,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This conversation is about distributing spacy over multiple machines.,Solution Discussion,69,69,0.6363636364,0.5698924731,0.1671383829,0.8328616171,0.2368421053,0.05882352941,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"The problem is not that it doesn't work, but that the distributed computing frameworks mentioned in this thread pickle and send over the spacy data models.",Solution Discussion,155,155,0.7272727273,0.5734767025,0.1671383829,0.8328616171,0.6842105263,0.1699346405,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,That could amount to several GB of data.,Solution Discussion,40,40,0.8181818182,0.5770609319,0.1671383829,0.8328616171,0.2105263158,0.0522875817,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Hope this helps!,Social Conversation,16,16,0.9090909091,0.5806451613,0.1671383829,0.8328616171,0.07894736842,0.01960784314,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Cheers.,Social Conversation,7,7,1,0.5842293907,0.1671383829,0.8328616171,0.02631578947,0.006535947712,2.60E-05,3.92E-06,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Tagging Wikipedia should be no problem.,Solution Discussion,39,39,0.2,0.5878136201,0.1671397646,0.8328602354,0.2068965517,0.03921568627,3.92E-06,4.69E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I haven't benchmarked the tagger in a while, but I think it should be running at over 100k tokens a second per process, and it doesn't use much memory.",Solution Discussion,151,151,0.4,0.5913978495,0.1671397646,0.8328602354,1,0.1895424837,3.92E-06,4.69E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,On a high compute node you should be done in a couple of hours.,Solution Discussion,63,63,0.6,0.5949820789,0.1671397646,0.8328602354,0.4827586207,0.09150326797,3.92E-06,4.69E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I've run the full pipeline on over ten times that much data, and I don't use Spark --- just simple multiprocessing, on a node with lots of cores.",Solution Discussion,145,145,0.8,0.5985663082,0.1671397646,0.8328602354,1,0.1895424837,3.92E-06,4.69E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Example script: https://github.com/spacy-io/spaCy/blob/master/examples/parallel_parse.py,Solution Discussion,88,88,1,0.6021505376,0.1671397646,0.8328602354,0.1034482759,0.01960784314,3.92E-06,4.69E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks both of you.,Social Conversation,19,19,0.3333333333,0.605734767,0.1671414152,0.8328585848,0.1212121212,0.02614379085,4.69E-06,7.98E-07,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I was thinking Spark because of the benchmarking on this [blog post] URL  suggested I'd be at it for about half a year (although I also may have misinterpreted the results).,Solution Discussion,227,173,0.6666666667,0.6093189964,0.1671414152,0.8328585848,1,0.2156862745,4.69E-06,7.98E-07,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Will continue onwards and let you know about my results when I get them!,Social Conversation,72,72,1,0.6129032258,0.1671414152,0.8328585848,0.4242424242,0.09150326797,4.69E-06,7.98E-07,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Second what @honnibal said.,Social Conversation,27,27,0.3333333333,0.6164874552,0.1671416964,0.8328583036,0.1904761905,0.02614379085,7.98E-07,0.0004388490277,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The issues I ran into were outside of spacy in doing the word count.,Solution Discussion,68,68,0.6666666667,0.6200716846,0.1671416964,0.8328583036,0.6666666667,0.09150326797,7.98E-07,0.0004388490277,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"You could try the [HashingVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.HashingVectorizer.html#sklearn.feature_extraction.text.HashingVectorizer) in sklearn, though I had issues with that too.",Solution Discussion,239,239,1,0.623655914,0.1671416964,0.8328583036,1,0.137254902,7.98E-07,0.0004388490277,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Hey @honnibal, before going onto AWS, I wanted to start small.",Solution Discussion,62,62,0.1428571429,0.6272401434,0.1672962813,0.8327037187,0.5789473684,0.07189542484,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I took your merge_text.py from the sense2vec implementation and trimmed it down.,Solution Discussion,80,80,0.2857142857,0.6308243728,0.1672962813,0.8327037187,0.6315789474,0.07843137255,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Running it on a pretty small input is taking a while.,Solution Discussion,53,53,0.4285714286,0.6344086022,0.1672962813,0.8327037187,0.5789473684,0.07189542484,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Can you see something that I'm doing wrong?,Solution Discussion,43,43,0.5714285714,0.6379928315,0.1672962813,0.8327037187,0.4210526316,0.0522875817,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Updated script and data file attached.,Solution Discussion,38,38,0.7142857143,0.6415770609,0.1672962813,0.8327037187,0.3157894737,0.03921568627,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'm on a 4 core 2011 MacBook Pro with 8GB RAM, so it shouldn't be the hardware.[Archive.zip] URL ",Solution Discussion,152,97,0.8571428571,0.6451612903,0.1672962813,0.8327037187,1,0.1241830065,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks!,Social Conversation,7,7,1,0.6487455197,0.1672962813,0.8327037187,0.05263157895,0.006535947712,0.0004388490277,6.25E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Seems to me that Parallel is doing the pickle thing mentioned in this thread.,Solution Discussion,77,77,0.08333333333,0.6523297491,0.1673183142,0.8326816858,0.6363636364,0.09150326797,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This means that each worker process will take a while to load all the data models.,Solution Discussion,82,82,0.1666666667,0.6559139785,0.1673183142,0.8326816858,0.7272727273,0.1045751634,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"On my MacBook Pro, each Python worker process uses between 800MB and 1.5GB.",Solution Discussion,75,75,0.25,0.6594982079,0.1673183142,0.8326816858,0.6818181818,0.09803921569,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I have 16GB physical memory and an SSD, so I don't notice paging as much.",Solution Discussion,73,73,0.3333333333,0.6630824373,0.1673183142,0.8326816858,0.7272727273,0.1045751634,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Apple didn't make SSD MBP in 2011, so it's probably going to be much slower for you.",Solution Discussion,84,84,0.4166666667,0.6666666667,0.1673183142,0.8326816858,0.7727272727,0.1111111111,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I stopped your script after spending a few minutes writing this post.,Solution Discussion,69,69,0.5,0.6702508961,0.1673183142,0.8326816858,0.5454545455,0.07843137255,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,The overhead of pickling and unpickling the spacy data models is significant.,Solution Discussion,77,77,0.5833333333,0.6738351254,0.1673183142,0.8326816858,0.5454545455,0.07843137255,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"As spacy itself is very fast, it would take huge batch sizes to make it worth it to use this multiprocessing model.",Solution Discussion,115,115,0.6666666667,0.6774193548,0.1673183142,0.8326816858,1,0.1437908497,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Instead, it would be significantly faster to use a single Python process and spacy's CODE multithreading API.",Solution Discussion,135,109,0.75,0.6810035842,0.1673183142,0.8326816858,0.7727272727,0.1111111111,6.25E-05,0.003166981448,NONE,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"On Linux, this is supported natively.",Solution Discussion,37,37,0.8333333333,0.6845878136,0.1673183142,0.8326816858,0.2727272727,0.03921568627,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"On Mac, you'll need to do a little more work (#267).",Solution Discussion,52,52,0.9166666667,0.688172043,0.1673183142,0.8326816858,0.5,0.07189542484,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I modified your script to not use Parallel and it ran to completion in seconds, single-threaded.",Solution Discussion,96,96,1,0.6917562724,0.1673183142,0.8326816858,0.7727272727,0.1111111111,6.25E-05,0.003166981448,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Would a different serialization format help here?,Solution Discussion,49,49,0.2,0.6953405018,0.1684338854,0.8315661146,0.4375,0.04575163399,0.003166981448,0.08051496432,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Pickle is heavyweight.,Solution Discussion,22,22,0.4,0.6989247312,0.1684338854,0.8315661146,0.1875,0.01960784314,0.003166981448,0.08051496432,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,There are many to choose from.,Solution Discussion,30,30,0.6,0.7025089606,0.1684338854,0.8315661146,0.375,0.03921568627,0.003166981448,0.08051496432,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I maintain the Python port of FlatBuffers, which is a serialization formatoptimized for minimal memory usage.",Solution Discussion,109,109,0.8,0.70609319,0.1684338854,0.8315661146,1,0.1045751634,0.003166981448,0.08051496432,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Happy to answer any questions.,Social Conversation,30,30,1,0.7096774194,0.1684338854,0.8315661146,0.3125,0.03267973856,0.003166981448,0.08051496432,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I ran into this issue too.,Bug Reproduction,26,26,0.1428571429,0.7132616487,0.1967953314,0.8032046686,0.3333333333,0.03921568627,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I'm trying to do some work on the text from Wiki Dump.,Motivation,54,54,0.2857142857,0.7168458781,0.1967953314,0.8032046686,0.6666666667,0.07843137255,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Using a Spark map function do_work.,Solution Discussion,35,35,0.4285714286,0.7204301075,0.1967953314,0.8032046686,0.3333333333,0.03921568627,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,As suggested here when I move English() inside the function it works but when it's outside it doesn't.,Solution Discussion,102,102,0.5714285714,0.7240143369,0.1967953314,0.8032046686,1,0.1176470588,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Python crashes.,Solution Discussion,15,15,0.7142857143,0.7275985663,0.1967953314,0.8032046686,0.1111111111,0.01307189542,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But instantiating English() in every function call makes it super slow and practically useless.,Solution Discussion,95,95,0.8571428571,0.7311827957,0.1967953314,0.8032046686,0.7777777778,0.09150326797,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,CODE,Solution Discussion,84,4,1,0.7347670251,0.1967953314,0.8032046686,0.05555555556,0.006535947712,0.08051496432,0.0003125363162,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,I really need to write a blog post/tutorial on working with large jobs.,Social Conversation,71,71,0.05882352941,0.7383512545,0.1969054225,0.8030945775,0.35,0.09150326797,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I think at the moment this is quite confusing.,Social Conversation,46,46,0.1176470588,0.7419354839,0.1969054225,0.8030945775,0.225,0.05882352941,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"I'm grateful to @mikepb , @aborsu and others for their contributions to the discussion here.",Social Conversation,92,92,0.1764705882,0.7455197133,0.1969054225,0.8030945775,0.35,0.09150326797,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"In future more of the pipeline will be multi-threaded, so I'd recommend using this construction even if you're just using the tokenizer and tagger, which are currently single-threaded (they're very fast though --- and load much quicker.)",Solution Discussion,237,237,0.2352941176,0.7491039427,0.1969054225,0.8030945775,1,0.2614379085,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"A much better improvement will be gained if you can manage to reuse the same CODE object across more text, i.e. if you can increase the size of your batches of documents.",Solution Discussion,171,170,0.2941176471,0.752688172,0.1969054225,0.8030945775,0.8,0.2091503268,0.0003125363162,0.0005700212555,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"To summarize the deeper issue as I understand it: the ultimate dream is to have CODE ""Just Work"", without having to deal with the details of how work is allocated to physical machines, let alone individual processes or threads.",Expected Behaviour,272,227,0.3529411765,0.7562724014,0.1969054225,0.8030945775,0.975,0.2549019608,0.0003125363162,0.0005700212555,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"Unfortunately, with spaCy (and probably with lots of other situations), the constants really matter.",Solution Discussion,100,100,0.4117647059,0.7598566308,0.1969054225,0.8030945775,0.35,0.09150326797,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Loading the spaCy models takes about as much time as processing 1,000 documents (at ~200 tokens each).",Solution Discussion,102,102,0.4705882353,0.7634408602,0.1969054225,0.8030945775,0.425,0.1111111111,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This means you have to somehow manually manage the chunk size.,Solution Discussion,62,62,0.5294117647,0.7670250896,0.1969054225,0.8030945775,0.275,0.07189542484,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,You have to somehow help Spark schedule the work in larger increments.,Solution Discussion,70,70,0.5882352941,0.770609319,0.1969054225,0.8030945775,0.3,0.07843137255,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If you have your data already split out into large files, e.g. by month, then it might be enough to have each process work on one month of data.",Solution Discussion,144,144,0.6470588235,0.7741935484,0.1969054225,0.8030945775,0.725,0.1895424837,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"In this situation, we can make CODE work transparently, which is nice.",Solution Discussion,116,70,0.7058823529,0.7777777778,0.1969054225,0.8030945775,0.3,0.07843137255,0.0003125363162,0.0005700212555,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"But if what you have is a collection of texts, not a collection of larger archives, you have to think about the details a bit more.",Solution Discussion,131,131,0.7647058824,0.7813620072,0.1969054225,0.8030945775,0.65,0.1699346405,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"My main advice would be to not assume that Spark, Hadoop etc are automatically better than using a single machine and using multiple processes with spaCy's CODE method for multithreading.",Solution Discussion,192,187,0.8235294118,0.7849462366,0.1969054225,0.8030945775,0.75,0.1960784314,0.0003125363162,0.0005700212555,MEMBER,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,"In the worst case, if you had a chunk size of 1, you could use a thousand node cluster and have your job complete slower than it would on a Macbook Air.",Solution Discussion,152,152,0.8823529412,0.7885304659,0.1969054225,0.8030945775,0.8,0.2091503268,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"So, if your process is slow, it might be worth taking a closer look and checking that you're at least doing around 10,000 tokens per thread per second.",Solution Discussion,151,151,0.9411764706,0.7921146953,0.1969054225,0.8030945775,0.7,0.1830065359,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"If you're doing an order of magnitude less than that, then either the problem is outside of spaCy, or the work isn't being scheduled effectively.",Solution Discussion,145,145,1,0.7956989247,0.1969054225,0.8030945775,0.625,0.1633986928,0.0003125363162,0.0005700212555,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks @honnibal for your advice.,Social Conversation,33,33,0.125,0.7992831541,0.1971062128,0.8028937872,0.2777777778,0.03267973856,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I've been trying to do NLP with Spark with NLTK and Stanford and etc.,Motivation,69,69,0.25,0.8028673835,0.1971062128,0.8028937872,0.8333333333,0.09803921569,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But their objects are big and not serializable.,Motivation,47,47,0.375,0.8064516129,0.1971062128,0.8028937872,0.4444444444,0.0522875817,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I really like Spacy's simple and all in one approach.,Motivation,53,53,0.5,0.8100358423,0.1971062128,0.8028937872,0.5555555556,0.06535947712,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It's close integration with Spark will be a great advantage for many researchers.,Motivation,81,81,0.625,0.8136200717,0.1971062128,0.8028937872,0.7222222222,0.08496732026,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,As you mentioned that would be heaven to see this code just work: CODE,Motivation,976,70,0.75,0.8172043011,0.1971062128,0.8028937872,0.7777777778,0.09150326797,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,So far it looks like using Spacy pipe without Spark is the fastest option to do the job.,Solution Discussion,88,88,0.875,0.8207885305,0.1971062128,0.8028937872,1,0.1176470588,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I will feed Spark with processed data for the rest of the work.,Social Conversation,63,63,1,0.8243727599,0.1971062128,0.8028937872,0.7222222222,0.08496732026,0.0005700212555,0.00195977348,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It might be off topic but @mikepb mentioned with CODE we can see a lot of improvement in speed.,Solution Discussion,127,95,0.25,0.8279569892,0.1977965443,0.8022034557,1,0.1241830065,0.00195977348,8.96E-06,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,But I'm not gaining speed using pipe.,Solution Discussion,37,37,0.5,0.8315412186,0.1977965443,0.8022034557,0.3684210526,0.04575163399,0.00195977348,8.96E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I suspect that I have to enable multi-threading using OpenMP.,Solution Discussion,61,61,0.75,0.835125448,0.1977965443,0.8022034557,0.5789473684,0.07189542484,0.00195977348,8.96E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But I couldn't find any instructions to do that on Windows.,Solution Discussion,59,59,1,0.8387096774,0.1977965443,0.8022034557,0.5789473684,0.07189542484,0.00195977348,8.96E-06,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Yes, you would need OpenMP to enable multithreading.",Solution Discussion,52,52,0.1666666667,0.8422939068,0.1977996988,0.8022003012,0.6153846154,0.0522875817,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It's tricky to get right:,Solution Discussion,25,25,0.3333333333,0.8458781362,0.1977996988,0.8022003012,0.3846153846,0.03267973856,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,-         See #267 and #266 for info on using OpenMP on OS X.,Solution Discussion,61,61,0.5,0.8494623656,0.1977996988,0.8022003012,1,0.08496732026,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It's wonderful when it works though!,Social Conversation,36,36,0.6666666667,0.853046595,0.1977996988,0.8022003012,0.4615384615,0.03921568627,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I believe Microsoft has implemented OpenMP in Visual Studio.,Solution Discussion,60,60,0.8333333333,0.8566308244,0.1977996988,0.8022003012,0.6923076923,0.05882352941,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I'm wholly unfamiliar with Windows development...,Social Conversation,49,49,1,0.8602150538,0.1977996988,0.8022003012,0.4615384615,0.03921568627,8.96E-06,0.0009535759306,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"@mikepb Normally, you don't have to do anything special on Windows, it's trickier on OS X because Apple's default clang doesn't support OpenMP, yet. MSVC does, though.",Solution Discussion,167,167,1,0.8637992832,0.1981355965,0.8018644035,1,0.1764705882,0.0009535759306,0.002396331593,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,@henningpeters I managed to compile and run pipe with OpenMP support.,Solution Discussion,69,69,0.09090909091,0.8673835125,0.1989797058,0.8010202942,0.4074074074,0.07189542484,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It looks beautiful when it utilizes all CPU cores.,Social Conversation,50,50,0.1818181818,0.8709677419,0.1989797058,0.8010202942,0.3333333333,0.05882352941,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,OpenMP support is by default disabled for MSVC.,Solution Discussion,47,47,0.2727272727,0.8745519713,0.1989797058,0.8010202942,0.2962962963,0.0522875817,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I added the compiler option to the setup file and committed the changes to the master branch.,Solution Discussion,93,93,0.3636363636,0.8781362007,0.1989797058,0.8010202942,0.6296296296,0.1111111111,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I'm surprised nobody is using Windows it seems.,Social Conversation,47,47,0.4545454545,0.8817204301,0.1989797058,0.8010202942,0.2962962963,0.0522875817,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But with that switch enabled next releases will work properly on Windows,Task Progress,72,72,0.5454545455,0.8853046595,0.1989797058,0.8010202942,0.4444444444,0.07843137255,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,@honnibal What you mentioned about some parts of the pipeline multi-threaded made a lot more sense after I managed to use pipe in multi-threaded scenario.,Solution Discussion,154,154,0.6363636364,0.8888888889,0.1989797058,0.8010202942,1,0.1764705882,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,But it also seems single-threaded parts of the pipeline take almost the same time as the multi-threaded parts.,Solution Discussion,110,110,0.7272727273,0.8924731183,0.1989797058,0.8010202942,0.7407407407,0.1307189542,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,That would make it a lot faster if those single threads also support multithreaded.,Solution Discussion,83,83,0.8181818182,0.8960573477,0.1989797058,0.8010202942,0.5185185185,0.09150326797,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I attach my CPU usage here. It's clear the single threads play some role in the time it takes to finish the job.,Solution Discussion,112,112,0.9090909091,0.8996415771,0.1989797058,0.8010202942,0.8518518519,0.1503267974,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,![pipe_performance] URL,Solution Discussion,121,24,1,0.9032258065,0.1989797058,0.8010202942,0.07407407407,0.01307189542,0.002396331593,0.0001526929426,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Tricky,Social Conversation,6,6,0.5,0.9068100358,0.199033492,0.800966508,1,0.006535947712,0.0001526929426,0.0007126827681,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,:+1:,Social Conversation,4,4,1,0.9103942652,0.199033492,0.800966508,1,0.006535947712,0.0001526929426,0.0007126827681,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Oh, seems we overlooked msvc's openmp option.",Social Conversation,45,45,0.25,0.9139784946,0.1992845349,0.8007154651,1,0.04575163399,0.0007126827681,0.00591569739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks,Social Conversation,6,6,0.5,0.917562724,0.1992845349,0.8007154651,0.1428571429,0.006535947712,0.0007126827681,0.00591569739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks @sjjpo2002 for your PR!,Action on Issue,30,30,0.75,0.9211469534,0.1992845349,0.8007154651,0.7142857143,0.03267973856,0.0007126827681,0.00591569739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Just merged it.,Action on Issue,15,15,1,0.9247311828,0.1992845349,0.8007154651,0.4285714286,0.01960784314,0.0007126827681,0.00591569739,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,It seems the CODE option is not available for some(?) Visual Studio express editions.,Solution Discussion,90,85,0.25,0.9283154122,0.201368343,0.798631657,0.6086956522,0.09150326797,0.00591569739,0.00137409764,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
13 125_spaCy.doc,That means many/most(?) Windows users won't be able to install spaCy anymore from source for free.,Solution Discussion,98,98,0.5,0.9318996416,0.201368343,0.798631657,0.7391304348,0.1111111111,0.00591569739,0.00137409764,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"There seems to exist a workaround  URL , but it's not something I'd like to put in our getting-started install guide.",Solution Discussion,193,117,0.75,0.935483871,0.201368343,0.798631657,1,0.1503267974,0.00591569739,0.00137409764,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Hence, I think we should make OpenMP support on Windows optional for now.",Solution Discussion,73,73,1,0.9390681004,0.201368343,0.798631657,0.5652173913,0.08496732026,0.00591569739,0.00137409764,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Microsoft Visual C++ Compiler for Python is [free ] URL for eveyone and it supports openmp.,Solution Discussion,150,91,1,0.9426523297,0.2018523698,0.7981476302,1,0.09803921569,0.00137409764,1.09E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Thanks, do you know whether this also works for Python 3.4/3.5?",Solution Discussion,63,63,0.5,0.9462365591,0.201856209,0.798143791,0.6470588235,0.07189542484,1.09E-05,6.51E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,We need to have a solution in place that works as seamless as possible across all environments.,Solution Discussion,95,95,1,0.9498207885,0.201856209,0.798143791,1,0.1111111111,1.09E-05,6.51E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I never tried it on Python 3.x. But a quick check for /openmp [here] URL  it is supported on VS 2010 ans 2015. For Python 3.4 using VS 2010 and for 3.5 VS 2015 are [suggested] URL .,Solution Discussion,329,181,0.3333333333,0.9534050179,0.2018791345,0.7981208655,1,0.2483660131,6.51E-05,4.38E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"But, I agree that it should be tested on all platforms.",Social Conversation,55,55,0.6666666667,0.9569892473,0.2018791345,0.7981208655,0.2894736842,0.07189542484,6.51E-05,4.38E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Maybe I do it over the weekend.,Social Conversation,31,31,1,0.9605734767,0.2018791345,0.7981208655,0.1842105263,0.04575163399,6.51E-05,4.38E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,My reading about it so far is that MS only provides support for OpenMP in VS professional editions or higher.,Solution Discussion,109,109,0.3333333333,0.9641577061,0.2018945648,0.7981054352,0.6060606061,0.1307189542,4.38E-05,0.1692698285,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Here's the error output from VS 2010 express edition: https://ci.spacy.io/builders/spacy-win64-py34-64-install/builds/98/steps/shell_2/logs/stdio.,Solution Discussion,146,146,0.6666666667,0.9677419355,0.2018945648,0.7981054352,0.303030303,0.06535947712,4.38E-05,0.1692698285,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"It might be possible to make it work as I suggested above, but so far I haven't seen a simple install instruction I would like to keep as default for spaCy all users.",Solution Discussion,166,166,1,0.9713261649,0.2018945648,0.7981054352,1,0.2156862745,4.38E-05,0.1692698285,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,I think this is relevant: https://github.com/spacy-io/spaCy/issues/413,Potential New Issues and Requests,70,70,1,0.9749103943,0.2615199667,0.7384800333,1,0.03921568627,0.1692698285,1,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Closing this and making #1045 the master issue.,Action on Issue,47,47,0.5,0.9784946237,0.6137705859,0.3862294141,1,0.0522875817,1,0.5841431139,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Work in progress for spaCy v2.0!,Task Progress,32,32,1,0.982078853,0.6137705859,0.3862294141,0.75,0.03921568627,1,0.5841431139,MEMBER,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,"Dears,Is this issue resolved with the release of spacy 2.0.",Task Progress,59,59,0.3333333333,0.9856630824,0.8195353595,0.1804646405,1,0.07189542484,0.5841431139,0.5123188737,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,How can I use spacy in Spark?,Usage,29,29,0.6666666667,0.9892473118,0.8195353595,0.1804646405,0.6363636364,0.04575163399,0.5841431139,0.5123188737,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,Thanks for your help.,Social Conversation,21,21,1,0.9928315412,0.8195353595,0.1804646405,0.3636363636,0.02614379085,0.5841431139,0.5123188737,NONE,FALSE,FALSE,FALSE,FALSE
13 125_spaCy.doc,This thread has been automatically locked since there has not been any recent activity after it was closed.,Action on Issue,107,107,1,0.9964157706,1,0,18,0.1176470588,0.5123188737,0,NONE,FALSE,FALSE,FALSE,TRUE
13 125_spaCy.doc,Please open a new issue for related bugs.,Action on Issue,41,41,2,1,1,0,8,0.0522875817,0.5123188737,0,NONE,FALSE,FALSE,FALSE,TRUE
14 6665_scikit-learn.doc,t-SNE fails with array must not contain infs or NaNs (OSX specific),Observed Bug Behaviour,67,67,0.2,0.003144654088,0,1,1,0.1780821918,0,0.0002726161379,NONE,TRUE,FALSE,TRUE,FALSE
14 6665_scikit-learn.doc,CODE,Observed Bug Behaviour,219,4,0.4,0.006289308176,0,1,0.07692307692,0.01369863014,0,0.0002726161379,NONE,TRUE,TRUE,TRUE,FALSE
14 6665_scikit-learn.doc,When trying to run a t-SNE CODE,Observed Bug Behaviour,110,31,0.6,0.009433962264,0,1,0.6153846154,0.1095890411,0,0.0002726161379,NONE,TRUE,TRUE,TRUE,FALSE
14 6665_scikit-learn.doc,However CODE,Observed Bug Behaviour,91,12,0.8,0.01257861635,0,1,0.1538461538,0.02739726027,0,0.0002726161379,NONE,TRUE,TRUE,TRUE,FALSE
14 6665_scikit-learn.doc,Full Stack Trace: CODE,Observed Bug Behaviour,2528,22,1,0.01572327044,0,1,0.3076923077,0.05479452055,0,0.0002726161379,NONE,TRUE,TRUE,TRUE,FALSE
14 6665_scikit-learn.doc,"Same with ('Scikit-Learn', '0.18.dev0')",Bug Reproduction,39,39,1,0.01886792453,4.68E-05,0.9999532016,1,0.06849315068,0.0002726161379,0.02136065067,NONE,TRUE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Do you mind sharing your data X with me?,Bug Reproduction,40,40,1,0.02201257862,0.003713653838,0.9962863462,1,0.1232876712,0.02136065067,0.0008763847724,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Sure, where and in what format would you like it?",Bug Reproduction,49,49,1,0.0251572327,0.003864097583,0.9961359024,1,0.1369863014,0.0008763847724,8.51E-05,NONE,TRUE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,My email is 370846270@qq.com,Bug Reproduction,28,28,0.5,0.02830188679,0.003878707231,0.9961212928,0.2105263158,0.05479452055,8.51E-05,0.007997893245,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"As i know, there is a function numpy.save for saving an array to a binary file in .npy format~~",Bug Reproduction,95,95,1,0.03144654088,0.003878707231,0.9961212928,1,0.2602739726,8.51E-05,0.007997893245,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I test your data in ubuntu 14.04 LTS withPython==2.7.6scikit-learn==0.17.1numpy==1.8.2scipy==0.13.3,Bug Reproduction,99,99,0.25,0.03459119497,0.005251657845,0.9947483422,0.4761904762,0.1369863014,0.007997893245,0.2771530517,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,It is fine and doesn't raise the ValueError.,Bug Reproduction,44,44,0.5,0.03773584906,0.005251657845,0.9947483422,0.380952381,0.1095890411,0.007997893245,0.2771530517,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The test code is:CODE,Bug Reproduction,332,21,0.75,0.04088050314,0.005251657845,0.9947483422,0.2380952381,0.06849315068,0.007997893245,0.2771530517,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Then i upgrade numpy, scipy to 1.11.0, 0.17.0 and test with the same code and it also doesn't raise any error.",Bug Reproduction,110,110,1,0.04402515723,0.005251657845,0.9947483422,1,0.2876712329,0.007997893245,0.2771530517,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Reproduced for 3.5 with anaconda under OS X El Capitan.,Bug Reproduction,55,55,0.3333333333,0.04716981132,0.05282886859,0.9471711314,1,0.1369863014,0.2771530517,0.0003346120921,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Bug Reproduction,102,4,0.6666666667,0.05031446541,0.05282886859,0.9471711314,0.1,0.01369863014,0.2771530517,0.0003346120921,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Example run: CODE,Bug Reproduction,159,17,1,0.0534591195,0.05282886859,0.9471711314,0.3,0.04109589041,0.2771530517,0.0003346120921,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Thanks @ivan-krukov, but I'm failing to replicate in Python 3.3.",Bug Reproduction,64,64,0.5,0.05660377358,0.05288630945,0.9471136905,1,0.1506849315,0.0003346120921,0.004970747043,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Will try 3.5,Bug Reproduction,12,12,1,0.05974842767,0.05288630945,0.9471136905,0.2727272727,0.04109589041,0.0003346120921,0.004970747043,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"This does not apply to CODE (4.4.0-21, Ubuntu 16.04) with the same packages under 3.5.",Bug Reproduction,89,86,1,0.06289308176,0.05373960794,0.9462603921,1,0.2191780822,0.004970747043,0.003152245181,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I'm on El-Capitan, but I'm failing to get a Python 3.5 installation up and running.",Bug Reproduction,83,83,1,0.06603773585,0.05428073506,0.9457192649,1,0.2191780822,0.003152245181,0.247501826,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Is there any update on this?,Task Progress,28,28,0.3333333333,0.06918238994,0.0967678968,0.9032321032,0.3333333333,0.08219178082,0.247501826,0.008713891162,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I have the issue on a dataset of mine, on Anaconda, Py 3.5, sklearn 0.17.1, OSX El Capitan.",Bug Reproduction,91,91,0.6666666667,0.07232704403,0.0967678968,0.9032321032,1,0.2465753425,0.247501826,0.008713891162,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I can reproduce the error with the example provided by @ivan-krukov .,Bug Reproduction,69,69,1,0.07547169811,0.0967678968,0.9032321032,0.6666666667,0.1643835616,0.247501826,0.008713891162,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Same issue.,Bug Reproduction,11,11,0.3333333333,0.0786163522,0.09826375851,0.9017362415,0.1428571429,0.02739726027,0.008713891162,0.07295885932,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Python 2.7.6 on OS X El Capitan on 0.17.,Bug Reproduction,40,40,0.6666666667,0.08176100629,0.09826375851,0.9017362415,0.6428571429,0.1232876712,0.008713891162,0.07295885932,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Tried the same code on Linux using Python 2.7.6 and 0.17, and it works.",Bug Reproduction,71,71,1,0.08490566038,0.09826375851,0.9017362415,1,0.1917808219,0.008713891162,0.07295885932,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Same issue.,Bug Reproduction,11,11,0.5,0.08805031447,0.1107881706,0.8892118294,0.3333333333,0.02739726027,0.07295885932,0.0628243198,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,OSX El Capitan Python 3.5.1scikit-learn==0.17.1scipy==0.17.1,Bug Reproduction,60,60,1,0.09119496855,0.1107881706,0.8892118294,1,0.08219178082,0.07295885932,0.0628243198,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I have the same problem and would really appreciate a fix (or workaround?),Bug Reproduction,74,74,0.3333333333,0.09433962264,0.1215728467,0.8784271533,1,0.1780821918,0.0628243198,0.03406414755,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,System Version: OS X 10.11.5Python 3.5.1 :: Anaconda 4.0.0 (x86_64)numpy.version.version 1.11.0scipy.version 0.17.1sklearn.**version** 0.17.1,Bug Reproduction,141,141,0.6666666667,0.09748427673,0.1215728467,0.8784271533,0.9230769231,0.1643835616,0.0628243198,0.03406414755,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I can also reproduce the bug with the code sample from ivan-krukov,Bug Reproduction,66,66,1,0.1006289308,0.1215728467,0.8784271533,1,0.1780821918,0.0628243198,0.03406414755,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Same issue on OS X EI Capitan using Python 3.5,Bug Reproduction,46,46,1,0.1037735849,0.1274204357,0.8725795643,1,0.1369863014,0.03406414755,0.1585619872,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"System Version: OS X 10.11.5Python 3.5.1 :: Continuum Analytics, Inc.numpy.**version** 1.11.1scipy.**version** 0.16.0sklearn.**version** 0.17.1",Bug Reproduction,143,143,0.25,0.106918239,0.154639826,0.845360174,0.5,0.1643835616,0.1585619872,5.56E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Same problem.,Bug Reproduction,13,13,0.5,0.1100628931,0.154639826,0.845360174,0.08333333333,0.02739726027,0.1585619872,5.56E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Though I have noticed that **it only occurs for a subset of my dataset and not with the whole thing**.,Investigation and Exploration,102,102,0.75,0.1132075472,0.154639826,0.845360174,0.8333333333,0.2739726027,0.1585619872,5.56E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"That is, if I do TSNE on the whole data set it **works**, if I do it on a reduced set it does not.",Investigation and Exploration,98,98,1,0.1163522013,0.154639826,0.845360174,1,0.3287671233,0.1585619872,5.56E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,O_o;;,Social Conversation,5,5,0.2,0.1194968553,0.1546493757,0.8453506243,0.05263157895,0.01369863014,5.56E-05,0.007793915485,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"This just in, if I repeat the same 'broken' subset that doesn't work(by means of list*10) then it works.",Investigation and Exploration,104,104,0.4,0.1226415094,0.1546493757,0.8453506243,1,0.2602739726,5.56E-05,0.007793915485,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Multiplying each individual vector by 10 doesn't work, but duplicating the date does.",Investigation and Exploration,85,85,0.6,0.1257861635,0.1546493757,0.8453506243,0.6842105263,0.1780821918,5.56E-05,0.007793915485,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,just doubling the length of the list is insufficient.,Investigation and Exploration,53,53,0.8,0.1289308176,0.1546493757,0.8453506243,0.4736842105,0.1232876712,5.56E-05,0.007793915485,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Maybe this is some kind of degrees of freedom check run amok?,Investigation and Exploration,61,61,1,0.1320754717,0.1546493757,0.8453506243,0.6315789474,0.1643835616,5.56E-05,0.007793915485,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@ivan-krukov I bit the bullet today and installed an El Capitan VM.,Bug Reproduction,67,67,0.3333333333,0.1352201258,0.1559873107,0.8440126893,0.9285714286,0.1780821918,0.007793915485,0.0003311524965,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Unfortunately I can not reproduce your problem.,Bug Reproduction,47,47,0.6666666667,0.1383647799,0.1559873107,0.8440126893,0.5,0.09589041096,0.007793915485,0.0003311524965,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@Concomitant can you reproduce the error on the stand-alone example given in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction,157,157,1,0.141509434,0.1559873107,0.8440126893,1,0.1917808219,0.007793915485,0.0003311524965,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@jnothman it doesn't seem to be happening only on Python 3.5 so if you could try to reproduce with Python 2.7 (snippet: https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) that would be great.,Bug Reproduction,221,221,1,0.1446540881,0.1560441576,0.8439558424,1,0.3698630137,0.0003311524965,0.001746127121,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve I can reproduce the issue.,Bug Reproduction,35,35,0.25,0.1477987421,0.1563439049,0.8436560951,1,0.08219178082,0.001746127121,0.05890874943,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Bug Reproduction,1226,4,0.5,0.1509433962,0.1563439049,0.8436560951,0.1666666667,0.01369863014,0.001746127121,0.05890874943,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Following the same code, however: CODE",Bug Reproduction,357,38,0.75,0.1540880503,0.1563439049,0.8436560951,1,0.08219178082,0.001746127121,0.05890874943,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Bizarre.,Social Conversation,8,8,1,0.1572327044,0.1563439049,0.8436560951,0.1666666667,0.01369863014,0.001746127121,0.05890874943,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I cannot reproduce either with python 3.5.1, numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1 from miniconda (with MKL) on a virtualbox with OSX El Capitan.",Bug Reproduction,158,158,0.5,0.1603773585,0.1664564184,0.8335435816,1,0.3698630137,0.05890874943,8.59E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I will try on a real mac hardware later.,Bug Reproduction,40,40,1,0.1635220126,0.1664564184,0.8335435816,0.3333333333,0.1232876712,0.05890874943,8.59E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Also @joelkuiper and @Concomitant can you please check that you can reproduce the problem on the current state of the scikit-learn master branch?,Bug Reproduction,145,145,1,0.1666666667,0.1664711706,0.8335288294,1,0.3287671233,8.59E-05,0.0002442474535,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve and others I cannot reproduce the error with the [snippet posted earlier](https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487) on the latest master with python 2.7.,Bug Reproduction,201,201,0.5,0.1698113208,0.1665130991,0.8334869009,1,0.3561643836,0.0002442474535,0.008272861908,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,System info: CODE,Bug Reproduction,229,17,1,0.1729559748,0.1665130991,0.8334869009,0.1153846154,0.04109589041,0.0002442474535,0.008272861908,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I tried again on a real mac running OSX El Capitan 10.11.3 (with anaconda's latest numpy scipy and scikit-learn, same setting as reported by @Concomitant in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-229703129) but could not reproduce the problem either (tried running the snippet several times).",Bug Reproduction,323,323,0.3333333333,0.1761006289,0.1679332519,0.8320667481,1,0.5616438356,0.008272861908,0.002433479587,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,What is weird though it that the despite the CODE line I get different results for the output of CODE.,Investigation and Exploration,128,102,0.6666666667,0.179245283,0.1679332519,0.8320667481,0.487804878,0.2739726027,0.008272861908,0.002433479587,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,This might be a bug in itself.,Investigation and Exploration,30,30,1,0.1823899371,0.1679332519,0.8320667481,0.1707317073,0.09589041096,0.008272861908,0.002433479587,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Actually I read @Concomitant's code snippet too quickly:,Bug Reproduction,56,56,0.5,0.1855345912,0.1683509928,0.8316490072,0.3636363636,0.1095890411,0.002433479587,8.16E-06,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,instead of CODE it should be CODE otherwise the numpy RNG is not reseeded appropriately and one cannot get deterministic results.,Bug Reproduction,156,129,1,0.1886792453,0.1683509928,0.8316490072,1,0.301369863,0.002433479587,8.16E-06,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Also I now realized that I read the whole discussion too quickly and that the bug only happens with python 2.7.,Bug Reproduction,111,111,0.5,0.1918238994,0.1683523944,0.8316476056,1,0.2876712329,8.16E-06,9.77E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Will try again.,Bug Reproduction,15,15,1,0.1949685535,0.1683523944,0.8316476056,0.1428571429,0.04109589041,8.16E-06,9.77E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I cannot reproduce either with python 2.7.12 from conda on OSX 10.11.3 either.,Bug Reproduction,78,78,0.3333333333,0.1981132075,0.1683691658,0.8316308342,0.6363636364,0.1917808219,9.77E-05,0.000240649474,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Actually @Ekliptor can reproduce the issue with python 3.5.1 from conda so it's probably not related to the version of Python either.,Investigation and Exploration,133,133,0.6666666667,0.2012578616,0.1683691658,0.8316308342,1,0.301369863,9.77E-05,0.000240649474,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Maybe it depends on the minor version of OSX.,Investigation and Exploration,45,45,1,0.2044025157,0.1683691658,0.8316308342,0.4090909091,0.1232876712,9.77E-05,0.000240649474,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I cannot replicate either with OSX 10.11.5.,Bug Reproduction,43,43,0.25,0.2075471698,0.1684104767,0.8315895233,0.1818181818,0.1095890411,0.000240649474,0.05891636054,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I tried both with Python 2.7.12 and 3.5.2 installed with conda along with numpy 1.11.1, scipy 0.17.1 and scikit-learn 0.17.1.",Bug Reproduction,125,125,0.5,0.2106918239,0.1684104767,0.8315895233,0.4772727273,0.2876712329,0.000240649474,0.05891636054,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I don't know what to do.,Social Conversation,24,24,0.75,0.213836478,0.1684104767,0.8315895233,0.1363636364,0.08219178082,0.000240649474,0.05891636054,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"If one of you can reproduce the problem, please try to find a numpy random seed that trigger the issue (using CODE instead of CODE in the above snippet) and communicate the value here (along with the version of OSX and you python packages).",Investigation and Exploration,273,240,1,0.2169811321,0.1684104767,0.8315895233,1,0.602739726,0.000240649474,0.05891636054,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,I can not reproduce it anymore as before.,Bug Reproduction,41,41,0.2,0.2201257862,0.1785242968,0.8214757032,0.4444444444,0.1095890411,0.05891636054,0.0003516333028,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I only updated numpy:numpy.version.version 1.11.1,Solution Discussion,49,49,0.4,0.2232704403,0.1785242968,0.8214757032,0.3333333333,0.08219178082,0.05891636054,0.0003516333028,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,To all people working with Tensorflow I can add:,Solution Discussion,48,48,0.6,0.2264150943,0.1785242968,0.8214757032,0.5,0.1232876712,0.05891636054,0.0003516333028,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,When I try to plot a very small sample (< 200 points) I sometimes still run into this error.,Solution Discussion,92,92,0.8,0.2295597484,0.1785242968,0.8214757032,1,0.2465753425,0.05891636054,0.0003516333028,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,After increasing the sample size I pass into tsne.fit_transform() it always works.,Solution Discussion,82,82,1,0.2327044025,0.1785242968,0.8214757032,0.6666666667,0.1643835616,0.05891636054,0.0003516333028,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@joelkuiper and @Concomitant do you confirm that scikit-learn master also work for you?,Solution Discussion,87,87,0.5,0.2358490566,0.1785846596,0.8214153404,1,0.1917808219,0.0003516333028,0.0009277251719,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,If so we can close this issue.,Action on Issue,30,30,1,0.2389937107,0.1785846596,0.8214153404,0.5,0.09589041096,0.0003516333028,0.0009277251719,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I installed master, the code snippet runs cleanly now.",Solution Discussion,54,54,1,0.2421383648,0.1787439166,0.8212560834,1,0.1232876712,0.0009277251719,0.2064171901,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,seems to work for everybody now.,Task Progress,32,32,0.5,0.2452830189,0.214178324,0.785821676,1,0.08219178082,0.2064171901,0.04731273831,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,closing.,Action on Issue,8,8,1,0.248427673,0.214178324,0.785821676,0.1666666667,0.01369863014,0.2064171901,0.04731273831,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Sorry, but I still get this on Python 3.5.1, scikit 0.17, scikit-learn 0.18 (commit 9e913c04d748), and Numpy 1.11.1 on Mac OS 10.11.5.",Bug Reproduction,134,134,1,0.251572327,0.2223002195,0.7776997805,1,0.3150684932,0.04731273831,0.003913356226,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@dmyersturnbull do you get the error when running the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-218365487?,Bug Reproduction,147,147,1,0.2547169811,0.222972002,0.777027998,1,0.1643835616,0.003913356226,0.007534999345,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@lesteve I did with that exact snippet, yes.",Bug Reproduction,44,44,0.5,0.2578616352,0.2242654904,0.7757345096,0.4444444444,0.1095890411,0.007534999345,0.08372802707,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, I no longer get it after clearing my Anaconda installation and reinstalling from scratch with Python 3.5.2.",Solution Discussion,116,116,1,0.2610062893,0.2242654904,0.7757345096,1,0.2465753425,0.007534999345,0.08372802707,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I get the same problem with Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3.",Bug Reproduction,121,121,0.5,0.2641509434,0.2386385813,0.7613614187,1,0.301369863,0.08372802707,0.1743374667,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,It works when I have more than 2100 points but fails for lower values.,Bug Reproduction,70,70,1,0.2672955975,0.2386385813,0.7613614187,0.6363636364,0.1917808219,0.08372802707,0.1743374667,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Analogically **fails for low points' values**,Bug Reproduction,45,45,0.5,0.2704402516,0.268566054,0.731433946,1,0.08219178082,0.1743374667,0.0859712289,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Reopen, please",Action on Issue,14,14,1,0.2735849057,0.268566054,0.731433946,0.3333333333,0.02739726027,0.1743374667,0.0859712289,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I am getting the same problem on OS X 10.11.6, python 3.5.1,  sklearn 0.17.1 and numpy 1.11.1 .On this dataset: https://dl.dropboxusercontent.com/u/103591/vals.out (with np.savetxt)",Bug Reproduction,181,181,1,0.2767295597,0.2833242219,0.7166757781,1,0.3287671233,0.0859712289,0.0008809514386,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@Lucidyan I don't understand what you mean by that.,Investigation and Exploration,51,51,0.1666666667,0.2798742138,0.2834754496,0.7165245504,0.375,0.1232876712,0.0008809514386,0.02320572223,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@pbnsilva can you try this snippet posted below ?,Investigation and Exploration,49,49,0.3333333333,0.2830188679,0.2834754496,0.7165245504,0.3333333333,0.1095890411,0.0008809514386,0.02320572223,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,You may need to run it multiple times because unfortunately the seed is not set appropriately (you need to use CODE rather than CODE).,Investigation and Exploration,155,134,0.5,0.286163522,0.2834754496,0.7165245504,1,0.3287671233,0.0008809514386,0.02320572223,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Investigation and Exploration,142,4,0.6666666667,0.2893081761,0.2834754496,0.7165245504,0.04166666667,0.01369863014,0.0008809514386,0.02320572223,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Alternatively some people reported that this bug was fixed in master.,Solution Discussion,69,69,0.8333333333,0.2924528302,0.2834754496,0.7165245504,0.4583333333,0.1506849315,0.0008809514386,0.02320572223,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Could you try to build scikit-learn master to see whether the problem disappears ?,Solution Discussion,82,82,1,0.2955974843,0.2834754496,0.7165245504,0.5833333333,0.1917808219,0.0008809514386,0.02320572223,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@lesteve I meant that I get the same error with a small number of instances, with the same system parameters (Python 3.5.2, scikit-learn 0.17.1, scipy 0.17.1, numpy 1.11.1 on Mac OS X El Capitan 10.11.3)",Bug Reproduction,203,203,0.3333333333,0.2987421384,0.2874590375,0.7125409625,1,0.4931506849,0.02320572223,0.0448632062,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I tried it, and it fails with X_SIZE <= 1750 (Y_SIZE=20, n_components=2 became constants).",Investigation and Exploration,90,90,0.6666666667,0.3018867925,0.2874590375,0.7125409625,0.3611111111,0.1780821918,0.02320572223,0.0448632062,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"if I start to change the constants (increase) with fixed X_SIZE=1750, it fails too.",Investigation and Exploration,83,83,1,0.3050314465,0.2874590375,0.7125409625,0.3888888889,0.1917808219,0.02320572223,0.0448632062,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@Lucidyan could you try the same snippet with scikit-learn master and see whether it fails too ?,Investigation and Exploration,96,96,1,0.3081761006,0.2951604364,0.7048395636,1,0.2328767123,0.0448632062,0.1677394642,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,what did you guys change...?,Social Conversation,28,28,1,0.3113207547,0.3239552694,0.6760447306,1,0.06849315068,0.1677394642,0.0003023686606,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@act65 we are more than keen to get to the bottom of this but we haven't been able to reproduce and it seems like we are getting mixed reports from users so far unfortunately.,Task Progress,175,175,0.25,0.3144654088,0.3240071752,0.6759928248,0.4657534247,0.4657534247,0.0003023686606,0.0002259807885,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"So if you haven't already (unfortunately we are not mind readers and ""not working for me"" does not tell us what you tried) could you try to run the snippet mentioned above in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185.",Investigation and Exploration,255,255,0.5,0.3176100629,0.3240071752,0.6759928248,0.4657534247,0.4657534247,0.0003023686606,0.0002259807885,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Try to run it multiple times just in case because the random seed is not set properly and there may be some randomness left in the snippet.,Investigation and Exploration,139,139,0.75,0.320754717,0.3240071752,0.6759928248,0.3698630137,0.3698630137,0.0003023686606,0.0002259807885,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Then what would be really great if you could try with the 0.18 release candidate which is straightforward to install (highly recommended to do it in a separate virtualenv or conda env): CODE **Edited: 0.18 has been released so you can just use (no need to use CODE):** CODE and re-run the snippet to see whether it is fixed in 0.18 as some users have reported in this thread already.,Solution Discussion,450,383,1,0.3238993711,0.3240071752,0.6759928248,1,1,0.0003023686606,0.0002259807885,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"yea my bad, should have been clearer.",Social Conversation,37,37,0.25,0.3270440252,0.324045968,0.675954032,0.5833333333,0.09589041096,0.0002259807885,0.0001194252422,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"(I had tried roughly the same thing others had, just on MNIST).",Solution Discussion,63,63,0.5,0.3301886792,0.324045968,0.675954032,1,0.1643835616,0.0002259807885,0.0001194252422,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"anyway, it works!",Social Conversation,17,17,0.75,0.3333333333,0.324045968,0.675954032,0.25,0.04109589041,0.0002259807885,0.0001194252422,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,thanks :),Social Conversation,9,9,1,0.3364779874,0.324045968,0.675954032,0.1666666667,0.02739726027,0.0002259807885,0.0001194252422,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,This seems to match what other have reported when they say it was fixed in master.,Social Conversation,82,82,0.5,0.3396226415,0.324066469,0.675933531,0.5161290323,0.2191780822,0.0001194252422,0.01058262635,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Just for completeness though, it is recommended to stick to released versions for production code, so you may need to wait a little bit more until the 0.18 release is out.",Solution Discussion,171,171,1,0.3427672956,0.324066469,0.675933531,1,0.4246575342,0.0001194252422,0.01058262635,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Thanks @Lucidyan for giving it a try.,Social Conversation,37,37,1,0.3459119497,0.3258831253,0.6741168747,1,0.09589041096,0.01058262635,0.502908828,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Try uninstalling and reinstalling numpy, scipy and scikit-learn.",Solution Discussion,64,64,0.5,0.3490566038,0.4122144832,0.5877855168,0.3214285714,0.1232876712,0.502908828,0.01555461885,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"If that still fails, try in a different virtualenv (or conda environment if you are using conda) to make sure something is not wrong in your Python environment.",Solution Discussion,160,160,1,0.3522012579,0.4122144832,0.5877855168,1,0.3835616438,0.502908828,0.01555461885,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Still get the same error (CODE) in sklearn 0.18  (CODE) via conda.,Solution Discussion,125,66,0.5,0.3553459119,0.4148846518,0.5851153482,1,0.1780821918,0.01555461885,0.0004752100597,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,The pip wheels seem to work fine though!,Solution Discussion,40,40,1,0.358490566,0.4148846518,0.5851153482,0.6153846154,0.1095890411,0.01555461885,0.0004752100597,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Hmmm interesting ...,Social Conversation,20,20,0.3333333333,0.3616352201,0.4149662283,0.5850337717,0.08333333333,0.02739726027,0.0004752100597,0.0002007949321,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"could you try using conda packages without mkl, i.e. something like CODE so we can see whether that is a MKL vs openblas thing?",Investigation and Exploration,180,127,0.6666666667,0.3647798742,0.4149662283,0.5850337717,1,0.3287671233,0.0004752100597,0.0002007949321,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Up until now the snippet we have is non-deterministic (CODE is used and has no influence of numpy.random seed).,Investigation and Exploration,120,111,1,0.3679245283,0.4149662283,0.5850337717,0.8333333333,0.2739726027,0.0004752100597,0.0002007949321,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Sure, no problem.",Social Conversation,17,17,0.1111111111,0.3710691824,0.4150006976,0.5849993024,0.15,0.04109589041,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"This may be be a BLAS problem indeed, the CODE env works fine.",Investigation and Exploration,115,62,0.2222222222,0.3742138365,0.4150006976,0.5849993024,0.65,0.1780821918,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"E.g., CODE reproduces the problem on my machine.",Investigation and Exploration,374,48,0.3333333333,0.3773584906,0.4150006976,0.5849993024,0.4,0.1095890411,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, when I replace CODE by CODE it seems to be fine.",Investigation and Exploration,151,57,0.4444444444,0.3805031447,0.4150006976,0.5849993024,0.6,0.1643835616,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Would be good to find a more light-weight example maybe, to add this particular case to the travis tests.",Investigation and Exploration,105,105,0.5555555556,0.3836477987,0.4150006976,0.5849993024,1,0.2739726027,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,EDIT: Same is true for iris.,Investigation and Exploration,28,28,0.6666666667,0.3867924528,0.4150006976,0.5849993024,0.3,0.08219178082,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"CODE works in fit_transform, a splitted dataset (CODE) does not.",Investigation and Exploration,76,64,0.7777777778,0.3899371069,0.4150006976,0.5849993024,0.5,0.1369863014,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Maybe there's sth funny going on in CODE.,Investigation and Exploration,55,41,0.8888888889,0.393081761,0.4150006976,0.5849993024,0.4,0.1095890411,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, both CODE and CODE seem to be float 64 arrays ...",Investigation and Exploration,70,58,1,0.3962264151,0.4150006976,0.5849993024,0.55,0.1506849315,0.0002007949321,0.0001917999833,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"What about the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-243782185, you didn't find a way to make it deterministic and still fail on your machine?",Investigation and Exploration,187,187,1,0.3993710692,0.4150336227,0.5849663773,1,0.2876712329,0.0001917999833,0.0004979050073,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The snippet CODE reproduces the error (but it works fine on the nomkl env),Investigation and Exploration,243,74,1,0.4025157233,0.4151190951,0.5848809049,1,0.1917808219,0.0004979050073,0.001838152366,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"OK thanks a lot for this, at least we have a deterministic snippet now.",Social Conversation,71,71,0.25,0.4056603774,0.4154346398,0.5845653602,0.6666666667,0.1917808219,0.001838152366,0.0002081292748,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"For the record, can you post the output of this snippet: CODE",Investigation and Exploration,305,61,0.5,0.4088050314,0.4154346398,0.5845653602,0.5714285714,0.1643835616,0.001838152366,0.0002081292748,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Also, just for the sake of sanity, can you make sure you can reproduce the problem in a fresh conda environment.",Investigation and Exploration,112,112,0.75,0.4119496855,0.4154346398,0.5845653602,1,0.2876712329,0.001838152366,0.0002081292748,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"To be honest, I am not sure where we go from this.",Social Conversation,50,50,1,0.4150943396,0.4154346398,0.5845653602,0.5714285714,0.1643835616,0.001838152366,0.0002081292748,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Sure, the machine that causes this problem: CODE (tested it in a fresh conda environment)",Investigation and Exploration,290,89,0.1666666667,0.4182389937,0.4154703681,0.5845296319,0.75,0.2054794521,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,I think you may be onto sth!,Social Conversation,28,28,0.3333333333,0.4213836478,0.4154703681,0.5845296319,0.35,0.09589041096,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I tried it on my other mac, and it works fine there.",Bug Reproduction,52,52,0.5,0.4245283019,0.4154703681,0.5845296319,0.6,0.1643835616,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The only difference is to the output above it is running on an older kernel (CODE).,Investigation and Exploration,112,83,0.6666666667,0.427672956,0.4154703681,0.5845296319,0.8,0.2191780822,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Haven't updated the second mac to macOS Sierra yet, which is running on the former machine that has this problem.",Investigation and Exploration,113,113,0.8333333333,0.4308176101,0.4154703681,0.5845296319,1,0.2739726027,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Could be OS-related.,Investigation and Exploration,20,20,1,0.4339622642,0.4154703681,0.5845296319,0.2,0.05479452055,0.0002081292748,0.0005572716688,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Given that the problem has been reported on different OSX versions, I kind of doubt this is only a OSX version issue.",Investigation and Exploration,117,117,0.3333333333,0.4371069182,0.4155660316,0.5844339684,1,0.301369863,0.0005572716688,0.0001185949392,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,IIRC @ogrisel's hunch was that it was CPU architecture related.,Investigation and Exploration,63,63,0.6666666667,0.4402515723,0.4155660316,0.5844339684,0.4545454545,0.1369863014,0.0005572716688,0.0001185949392,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Another (more time-intensive) way to debug this problem would be to track down where the NaNs appear in the code.,Investigation and Exploration,113,113,1,0.4433962264,0.4155660316,0.5844339684,0.9545454545,0.2876712329,0.0005572716688,0.0001185949392,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hm, how would the conda scikit-learn version differ from the pip wheels?",Investigation and Exploration,72,72,0.3333333333,0.4465408805,0.4155863901,0.5844136099,1,0.1780821918,0.0001185949392,0.0004713353126,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Because the latter seem to work on the same machine.,Investigation and Exploration,52,52,0.6666666667,0.4496855346,0.4155863901,0.5844136099,0.7692307692,0.1369863014,0.0001185949392,0.0004713353126,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Maybe it's somehow related to conda,Investigation and Exploration,35,35,1,0.4528301887,0.4155863901,0.5844136099,0.4615384615,0.08219178082,0.0001185949392,0.0004713353126,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I noticed that the gradient in https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L387 explodes, until it becomes CODE in one position after the 25th iteration in the https://github.com/scikit-learn/scikit-learn/blob/master/sklearn/manifold/t_sne.py#L386 for-loop",Investigation and Exploration,297,295,0.25,0.4559748428,0.4156673014,0.5843326986,1,0.3287671233,0.0004713353126,0.003024101758,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Investigation and Exploration,299,4,0.5,0.4591194969,0.4156673014,0.5843326986,0.04166666667,0.01369863014,0.0004713353126,0.003024101758,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"On the other machine (the one that works fine), the gradients are all < 0 after the same iteration.",Investigation and Exploration,99,99,0.75,0.4622641509,0.4156673014,0.5843326986,0.75,0.2465753425,0.0004713353126,0.003024101758,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"So, somehow the CODE function doesn't work properly (maybe due to some BLAS thing).",Investigation and Exploration,98,83,1,0.465408805,0.4156673014,0.5843326986,0.5833333333,0.1917808219,0.0004713353126,0.003024101758,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"The pip wheels are using OpenBLAS and you don't have the problem when using OpenBLAS with conda (through the CODE trick) so this does look like a MKL problem, which on top of that is likely CPU-specific.",Investigation and Exploration,206,203,1,0.4685534591,0.4161864309,0.5838135691,1,0.5205479452,0.003024101758,0.0005175555106,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Great job debugging the issue by the way!,Social Conversation,41,41,0.5,0.4716981132,0.4162752766,0.5837247234,0.6666666667,0.1095890411,0.0005175555106,0.2109192312,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The problem arises very likely in some cython code in sklearn/manifold/_barnes_hut_tsne.pyx.,Investigation and Exploration,92,92,1,0.4748427673,0.4162752766,0.5837247234,1,0.1643835616,0.0005175555106,0.2109192312,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Shouldn't this issue be re-opened given the latest findings?,Action on Issue,60,60,0.3333333333,0.4779874214,0.4524825225,0.5475174775,0.3703703704,0.1369863014,0.2109192312,0.004397699618,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I hit it as well and also managed to get past it with the nomkl trick, but feels like an active bug vs. a closed one, no?",Action on Issue,121,121,0.6666666667,0.4811320755,0.4524825225,0.5475174775,1,0.3698630137,0.2109192312,0.004397699618,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Others that have been hitting this: https://discussions.udacity.com/t/assignment-5-error-in-the-main-code-valueerror-array-must-not-contain-infs-or-nans/178187/7,Observed Bug Behaviour,161,161,1,0.4842767296,0.4524825225,0.5475174775,0.2592592593,0.09589041096,0.2109192312,0.004397699618,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"You are right, reopening.",Action on Issue,25,25,0.5,0.4874213836,0.4532374494,0.5467625506,0.1904761905,0.05479452055,0.004397699618,0.005172233894,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The only way this can get fixed is if people having the issue invest some time in debugging the problem further.,Contribution and Commitment,112,112,1,0.4905660377,0.4532374494,0.5467625506,1,0.2876712329,0.004397699618,0.005172233894,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I am happy to look into it further in December after all the November deadlines ...,Contribution and Commitment,83,83,0.3333333333,0.4937106918,0.4541253359,0.5458746641,0.5357142857,0.2054794521,0.005172233894,9.74E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, even this can be further isolated, I am curious if there's a fix for such a hardware-specific problem.",Solution Discussion,111,111,0.6666666667,0.4968553459,0.4541253359,0.5458746641,0.7142857143,0.2739726027,0.005172233894,9.74E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Maybe, until this is fully resolved, it may be worthwhile to raise a more specific exception/warning if the gradient contains infs with a note about this problem?",Solution Discussion,162,162,1,0.5,0.4541253359,0.5458746641,1,0.3835616438,0.005172233894,9.74E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I just created a new conda virtualenv and built a devp version of sklearn from the source code freshly forked from the sciki-learn master branch, the error disappeared.",Investigation and Exploration,168,168,0.5,0.5031446541,0.4541420598,0.5458579402,1,0.397260274,9.74E-05,0.002465307867,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Is the devp sklearn built from source code using OpenBLAS instead of MKL?,Investigation and Exploration,73,73,1,0.5062893082,0.4541420598,0.5458579402,0.4482758621,0.1780821918,9.74E-05,0.002465307867,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Sounds great, thanks a lot !",Social Conversation,28,28,0.25,0.5094339623,0.4545652645,0.5454347355,0.1282051282,0.06849315068,0.002465307867,7.60E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Not sure about a fix, one hope would be if we can change our cython code to work-around problem once we have isolated it.",Solution Discussion,121,121,0.5,0.5125786164,0.4545652645,0.5454347355,0.641025641,0.3424657534,0.002465307867,7.60E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Also it could well be an openblas issue and that would be great reporting it upstream, especially since wheels use openblas.",Solution Discussion,124,124,0.75,0.5157232704,0.4545652645,0.5454347355,0.5384615385,0.2876712329,0.002465307867,7.60E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Adding some advice to the error message (only on OS X), sounds like a good idea, but I am not sure what it should say, maybe ""consider using conda and install scikit-learn with MKL"" or something like this.",Solution Discussion,205,205,1,0.5188679245,0.4545652645,0.5454347355,1,0.5342465753,0.002465307867,7.60E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@zhongyuk depends which library you have installed.,Investigation and Exploration,51,51,0.25,0.5220125786,0.4545783063,0.5454216937,0.175,0.09589041096,7.60E-05,4.18E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"One way to know once you have built scikit-learn from source is to run the equivalent of CODE (Google seems to say CODE) on CODE (name will be different if you are using Python 3, i.e. something like CODE).",Investigation and Exploration,293,206,0.5,0.5251572327,0.4545783063,0.5454216937,1,0.5479452055,7.60E-05,4.18E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"On my Ubuntu machine for example, I get this: CODE",Investigation and Exploration,1078,50,0.75,0.5283018868,0.4545783063,0.5454216937,0.25,0.1369863014,7.60E-05,4.18E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"So you can see from the third line, that it is using MKL.",Investigation and Exploration,57,57,1,0.5314465409,0.4545783063,0.5454216937,0.325,0.1780821918,7.60E-05,4.18E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I just wanted to write that I think you got it flipped: the wheels worked find and the issue only occured when I was using it via conda with MKL ...,Solution Discussion,148,148,0.1428571429,0.534591195,0.4545854804,0.5454145196,0.8823529412,0.4109589041,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Now, I think I have good news in some way: I just wanted to rerun the above example that previously caused this issue to confirm CODE and I am no longer getting this problem.",Investigation and Exploration,342,174,0.2857142857,0.5377358491,0.4545854804,0.5454145196,1,0.4657534247,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,I remember that I reininstalled miniconda the other week due to some other problems.,Investigation and Exploration,84,84,0.4285714286,0.5408805031,0.4545854804,0.5454145196,0.4117647059,0.1917808219,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Do you think it could be related to some issue in the old conda?,Investigation and Exploration,64,64,0.5714285714,0.5440251572,0.4545854804,0.5454145196,0.4117647059,0.1917808219,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Would be great if some other people who had this issue could maybe also try updating/reinstalling conda and check if that solves the problem for them.,Contribution and Commitment,150,150,0.7142857143,0.5471698113,0.4545854804,0.5454145196,0.7941176471,0.3698630137,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Meanwhile, I will try to see if I can find an old backupstate to find out which conda version I had installed previously.",Investigation and Exploration,121,121,0.8571428571,0.5503144654,0.4545854804,0.5454145196,0.6764705882,0.3150684932,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"(right now, I have conda 4.2.12)",Investigation and Exploration,32,32,1,0.5534591195,0.4545854804,0.5454145196,0.1764705882,0.08219178082,4.18E-05,0.0006836161022,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Just wanna say that I ran CODE on CODE (I assume this is the t_sne.py compiled file?), it seems like it's indeed using BLAS.",Investigation and Exploration,164,124,0.3333333333,0.5566037736,0.4547028327,0.5452971673,0.8275862069,0.3287671233,0.0006836161022,0.0003054131048,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,And the one which threw error seems to use MKL..,Investigation and Exploration,48,48,0.6666666667,0.5597484277,0.4547028327,0.5452971673,0.3793103448,0.1506849315,0.0006836161022,0.0003054131048,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"The conda version I have is 4.2.13, both the env which throws the error and the env with source built sklearn (which does not throw error) are inside conda.",Investigation and Exploration,156,156,1,0.5628930818,0.4547028327,0.5452971673,1,0.397260274,0.0006836161022,0.0003054131048,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hm, interesting, so it's not a conda issue after all then ...",Investigation and Exploration,61,61,0.3333333333,0.5660377358,0.4547552612,0.5452447388,0.7857142857,0.1506849315,0.0003054131048,0.003896611783,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Curious why it works for me now :/,Investigation and Exploration,34,34,0.6666666667,0.5691823899,0.4547552612,0.5452447388,0.5714285714,0.1095890411,0.0003054131048,0.003896611783,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,all I can think that has changed (except for reinstalling conda) was rebooting :P,Investigation and Exploration,81,81,1,0.572327044,0.4547552612,0.5452447388,1,0.1917808219,0.0003054131048,0.003896611783,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Yeah, sorry about that.",Social Conversation,23,23,0.3333333333,0.5754716981,0.4554241693,0.5445758307,0.16,0.05479452055,0.003896611783,8.64E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I'll edit the issue title to try to remember it right for next time.,Social Conversation,68,68,0.6666666667,0.5786163522,0.4554241693,0.5445758307,0.56,0.1917808219,0.003896611783,8.64E-05,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hmmm, random guess maybe the mkl version, although if I believe the output of CODE the latest mkl version (11.3.3) is from 2016-05-13.",Investigation and Exploration,146,134,1,0.5817610063,0.4554241693,0.5445758307,1,0.3424657534,0.003896611783,8.64E-05,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"@zhongyuk try to build scikit-learn inside a conda env that uses mkl, I believe this should be enough for mkl to be picked up (probably a good idea in this case to do CODE and then CODE to rebuild from scratch).",Investigation and Exploration,224,211,1,0.5849056604,0.4554389927,0.5445610073,1,0.5753424658,8.64E-05,0.009630545628,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"@lesteve I built scikit-learn in two conda virtual environments from source code (branch 0.18 release), the one uses MKL indeed throws the error; the one uses libBLAS does not throw error.",Investigation and Exploration,188,188,0.5,0.5880503145,0.457092211,0.542907789,1,0.4383561644,0.009630545628,0.001200894845,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The output running CODE on CODE is here (in case MKL version gives you any clue?) CODE,Investigation and Exploration,527,86,1,0.5911949686,0.457092211,0.542907789,0.53125,0.2328767123,0.009630545628,0.001200894845,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,@zhongyuk great !,Social Conversation,17,17,0.2,0.5943396226,0.4572983615,0.5427016385,0.0625,0.02739726027,0.001200894845,0.004204377413,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"For completeness, can you post the output of CODE (in your MKL conda environment)?",Investigation and Exploration,118,82,0.4,0.5974842767,0.4572983615,0.5427016385,0.4375,0.1917808219,0.001200894845,0.004204377413,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,While we are at it your CPU information (CODE according to Google) and your platform information (CODE) would be great.,Investigation and Exploration,204,119,0.6,0.6006289308,0.4572983615,0.5427016385,0.625,0.2739726027,0.001200894845,0.004204377413,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,What would be really great is to continue where @rabst stopped and further isolate the problem:https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-258311980,Investigation and Exploration,174,174,0.8,0.6037735849,0.4572983615,0.5427016385,0.6875,0.301369863,0.001200894845,0.004204377413,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Since this is related to BLAS, my hunch is that something goes wrong in this [line](https://github.com/scikit-learn/scikit-learn/blob/46fc1be145bf952a916ef5abd06efec105105c2e/sklearn/manifold/_barnes_hut_tsne.pyx#L660) causing the gradient to have some non-finite values.",Investigation and Exploration,271,271,1,0.606918239,0.4572983615,0.5427016385,1,0.4383561644,0.001200894845,0.004204377413,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve Output of conda MKL environment info:CODE,Investigation and Exploration,337,50,0.5,0.6100628931,0.4580201019,0.5419798981,1,0.1095890411,0.004204377413,0.003934390567,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,CPU info: CODEPlatform info: CODE,Investigation and Exploration,100,33,1,0.6132075472,0.4580201019,0.5419798981,0.625,0.06849315068,0.004204377413,0.003934390567,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"@zhongyuk If it helps, I have a very similar setup (can't reproduce the issue anymore since reinstalling miniconda), except that I have macOS Sierra instead of OS X El Capitan and that I have numpy 1.11.2 instead of 1.11.1.",Investigation and Exploration,223,223,1,0.6163522013,0.4586954952,0.5413045048,1,0.5342465753,0.003934390567,7.54E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@rasbt hmm, I wonder if the problem goes away in Sierra...",Investigation and Exploration,58,58,0.3333333333,0.6194968553,0.458708442,0.541291558,0.2682926829,0.1506849315,7.54E-05,3.10E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I don't want to upgrade OS yet b/z I thought I read somewhere that TensorFlow doesn't support Sierra yet (could be mistaken or no longer be true anymore since I don't remember where or how long ago I read it)?,Investigation and Exploration,209,209,0.6666666667,0.6226415094,0.458708442,0.541291558,1,0.5616438356,7.54E-05,3.10E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,And I don't wanna break my projects with TF dependency,Social Conversation,54,54,1,0.6257861635,0.458708442,0.541291558,0.243902439,0.1369863014,7.54E-05,3.10E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@zhongyuk Hm, I think it's unlikely that it is related.",Investigation and Exploration,55,55,0.3333333333,0.6289308176,0.4587137632,0.5412862368,0.3571428571,0.1369863014,3.10E-05,4.88E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Before I reinstalled miniconda, I also had the problem in macOS Sierra.",Investigation and Exploration,71,71,0.6666666667,0.6320754717,0.4587137632,0.5412862368,0.4285714286,0.1643835616,3.10E-05,4.88E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"PS: Tensorflow works fine for me on Sierra, but I only do CPU and prototyping on my macs so I don't know about GPU issues related to Sierra",Investigation and Exploration,139,139,1,0.6352201258,0.4587137632,0.5412862368,1,0.3835616438,3.10E-05,4.88E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@rasbt hmm, that's good to know that TF works fine on Sierra.",Investigation and Exploration,61,61,0.3333333333,0.6383647799,0.4587221489,0.5412778511,0.5714285714,0.1643835616,4.88E-05,0.0004141827923,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Do you wanna run CODE on the CODE file in your platform to see which math library sklearn using underneath?,Investigation and Exploration,147,107,0.6666666667,0.641509434,0.4587221489,0.5412778511,0.9523809524,0.2739726027,4.88E-05,0.0004141827923,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,At least that way we might know if the problem went away after reinstalling miniconda is fundamentally linked to math library?,Investigation and Exploration,126,126,1,0.6446540881,0.4587221489,0.5412778511,1,0.2876712329,4.88E-05,0.0004141827923,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I am getting the following on CODE: CODE,Investigation and Exploration,484,40,1,0.6477987421,0.4587932492,0.5412067508,1,0.1095890411,0.0004141827923,7.50E-05,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"@rasbt Hmm, that's really interesting.",Social Conversation,38,38,0.1666666667,0.6509433962,0.4588061247,0.5411938753,0.3571428571,0.06849315068,7.50E-05,9.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,It's using MKL as well.,Investigation and Exploration,23,23,0.3333333333,0.6540880503,0.4588061247,0.5411938753,0.3571428571,0.06849315068,7.50E-05,9.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I don't know enough about the math library to speculate what does this mean...,Social Conversation,78,78,0.5,0.6572327044,0.4588061247,0.5411938753,1,0.1917808219,7.50E-05,9.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve probably will be able to infer more from this?,Contribution and Commitment,55,55,0.6666666667,0.6603773585,0.4588061247,0.5411938753,0.7142857143,0.1369863014,7.50E-05,9.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I noticed that in my platform CODE is not loaded...,Investigation and Exploration,72,51,0.8333333333,0.6635220126,0.4588061247,0.5411938753,0.7142857143,0.1369863014,7.50E-05,9.35E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Is it possible that caused the problem?,Investigation and Exploration,39,39,1,0.6666666667,0.4588061247,0.5411938753,0.5,0.09589041096,7.50E-05,9.35E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"WOW, yes!",Social Conversation,9,9,0.1666666667,0.6698113208,0.4588221835,0.5411778165,0.02985074627,0.02739726027,9.35E-05,0.001079117078,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,it is caused by CODE not loaded!!!,Investigation and Exploration,55,34,0.3333333333,0.6729559748,0.4588221835,0.5411778165,0.1044776119,0.09589041096,9.35E-05,0.001079117078,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I found [this thread on stack overflow] URL  and then ran CODE, then ran CODE on the  CODE file, then CODE loaded up, and ran the code snippet, error went away!",Solution Discussion,350,160,0.5,0.6761006289,0.4588221835,0.5411778165,0.4925373134,0.4520547945,9.35E-05,0.001079117078,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Have five team work! @rasbt,Social Conversation,27,27,0.6666666667,0.679245283,0.4588221835,0.5411778165,0.07462686567,0.06849315068,9.35E-05,0.001079117078,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@lesteve Since it does look like a lot of ppl has hit this problem, and it does look like it's related to (some version of ?) conda not extracting full MKL libraries (my understanding of the situation so far), even though it's not a scikit-learn bug, I do think either add some kind of remark or warning or error messages to (OS X) users would be nice?",Solution Discussion,352,352,0.8333333333,0.6823899371,0.4588221835,0.5411778165,1,0.9178082192,9.35E-05,0.001079117078,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,That way at least they can check if MKL lib is fully extracted in their platform and then fix it if it's not?,Solution Discussion,109,109,1,0.6855345912,0.4588221835,0.5411778165,0.3432835821,0.3150684932,9.35E-05,0.001079117078,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"@zhongyuk awesome, glad to hear that you were able to narrow it down!",Social Conversation,69,69,0.1428571429,0.6886792453,0.459007429,0.540992571,0.4814814815,0.1780821918,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,That would also explain why it works for me now after re-installing Miniconda ...,Solution Discussion,81,81,0.2857142857,0.6918238994,0.459007429,0.540992571,0.5185185185,0.1917808219,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Would be great if someone else could try the ""fix.""",Contribution and Commitment,51,51,0.4285714286,0.6949685535,0.459007429,0.540992571,0.3703703704,0.1369863014,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"If the aforementioned CODE really caused this issue, the remaining question would be how to deal with that in scikit-learn.",Solution Discussion,144,123,0.5714285714,0.6981132075,0.459007429,0.540992571,0.7777777778,0.2876712329,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I mean, this ""bug"" is kind of hideous and it may be a bit tricky for folks to figure out that it's due to CODE.",Solution Discussion,132,111,0.7142857143,0.7012578616,0.459007429,0.540992571,0.9259259259,0.3424657534,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I probably wouldn't inject an additional ""if gradient contains inf raise error + message"" in the code in scikit-learn since it could be quite annoying performance-wise.",Solution Discussion,168,168,0.8571428571,0.7044025157,0.459007429,0.540992571,1,0.3698630137,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, i think that adding a note or comment in the installation and/or T-SNE docs would be a good idea.",Solution Discussion,106,106,1,0.7075471698,0.459007429,0.540992571,0.7777777778,0.2876712329,0.001079117078,0.0009613524417,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Just want to add a quick update: I had 2 virtual envs in conda both using MKL.,Investigation and Exploration,78,78,0.1111111111,0.7106918239,0.4591724587,0.5408275413,0.5151515152,0.2328767123,0.0009613524417,0.007162331701,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,One of them is equipped with CODE and the other is equipped with CODE.,Investigation and Exploration,90,70,0.2222222222,0.713836478,0.4591724587,0.5408275413,0.4242424242,0.1917808219,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Running CODE indicated that both of them somehow didn't have CODE loaded.,Investigation and Exploration,100,73,0.3333333333,0.7169811321,0.4591724587,0.5408275413,0.3636363636,0.1643835616,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"After making sure CODE loaded up, the error disappeared in the virtual env with CODE.",Investigation and Exploration,116,85,0.4444444444,0.7201257862,0.4591724587,0.5408275413,0.4545454545,0.2054794521,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, the error remained appearing in the env with CODE.",Investigation and Exploration,69,59,0.5555555556,0.7232704403,0.4591724587,0.5408275413,0.303030303,0.1369863014,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"After upgrading CODE to 1.11.2, I can no longer reproduce the error in either conda virtual environment.",Investigation and Exploration,107,104,0.6666666667,0.7264150943,0.4591724587,0.5408275413,0.5151515152,0.2328767123,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"As it sounds complicated and the exact cause of the error is still obscure, I speculate it's probably a complication interweaved by incomplete MKL library loading and scikit-learn dependent libraries (possibly numpy?).",Investigation and Exploration,218,218,0.7777777778,0.7295597484,0.4591724587,0.5408275413,1,0.4520547945,0.0009613524417,0.007162331701,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Although I haven't tried to create an virtualenv with MKL and CODE to see if this would reproduce the error.,Investigation and Exploration,118,108,0.8888888889,0.7327044025,0.4591724587,0.5408275413,0.6060606061,0.2739726027,0.0009613524417,0.007162331701,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"And I second @rasbt suggestion on adding some kind of note, comment or docs!",Solution Discussion,76,76,1,0.7358490566,0.4591724587,0.5408275413,0.4242424242,0.1917808219,0.0009613524417,0.007162331701,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@zhongyuk glad you got it fixed !,Social Conversation,33,33,0.5,0.7389937107,0.4604019734,0.5395980266,0.2068965517,0.08219178082,0.007162331701,0.06102214722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,It seems that reinstalling packages with conda may help but I am afraid there doesn't seem to be a very clear picture of the cause of the problem :(.,Investigation and Exploration,149,149,1,0.7421383648,0.4604019734,0.5395980266,1,0.397260274,0.007162331701,0.06102214722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"This is a conda bug, right?",Investigation and Exploration,27,27,0.5,0.7452830189,0.4708772814,0.5291227186,0.6666666667,0.08219178082,0.06102214722,0.0008236605345,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Or did anyone experience the bug not using conda?,Investigation and Exploration,49,49,1,0.748427673,0.4708772814,0.5291227186,1,0.1232876712,0.06102214722,0.0008236605345,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I managed to find a way to reproduce I think by installing the numpy wheel and then scikit-learn via conda on top of it (got the hint from the CODE output in https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762 where two CODE are listed).,Bug Reproduction,276,265,0.1428571429,0.751572327,0.4710186742,0.5289813258,0.829787234,0.5342465753,0.0008236605345,0.003313600722,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Bug Reproduction,104,4,0.2857142857,0.7547169811,0.4710186742,0.5289813258,0.02127659574,0.01369863014,0.0008236605345,0.003313600722,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,then execute the snippet from https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-262800762.,Bug Reproduction,110,110,0.4285714286,0.7578616352,0.4710186742,0.5289813258,0.1276595745,0.08219178082,0.0008236605345,0.003313600722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,So it seems like this is happening when mixing numpy installed via pip and conda.,Investigation and Exploration,81,81,0.5714285714,0.7610062893,0.4710186742,0.5289813258,0.3191489362,0.2054794521,0.0008236605345,0.003313600722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"In my book this is never a good idea to mix pip and conda for a given package but I guess this can happen without realizing it quite easily (for example you install a project that depends on numpy via pip, and then scikit-learn via conda).",Solution Discussion,239,239,0.7142857143,0.7641509434,0.4710186742,0.5289813258,1,0.6438356164,0.0008236605345,0.003313600722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Why this exactly happens I don't know ...,Social Conversation,41,41,0.8571428571,0.7672955975,0.4710186742,0.5289813258,0.1489361702,0.09589041096,0.0008236605345,0.003313600722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,and it seems to happen only on OSX by the way (i.e. not on my Ubuntu box).,Investigation and Exploration,74,74,1,0.7704402516,0.4710186742,0.5289813258,0.3617021277,0.2328767123,0.0008236605345,0.003313600722,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"For anyone affected by this, this should fix it: CODE",Solution Discussion,129,53,0.5,0.7735849057,0.4715875003,0.5284124997,1,0.1369863014,0.003313600722,0.007772604375,MEMBER,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Let me know if that doesn't work for you.,Solution Discussion,41,41,1,0.7767295597,0.4715875003,0.5284124997,0.9,0.1232876712,0.003313600722,0.007772604375,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Thanks for the deep dive (again!) @lesteve,Social Conversation,42,42,1,0.7798742138,0.4729217769,0.5270782231,1,0.09589041096,0.007772604375,0.006263805516,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I thought we would never get to the bottom of this one to be honest :) !,Social Conversation,72,72,0.5,0.7830188679,0.473997047,0.526002953,1,0.2191780822,0.006263805516,1,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,OK it's not quite the bottom but it's low enough as far as I am concerned.,Social Conversation,74,74,1,0.786163522,0.473997047,0.526002953,1,0.2191780822,0.006263805516,1,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Hi,Social Conversation,2,2,0.06666666667,0.7893081761,0.6456610805,0.3543389195,0.05555555556,0.01369863014,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I tried two setups, where",Bug Reproduction,25,25,0.1333333333,0.7924528302,0.6456610805,0.3543389195,0.2777777778,0.06849315068,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"-         TSNE works well with one setup (where Tensorflow is de-activated, Python-3.x), however,",Bug Reproduction,97,97,0.2,0.7955974843,0.6456610805,0.3543389195,0.7777777778,0.1917808219,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"-         TSNE does not work with the other setup (where Tensorflow is activated, Python 2.x).",Bug Reproduction,94,94,0.2666666667,0.7987421384,0.6456610805,0.3543389195,0.8333333333,0.2054794521,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,**The set up where TSNE works well:**,Bug Reproduction,37,37,0.3333333333,0.8018867925,0.6456610805,0.3543389195,0.4444444444,0.1095890411,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Terminal:CODE,Bug Reproduction,73,13,0.4,0.8050314465,0.6456610805,0.3543389195,0.1111111111,0.02739726027,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Jupyer notebook:CODE>>CODE,Bug Reproduction,177,26,0.4666666667,0.8081761006,0.6456610805,0.3543389195,0.1666666667,0.04109589041,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Note: I triedCODEto make TSNE work well with Tensorflow deactivated.,Solution Discussion,140,68,0.5333333333,0.8113207547,0.6456610805,0.3543389195,0.5555555556,0.1369863014,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, with the new setup below (where I have to use Tensorflow), this does not work any more.",Solution Discussion,96,96,0.6,0.8144654088,0.6456610805,0.3543389195,1,0.2465753425,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,**The set up where TSNE does not work:**,Bug Reproduction,40,40,0.6666666667,0.8176100629,0.6456610805,0.3543389195,0.5,0.1232876712,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,**Terminal:**CODE,Bug Reproduction,160,17,0.7333333333,0.820754717,0.6456610805,0.3543389195,0.05555555556,0.01369863014,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,**Jupyer notebook:**CODE>> CODE,Bug Reproduction,185,31,0.8,0.8238993711,0.6456610805,0.3543389195,0.1666666667,0.04109589041,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,**Error**:CODE,Bug Reproduction,59,14,0.8666666667,0.8270440252,0.6456610805,0.3543389195,0.05555555556,0.01369863014,1,4.68E-05,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Any suggestions ?,Solution Discussion,17,17,0.9333333333,0.8301886792,0.6456610805,0.3543389195,0.1111111111,0.02739726027,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Thanks a lot,Social Conversation,12,12,1,0.8333333333,0.6456610805,0.3543389195,0.1666666667,0.04109589041,1,4.68E-05,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Interesting.,Social Conversation,12,12,0.5,0.8364779874,0.6456691099,0.3543308901,0.03225806452,0.01369863014,4.68E-05,3.47E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I think it has nothing to do with tensorflow; my guess is that [GCC 4.2.1 Compatible Apple LLVM 4.2 (clang-425.0.28)] vs [GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)] is the culprit!?,Investigation and Exploration,192,192,1,0.8396226415,0.6456691099,0.3543308901,1,0.4246575342,4.68E-05,3.47E-05,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Thanks for response :),Social Conversation,22,22,0.25,0.8427672956,0.6456750725,0.3543249275,0.25,0.05479452055,3.47E-05,0.0001660605916,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Any suggested solutions/to_do_list ?,Solution Discussion,36,36,0.5,0.8459119497,0.6456750725,0.3543249275,0.25,0.05479452055,3.47E-05,0.0001660605916,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Need use bothTensorflow andTSNEin Jupyter notebook ....,Motivation,55,55,0.75,0.8490566038,0.6456750725,0.3543249275,0.4375,0.09589041096,3.47E-05,0.0001660605916,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"BTW: just tried ""from __future__ import division"" in Python 2.x and did not solve the problem.",Solution Discussion,94,94,1,0.8522012579,0.6456750725,0.3543249275,1,0.2191780822,3.47E-05,0.0001660605916,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hm, not sure if that helps -- personally, I am not getting this mysterious issue anymore with  CODE",Solution Discussion,238,99,0.25,0.8553459119,0.6457035792,0.3542964208,0.8260869565,0.2602739726,0.0001660605916,0.002055691741,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"I am on Tf (now 1.0) as well, and I don't have this CODE issue anymorewhen I execute CODE which previously didn't work.",Solution Discussion,333,119,0.5,0.858490566,0.6457035792,0.3542964208,1,0.3150684932,0.0001660605916,0.002055691741,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Maybe try to create a new python 3.5 env and try the above-mentioned snippet to see if it works without error:,Solution Discussion,110,110,0.75,0.8616352201,0.6457035792,0.3542964208,0.9565217391,0.301369863,0.0001660605916,0.002055691741,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Solution Discussion,116,4,1,0.8647798742,0.6457035792,0.3542964208,0.04347826087,0.01369863014,0.0001660605916,0.002055691741,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hi rasbt,Yes I made TSNE work on Python 3.5.",Solution Discussion,44,44,0.25,0.8679245283,0.6460564675,0.3539435325,0.5555555556,0.1369863014,0.002055691741,0.0001352009984,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"However, for some other reason I'd better use Python 2.7, so I have to continue to explore ...",Solution Discussion,94,94,0.5,0.8710691824,0.6460564675,0.3539435325,1,0.2465753425,0.002055691741,0.0001352009984,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,cross fingers,Social Conversation,13,13,0.75,0.8742138365,0.6460564675,0.3539435325,0.1111111111,0.02739726027,0.002055691741,0.0001352009984,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Thanks for your help.,Social Conversation,21,21,1,0.8773584906,0.6460564675,0.3539435325,0.2222222222,0.05479452055,0.002055691741,0.0001352009984,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Do you have an old(er) Miniconda/Anaconda 2.7 distro installed?,Investigation and Exploration,63,63,0.3333333333,0.8805031447,0.6460796767,0.3539203233,0.25,0.1369863014,0.0001352009984,0.00843712351,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"In this case, maybe consider installing one of the more recent ones, or update your conda root or default python and give it another try (or create a new py 27 env by substituting the 3.5 by 2.7 in CODE) ?",Solution Discussion,262,205,0.6666666667,0.8836477987,0.6460796767,0.3539203233,1,0.5479452055,0.0001352009984,0.00843712351,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"not sure if this is really the reason, but I think CODE may be an issue; since the error doesn't seem to occur via CODE",Investigation and Exploration,194,119,1,0.8867924528,0.6460796767,0.3539203233,0.625,0.3424657534,0.0001352009984,0.00843712351,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Update: TSNE(perplexity=30, n_components=2, init='pca', n_iter=1000, **method='exact'**) make it  worked ...",Solution Discussion,108,108,0.5,0.8899371069,0.6475280273,0.3524719727,1,0.1369863014,0.00843712351,0.0351468626,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,**method='exact'** was the trick.,Solution Discussion,33,33,1,0.893081761,0.6475280273,0.3524719727,0.4,0.05479452055,0.00843712351,0.0351468626,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Also been having this problem.,Bug Reproduction,30,30,0.3333333333,0.8962264151,0.6535614795,0.3464385205,0.3846153846,0.06849315068,0.0351468626,0.006016236851,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Using method='exact' seems to works for me, but it is so painfully slow.",Solution Discussion,72,72,0.6666666667,0.8993710692,0.6535614795,0.3464385205,1,0.1780821918,0.0351468626,0.006016236851,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Is there really no other solution that people have found?,Solution Discussion,57,57,1,0.9025157233,0.6535614795,0.3464385205,0.7692307692,0.1369863014,0.0351468626,0.006016236851,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Have you read https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264029983 and https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264087057 ?,Solution Discussion,179,179,0.25,0.9056603774,0.654594251,0.345405749,0.2068965517,0.08219178082,0.006016236851,0.8667419106,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,The only way I managed to reproduce this problem was to install numpy with both pip and conda in the same conda environment.,Investigation and Exploration,124,124,0.5,0.9088050314,0.654594251,0.345405749,0.7931034483,0.3150684932,0.006016236851,0.8667419106,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,If you create a conda environment from scratch you should not have this problem.,Investigation and Exploration,80,80,0.75,0.9119496855,0.654594251,0.345405749,0.4827586207,0.1917808219,0.006016236851,0.8667419106,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"In case your problem do not seem to match this description, please post the exact commands you ran to create your conda environment, so we can try to reproduce.",Bug Reproduction,160,160,1,0.9150943396,0.654594251,0.345405749,1,0.397260274,0.006016236851,0.8667419106,MEMBER,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Hi,",Social Conversation,3,3,0.125,0.9182389937,0.8033826633,0.1966173367,0.03125,0.01369863014,0.8667419106,0.0005974029784,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I read the above comments and can reproduce this.,Bug Reproduction,49,49,0.25,0.9213836478,0.8033826633,0.1966173367,0.28125,0.1232876712,0.8667419106,0.0005974029784,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I re-ran code from a few weeks ago and now this issue appears.,Bug Reproduction,62,62,0.375,0.9245283019,0.8033826633,0.1966173367,0.4375,0.1917808219,0.8667419106,0.0005974029784,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Here's a minimal example that now reproduces this issue:CODE,Bug Reproduction,163,60,0.5,0.927672956,0.8033826633,0.1966173367,0.3125,0.1369863014,0.8667419106,0.0005974029784,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,And the output ofCODEis CODE,Bug Reproduction,466,28,0.625,0.9308176101,0.8033826633,0.1966173367,0.15625,0.06849315068,0.8667419106,0.0005974029784,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"Again, changing the method to exact (CODE) gets rid of the error.",Solution Discussion,83,65,0.75,0.9339622642,0.8033826633,0.1966173367,0.375,0.1643835616,0.8667419106,0.0005974029784,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,"More generally, I have noticed wildly different results when using sklearn's TSNE (with identitical perplexity and other parameters) from the bh implementation published by Laurens van der Maaten and the MATLAB version.",Investigation and Exploration,219,219,0.875,0.9371069182,0.8033826633,0.1966173367,1,0.4383561644,0.8667419106,0.0005974029784,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I wonder if there may be a connection?,Investigation and Exploration,38,38,1,0.9402515723,0.8033826633,0.1966173367,0.25,0.1095890411,0.8667419106,0.0005974029784,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Did you refer to https://github.com/scikit-learn/scikit-learn/issues/6665#issuecomment-264087057,Solution Discussion,96,96,1,0.9433962264,0.803485216,0.196514784,1,0.06849315068,0.0005974029784,0.001758720049,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,That fixed it.,Solution Discussion,14,14,1,0.9465408805,0.8037871249,0.1962128751,1,0.04109589041,0.001758720049,0.1070466705,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"I had the same problem as reported here, and I do not use conda.",Bug Reproduction,64,64,0.25,0.9496855346,0.8221631882,0.1778368118,1,0.1917808219,0.1070466705,0.1393667667,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,My Python version is installed via brew on macOS Sierra 10.12.4,Bug Reproduction,63,63,0.5,0.9528301887,0.8221631882,0.1778368118,0.7857142857,0.1506849315,0.1070466705,0.1393667667,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,CODE,Bug Reproduction,64,4,0.75,0.9559748428,0.8221631882,0.1778368118,0.07142857143,0.01369863014,0.1070466705,0.1393667667,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,Adding CODE solved my problem.,Solution Discussion,40,30,1,0.9591194969,0.8221631882,0.1778368118,0.3571428571,0.06849315068,0.1070466705,0.1393667667,NONE,FALSE,TRUE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve: i had this error using the setup you describe (two versions of numpy installed).,Bug Reproduction,90,90,0.3333333333,0.9622641509,0.8460874495,0.1539125505,0.7142857143,0.2054794521,0.1393667667,0.01200604239,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,simply updating the conda install of numpy to the same version as the pip install (1.12.1) did the trick for me.,Solution Discussion,112,112,0.6666666667,0.965408805,0.8460874495,0.1539125505,1,0.2876712329,0.1393667667,0.01200604239,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"i did remove the pip numpy install, though, as i didn't intend to have two versions :)",Solution Discussion,86,86,1,0.9685534591,0.8460874495,0.1539125505,0.8095238095,0.2328767123,0.1393667667,0.01200604239,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@lesteve: Thank you for the solution!,Social Conversation,37,37,0.3333333333,0.9716981132,0.8481484551,0.1518515449,0.5,0.08219178082,0.01200604239,0.8838761808,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I happened to have this error and then I found this discussion.,Social Conversation,63,63,0.6666666667,0.9748427673,0.8481484551,0.1518515449,1,0.1643835616,0.01200604239,0.8838761808,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,Fix it right away after remove the duplicated version of numpy.,Solution Discussion,63,63,1,0.9779874214,0.8481484551,0.1518515449,0.9166666667,0.1506849315,0.01200604239,0.8838761808,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,**Replicated**,Bug Reproduction,14,14,0.2,0.9811320755,0.9998782054,0.0001217945808,0.03448275862,0.01369863014,0.8838761808,0.0007094938778,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,I have removed pip installs of numpy and updated conda.,Solution Discussion,55,55,0.4,0.9842767296,0.9998782054,0.0001217945808,0.3448275862,0.1369863014,0.8838761808,0.0007094938778,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Darwin-16.7.0-x86_64-i386-64bit('Python', '2.7.13 |Anaconda custom (x86_64)| (default, Dec 20 2016, 23:05:08) \n[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]')('NumPy', '1.13.1')('SciPy', '0.19.0')('Scikit-Learn', '0.18.1')",Solution Discussion,232,232,0.6,0.9874213836,0.9998782054,0.0001217945808,0.8275862069,0.3287671233,0.8838761808,0.0007094938778,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,It seems fine on my linux machine Linux:,Bug Reproduction,40,40,0.8,0.9905660377,0.9998782054,0.0001217945808,0.275862069,0.1095890411,0.8838761808,0.0007094938778,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,"Linux-3.0.101-0.47.71-default-x86_64-with-SuSE-11-x86_64('Python', '2.7.12 |Anaconda 2.3.0 (64-bit)| (default, Jul  2 2016, 17:42:40) \n[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]')('NumPy', '1.12.1')('SciPy', '0.19.1')('Scikit-Learn', '0.18.1')",Bug Reproduction,240,240,1,0.9937106918,0.9998782054,0.0001217945808,1,0.397260274,0.8838761808,0.0007094938778,NONE,FALSE,FALSE,FALSE,FALSE
14 6665_scikit-learn.doc,@wolfiex so you didCODE,Solution Discussion,95,23,1,0.9968553459,1,0,4,0.05479452055,0.0007094938778,0,MEMBER,FALSE,TRUE,FALSE,TRUE
14 6665_scikit-learn.doc,Somewhat related I recommend you update to scikit-learn 0.19 which has some fixes in t-SNE,Solution Discussion,90,90,2,1,1,0,17,0.2328767123,0.0007094938778,0,MEMBER,FALSE,FALSE,FALSE,TRUE
15 15604_tensorflow.doc,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Observed Bug Behaviour,88,88,0.1666666667,0.003144654088,0,1,0.8666666667,0.09352517986,0,0.004121172682,NONE,TRUE,FALSE,TRUE,FALSE
15 15604_tensorflow.doc,I installed tf-nightly build and I get the following error on import of tensorflow.,Observed Bug Behaviour,83,83,0.3333333333,0.006289308176,0,1,1,0.1079136691,0,0.004121172682,NONE,TRUE,FALSE,TRUE,FALSE
15 15604_tensorflow.doc,CODE.,Observed Bug Behaviour,91,5,0.5,0.009433962264,0,1,0.06666666667,0.007194244604,0,0.004121172682,NONE,TRUE,TRUE,TRUE,FALSE
15 15604_tensorflow.doc,"If I check for cuda 9, I get the following:CODE",Observed Bug Behaviour,2342,47,0.6666666667,0.01257861635,0,1,0.7333333333,0.07913669065,0,0.004121172682,NONE,TRUE,TRUE,TRUE,FALSE
15 15604_tensorflow.doc,I that due to a name mismatch. CODE?,Investigation and Exploration,70,36,0.8333333333,0.01572327044,0,1,0.5333333333,0.05755395683,0,0.004121172682,NONE,TRUE,TRUE,TRUE,FALSE
15 15604_tensorflow.doc,And if so how can we overcome this?,Solution Discussion,35,35,1,0.01886792453,0,1,0.5333333333,0.05755395683,0,0.004121172682,NONE,TRUE,FALSE,TRUE,FALSE
15 15604_tensorflow.doc,@Timonzimm I know and I think the whole issue is this f** naming libcublas.so.xxx that nvidia puts.,Investigation and Exploration,99,99,0.5,0.02201257862,0.0003350798813,0.9996649201,0.5483870968,0.1223021583,0.004121172682,0.1834480158,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"This inherently is mismatch on linux systems whenever that number changes, so since it can not find the exact matches then it thinks the file doesn't exist and throws the error.",Investigation and Exploration,177,177,1,0.0251572327,0.0003350798813,0.9996649201,1,0.2230215827,0.004121172682,0.1834480158,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I think you should use symbol link from ''cuda/''   to ''cuda/9.1"",or your cuda version is too new to tensorflow master branch",Solution Discussion,126,126,1,0.02830188679,0.01525067408,0.9847493259,1,0.1798561151,0.1834480158,0.08816336793,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@burui11087 I completely forgot about symlinking.,Social Conversation,49,49,0.5,0.03144654088,0.0224189665,0.9775810335,1,0.04316546763,0.08816336793,0.1295333454,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Thanks for reminding me.,Social Conversation,24,24,1,0.03459119497,0.0224189665,0.9775810335,0.6666666667,0.02877697842,0.08816336793,0.1295333454,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Closing this out since I understand it to be resolved, but please let me know if I'm mistaken.",Action on Issue,94,94,0.5,0.03773584906,0.0329509246,0.9670490754,1,0.1294964029,0.1295333454,0.2905541361,MEMBER,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,FYI @gunan @av8ramit (who are working on the upcoming 1.5 release),Contribution and Commitment,66,66,1,0.04088050314,0.0329509246,0.9670490754,0.6111111111,0.07913669065,0.1295333454,0.2905541361,MEMBER,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I also occur the exactly same problem with kirk86.,Bug Reproduction,50,50,0.3333333333,0.04402515723,0.05657498818,0.9434250118,0.6428571429,0.06474820144,0.2905541361,0.02745205338,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"For me, I installed cuda toolkit 8.0, and cudnn 5.1.",Bug Reproduction,52,52,0.6666666667,0.04716981132,0.05657498818,0.9434250118,0.7142857143,0.07194244604,0.2905541361,0.02745205338,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Then I did what you guys said above, all of them does not work.",Solution Discussion,63,63,1,0.05031446541,0.05657498818,0.9434250118,1,0.1007194245,0.2905541361,0.02745205338,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"For using nightlies, you have to have CUDA 9.0 and cudnn 7 installed.",Solution Discussion,69,69,0.5,0.0534591195,0.05880703024,0.9411929698,0.5416666667,0.09352517986,0.02745205338,0.3335768717,MEMBER,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@yangfengKAUST with the current version of cuda and cudnn installed TF is just complaining that it cannot find the versions it is expecting.,Investigation and Exploration,140,140,1,0.05660377358,0.05880703024,0.9411929698,1,0.1726618705,0.02745205338,0.3335768717,MEMBER,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@Timonzimm  I am facing the same issue.,Bug Reproduction,39,39,0.5,0.05974842767,0.0859291402,0.9140708598,1,0.05755395683,0.3335768717,0.562496811,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Have you figured it out?,Task Progress,24,24,1,0.06289308176,0.0859291402,0.9140708598,0.625,0.03597122302,0.3335768717,0.562496811,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I have 8.0, 9.0, 9.1 installed + cudnn versions which seem specific to each.",Bug Reproduction,76,76,0.2,0.06603773585,0.1316640267,0.8683359733,0.2407407407,0.09352517986,0.562496811,0.05368173129,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,The sym  linking didn't work from the 9.1 libs.,Solution Discussion,47,47,0.4,0.06918238994,0.1316640267,0.8683359733,0.1851851852,0.07194244604,0.562496811,0.05368173129,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I suspect that sometimes the symlink in the LD_LIBRARY_PATH doesn't work either when I switch versions on the /usr/local/cuda link.,Solution Discussion,131,131,0.6,0.07232704403,0.1316640267,0.8683359733,0.4074074074,0.1582733813,0.562496811,0.05368173129,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I ended up just doing it the low tech way to get the libraries loaded into my java program until I can figure out a cleaner way to handle the paths inside of Eclipse.,Workarounds,166,166,0.8,0.07547169811,0.1316640267,0.8683359733,0.6296296296,0.2446043165,0.562496811,0.05368173129,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"try {         System.load(""/usr/local/cuda/lib64/libcublas.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcusolver.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcudart.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcufft.so.9.0"");         System.load(""/usr/local/cuda/lib64/libcurand.so.9.0"");          System.load(""/home/greg/Desktop/platform/tensorbuilder/jni/libtensorflow_jni.so"");       } catch (UnsatisfiedLinkError e) {           System.err.println(""Native code library failed to load.\n"" + e);           System.exit(1);       }",Workarounds,563,563,1,0.0786163522,0.1316640267,0.8683359733,1,0.3884892086,0.562496811,0.05368173129,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@asimshankar Would like to know that in your above comment you mean that we should downgrade cuda to 9.0 and tensorflow 1.5 doesn't work with cuda 9.1 ?,Solution Discussion,152,152,0.5,0.08176100629,0.1360287232,0.8639712768,1,0.1942446043,0.05368173129,0.001267484295,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Note: I also have cuda 9.1 installed instead of cuda 9.0.,Bug Reproduction,57,57,1,0.08490566038,0.1360287232,0.8639712768,0.4074074074,0.07913669065,0.05368173129,0.001267484295,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Just FYI, I have both installed.",Solution Discussion,32,32,0.5,0.08805031447,0.1361317784,0.8638682216,0.4615384615,0.04316546763,0.001267484295,0.0003224172419,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Building from scratch will work w/ either, but the nightly binaries use 9.0.",Solution Discussion,76,76,1,0.09119496855,0.1361317784,0.8638682216,1,0.09352517986,0.001267484295,0.0003224172419,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@AwasthiMaddy - Yes TensorFlow 1.5 release binaries are built for CUDA 9.,Solution Discussion,73,73,1,0.09433962264,0.1361579932,0.8638420068,1,0.07913669065,0.0003224172419,0.7235035514,MEMBER,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Have you solved it ?,Task Progress,20,20,0.3333333333,0.09748427673,0.1949838428,0.8050161572,0.5714285714,0.02877697842,0.7235035514,0.209218471,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,And rember uninstall tensorflow-gpu-1.5.,Solution Discussion,40,40,0.6666666667,0.1006289308,0.1949838428,0.8050161572,0.7142857143,0.03597122302,0.7235035514,0.209218471,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Please use this""pip install --upgrade tensorflow-gpu==1.4""",Solution Discussion,58,58,1,0.1037735849,0.1949838428,0.8050161572,1,0.05035971223,0.7235035514,0.209218471,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@aipeteryao  - Thank you.,Social Conversation,25,25,1,0.106918239,0.2119947534,0.7880052466,1,0.02877697842,0.209218471,0.01947000817,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Then as soon as you're done, you get this error (it is looking for cublas 9.0, which, from what I can read here, would not have worked either, as CUDA 9.1 is the default you get from NVIDIA).",Bug Reproduction,191,191,0.5,0.1100628931,0.2135778,0.7864222,1,0.273381295,0.01947000817,0.01902853319,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Either the webpage instructions should work with the default latest of everything, or it should tell you explicitly to install tensorflow-gpu-1.4 (for example) and not tensorflow-gpu..",Solution Discussion,184,184,1,0.1132075472,0.2135778,0.7864222,0.7631578947,0.2086330935,0.01947000817,0.01902853319,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Seconding bwesons's comment.,Social Conversation,28,28,0.25,0.1163522013,0.2151249515,0.7848750485,0.1666666667,0.02158273381,0.01902853319,0.002231038575,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I have CUDA 8.0 and Tensorflow 1.3.,Bug Reproduction,35,35,0.5,0.1194968553,0.2151249515,0.7848750485,0.3888888889,0.05035971223,0.01902853319,0.002231038575,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I followed the current install instructions for TF 1.5 (GPU, ubuntu, virtualenv) and it breaks as described above.",Bug Reproduction,114,114,0.75,0.1226415094,0.2151249515,0.7848750485,1,0.1294964029,0.01902853319,0.002231038575,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Reverting to TF 1.3 until this is resolved.,Workarounds,43,43,1,0.1257861635,0.2151249515,0.7848750485,0.4444444444,0.05755395683,0.01902853319,0.002231038575,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I ended up uninstalling the latest version and installing 1.4, in my virtualenv.",Solution Discussion,80,80,0.2,0.1289308176,0.2153063504,0.7846936496,0.9285714286,0.09352517986,0.002231038575,0.01329083736,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,77,4,0.4,0.1320754717,0.2153063504,0.7846936496,0.07142857143,0.007194244604,0.002231038575,0.01329083736,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,The install page for Ubuntu should be updated:,Solution Discussion,46,46,0.6,0.1352201258,0.2153063504,0.7846936496,0.5714285714,0.05755395683,0.002231038575,0.01329083736,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,https://www.tensorflow.org/install/install_linux,Solution Discussion,48,48,0.8,0.1383647799,0.2153063504,0.7846936496,0.07142857143,0.007194244604,0.002231038575,0.01329083736,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Since TensorFlow 1.5 is expecting Cuda 9.0 ( NOT 9.1 ), as well as cuDNN 7",Solution Discussion,74,74,1,0.141509434,0.2153063504,0.7846936496,1,0.1007194245,0.002231038575,0.01329083736,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"In fact, we should view the official document of tensorflow ,it give tensorflowâs envirment(include python,gcc,cuda,cudnn,an so on).",Solution Discussion,132,132,1,0.1446540881,0.2163869875,0.7836130125,1,0.1510791367,0.01329083736,0.1507278421,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@bwesen yes,you were right .",Social Conversation,28,28,0.5,0.1477987421,0.228642205,0.771357795,0.625,0.03597122302,0.1507278421,0.1948879119,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"My computer installed CUDA 8.0,cudnn 6.0 ,tensorflow 1.4.",Bug Reproduction,57,57,1,0.1509433962,0.228642205,0.771357795,1,0.05755395683,0.1507278421,0.1948879119,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I think this issue should still be open.,Action on Issue,40,40,0.2,0.1540880503,0.244487942,0.755512058,0.5714285714,0.05755395683,0.1948879119,0.2449173066,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@bwesen's [comment](https://github.com/tensorflow/tensorflow/issues/15604#issuecomment-362637994) is correct.,Social Conversation,109,109,0.4,0.1572327044,0.244487942,0.755512058,0.5,0.05035971223,0.1948879119,0.2449173066,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,[The docs] URL  tell you to install Cuda 8.0 and use CODE.,Solution Discussion,112,58,0.6,0.1603773585,0.244487942,0.755512058,0.9285714286,0.09352517986,0.1948879119,0.2449173066,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Right now that gives you tensorflow 1.5 which does not work with Cuda 8.0,Solution Discussion,73,73,0.8,0.1635220126,0.244487942,0.755512058,1,0.1007194245,0.1948879119,0.2449173066,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,pinging @asimshankar,Contribution and Commitment,20,20,1,0.1666666667,0.244487942,0.755512058,0.1428571429,0.01438848921,0.1948879119,0.2449173066,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I have the same issue (with cuda 9.1 + tensorflow 1.5).,Bug Reproduction,55,55,0.25,0.1698113208,0.2644014152,0.7355985848,0.4,0.07194244604,0.2449173066,0.2378544464,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I think to resolve it, one option is that to downgrade cuda to 9.0.",Solution Discussion,67,67,0.5,0.1729559748,0.2644014152,0.7355985848,0.56,0.1007194245,0.2449173066,0.2378544464,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,The other option would be to downgrade both cuda to 8.0 and tensorflow to 1.4.,Solution Discussion,78,78,0.75,0.1761006289,0.2644014152,0.7355985848,0.6,0.1079136691,0.2449173066,0.2378544464,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"If you have already installed cuda 8.0, you only need to modify CODE (and CODE) environment variable to point to cuda 8.0 directory (i.e. CODE).",Solution Discussion,181,144,1,0.179245283,0.2644014152,0.7355985848,1,0.1798561151,0.2449173066,0.2378544464,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"I'm getting this issue (Cuda 9.1.85, cuDNN 7.05)",Bug Reproduction,48,48,0.3333333333,0.1823899371,0.2837406291,0.7162593709,1,0.05755395683,0.2378544464,0.001119586478,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Tried with tensorflow 1.5, it broke.",Solution Discussion,36,36,0.6666666667,0.1855345912,0.2837406291,0.7162593709,0.75,0.04316546763,0.2378544464,0.001119586478,CONTRIBUTOR,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Uninstalled, installed 1.4 with CODE, still broke.",Solution Discussion,94,50,1,0.1886792453,0.2837406291,0.7162593709,0.875,0.05035971223,0.2378544464,0.001119586478,CONTRIBUTOR,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"@DylanDmitri  1.5 expects Cuda 9.0, not 9.1",Solution Discussion,43,43,0.5,0.1918238994,0.2838316592,0.7161683408,1,0.05755395683,0.001119586478,3.70E-05,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Have you tried with Cuda 9.0 drivers?,Solution Discussion,37,37,1,0.1949685535,0.2838316592,0.7161683408,0.875,0.05035971223,0.001119586478,3.70E-05,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@DylanDmitri @mkaze You need Cuda 9.0.,Solution Discussion,38,38,0.25,0.1981132075,0.2838346655,0.7161653345,0.2727272727,0.04316546763,3.70E-05,0.5779195954,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Also, for anyone having trouble installing requirements, I suggest double checking your cuDNN installation.",Solution Discussion,107,107,0.5,0.2012578616,0.2838346655,0.7161653345,0.6363636364,0.1007194245,3.70E-05,0.5779195954,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,The .deb file didn't work for me because it did not copy files to the right place.,Solution Discussion,82,82,0.75,0.2044025157,0.2838346655,0.7161653345,0.7727272727,0.1223021583,3.70E-05,0.5779195954,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I had to use the .tgz file and manually copy files according to nVidia's directions in order to get a working installation.,Solution Discussion,123,123,1,0.2075471698,0.2838346655,0.7161653345,1,0.1582733813,3.70E-05,0.5779195954,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Why not just install cuda-9-0?,Solution Discussion,30,30,0.25,0.2106918239,0.3308235311,0.6691764689,0.8571428571,0.04316546763,0.5779195954,0.02958178195,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,-         Go here: https://developer.nvidia.com/cuda-90-download-archive,Solution Discussion,72,72,0.5,0.213836478,0.3308235311,0.6691764689,0.5714285714,0.02877697842,0.5779195954,0.02958178195,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"-         Then, for me: Download deb (network)",Solution Discussion,46,46,0.75,0.2169811321,0.3308235311,0.6691764689,1,0.05035971223,0.5779195954,0.02958178195,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,225,4,1,0.2201257862,0.3308235311,0.6691764689,0.1428571429,0.007194244604,0.5779195954,0.02958178195,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@abrahamrhoffman That's easy for anyone who has sudo privileges but what about people on a shared system like a cluster environment with simple user privileges.,Solution Discussion,160,160,0.25,0.2232704403,0.3332287349,0.6667712651,1,0.1798561151,0.02958178195,0.02419682242,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,In those cases even if you ask from the sys admin to install any libraries most probably the answer is gonna be NO!,Solution Discussion,115,115,0.5,0.2264150943,0.3332287349,0.6667712651,0.96,0.1726618705,0.02958178195,0.02419682242,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Since they are afraid that might interfere with other users' settings and environments.,Solution Discussion,87,87,0.75,0.2295597484,0.3332287349,0.6667712651,0.52,0.09352517986,0.02958178195,0.02419682242,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@abrahamrhoffman Would you also mind providing a justification on the down vote?,Solution Discussion,80,80,1,0.2327044025,0.3332287349,0.6667712651,0.48,0.08633093525,0.02958178195,0.02419682242,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I installed cuda-9.0 and still it does not work.,Solution Discussion,48,48,0.5,0.2358490566,0.3351961041,0.6648038959,1,0.06474820144,0.02419682242,0.0004392565177,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,This is really irritating.,Social Conversation,26,26,1,0.2389937107,0.3351961041,0.6648038959,0.4444444444,0.02877697842,0.02419682242,0.0004392565177,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Please make sure to set your PATH variable appropriately, such as described here: https://stackoverflow.com/questions/39287744/ubuntu-16-04-nvidia-toolkit-8-0-rc-darknet-compilation-error-expected-a/41290056#41290056",Solution Discussion,216,216,0.5,0.2421383648,0.3352318187,0.6647681813,1,0.1007194245,0.0004392565177,0.03156952861,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,144,4,1,0.2452830189,0.3352318187,0.6647681813,0.07142857143,0.007194244604,0.0004392565177,0.03156952861,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,cuda 9.1 is the current version.,Solution Discussion,32,32,0.5,0.248427673,0.33779864,0.66220136,0.75,0.04316546763,0.03156952861,0.0002203677479,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I want TF to use it. How to?,Solution Discussion,28,28,1,0.251572327,0.33779864,0.66220136,1,0.05755395683,0.03156952861,0.0002203677479,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Even tf-nightly-gpu is not looking for cuda 9.1.,Solution Discussion,48,48,0.5,0.2547169811,0.3378165574,0.6621834426,1,0.07194244604,0.0002203677479,0.001120325967,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Meh,Social Conversation,3,3,1,0.2578616352,0.3378165574,0.6621834426,0.1,0.007194244604,0.0002203677479,0.001120325967,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I tried symbolic links from all the 9.0 filenames to all the 9.1 filenames and it didn't work.,Solution Discussion,94,94,0.3333333333,0.2610062893,0.3379076477,0.6620923523,0.75,0.1294964029,0.001120325967,0.0004436934522,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"In the end, TF knows the true version.",Solution Discussion,38,38,0.6666666667,0.2641509434,0.3379076477,0.6620923523,0.3333333333,0.05755395683,0.001120325967,0.0004436934522,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,The repo doesn't even have 9.0 anymore so I'm afraid I'll break my nvidia stuff if I remove 9.1 and then manually install 9.0.,Solution Discussion,126,126,1,0.2672955975,0.3379076477,0.6620923523,1,0.1726618705,0.001120325967,0.0004436934522,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I fix him for now by:,Workarounds,21,21,0.1666666667,0.2704402516,0.3379437231,0.6620562769,1,0.04316546763,0.0004436934522,0.05817708545,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Download deb (network) from:,Workarounds,28,28,0.3333333333,0.2735849057,0.3379437231,0.6620562769,0.6666666667,0.02877697842,0.0004436934522,0.05817708545,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=debnetwork,Workarounds,152,152,0.5,0.2767295597,0.3379437231,0.6620562769,0.1666666667,0.007194244604,0.0004436934522,0.05817708545,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Then: CODE,Workarounds,56,10,0.6666666667,0.2798742138,0.3379437231,0.6620562769,0.3333333333,0.01438848921,0.0004436934522,0.05817708545,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Then: aptitude update,Workarounds,21,21,0.8333333333,0.2830188679,0.3379437231,0.6620562769,0.5,0.02158273381,0.0004436934522,0.05817708545,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Then: aptitude install cuda-9-0,Workarounds,31,31,1,0.286163522,0.3379437231,0.6620562769,0.8333333333,0.03597122302,0.0004436934522,0.05817708545,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"First I've installed tensorflow 1.5, it broke, and I get the following error:CODE",Bug Reproduction,167,81,0.5,0.2893081761,0.342673923,0.657326077,0.652173913,0.1079136691,0.05817708545,0.00239742362,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"then I uninstalled,  installed 1.4 with pip install --upgrade tensorflow-gpu==1.4, it did't work,  and I get the following error:CODE",Solution Discussion,219,133,1,0.2924528302,0.342673923,0.657326077,1,0.1654676259,0.05817708545,0.00239742362,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@xiezhongzhao What version of Cuda are you using?,Solution Discussion,49,49,0.3333333333,0.2955974843,0.3428688502,0.6571311498,0.4210526316,0.05755395683,0.00239742362,0.0004045005306,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,For tensorflow 1.5 you must have installed the Cuda 9.0 and for tensorflow 1.4 you must use cuda 8.0.,Solution Discussion,101,101,0.6666666667,0.2987421384,0.3428688502,0.6571311498,1,0.1366906475,0.00239742362,0.0004045005306,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"If the the tensorflow version and cuda version are compatible, then check the environment variables i.e. CODEand CODE.",Solution Discussion,139,118,1,0.3018867925,0.3428688502,0.6571311498,0.9473684211,0.1294964029,0.00239742362,0.0004045005306,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@mkaze I used Cuda9.1,Solution Discussion,21,21,1,0.3050314465,0.3429017389,0.6570982611,1,0.02877697842,0.0004045005306,0.0006411370384,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@xiezhongzhao Install Cuda 9.0 and you should be fine.,Solution Discussion,54,54,0.5,0.3081761006,0.3429538677,0.6570461323,1,0.06474820144,0.0006411370384,0.03386342376,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Tensorflow 1.5 does not work with Cuda 9.1.,Solution Discussion,43,43,1,0.3113207547,0.3429538677,0.6570461323,0.8888888889,0.05755395683,0.0006411370384,0.03386342376,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@mkaze Thank you very much,Social Conversation,26,26,1,0.3144654088,0.3457071986,0.6542928014,1,0.03597122302,0.03386342376,0.1351135301,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I am also getting this issue and struggling to resolve it.,Bug Reproduction,58,58,0.09090909091,0.3176100629,0.3566928644,0.6433071356,0.5238095238,0.07913669065,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Bug Reproduction,924,4,0.1818181818,0.320754717,0.3566928644,0.6433071356,0.04761904762,0.007194244604,0.1351135301,0.002261357628,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,I installed following these instructionshttps://www.tensorflow.org/install/install_linux#nvidia_requirements_to_run_tensorflow_with_gpu_support,Bug Reproduction,143,143,0.2727272727,0.3238993711,0.3566928644,0.6433071356,0.2380952381,0.03597122302,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I believe I installed the right versions from nvidia.,Bug Reproduction,53,53,0.3636363636,0.3270440252,0.3566928644,0.6433071356,0.4285714286,0.06474820144,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,filenames wereCODEand CODE (version 7.0.5),Bug Reproduction,104,42,0.4545454545,0.3301886792,0.3566928644,0.6433071356,0.2380952381,0.03597122302,0.1351135301,0.002261357628,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,I set the path as per those instructions on the tensorflow docs and also tried the instructions that CODE gave above.,Solution Discussion,130,117,0.5454545455,0.3333333333,0.3566928644,0.6433071356,1,0.1510791367,0.1351135301,0.002261357628,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"When I run ldconfig -v I get some 9.0 libs, but do not see libcublas.so.9.0CODE",Solution Discussion,1622,79,0.6363636364,0.3364779874,0.3566928644,0.6433071356,0.7142857143,0.1079136691,0.1351135301,0.002261357628,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"I did not install 9.1, at least not intentionally.",Bug Reproduction,50,50,0.7272727273,0.3396226415,0.3566928644,0.6433071356,0.4285714286,0.06474820144,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,This is on a amazon ec2 instance with stock ubuntu 16.04.,Bug Reproduction,57,57,0.8181818182,0.3427672956,0.3566928644,0.6433071356,0.5238095238,0.07913669065,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"nvidia-smi also returns a gpu, this is a g3.4xlarge instance",Bug Reproduction,60,60,0.9090909091,0.3459119497,0.3566928644,0.6433071356,0.5238095238,0.07913669065,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,any guidance is greatly appreciated.,Social Conversation,36,36,1,0.3490566038,0.3566928644,0.6433071356,0.2380952381,0.03597122302,0.1351135301,0.002261357628,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Per the CUDNN guide at: http://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html You need to copy the unpacked files (from the directory you ran CODE or similar) into CODE subdirectories: CODECODECODECODE,Solution Discussion,438,212,1,0.3522012579,0.3568767284,0.6431232716,1,0.1798561151,0.002261357628,0.02559963321,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Thank you for the reply @entropy43.,Social Conversation,35,35,0.1666666667,0.3553459119,0.3589581559,0.6410418441,0.3157894737,0.04316546763,0.02559963321,0.2554187912,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I should have been more specific.,Social Conversation,33,33,0.3333333333,0.358490566,0.3589581559,0.6410418441,0.3157894737,0.04316546763,0.02559963321,0.2554187912,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I did those two CODE and the CODE commands after CODE.,Solution Discussion,58,54,0.5,0.3616352201,0.3589581559,0.6410418441,0.5789473684,0.07913669065,0.02559963321,0.2554187912,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,When I look in the folder cuda folder for where I ran the tar command like CODE I seeCODE,Solution Discussion,166,89,0.6666666667,0.3647798742,0.3589581559,0.6410418441,1,0.1366906475,0.02559963321,0.2554187912,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,I tried this section as well from the nvidia [doc] URL CODE and the tests pass here in CODE,Solution Discussion,198,91,0.8333333333,0.3679245283,0.3589581559,0.6410418441,1,0.1366906475,0.02559963321,0.2554187912,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Any advice to get that lib is appreciated,Social Conversation,41,41,1,0.3710691824,0.3589581559,0.6410418441,0.4210526316,0.05755395683,0.02559963321,0.2554187912,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Could someone please summarize where this currently stands?,Task Progress,59,59,0.5,0.3742138365,0.3797254726,0.6202745274,1,0.05755395683,0.2554187912,0.006558528713,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Advice?,Social Conversation,7,7,1,0.3773584906,0.3797254726,0.6202745274,0.125,0.007194244604,0.2554187912,0.006558528713,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Similar to what yazabazra is asking above:,Social Conversation,42,42,0.09090909091,0.3805031447,0.3802587264,0.6197412736,0.1891891892,0.05035971223,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"TF1.6 Ubuntu 16.04nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2017 NVIDIA CorporationBuilt on Fri_Nov__3_21:07:56_CDT_2017Cuda compilation tools, release 9.1, V9.1.85Which requited a Nvidia display driver 390+",Bug Reproduction,228,228,0.1818181818,0.3836477987,0.3802587264,0.6197412736,0.7297297297,0.1942446043,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Critical to see: https://devtalk.nvidia.com/default/topic/1000340/cuda-setup-and-installation/-quot-nvidia-smi-has-failed-because-it-couldn-t-communicate-with-the-nvidia-driver-quot-ubuntu-16-04/post/5243047/#5243047,Motivation,216,216,0.2727272727,0.3867924528,0.3802587264,0.6197412736,0.1081081081,0.02877697842,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"whelp to add to it all,, After a major amount of hassle I got the Nvidia updated to the newest release see above, as the TF doc indicated that there were bugs in an earlier release..",Bug Reproduction,182,182,0.3636363636,0.3899371069,0.3802587264,0.6197412736,1,0.2661870504,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Now I'm getting the :,Bug Reproduction,21,21,0.4545454545,0.393081761,0.3802587264,0.6197412736,0.1081081081,0.02877697842,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory,Bug Reproduction,88,88,0.5454545455,0.3962264151,0.3802587264,0.6197412736,0.3513513514,0.09352517986,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Failed to load the native TensorFlow runtime.,Bug Reproduction,45,45,0.6363636364,0.3993710692,0.3802587264,0.6197412736,0.1891891892,0.05035971223,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Which appears to be a mismatch between 9.0 (TF wants) vs 9.1 Which is most current Nvidia.,Investigation and Exploration,90,90,0.7272727273,0.4025157233,0.3802587264,0.6197412736,0.4594594595,0.1223021583,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,It would seem better to run with 9.1 but I'd rather avoid building TF from source and it seems that may not fix it anyhow..,Solution Discussion,123,123,0.8181818182,0.4056603774,0.3802587264,0.6197412736,0.7297297297,0.1942446043,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Can this combo be made to work with a binary package?,Solution Discussion,53,53,0.9090909091,0.4088050314,0.3802587264,0.6197412736,0.2972972973,0.07913669065,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,TF 1.6 Cuda 9.1 ??,Solution Discussion,18,18,1,0.4119496855,0.3802587264,0.6197412736,0.1081081081,0.02877697842,0.006558528713,0.00183836987,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Further note and caution to those looking here..,Social Conversation,48,48,0.1428571429,0.4150943396,0.3804081986,0.6195918014,0.2571428571,0.06474820144,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,after upgrading my Nvidia stuff my older versions of TF in separate conda env's no longer work as the older TF wants : ImportError: libcublas.so.8.0: cannot open shared object file: No such file or directory,Bug Reproduction,207,207,0.2857142857,0.4182389937,0.3804081986,0.6195918014,1,0.2517985612,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,so 9.1 won't cut it..,Investigation and Exploration,21,21,0.4285714286,0.4213836478,0.3804081986,0.6195918014,0.1714285714,0.04316546763,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,how about specifying greater than??,Solution Discussion,35,35,0.5714285714,0.4245283019,0.3804081986,0.6195918014,0.1428571429,0.03597122302,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,vs specific versions?,Solution Discussion,21,21,0.7142857143,0.427672956,0.3804081986,0.6195918014,0.08571428571,0.02158273381,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,just a suggestion..,Social Conversation,19,19,0.8571428571,0.4308176101,0.3804081986,0.6195918014,0.1142857143,0.02877697842,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,In the meantime I'm dead in the water..,Social Conversation,39,39,1,0.4339622642,0.3804081986,0.6195918014,0.2571428571,0.06474820144,0.00183836987,0.0006322631694,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,And this is why availability of a binary that supports 9.1 would be nice: (from the TF1.6 release notes),Motivation,104,104,0.1111111111,0.4371069182,0.380459606,0.619540394,0.4418604651,0.1366906475,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Using XLA:GPU with CUDA 9 and CUDA 9.1 results in garbage results and/orCUDA_ILLEGAL_ADDRESS failures.,Motivation,102,102,0.2222222222,0.4402515723,0.380459606,0.619540394,0.3720930233,0.1151079137,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Google discovered in mid-December 2017 that the PTX-to-SASS compiler in CUDA 9and CUDA 9.1 sometimes does not properly compute the carry bit whendecomposing 64-bit address calculations with large offsets (e.g. load [x + large_constant]) into 32-bit arithmetic in SASS.,Motivation,268,268,0.3333333333,0.4433962264,0.380459606,0.619540394,1,0.309352518,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"As a result, these versions of ptxas miscompile most XLA programs which usemore than 4GB of temp memory.",Motivation,104,104,0.4444444444,0.4465408805,0.380459606,0.619540394,0.4418604651,0.1366906475,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,This results in garbage results and/orCUDA_ERROR_ILLEGAL_ADDRESS failures.,Motivation,74,74,0.5555555556,0.4496855346,0.380459606,0.619540394,0.1860465116,0.05755395683,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,A fix in CUDA 9.1.121 is expected in late February 2018.,Motivation,56,56,0.6666666667,0.4528301887,0.380459606,0.619540394,0.2558139535,0.07913669065,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,We do not expect afix for CUDA 9.0.x.,Motivation,37,37,0.7777777778,0.4559748428,0.380459606,0.619540394,0.1860465116,0.05755395683,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Until the fix is available, the only workaround is todowngrade to CUDA 8.0.xor disable XLA:GPU.",Motivation,95,95,0.8888888889,0.4591194969,0.380459606,0.619540394,0.3720930233,0.1151079137,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Maybe one of the nightlies does it?,Solution Discussion,35,35,1,0.4622641509,0.380459606,0.619540394,0.1627906977,0.05035971223,0.0006322631694,0.001605430808,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Another solution?,Solution Discussion,17,17,0.25,0.465408805,0.3805901386,0.6194098614,0.06896551724,0.01438848921,0.001605430808,0.001735580887,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,can one install multiple revisions of Cuda since  TF seems to search for specific Rev's?,Solution Discussion,88,88,0.5,0.4685534591,0.3805901386,0.6194098614,0.5517241379,0.1151079137,0.001605430808,0.001735580887,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"If so, any advice as to how to?",Solution Discussion,31,31,0.75,0.4716981132,0.3805901386,0.6194098614,0.275862069,0.05755395683,0.001605430808,0.001735580887,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,So Ideally I'd be able to to run TF 1.4(which currently requires Cuda 8.0) in one conda environment and TF 1.6 (which currently requires Cuda 9.0) in another?,Solution Discussion,158,158,1,0.4748427673,0.3805901386,0.6194098614,1,0.2086330935,0.001605430808,0.001735580887,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,So I  just added sudo apt-get -y install cuda-toolkit-9.0 and I'm up and running with TF1.6,Solution Discussion,91,91,1,0.4779874214,0.3807312534,0.6192687466,1,0.1366906475,0.001735580887,0.09812724389,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@dartdog after installing cuda-toolkit-9.0, did you face the issue CODE ?",Solution Discussion,156,73,1,0.4811320755,0.3887096779,0.6112903221,1,0.07913669065,0.09812724389,0.08170171229,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@dartdogCODE,Solution Discussion,332,12,1,0.4842767296,0.395352593,0.604647407,1,0.007194244604,0.08170171229,0.1167490581,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"This is definitely supposed to be included in the tensorflow documentation, as said by @bwesen.",Solution Discussion,95,95,0.3333333333,0.4874213836,0.4048451,0.5951549,1,0.1079136691,0.1167490581,0.001195753854,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,It should also be included in the errors list.,Solution Discussion,46,46,0.6666666667,0.4905660377,0.4048451,0.5951549,0.6,0.06474820144,0.1167490581,0.001195753854,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Is it possible for us do this in anyway?,Contribution and Commitment,40,40,1,0.4937106918,0.4048451,0.5951549,0.6,0.06474820144,0.1167490581,0.001195753854,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Ok, guys.",Social Conversation,9,9,0.5,0.4968553459,0.404942323,0.595057677,0.2222222222,0.01438848921,0.001195753854,0.01097919447,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I have now opened a new issue at https://github.com/tensorflow/tensorflow/issues/17629.,Potential New Issues and Requests,87,87,1,0.5,0.404942323,0.595057677,1,0.06474820144,0.001195753854,0.01097919447,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I was handling with this issue as well.,Bug Reproduction,39,39,0.1666666667,0.5031446541,0.4058350076,0.5941649924,0.347826087,0.05755395683,0.01097919447,0.0003105854165,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,What worked for me with tensorflow-gpu 1.6:,Solution Discussion,43,43,0.3333333333,0.5062893082,0.4058350076,0.5941649924,0.347826087,0.05755395683,0.01097919447,0.0003105854165,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,-         I downloaded the toolkit from the [archive] URL  as 9.0 but it got installed as 9.1 (I do not know why...),Solution Discussion,162,116,0.5,0.5094339623,0.4058350076,0.5941649924,1,0.1654676259,0.01097919447,0.0003105854165,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,-         Still not found libcublas.so.9.0,Solution Discussion,42,42,0.6666666667,0.5125786164,0.4058350076,0.5941649924,0.2173913043,0.03597122302,0.01097919447,0.0003105854165,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,-         Run: CODE as suggested at the end of the installation instructions.,Solution Discussion,114,77,0.8333333333,0.5157232704,0.4058350076,0.5941649924,0.5217391304,0.08633093525,0.01097919447,0.0003105854165,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,-         The issue seems to have been solved.,Solution Discussion,46,46,1,0.5188679245,0.4058350076,0.5941649924,0.347826087,0.05755395683,0.01097919447,0.0003105854165,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"If you want to have tensorflow work with your CUDA version, you need to first uninstall it then compile it from source and specify the CUDA version while running ./configure",Solution Discussion,173,173,0.5,0.5220125786,0.4058602603,0.5941397397,1,0.2158273381,0.0003105854165,0.001371752256,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Detailed information can be found here:  URL,Solution Discussion,97,45,1,0.5251572327,0.4058602603,0.5941397397,0.2666666667,0.05755395683,0.0003105854165,0.001371752256,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I am trying this (which builds tensorflow manually)[link] URL,Solution Discussion,109,62,0.5,0.5283018868,0.4059717933,0.5940282067,0.6428571429,0.06474820144,0.001371752256,0.0230868493,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Might take a while longer but you can define the minor versions this way.,Solution Discussion,73,73,1,0.5314465409,0.4059717933,0.5940282067,1,0.1007194245,0.001371752256,0.0230868493,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@mldm4 actually, the command CODE probably installed 9.1 for you because you also had that in your system.",Solution Discussion,129,106,0.3333333333,0.534591195,0.407848914,0.592151086,0.8571428571,0.1294964029,0.0230868493,0.04783163312,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"I had the same problem, and I did CODE to install a specific version (I had also downloaded from the archive).",Solution Discussion,137,110,0.6666666667,0.5377358491,0.407848914,0.592151086,1,0.1510791367,0.0230868493,0.04783163312,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,I think the commad you did (CODE) also downloads cuda 9.0.,Solution Discussion,95,58,1,0.5408805031,0.407848914,0.592151086,0.5238095238,0.07913669065,0.0230868493,0.04783163312,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,so no solution yet?,Task Progress,19,19,1,0.5440251572,0.4117379571,0.5882620429,1,0.02877697842,0.04783163312,0.002720580351,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@thread :,Social Conversation,9,9,0.3333333333,0.5471698113,0.4119591591,0.5880408409,0.05555555556,0.007194244604,0.002720580351,0.001728185996,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,****Please read through the posts carefully! The answer is posted.****,Social Conversation,70,70,0.6666666667,0.5503144654,0.4119591591,0.5880408409,0.5555555556,0.07194244604,0.002720580351,0.001728185996,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"It is your job to read the thread, and discover the solution; not simply scroll to the end.",Social Conversation,91,91,1,0.5534591195,0.4119591591,0.5880408409,1,0.1294964029,0.002720580351,0.001728185996,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@abrahamrhoffman that's rude.,Social Conversation,29,29,0.3333333333,0.5566037736,0.4120996726,0.5879003274,0.3,0.02158273381,0.001728185996,0.2379527984,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I just changed my batchrc from cuda-9.1 to just cuda.,Solution Discussion,53,53,0.6666666667,0.5597484277,0.4120996726,0.5879003274,1,0.07194244604,0.001728185996,0.2379527984,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Then my tensorflow is able of finding the libcublas.so.9.0,Solution Discussion,58,58,1,0.5628930818,0.4120996726,0.5879003274,0.9,0.06474820144,0.001728185996,0.2379527984,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,just fyi: nvidia website for downloading cuda-9.0 is actually downloading cuda-9.1.,Solution Discussion,83,83,0.5,0.5660377358,0.4314468831,0.5685531169,1,0.07913669065,0.2379527984,0.0008762945681,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=deblocal,Solution Discussion,150,150,1,0.5691823899,0.4314468831,0.5685531169,0.09090909091,0.007194244604,0.2379527984,0.0008762945681,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@DanlanChen That is probably because you also have 9.1 installed.,Solution Discussion,65,65,0.5,0.572327044,0.4315181319,0.5684818681,0.7692307692,0.07194244604,0.0008762945681,0.0002514262896,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"To install 9.0, in the steps to download, do CODE instead of CODE.",Solution Discussion,116,66,1,0.5754716981,0.4315181319,0.5684818681,1,0.09352517986,0.0008762945681,0.0002514262896,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"@DanlanChen but then, I guess it is preffered to use the latest version.",Social Conversation,72,72,0.3333333333,0.5786163522,0.4315385746,0.5684614254,1,0.09352517986,0.0002514262896,0.2835245529,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"So, if you ever want to upgrade, you now know what to do!",Social Conversation,57,57,0.6666666667,0.5817610063,0.4315385746,0.5684614254,1,0.09352517986,0.0002514262896,0.2835245529,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,:smile:,Social Conversation,7,7,1,0.5849056604,0.4315385746,0.5684614254,0.07692307692,0.007194244604,0.0002514262896,0.2835245529,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Im facing the same issue, but I am trying to run tensorflow using nvidia-docker.",Bug Reproduction,80,80,0.5,0.5880503145,0.4545910844,0.5454089156,0.8,0.1151079137,0.2835245529,0.04654492211,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I have cuda-9-0 installed on the host, but when I try to run my docker container I get CODE",Bug Reproduction,173,91,1,0.5911949686,0.4545910844,0.5454089156,1,0.1438848921,0.2835245529,0.04654492211,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@magick93 and all that turn up here!,Social Conversation,36,36,0.1666666667,0.5943396226,0.4583755089,0.5416244911,0.2592592593,0.05035971223,0.04654492211,0.08662966756,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,LISTEN!,Social Conversation,7,7,0.3333333333,0.5974842767,0.4583755089,0.5416244911,0.03703703704,0.007194244604,0.04654492211,0.08662966756,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Anything you need is downgrade your cuda 9.1 -> cuda 9.0.,Solution Discussion,57,57,0.5,0.6006289308,0.4583755089,0.5416244911,0.3703703704,0.07194244604,0.04654492211,0.08662966756,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,That's it!,Social Conversation,10,10,0.6666666667,0.6037735849,0.4583755089,0.5416244911,0.07407407407,0.01438848921,0.04654492211,0.08662966756,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Just do it (if you downloaded cuda 9.1 before that you can execute following command in your terminal): CODE and remove cuda 9.1 by rm -rf.,Solution Discussion,166,139,0.8333333333,0.606918239,0.4583755089,0.5416244911,1,0.1942446043,0.04654492211,0.08662966756,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"Btw, don't forget to change $PATH in your CODE (9.1 -> 9.0).",Solution Discussion,67,60,1,0.6100628931,0.4583755089,0.5416244911,0.4074074074,0.07913669065,0.04654492211,0.08662966756,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@Oktai15 doesn't CODE delete your system?,Solution Discussion,45,41,0.5,0.6132075472,0.4654191009,0.5345808991,0.2608695652,0.04316546763,0.08662966756,5.40E-05,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"Please be more clear here, because people might try it without going into the required directory, and end up emptying their home folder.",Solution Discussion,136,136,1,0.6163522013,0.4654191009,0.5345808991,1,0.1654676259,0.08662966756,5.40E-05,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@magick93 your issue seems to be something else, not the CUDA version.",Potential New Issues and Requests,70,70,1,0.6194968553,0.46542349,0.53457651,1,0.08633093525,5.40E-05,0.02832686897,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,If you install new cuda while you still have previous version please make sure to specify the path  like this CODE,Solution Discussion,255,114,1,0.6226415094,0.4677266607,0.5322733393,1,0.1582733813,0.02832686897,0.06170592737,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@Abduoit your Ubuntu version doesn't really matter.,Solution Discussion,51,51,0.5,0.6257861635,0.4727437799,0.5272562201,0.3181818182,0.05035971223,0.06170592737,0.4007313547,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"The thing is, TensorFlow 1.6 expects CUDA to be version 9.0, and cuDNN to be version 7.0.4 (yes, the 0.4 _does_ matter)",Solution Discussion,119,119,1,0.6289308176,0.4727437799,0.5272562201,1,0.1582733813,0.06170592737,0.4007313547,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Traceback (most recent call last):File ""utils.py"", line 15, in <module>import tensorflow as tfFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/__init__.py"", line 24, in <module>from tensorflow.python import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/__init__.py"", line 49, in <module>from tensorflow.python import pywrap_tensorflowFile ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 74, in <module>raise ImportError(msg)ImportError: Traceback (most recent call last):File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow.py"", line 58, in <module>from tensorflow.python.pywrap_tensorflow_internal import *File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 28, in <module>_pywrap_tensorflow_internal = swig_import_helper()File ""/home/sagar/miniconda2/lib/python2.7/site-packages/tensorflow/python/pywrap_tensorflow_internal.py"", line 24, in swig_import_helper_mod = imp.load_module('_pywrap_tensorflow_internal', fp, pathname, description)ImportError: libcublas.so.9.0: cannot open shared object file: No such file or directory  Failed to load the native TensorFlow runtime.",Bug Reproduction,1275,1275,0.3333333333,0.6320754717,0.5053260144,0.4946739856,1,1,0.4007313547,0.01499535971,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,See https://www.tensorflow.org/install/install_sources#common_installation_problemssudo apt-get install cuda-7-0vim ~/.bashrcexport PATH=/usr/local/cuda-7.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda7.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}export PATH=/usr/local/cuda-9.0/bin${PATH:+:${PATH}}export LD_LIBRARY_PATH=/usr/local/cuda9.0/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PAfor some common reasons and solutions.,Bug Reproduction,435,435,0.6666666667,0.6352201258,0.5053260144,0.4946739856,0.2086330935,0.2086330935,0.4007313547,0.01499535971,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Include the entire stack traceabove this error message when asking for help.,Solution Discussion,76,76,1,0.6383647799,0.5053260144,0.4946739856,0.08633093525,0.08633093525,0.4007313547,0.01499535971,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"As @pascalwhoop mentioned, I followed the instructions in here  URL  to build Tensorflow from source.",Solution Discussion,200,101,0.3333333333,0.641509434,0.506545241,0.493454759,1,0.1223021583,0.01499535971,0.001849462207,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Whenever it said cuda 9.0 I changed to 9.1, and cudnn 7.0 I put 7.1.2.",Solution Discussion,70,70,0.6666666667,0.6446540881,0.506545241,0.493454759,0.8823529412,0.1079136691,0.01499535971,0.001849462207,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Worked fine, so far!",Social Conversation,20,20,1,0.6477987421,0.506545241,0.493454759,0.2352941176,0.02877697842,0.01499535971,0.001849462207,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@SAGGSOC why are you installing cuda 7.0?,Solution Discussion,41,41,0.5,0.6509433962,0.5066956151,0.4933043849,1,0.05035971223,0.001849462207,0.01267336397,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,You need CUDA 9.0 and CuDNN 7.0.4,Solution Discussion,33,33,1,0.6540880503,0.5066956151,0.4933043849,1,0.05035971223,0.001849462207,0.01267336397,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Rather do a 6gb image pull once that works than DLing 5 versions of CuDNN before stuff works..,Solution Discussion,94,94,0.2,0.6572327044,0.5077260474,0.4922739526,1,0.1438848921,0.01267336397,0.02165076149,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,https://github.com/pascalwhoop/tf_openailab_gpu_docker,Solution Discussion,54,54,0.4,0.6603773585,0.5077260474,0.4922739526,0.05,0.007194244604,0.01267336397,0.02165076149,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I started a while back but stopped because of shifting project focuses.,Social Conversation,71,71,0.6,0.6635220126,0.5077260474,0.4922739526,0.6,0.08633093525,0.01267336397,0.02165076149,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,But I think it's worth pursuing.,Social Conversation,32,32,0.8,0.6666666667,0.5077260474,0.4922739526,0.3,0.04316546763,0.01267336397,0.02165076149,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Keeps the whole trouble of finding a the right combination of 17 moving parts away from most ppl.,Solution Discussion,97,97,1,0.6698113208,0.5077260474,0.4922739526,0.9,0.1294964029,0.01267336397,0.02165076149,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Just to clarify a few things for anyone who might stumble on this post.,Social Conversation,71,71,0.1,0.6729559748,0.5094864043,0.4905135957,0.3783783784,0.1007194245,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I have in my system installed cuda-8.0, cuda-9.0, cuda-9.1.",Bug Reproduction,59,59,0.2,0.6761006289,0.5094864043,0.4905135957,0.2432432432,0.06474820144,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,You don't have to remove anything to make it work with tensorflow.,Solution Discussion,66,66,0.3,0.679245283,0.5094864043,0.4905135957,0.3243243243,0.08633093525,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Instead if you are missing cuda-9.0 from your system, as other have already pointed then you'll need to install it that is a prerequisite for tensorflow to work properly.",Solution Discussion,170,170,0.4,0.6823899371,0.5094864043,0.4905135957,0.7837837838,0.2086330935,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,If you have cuda-9.0 installed on you system and tensorflow is complaining about CODE again as others have said expose that during runtime through your  CODE environment variable in your CODE make it point to CODE.,Solution Discussion,269,214,0.5,0.6855345912,0.5094864043,0.4905135957,1,0.2661870504,0.02165076149,0.03664686068,NONE,TRUE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,This should be working even for tensorflow 1.7.,Solution Discussion,47,47,0.6,0.6886792453,0.5094864043,0.4905135957,0.2162162162,0.05755395683,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,What I have tried and failed to accomplish is build from source.,Solution Discussion,64,64,0.7,0.6918238994,0.5094864043,0.4905135957,0.3243243243,0.08633093525,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,For some reason bazel always exits with an error. If you try to build with cuda-9.0/cuda-9.1 and cudnn7 it complains about gcc7.,Solution Discussion,128,128,0.8,0.6949685535,0.5094864043,0.4905135957,0.6216216216,0.1654676259,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Using gcc5 compilation seems to be working fine but then at the end I always get an error and the build is unsuccessful.,Solution Discussion,120,120,0.9,0.6981132075,0.5094864043,0.4905135957,0.6216216216,0.1654676259,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,My question is if anyone has managed to compile from source with cuda-9.1/cuda-9.0 without problems?,Solution Discussion,100,100,1,0.7012578616,0.5094864043,0.4905135957,0.4324324324,0.1151079137,0.02165076149,0.03664686068,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,This worked for me: Download CUDA Toolkit 9.0 from NVidia previous releases section.,Solution Discussion,84,84,0.2,0.7044025157,0.5124660478,0.4875339522,1,0.09352517986,0.03664686068,0.234967481,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Then: CODE,Solution Discussion,178,10,0.4,0.7075471698,0.5124660478,0.4875339522,0.1538461538,0.01438848921,0.03664686068,0.234967481,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Notice 9.0 at the last line above.,Solution Discussion,34,34,0.6,0.7106918239,0.5124660478,0.4875339522,0.5384615385,0.05035971223,0.03664686068,0.234967481,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,50,4,0.8,0.713836478,0.5124660478,0.4875339522,0.07692307692,0.007194244604,0.03664686068,0.234967481,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,My setupTensorflow 1.7cuDNN 7.1.2Ubuntu 16.04,Bug Reproduction,45,45,1,0.7169811321,0.5124660478,0.4875339522,0.3846153846,0.03597122302,0.03664686068,0.234967481,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Thank you for your post :),Social Conversation,26,26,1,0.7201257862,0.5315705314,0.4684294686,1,0.04316546763,0.234967481,0.1028511002,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I had teh same situation.,Bug Reproduction,25,25,0.25,0.7232704403,0.5399330381,0.4600669619,0.3571428571,0.03597122302,0.1028511002,0.2627005402,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I had cuda 9.1, and tensorflow would not find libraries for cuda 9.0.",Bug Reproduction,69,69,0.5,0.7264150943,0.5399330381,0.4600669619,0.9285714286,0.09352517986,0.1028511002,0.2627005402,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I have installed cuda 9.0 with command: sudo apt-get install cuda-libraries-9-0,Solution Discussion,79,79,0.75,0.7295597484,0.5399330381,0.4600669619,1,0.1007194245,0.1028511002,0.2627005402,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,That solved my problem.,Solution Discussion,23,23,1,0.7327044025,0.5399330381,0.4600669619,0.2857142857,0.02877697842,0.1028511002,0.2627005402,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"So, I setCODE in pycharm Environment variable field and it works.",Solution Discussion,104,65,1,0.7358490566,0.5612924115,0.4387075885,1,0.07913669065,0.2627005402,0.09867224734,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,the above worked for installing on Ubuntu Server 17.,Solution Discussion,52,52,0.3333333333,0.7389937107,0.5693151486,0.4306848514,0.36,0.06474820144,0.09867224734,0.1256221876,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"namely, -         installing cuda-9.0 (NOT 9.1)-         cuDNN v7.1.2 (Mar 21, 2018) for CUDA 9.0-         everything else according to the official tf installation instructions",Solution Discussion,177,177,0.6666666667,0.7421383648,0.5693151486,0.4306848514,1,0.1798561151,0.09867224734,0.1256221876,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,much easier than compiling.,Solution Discussion,27,27,1,0.7452830189,0.5693151486,0.4306848514,0.16,0.02877697842,0.09867224734,0.1256221876,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,be careful conda users.,Social Conversation,23,23,0.25,0.748427673,0.5795291024,0.4204708976,0.1081081081,0.02877697842,0.1256221876,1,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"i hit the same problem and was scratching my head for two days, until finally i discovered that local copy of libcudnn.so was used by conda, under:/miniconda3/lib/libcudnn.so which pointed to libcudnn.so.7 which pointed to libcudnn.so.7.0.5",Investigation and Exploration,240,240,0.5,0.751572327,0.5795291024,0.4204708976,1,0.2661870504,0.1256221876,1,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,i don't remember who and how placed it there but pretty much it overloaded the system default libcudnn.so.7.1.2 !!!,Investigation and Exploration,115,115,0.75,0.7547169811,0.5795291024,0.4204708976,0.4864864865,0.1294964029,0.1256221876,1,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"once removed, everything works like a charm:tensorflow 1.7 or 1.8-nightly, cuda-9.1, cudnn-7.1.2 on ubuntu 16.04",Solution Discussion,112,112,1,0.7578616352,0.5795291024,0.4204708976,0.4594594595,0.1223021583,0.1256221876,1,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Somehow, I solved this by installing:cuda 9.1 (from package manager),cudnn 7.1 for 9.1and from anaconda:by using this default command 'conda install -c anaconda tensorflow-gpu'cudatoolkit 9.0,tensorflow 1.7,tensorflow-gpu 1.7",Solution Discussion,225,225,0.25,0.7610062893,0.6608360282,0.3391639718,1,0.2230215827,1,0.07077280307,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I used Antergos linux, GTX 1060 in my PC.",Solution Discussion,41,41,0.5,0.7641509434,0.6608360282,0.3391639718,0.2903225806,0.06474820144,1,0.07077280307,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"It worked as well in my notebook (Xubuntu 18.04, GT 840m).",Solution Discussion,58,58,0.75,0.7672955975,0.6608360282,0.3391639718,0.3870967742,0.08633093525,1,0.07077280307,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"In my notebook i used :cuda 9.1 (from nvidia ppa), cudnn 7.1 for 9.1 (from nvidia web), and the rest was the same",Solution Discussion,113,113,1,0.7704402516,0.6608360282,0.3391639718,0.7419354839,0.1654676259,1,0.07077280307,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Thanks @Suananda!,Social Conversation,17,17,0.5,0.7735849057,0.6665903473,0.3334096527,0.5,0.01438848921,0.07077280307,0.2453262441,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,It works like magic.,Solution Discussion,20,20,1,0.7767295597,0.6665903473,0.3334096527,1,0.02877697842,0.07077280307,0.2453262441,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"If you have old version of CUDA, the library link may point to the old library even you install the newer CUDA especially if you install it manually.",Investigation and Exploration,149,149,0.5,0.7798742138,0.68653707,0.31346293,1,0.2014388489,0.2453262441,0.1641710142,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Try delete your old installation, and then sudo ldconfig to update the dynamic links.",Solution Discussion,85,85,1,0.7830188679,0.68653707,0.31346293,0.5,0.1007194245,0.2453262441,0.1641710142,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,No solution yet!?,Task Progress,17,17,1,0.786163522,0.6998853104,0.3001146896,1,0.02158273381,0.1641710142,0.02172323142,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,For anyone that might stumble on this I have released a community wheel of latest tensorflow 1.8.0-rc1 built with cuda 9.1.,Solution Discussion,123,123,0.5,0.7893081761,0.7016515596,0.2983484404,1,0.1582733813,0.02172323142,0.4152157275,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,You can find it [here] URL !,Solution Discussion,92,28,1,0.7924528302,0.7016515596,0.2983484404,0.2727272727,0.04316546763,0.02172323142,0.4152157275,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I have find the reason is ldconf,  ldconfig is a dynamic link library management command whose purpose is to allow the dynamic link library to be usedby the system.",Investigation and Exploration,164,164,0.1111111111,0.7955974843,0.7354114739,0.2645885261,0.7894736842,0.2158273381,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"The default ldconf only search /lib and /usr/lib, as well as the library file under the directory listed in the configuration file /etc/ld. so. conf.",Investigation and Exploration,149,149,0.2222222222,0.7987421384,0.7354114739,0.2645885261,0.7105263158,0.1942446043,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,so all of this is caused by the  dynamic library of CUDA in the installed CUDA path such as : /path/cuda-9.0/lib64  or /path/cuda-9.0/lib. (for eample my CUDA is installed in /usr/local/cuda-9.0),Investigation and Exploration,195,195,0.3333333333,0.8018867925,0.7354114739,0.2645885261,1,0.273381295,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"1.         if you install the CUDA manual,  then after install, you should add the  path of cuda/lib64 to /etc/ld.so.conf fileCODEthenCODE",Solution Discussion,204,138,0.4444444444,0.8050314465,0.7354114739,0.2645885261,0.6578947368,0.1798561151,0.4152157275,0.1560011388,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"of course , you can add the path manual, like:CODEthen add the path  '/usr/local/cuda-9.0/lib64' at the end.",Solution Discussion,125,108,0.5555555556,0.8081761006,0.7354114739,0.2645885261,0.5526315789,0.1510791367,0.4152157275,0.1560011388,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"CODEafter the operation, reopen the ipython or pycharm ,import tensorflow as  tf",Solution Discussion,91,80,0.6666666667,0.8113207547,0.7354114739,0.2645885261,0.3421052632,0.09352517986,0.4152157275,0.1560011388,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"wow, you will enjoy it!",Social Conversation,23,23,0.7777777778,0.8144654088,0.7354114739,0.2645885261,0.1315789474,0.03597122302,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"2.         if you install the CUDA by command such as 'dpkg -i cuda-repo-ubuntu1604_9.0.176-1_amd64.deb' or others, it may add the cuda lib path to the /etc/ld.so.conf  automatically .",Solution Discussion,184,184,0.8888888889,0.8176100629,0.7354114739,0.2645885261,0.7631578947,0.2086330935,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"but to be on the safe side, check the /etc/ld.so.conf and see if the path add to it .",Solution Discussion,85,85,1,0.820754717,0.7354114739,0.2645885261,0.5,0.1366906475,0.4152157275,0.1560011388,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@NYcleanerOn Ubuntu, there is a CODE file containing :CODE",Solution Discussion,129,58,0.5,0.8238993711,0.748095447,0.251904553,0.6428571429,0.06474820144,0.1560011388,0.2854442666,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Is this enough or do I need to add the directory CODE to it ?,Solution Discussion,85,61,1,0.8270440252,0.748095447,0.251904553,1,0.1007194245,0.1560011388,0.2854442666,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,@sebmayou  should add  the CODE path  to itï¼ the ***.so files  are in the  lib64,Solution Discussion,105,81,1,0.8301886792,0.7713040428,0.2286959572,1,0.1438848921,0.2854442666,0.7490188829,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,90,4,0.5,0.8333333333,0.8322044655,0.1677955345,0.5,0.007194244604,0.7490188829,0.1779957627,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,from https://gist.github.com/zhanwenchen/e520767a409325d9961072f666815bb8,Solution Discussion,73,73,1,0.8364779874,0.8322044655,0.1677955345,1,0.01438848921,0.7490188829,0.1779957627,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@mashu Well the other option is that the community provides pre-built [wheels] URL .,Solution Discussion,138,84,0.5,0.8396226415,0.8466767537,0.1533232463,1,0.1007194245,0.1779957627,0.09933113212,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,If you read 2-3 threads above you'll also see that mentioned again.,Solution Discussion,67,67,1,0.8427672956,0.8466767537,0.1533232463,0.9285714286,0.09352517986,0.1779957627,0.09933113212,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"@Suananda  Thanks, it works for me in a tensorflow conda environment.",Solution Discussion,69,69,0.5,0.8459119497,0.8547530627,0.1452469373,0.4137931034,0.08633093525,0.09933113212,0.008876087511,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Suggest the official guys to modify the installation guide ""https://www.tensorflow.org/install/install_linux#InstallingAnaconda"", step 4 of Anaconda installing, from ""pip install --ignore-installed --upgrade tfBinaryURL"" to ""conda install -c anaconda tensorflow-gpu""",Solution Discussion,266,266,1,0.8490566038,0.8547530627,0.1452469373,1,0.2086330935,0.09933113212,0.008876087511,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Softlink seems not solve this issue: CODE,Solution Discussion,2497,41,0.5,0.8522012579,0.8554747501,0.1445252499,1,0.05035971223,0.008876087511,0.06974861068,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Still got: CODE,Solution Discussion,918,15,1,0.8553459119,0.8554747501,0.1445252499,0.4285714286,0.02158273381,0.008876087511,0.06974861068,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"when I run my code on the linux environment directly, everything is OK.",Bug Reproduction,71,71,0.5,0.858490566,0.8611457952,0.1388542048,0.7647058824,0.09352517986,0.06974861068,0.3262189553,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"But when I run on the local pycharm through the remote interpreter, I encounter the problem: CODE",Bug Reproduction,239,97,1,0.8616352201,0.8611457952,0.1388542048,1,0.1223021583,0.06974861068,0.3262189553,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,export PATH=${PATH}:/usr/local/cuda-9.0/binexport CUDA_HOME=${CUDA_HOME}:/usr/local/cuda:/usr/local/cuda-9.0export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda-9.0/lib64export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/extras/CUPTI/lib64,Solution Discussion,249,249,0.5,0.8647798742,0.8876696556,0.1123303444,1,0.1438848921,0.3262189553,0.2682755484,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,if use pycharm - add it to interpreter,Solution Discussion,38,38,1,0.8679245283,0.8876696556,0.1123303444,0.35,0.05035971223,0.3262189553,0.2682755484,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,what about f** I just only want to use tensorflow1.8 and cuda9.1?,Motivation,65,65,1,0.8710691824,0.9094823157,0.09051768429,1,0.08633093525,0.2682755484,0.05498545055,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@dongzhuoyao So what's the problem?,Solution Discussion,35,35,0.5,0.8742138365,0.9139530137,0.08604698634,0.3846153846,0.03597122302,0.05498545055,0.1457126271,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,look at my comment 6 threads above and you'll find your solution there!,Solution Discussion,71,71,1,0.8773584906,0.9139530137,0.08604698634,1,0.09352517986,0.05498545055,0.1457126271,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I guess the problem has cropped up again with CODE and CODE.,Bug Reproduction,82,60,0.1428571429,0.8805031447,0.9258004594,0.07419954058,0.5217391304,0.08633093525,0.1457126271,0.001998099513,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"In a virtualenv, I get:CODE",Bug Reproduction,144,27,0.2857142857,0.8836477987,0.9258004594,0.07419954058,0.2608695652,0.04316546763,0.1457126271,0.001998099513,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,My CODE folder has the following libcublas:CODE,Bug Reproduction,222,47,0.4285714286,0.8867924528,0.9258004594,0.07419954058,0.347826087,0.05755395683,0.1457126271,0.001998099513,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Versions:CODE,Bug Reproduction,66,13,0.5714285714,0.8899371069,0.9258004594,0.07419954058,0.08695652174,0.01438848921,0.1457126271,0.001998099513,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,We'll need an update to tensorflow-gpu to use cuda 9.2.,Solution Discussion,55,55,0.7142857143,0.893081761,0.9258004594,0.07419954058,0.4782608696,0.07913669065,0.1457126271,0.001998099513,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Also, if I were to downgrade to cuda 9.0, would I have to first remove cuda 9.2 or just install 9.0 straight away?",Solution Discussion,114,114,0.8571428571,0.8962264151,0.9258004594,0.07419954058,1,0.1654676259,0.1457126271,0.001998099513,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Would I have conflicting installations?,Solution Discussion,39,39,1,0.8993710692,0.9258004594,0.07419954058,0.2173913043,0.03597122302,0.1457126271,0.001998099513,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@mebble Here you go: [link] URL .,Solution Discussion,54,33,0.25,0.9025157233,0.9259629187,0.07403708125,0.5454545455,0.04316546763,0.001998099513,0.02806508983,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,That's tf 1.8 wheel for cuda 9.2.,Solution Discussion,33,33,0.5,0.9056603774,0.9259629187,0.07403708125,0.6363636364,0.05035971223,0.001998099513,0.02806508983,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Don't downgrade.,Solution Discussion,16,16,0.75,0.9088050314,0.9259629187,0.07403708125,0.1818181818,0.01438848921,0.001998099513,0.02806508983,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Install whatever other version you want they'll get installed at CODE,Solution Discussion,86,69,1,0.9119496855,0.9259629187,0.07403708125,1,0.07913669065,0.001998099513,0.02806508983,NONE,TRUE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,Thanks!,Social Conversation,7,7,0.25,0.9150943396,0.9282448049,0.07175519508,0.07692307692,0.007194244604,0.02806508983,0.00732168145,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,I forgot to mention that im using CODE and pip CODE.,Solution Discussion,66,52,0.5,0.9182389937,0.9282448049,0.07175519508,0.9230769231,0.08633093525,0.02806508983,0.00732168145,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,I think the wheel is for python 3.6 so the install doesn't work.,Solution Discussion,64,64,0.75,0.9213836478,0.9282448049,0.07175519508,1,0.09352517986,0.02806508983,0.00732168145,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Do you have one for 3.5 as well?,Solution Discussion,32,32,1,0.9245283019,0.9282448049,0.07175519508,0.6153846154,0.05755395683,0.02806508983,0.00732168145,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@kirk86 after installing the whl you gave it throws a similar error for libmpi.so.40,Solution Discussion,84,84,0.5,0.927672956,0.9288401083,0.07115989167,1,0.1007194245,0.00732168145,0.001770336874,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I'm on CentOS and K80 GPU, cuda 9.2 and cudnn v7.1",Solution Discussion,50,50,1,0.9308176101,0.9288401083,0.07115989167,0.7857142857,0.07913669065,0.00732168145,0.001770336874,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,### Suggestion,Solution Discussion,14,14,0.1666666667,0.9339622642,0.928984049,0.07101595102,0.03333333333,0.007194244604,0.001770336874,0.003939258366,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"As far as I know you can have sub-packages xxx,yyy,zzz etc.. and install them as followCODE",Solution Discussion,121,91,0.3333333333,0.9371069182,0.928984049,0.07101595102,0.6666666667,0.1438848921,0.001770336874,0.003939258366,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,This way different co-existing back-ends can be provided.,Solution Discussion,57,57,0.5,0.9402515723,0.928984049,0.07101595102,0.3333333333,0.07194244604,0.001770336874,0.003939258366,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"Tensorflow can be build with different options, so at least a couple of cuda-toolkit builds could be provided this way.",Solution Discussion,119,119,0.6666666667,0.9433962264,0.928984049,0.07101595102,0.7,0.1510791367,0.001770336874,0.003939258366,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"The whole point of package is to save time of building, but package build for very specific set of libraries that installs fine, but does not work is counter-productive.",Solution Discussion,169,169,0.8333333333,0.9465408805,0.928984049,0.07101595102,1,0.2158273381,0.001770336874,0.003939258366,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,It would be better off not to have such package in the first place.,Solution Discussion,67,67,1,0.9496855346,0.928984049,0.07101595102,0.4666666667,0.1007194245,0.001770336874,0.003939258366,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@mebble just make a conda virtual environment for python 3.6.,Solution Discussion,61,61,0.5,0.9528301887,0.929304338,0.07069566203,0.9090909091,0.07194244604,0.003939258366,8.36E-05,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Make sure that you also have installed on your system openmpi.,Solution Discussion,62,62,1,0.9559748428,0.929304338,0.07069566203,1,0.07913669065,0.003939258366,8.36E-05,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,@pavan-08 Install openmpi on your system also nccl 2.x whatever is the latest from nvidia.,Solution Discussion,90,90,0.3333333333,0.9591194969,0.9293111322,0.07068886784,0.75,0.1079136691,8.36E-05,0.5218093819,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,"I've compiled tf with most of the packages and libraries, so it can be used hdfs, kafta, aws, etc.",Solution Discussion,98,98,0.6666666667,0.9622641509,0.9293111322,0.07068886784,1,0.1438848921,8.36E-05,0.5218093819,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,That's why is asking libmpi.so because it's from openmpi library.,Solution Discussion,65,65,1,0.965408805,0.9293111322,0.07068886784,0.5,0.07194244604,8.36E-05,0.5218093819,NONE,TRUE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,With cuda 9.2 and tensorflow-gpu 1.8 I cannot build tensorflow,Solution Discussion,62,62,0.25,0.9685534591,0.9717378488,0.02826215116,0.9230769231,0.08633093525,0.5218093819,0.05092861342,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,declared output 'external/local_config_cuda/cuda/cuda/lib/libcudnn.so.7' is a dangling symbolic link,Solution Discussion,100,100,0.5,0.9716981132,0.9717378488,0.02826215116,1,0.09352517986,0.5218093819,0.05092861342,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,The symlink exists,Solution Discussion,18,18,0.75,0.9748427673,0.9717378488,0.02826215116,0.2307692308,0.02158273381,0.5218093819,0.05092861342,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Versions: Ubuntu 17.10cuda 9.2cudnn 7.1.4tensorflow-gpu 1.8.0,Solution Discussion,61,61,1,0.9779874214,0.9717378488,0.02826215116,0.5384615385,0.05035971223,0.5218093819,0.05092861342,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,Cuda is only compatible with Nvidia graphics card.,Solution Discussion,50,50,0.25,0.9811320755,0.9758786978,0.02412130216,0.4444444444,0.05755395683,0.05092861342,0.2966697109,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,If you still have the error after downgrading to tf-gpu 1.4; maybe you don't have a Nvidia !,Solution Discussion,92,92,0.5,0.9842767296,0.9758786978,0.02412130216,1,0.1294964029,0.05092861342,0.2966697109,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,You can check your graphic card with the command :,Solution Discussion,50,50,0.75,0.9874213836,0.9758786978,0.02412130216,0.5,0.06474820144,0.05092861342,0.2966697109,NONE,FALSE,FALSE,FALSE,FALSE
15 15604_tensorflow.doc,CODE,Solution Discussion,16,4,1,0.9905660377,0.9758786978,0.02412130216,0.05555555556,0.007194244604,0.05092861342,0.2966697109,NONE,FALSE,TRUE,FALSE,FALSE
15 15604_tensorflow.doc,"This works for me (tensorflow-gpu==1.8.0 and cuda version is 9.0, install in anaconda)",Solution Discussion,86,86,1,0.9937106918,1,0,14,0.1007194245,0.2966697109,0,NONE,FALSE,FALSE,FALSE,TRUE
15 15604_tensorflow.doc,CODE,Solution Discussion,71,4,2,0.9968553459,1,0,1,0.007194244604,0.2966697109,0,NONE,FALSE,TRUE,FALSE,TRUE
15 15604_tensorflow.doc,suggestion from: https://stackoverflow.com/questions/48428415/importerror-libcublas-so-9-0-cannot-open-shared-object-file,Solution Discussion,121,121,3,1,1,0,3,0.02158273381,0.2966697109,0,NONE,FALSE,FALSE,FALSE,TRUE